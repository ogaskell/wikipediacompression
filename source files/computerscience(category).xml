<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.36.0-wmf.36</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="446" case="first-letter">Education Program</namespace>
      <namespace key="447" case="first-letter">Education Program talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Category:Wikipedia books on computer science</title>
    <ns>14</ns>
    <id>27537394</id>
    <revision>
      <id>545925690</id>
      <parentid>503819094</parentid>
      <timestamp>2013-03-21T08:09:13Z</timestamp>
      <contributor>
        <username>Addbot</username>
        <id>6569922</id>
      </contributor>
      <minor/>
      <comment>[[User:Addbot|Bot:]] Migrating 1 interwiki links, now provided by [[Wikipedia:Wikidata|Wikidata]] on [[d:q7580294]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="222" xml:space="preserve">[[Category:Wikipedia books on applied sciences|Computer science]]
[[Category:Wikipedia books on formal sciences|Computer science]]
[[Category:Wikipedia books on computing|Computer science]]
[[Category:Computer science|β]]</text>
      <sha1>gh1ge33ev4zc69uhzlurt7eemjeetjb</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Philosophy of computer science</title>
    <ns>14</ns>
    <id>30759626</id>
    <revision>
      <id>717873027</id>
      <parentid>712607006</parentid>
      <timestamp>2016-04-30T06:52:59Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed parent categories of [[Category:Philosophy of technology]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="119" xml:space="preserve">{{catmain}}

[[Category:Philosophy of mathematics]]
[[Category:Philosophy of technology]]
[[Category:Computer science]]</text>
      <sha1>630qs35yc9romarohl875439modj76z</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer science organizations</title>
    <ns>14</ns>
    <id>2977994</id>
    <revision>
      <id>894915468</id>
      <parentid>833656945</parentid>
      <timestamp>2019-04-30T20:19:30Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Speedily moving category Science organizations by topic to [[:Category:Scientific organizations by topic]] per [[WP:CFDS|CFDS]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="192" xml:space="preserve">{{Commons category|Computer science organizations}}
[[Category:Scientific organizations by topic]]
[[Category:Information technology organizations]]
[[Category:Computer science|Organizations]]</text>
      <sha1>3cu4vfm7svsqndasgr23hela0ue1ub8</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer science literature</title>
    <ns>14</ns>
    <id>3179625</id>
    <revision>
      <id>849474142</id>
      <parentid>747435971</parentid>
      <timestamp>2018-07-09T08:16:15Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Moving category Scientific works to [[:Category:Academic works about science]] per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 May 7]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="170" xml:space="preserve">==See also==
* [[:Category:Computer science conferences|Computer science conferences]]

[[Category:Computer science|Literature]]
[[Category:Academic works about science]]</text>
      <sha1>d2l5bdd03rhwfg74nc27kxm5oc8kx2l</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer science awards</title>
    <ns>14</ns>
    <id>2379705</id>
    <revision>
      <id>936697598</id>
      <parentid>905604161</parentid>
      <timestamp>2020-01-20T12:58:23Z</timestamp>
      <contributor>
        <username>Aymatth2</username>
        <id>3311318</id>
      </contributor>
      <comment>main</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="178" xml:space="preserve">{{catmain|List of computer science awards}}

[[Category:Computer science|Awards]]
[[Category:Computer-related awards]]
[[Category:Science and technology awards|Computer science]]</text>
      <sha1>8jionfh4usu240pvguab7s66osjhk00</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer science conferences</title>
    <ns>14</ns>
    <id>2977953</id>
    <revision>
      <id>954169736</id>
      <parentid>954169669</parentid>
      <timestamp>2020-05-01T01:37:07Z</timestamp>
      <contributor>
        <ip>50.26.172.216</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="417" xml:space="preserve">{{Commons category|Computer science conferences}}
[[Academic conference]]s in the field of computer science.

==See also==
* [[:Category:Computer science journals]]
* [[:Category:Conference proceedings]]
[[Category:Academic conferences]]
[[Category:Computer conferences]]
[[Category:Science conferences]]
[[Category:Computer science|Conferences]]
[[Category:Computer science organizations|Conferences]]
{{CatAutoTOC}}</text>
      <sha1>sx6afm0kaumx0a667cvqcvj09cxtzap</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer science stubs</title>
    <ns>14</ns>
    <id>1859318</id>
    <revision>
      <id>943276684</id>
      <parentid>884325073</parentid>
      <timestamp>2020-02-29T23:04:56Z</timestamp>
      <contributor>
        <username>BrownHairedGirl</username>
        <id>754619</id>
      </contributor>
      <comment>[[Template:Stub category]] now includes {{[[Template:CatAutoTOC|CatAutoTOC]]}}, removed: {{Category TOC|numerals=no}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="257" xml:space="preserve">{{WPSS-cat}}
{{Stub Category|article=[[computer science]]|newstub=comp-sci-stub|category=Computer science}}

{{see also|Category:Computer science articles needing expert attention}}

[[Category:Computing stubs| Science]]
[[Category:Science stubs| Computer]]</text>
      <sha1>i1qw9woq07gb2xmqcfb8bgonpafucqx</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer science education</title>
    <ns>14</ns>
    <id>2275290</id>
    <revision>
      <id>833656897</id>
      <parentid>753567337</parentid>
      <timestamp>2018-04-01T20:21:50Z</timestamp>
      <contributor>
        <username>JarBot</username>
        <id>27077959</id>
      </contributor>
      <minor/>
      <comment>Bot:add Commons category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="223" xml:space="preserve">{{Commons category|Computer science education}}
{{Wikiversity}}

[[Category:Computer science|Education]]
[[Category:Computer science organizations|Education]]
[[Category:Education by subject]]
[[Category:Science education]]</text>
      <sha1>rso5ing7zmy6vrtim0e3fqitf9lxdz5</sha1>
    </revision>
  </page>
  <page>
    <title>Technology transfer in computer science</title>
    <ns>0</ns>
    <id>44409131</id>
    <revision>
      <id>786970592</id>
      <parentid>785715336</parentid>
      <timestamp>2017-06-22T17:27:08Z</timestamp>
      <contributor>
        <username>Jytdog</username>
        <id>6209803</id>
      </contributor>
      <comment>Undid revision 784425794 by [[Special:Contributions/5.134.180.123|5.134.180.123]] ([[User talk:5.134.180.123|talk]]) spamming dl.icdst.org</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4808" xml:space="preserve">'''Technology transfer in computer science''' refers to the [[technology transfer|transfer of technology]] developed in [[computer science]] or applied computing research, from universities and governments to the [[private sector]]. These technologies may be abstract, such as [[algorithms]] and [[data structures]], or concrete, such as [[open source software]] packages.

== Examples ==
{{Incomplete list|date=November 2014}}Notable examples of technology transfer in computer science include:
{| class="wikitable"
!Year of transfer
!Technology
!
Field(s)
!Originally developed at
!Transfer method(s)
!Commercialised at
!Patented
!Used by
|-
|c. 1964
|[[BASIC]]
|[[Programming languages]]
|{{Flagdeco|US}}[[Dartmouth College]]
|[[Freeware]]
|Computer manufacturers and others
|No
|Numerous [[BASIC dialects]]
|-
|1974 (Internet Protocol published)

1992 (interconnection)
|[[The Internet]]
|[[Computer networking]]

[[The Internet]]
|{{Flagdeco|US}}[[DARPA|Advanced Research Projects Agency]]
|[[Request for Comments|RFC]]

1992 law permitting commercial interconnection
|Numerous companies
|No
|Millions of [[web sites]] and other internet properties
|-
|1981
|[[KMS (hypertext)|KMS]]
|[[Hypertext]]
|{{Flagdeco|US}}[[Carnegie Mellon University]]
|Spin-out
|Knowledge Systems
|No
|?
|-
|1984
|[[MATLAB]]
|[[Programming languages]]

[[Scientific computing]]

[[List of numerical analysis software|Numerical computing]]
|{{Flagdeco|US}}[[University of New Mexico]]&lt;ref name=":0"&gt;{{Cite web|url = http://uk.mathworks.com/company/newsletters/articles/the-origins-of-matlab.html|title = The Origins of MATLAB|date = 2004|accessdate = 19 November 2014|website = Mathworks.com|publisher = |last = Moler|first = Cleve}}&lt;/ref&gt;
|Incorporation and rewrite&lt;ref name=":0" /&gt;
|{{Flagdeco|US}}[[MathWorks]]
|No (original)

Yes (from 2001)&lt;ref&gt;{{Cite web|url = http://uk.mathworks.com/company/aboutus/policies_statements/patents.html|title = Patents|date = |accessdate = 19 November 2014|website = Mathworks.com|publisher = |last = |first = }}&lt;/ref&gt;
|Millions of users
|-
|c. 1985
|[[HyperTIES]]
|[[Hypertext]]
|{{Flagdeco|US}}[[University of Maryland]]&lt;ref name=":1"&gt;{{Cite web|url = http://www.cs.umd.edu/hcil/hyperties/|title = Hypertext Research: The Development of HyperTIES|date = |accessdate = 22 November 2014|website = Human Computer Interaction Lab|publisher = University of Maryland|last = |first = }}&lt;/ref&gt;
|[[Intellectual property license|Licensing]]&lt;ref name=":1" /&gt;
|{{Flagdeco|US}}[[Cognetics Corporation]]
|?
|[[Union Carbide]], [[Hewlett-Packard]], others&lt;ref name="cognetics-hyperties"&gt;{{cite web|url=http://www.leadersintheknow.biz/AboutUs/OurHistory/tabid/174/Default.aspx|title=Cognetics History|publisher=[[Cognetics Corporation]]|accessdate = 22 November 2014}}&lt;/ref&gt;
|-
|1990 (initial software)

1994 (Netscape)&lt;ref&gt;{{Cite web|url = https://arstechnica.com/business/2011/10/before-netscape-forgotten-web-browsers-of-the-early-1990s/|title = Before Netscape: the forgotten Web browsers of the early 1990s|date = 11 October 2011|accessdate = 22 November 2014|website = [[Ars Technica]]|publisher = |last = Lasar|first = Matthew}}&lt;/ref&gt;
|[[World Wide Web]]
|[[Hypertext]]

[[World Wide Web]]
|{{Flagdeco|Switzerland}}[[CERN]]
|Unfettered use (no patents)
[[W3C|Consortium]] (to create recommended standards)
|{{Flagdeco|US}}[[Netscape]] and others
|No
|Millions of [[web sites]]
|-
|1991
|[[Gopher (protocol)|Gopher]]
|[[Computer networking]]

[[The Internet]]

[[Information retrieval]]
|{{Flagdeco|US}}[[University of Minnesota]]
|[[Request for Comments|RFC]]

[[Freeware]]
|Numerous companies
|No
|Numerous Gopher sites
|-
|1998
|[[PageRank]]
|[[Information retrieval]]

[[World Wide Web]]

[[Algorithms]]
|{{Flagdeco|US}}[[Stanford University]]
|[[Spin-out]]
|{{Flagdeco|US}}[[Google Inc.|Google]]
|Yes
|[[Google Search]]
|-
|2004 (software)

2011 (incorporation)
|[[Scala (programming language)|Scala]]
|[[Programming languages]]

[[Object-oriented programming]]
|{{Flagdeco|Switzerland}}[[École Polytechnique Fédérale de Lausanne]]
|Open source
|{{Flagdeco|US}}[[Typesafe Inc.]] and others
|?
|[[Play framework|Play]], [[Akka (toolkit)|Akka]] and others
|-
|2013
|[[Conflict-free replicated data types|CRDTs]]
|[[Distributed computing]]
|{{Flagdeco|France}}[[INRIA]] and others
|?
|{{Flagdeco|US}}[[Basho Technologies]]&lt;ref name=":2"&gt;{{Cite web|url = http://basho.com/introducing-riak-2-0/|title = Introducing Riak 2.0: Data Types, Strong Consistency, Full-Text Search, and Much More|date = 29 October 2013|accessdate = 29 November 2014|website = |publisher = [[Basho Technologies]]|last = |first = }}&lt;/ref&gt;
|No
|[[Riak]]&lt;ref name=":2" /&gt;
|}

== References ==
&lt;references /&gt;[[Category:Technology transfer|Computer science]]
[[Category:Computer science]]
[[Category:Computing-related lists]]</text>
      <sha1>4ovpol05757li3m5rl0k9pku290pv9o</sha1>
    </revision>
  </page>
  <page>
    <title>Visual computing</title>
    <ns>0</ns>
    <id>45350085</id>
    <revision>
      <id>996715929</id>
      <parentid>918526256</parentid>
      <timestamp>2020-12-28T06:32:06Z</timestamp>
      <contributor>
        <ip>73.183.243.192</ip>
      </contributor>
      <comment>Edited for style</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7132" xml:space="preserve">'''Visual computing''' is a generic term for all computer science disciplines dealing with images and [[3D model]]s, such as computer graphics, image processing, visualization, computer vision, virtual and augmented reality and [[video processing]]. Visual computing also includes aspects of [[pattern recognition]], human computer interaction, machine learning and digital libraries. The core challenges are the acquisition, processing, analysis and rendering of visual information (mainly images and video). Application areas include industrial quality control, [[medical image processing]] and visualization, surveying, robotics, multimedia systems, virtual heritage, special effects in movies and television, and computer games.

==History and overview==
Visual computing is a fairly new term, which got its current meaning around 2005, when the International Symposium on Visual Computing first convened.&lt;ref&gt;[http://www.isvc.net/ International Symposium on Visual Computing]&lt;/ref&gt; Areas of computer technology concerning images, such as image formats, filtering methods, color models, and image metrics, have in common many mathematical methods and algorithms. When computer scientists working in computer science disciplines that involve images, such as [[computer graphics]], [[image processing]], and [[computer vision]], noticed that their methods and applications increasingly overlapped, they began using the term "visual computing" to describe these fields collectively. And also the programming methods on graphics hardware, the manipulation tricks to handle huge data, textbooks and conferences, the scientific communities of these disciplines and working groups at companies intermixed more and more.

Furthermore, applications increasingly needed techniques from more than one of these fields concurrently. To generate very detailed models of complex objects you need [[image recognition]], 3D sensors and [[3D reconstruction|reconstruction algorithms]], and to display these models believably you need realistic rendering techniques with complex lighting simulation. [[real-time computer graphics|Real-time graphics]] is the basis for usable virtual and augmented reality software. A good segmentation of the organs is the basis for interactive manipulation of 3D visualizations of medical scans. Robot control needs the recognition of objects just as a model of its environment. And all devices (computers) need ergonomic graphical user interfaces.

Although many problems are considered solved within the scientific communities of the sub-disciplines making up visual computing (mostly under idealistic assumptions), one major challenge of visual computing as a whole is the integration of these partial solutions into applicable products. This includes dealing with many practical problems like addressing a multitude of hardware, the use of real data (that is often erroneous and/or gigantic in size), and the operation by untrained users. In this respect, '''Visual computing is more than just the sum of its sub-disciplines''', it is the next step towards systems fit for real use in all areas using images or 3D objects on the computer.

== Visual computing disciplines ==
At least the following disciplines are sub-fields of visual computing. More detailed descriptions of each of these fields can be found on the linked special pages.
* Computer graphics and computer animation
[[Computer graphics (computer science)|Computer graphics]] is a general term for all techniques that produce images as result with the help of a computer. To transform the description of objects to nice images is called [[Rendering (computer graphics)|rendering]] which is always a compromise between image quality and run-time.
* Image analysis and computer vision
Techniques that can extract content information from images are called [[image analysis]] techniques. [[Computer vision]] is the ability of computers (or of robots) to recognize their environment and to interpret it correctly.
* Visualization and visual analytics
[[Visualization (computer graphics)|Visualization]] is used to produce images that shall communicate messages. Data may be abstract or concrete, often with no a priori geometrical components. [[Visual analytics]] describes the discipline of interactive visual analysis of data, also described as “the science of analytical reasoning supported by the interactive visual interface”.&lt;ref&gt;[Thomas, J.J., and Cook, K.A. (Eds) (2005). An Illuminated Path: The Research and Development Agenda for Visual Analytics, IEEE Computer Society Press, {{ISBN|0-7695-2323-4}}]&lt;/ref&gt;
* Geometric modeling and 3D-printing
To represent objects for rendering it needs special methods and data structures, which subsumed with the term [[geometric modeling]]. In addition to describing and interactive geometric techniques, sensor data are more and more used to reconstruct geometrical models. Algorithms for the efficient control of [[3D printing|3D printers]] also belong to the field of visual computing.
* Image processing and image editing
In contrast to image analysis [[image processing]] manipulates images to produce better images. “Better” can have very different meanings subject to the respective application. Also, it has to be discriminated from [[image editing]] which describes interactive manipulation of images based on human validation.
* Virtual and augmented reality
Techniques that produce the feeling of immersion into a fictive world are called [[virtual reality]] (VR). Requirements for VR include [[head-mounted display]]s, real-time [[positional tracking|tracking]], and high-quality real-time rendering. [[Augmented reality]] enables the user to see the real environment in addition to the virtual objects, which augment this reality. Accuracy requirements on rendering speed and tracking precision are significantly higher here.
* Human computer interaction
The planning, design and uses of interfaces between people and computers is not only part of every system involving images. Due to the high bandwidth of the human visual channel (eye), images are also a preferred part of ergonomic user interfaces in any system, so that [[human-computer interaction]] is also an integral part of visual computing.

== Footnotes ==
&lt;references /&gt;

== External links ==
* [http://research.microsoft.com/en-us/groups/vc/ Microsoft Research Group Visual Computing]
* [http://www.nvidia.de/object/visual-computing-de.html Visual Computing at NVidia]
* [http://vcg.seas.harvard.edu/ Visual Computing Group at Harvard University]
* [http://vcc.kaust.edu.sa/Pages/Home.aspx Visual Computing Center at KAUST]
* [http://www.igd.fraunhofer.de/ Applied Research in Visual Computing] (Fraunhofer IGD)
* [http://www.ivc.h-brs.de/ Institute of Visual Computing] (Hochschule Bonn-Rhein-Sieg, Sankt Augustin)
* [http://www.vrvis.at  VRVis Research Center for Virtual Reality and Visualisation] (Vienna, Austria)
* [http://www.visual-computing.com Visual Computing Group @ HTW Berlin] (Germany)

{{Authority control}}

[[Category:Computer science]]
[[Category:Image processing]]
[[Category:Computer graphics]]</text>
      <sha1>91gi0bnsrs9164v68rvhx1azszcr074</sha1>
    </revision>
  </page>
  <page>
    <title>Philosophy of computer science</title>
    <ns>0</ns>
    <id>22458313</id>
    <revision>
      <id>999054557</id>
      <parentid>991828675</parentid>
      <timestamp>2021-01-08T07:44:47Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 9 templates: hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8226" xml:space="preserve">The '''philosophy of computer science''' is concerned with the [[philosophy|philosophical]] questions that arise within the study of [[computer science]]. There is still no common understanding of the content, aim, focus, or topic of the philosophy of computer science,&lt;ref name=Tedre2014&gt;{{cite book |last=Tedre |first=Matti |year=2014 |title=The Science of Computing: Shaping a Discipline |publisher=Chapman Hall}}&lt;/ref&gt; despite some attempts to develop a philosophy of computer science like the [[philosophy of physics]] or the [[philosophy of mathematics]]. Due to the abstract nature of computer programs and the technological ambitions of computer science, many of the conceptual questions of the philosophy of computer science are also comparable to the [[philosophy of science]], and the [[philosophy of technology]].&lt;ref&gt;{{Citation|last1=Turner|first1=Raymond|title=The Philosophy of Computer Science|date=2020|url=https://plato.stanford.edu/archives/spr2020/entries/computer-science/|encyclopedia=The Stanford Encyclopedia of Philosophy|editor-last=Zalta|editor-first=Edward N.|edition=Spring 2020|publisher=Metaphysics Research Lab, Stanford University|access-date=2020-05-21|last2=Angius|first2=Nicola}}&lt;/ref&gt;

==Overview==
Many of the central philosophical questions of computer science are centered on the logical, ontological and epistemological issues that concern it.&lt;ref&gt;{{Cite journal|last=Turner|first=Raymond|date=January 2008|title=The Philosophy of Computer Science|url=https://www.researchgate.net/publication/306292584|journal=Journal of Applied Logic|volume=6|issue=4|pages=459|doi=10.1016/j.jal.2008.09.006|via=ResearchGate}}&lt;/ref&gt; Some of these questions may include:

* What is computation?
* Does the [[Church–Turing thesis]] capture the mathematical notion of an [[effective method]] in logic and mathematics?&lt;ref&gt;{{Cite journal|last=Copeland|first=B. Jack|title=The Church-Turing Thesis|url=https://plato.stanford.edu/archives/fall2008/entries/church-turing/|journal=Stanford Encyclopedia of Philosophy}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.turing.org.uk/publications/sciam.html|title=Did Church and Turing have a thesis about machines?|last=Hodges|first=Andrew}}&lt;/ref&gt;
* What are the philosophical consequences of the [[P versus NP problem|P vs NP problem]]? 
* What is information?

== Church–Turing thesis ==
The [[Church–Turing thesis]] and its variations are central to the [[theory of computation]]. Since, as an informal notion, the concept of effective calculability does not have a formal definition, the thesis, although it has near-universal acceptance, cannot be formally proven. The implications of this thesis is also of philosophical concern. Philosophers have interpreted the Church–Turing thesis as having implications for the [[philosophy of mind]].&lt;ref&gt;{{Cite SEP|last=Copeland|first=B. Jack|author-link=Jack Copeland|date=November 10, 2017|title=The Church-Turing Thesis|url-id=church-turing}}&lt;/ref&gt;&lt;ref&gt;For a good place to encounter original papers see {{cite book|title=Philosophy of Mind: Classical and Contemporary Readings|date=2002|publisher=Oxford University Press|isbn=978-0-19-514581-6|editor-last=Chalmers|editor-first=David J.|editor-link=David Chalmers|location=New York|oclc=610918145}}&lt;/ref&gt;

== P versus NP problem ==
The [[P versus NP problem]] is an unsolved problem in computer science and mathematics. It asks whether every problem whose solution can be verified in [[polynomial time]] (and so defined to belong to the class '''NP''') can also be solved in polynomial time (and so defined to belong to the class '''P'''). Most computer scientists believe that '''P''' ≠ '''NP'''.'''&lt;ref name="poll"&gt;{{Cite journal|author=William I. Gasarch|date=June 2002|title=The '''P'''=?'''NP''' poll.|url=http://www.cs.umd.edu/~gasarch/papers/poll.pdf|journal=[[SIGACT News]]|volume=33|issue=2|pages=34–47|citeseerx=10.1.1.172.1005|doi=10.1145/564585.564599|s2cid=36828694|access-date=26 September 2018|author1-link=William Gasarch}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Rosenberger|first=Jack|date=May 2012|title='''P''' vs. '''NP''' poll results|url=http://mags.acm.org/communications/201205?pg=12|journal=Communications of the ACM|volume=55|issue=5|page=10}}&lt;/ref&gt;''' Apart from the reason that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3000 important known '''NP'''-complete problems, philosophical reasons that concern its implications may have motivated this belief. 

[[Scott Aaronson]], the American computer scientist then at [[Massachusetts Institute of Technology|MIT]], said:
&lt;blockquote&gt;
If '''P''' = '''NP''', then the world would be a profoundly different place than we usually assume it to be. There would be no special value in "creative leaps", no fundamental gap between solving a problem and recognizing the solution once it's found. Everyone who could appreciate a symphony would be [[Wolfgang Amadeus Mozart|Mozart]]; everyone who could follow a step-by-step argument would be [[Carl Friedrich Gauss|Gauss]]. 
&lt;/blockquote&gt;

==See also==
* [[Computer-assisted proof#Philosophical objections|Computer-assisted proof: Philosophical objections]]
* [[Philosophy of artificial intelligence]]
* [[Philosophy of information]]
* [[Philosophy of mathematics]]
* [[Philosophy of science]]
* [[Philosophy of technology]]

==References==
{{Reflist|2}}

==Further reading==
* [[Matti Tedre]] (2014). The Science of Computing: Shaping a Discipline. Chapman Hall.
* [[Scott Aaronson]]. "[http://eccc.hpi-web.de/report/2011/108/ Why Philosophers Should Care About Computational Complexity]". In ''Computability: Gödel, Turing, Church, and beyond''.
* [[Timothy Colburn]]. ''Philosophy and Computer Science''. Explorations in Philosophy. M.E. Sharpe, 1999. {{ISBN|1-56324-991-X}}.
* [[A.K. Dewdney]]. ''New Turing Omnibus: 66 Excursions in Computer Science''
* [[Luciano Floridi]] (editor). ''The Blackwell Guide to the Philosophy of Computing and Information'', 2004.
* [[Luciano Floridi]] (editor). ''Philosophy of Computing and Information: 5 Questions''. Automatic Press, 2008.
* [[Luciano Floridi]]. ''Philosophy and Computing: An Introduction'', Routledge, 1999.
* [[Christian Jongeneel]]. ''The informatical worldview, an inquiry into the methodology of computer science''.
* [[Jan van Leeuwen]]. [https://web.archive.org/web/20110721203232/http://www.nias.knaw.nl/Content/NIAS/Publicaties/Newsletter/NIAS_Newsletter_42.pdf "Towards a philosophy of the information and computing sciences"], ''NIAS Newsletter'' '''42''', 2009.
* Moschovakis, Y. (2001). What is an algorithm? In Enquist, B. and Schmid, W., editors, Mathematics unlimited &amp;mdash; 2001 and beyond, pages 919–936. Springer.
* [[Alexander Ollongren]], [[Jaap van den Herik]]. ''Filosofie van de informatica''. London and New York: Routledge, 1999. {{ISBN|0-415-19749-X}}
* {{citation|first=Matti|last=Tedre|year=2014|url=https://books.google.com/books?id=I2tYBQAAQBAJ|title=The Science of Computing: Shaping a Discipline|isbn=9781482217698}} Taylor and Francis.
* [[Ray Turner (computer scientist)|Ray Turner]] and [[Nicola Angius]]. "[http://plato.stanford.edu/entries/computer-science/ The Philosophy of Computer Science]". ''[[Stanford Encyclopedia of Philosophy]]''.
* [[Matti Tedre]] (2011). ''[https://doi.org/10.1007%2Fs11023-011-9240-4 Computing as a Science: A Survey of Competing Viewpoints]''. Minds &amp; Machines '''21''', 3, 361–387.
* [[Ray Turner (computer scientist)|Ray Turner]]. Computational Artefacts-Towards a Philosophy of Computer Science. Springer. [https://www.springer.com/gb/book/9783662555644]

==External links==
* [http://www.iacap.org/ The International Association for Computing and Philosophy]
* [http://philpapers.org/browse/philosophy-of-computing-and-information Philosophy of Computing and Information] at [[PhilPapers]]
* A draft version of [http://www.cse.buffalo.edu/~rapaport/Papers/phics.pdf ''Philosophy of Computer Science''] by [[William J. Rapaport]]
* [http://pocab.org Philosophy of Computation at Berkeley]

{{Computer science}}
{{Philosophy of science}}

[[Category:Philosophy of computer science| ]]
[[Category:Computer science]]


{{computer science stub}}</text>
      <sha1>siozz45dmqon3q4g1z1frv6owjak5ce</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computational geometry</title>
    <ns>14</ns>
    <id>25230402</id>
    <revision>
      <id>986768510</id>
      <parentid>798833961</parentid>
      <timestamp>2020-11-02T22:08:48Z</timestamp>
      <contributor>
        <username>Tarnoob</username>
        <id>9780599</id>
      </contributor>
      <comment>cat.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="314" xml:space="preserve">{{Commons category|Computational geometry}}
{{Cat main|Computational geometry}}

==Related categories==

*[[:Category:Computational topology|Computational topology]]

[[Category:Computer science]]
[[Category:Fields of geometry]]
[[Category:Computational fields of study]]
[[Category:Computational mathematics|geo]]</text>
      <sha1>8790jrqh49mgcnou94jtwp3lt0gsmxe</sha1>
    </revision>
  </page>
  <page>
    <title>Quaject</title>
    <ns>0</ns>
    <id>51401190</id>
    <revision>
      <id>956522592</id>
      <parentid>917413094</parentid>
      <timestamp>2020-05-13T20:40:21Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead.) #IABot (v2.0</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3844" xml:space="preserve">In [[computer science]], a '''quaject''' is an [[Object (computer programming)|object]]-like [[data structure]] containing both data and code (or pointers to code), exposed as an interface in the form of ''[[Method (computer programming)|callentries]]'', and can accept a list of callentries to other quajects for ''[[Callback (computer programming)|callbacks]]'' and ''[[Continuation|callouts]]''. They were developed by [[Alexia Massalin]] in 1989 for the ''[[Self-modifying code#Massalin's Synthesis kernel|Synthesis kernel]]'',&lt;ref name="Massalin_1992_Synthesis"/&gt; and named for the ''Qua! Machine'', a unique hardware platform built by Massalin. The origin of the term 'qua' is unclear; Massalin claims humorously that it is a sound made by [[koala]]s.&lt;ref name="Poole_1996_Qua"/&gt;

The main purpose of quajects is to provide an [[Abstraction (software engineering)|abstraction]] to manage [[self-modifying code]], by allowing runtime code optimizing on a per-object basis. While the original Synthesis kernel required quajects to be written in hand-developed [[assembly language]], this was done to avoid developing a complex compiler; Massalin noted that [[just-in-time compilation]] (JIT) for a [[high-level programming language]] that permits runtime [[Automatic programming|code generation]], as in [[Lisp (programming language)|Lisp]] or [[Smalltalk]], can also apply this approach, though she also asserted that the complexity of such a compiler was likely to be prohibitive.

Quajects differ from more conventional objects in two key ways: first, they always use a form of the [[dependency injection]] pattern to manage both interfaces to other quajects, and continuations out of the quaject; the list of callentry references for this is part of quaject creation, and may be updated during the quaject's lifetime. Second, and more critically, a given quaject's set of methods can be unique to the specific quaject; methods for a type or class of quajects are stored as one or more templates, rather than as fixed code. While shared methods can be accessed through a common table of pointers, individual quajects can also have methods that are generated specifically to tailor the performance for that quaject's behavior.

==References==
{{Reflist|refs=
&lt;ref name="Massalin_1992_Synthesis"&gt;{{Cite thesis |author-first1=Calton |author-last1=Pu |author-link1=Calton Pu |author-first2=Henry |author-last2=Massalin |author-link2=Henry Massalin |author-first3=John |author-last3=Ioannidis |degree=Ph.D. |title=Synthesis: An Efficient Implementation of Fundamental Operating System Services |publisher=Department of Computer Sciences, [[Columbia University]] |location=New York, NY, USA |id=UMI Order No. GAX92-32050 |date=1992 |url=http://www.scs.stanford.edu/nyu/04fa/sched/readings/synthesis.pdf |access-date=2012-04-25 |lay-url=https://lwn.net/Articles/270081/ |lay-date=2008-02-20 |url-status=live |archive-url=https://web.archive.org/web/20170704122520/http://www.scs.stanford.edu/nyu/04fa/sched/readings/synthesis.pdf |archive-date=2017-07-05 }} [https://www.cs.columbia.edu/~library/TR-repository/reports/reports-1992/cucs-039-92.ps.gz] {{Webarchive|url=https://web.archive.org/web/20160312005507/http://www.cs.columbia.edu/~library/TR-repository/reports/reports-1992/cucs-039-92.ps.gz |date=2016-03-12 }}&lt;/ref&gt;
&lt;ref name="Poole_1996_Qua"&gt;{{cite magazine |author-last=Poole |author-first=Gary Andrew |author-link=Gary Andrew Poole |date=1996-12-01 |title=Qua |url=https://www.wired.com/1996/12/ffmassalin/ |magazine=[[Wired (magazine)|Wired]] |publisher=Condé Nast |access-date=2016-08-23 |url-status=live |archive-url=https://web.archive.org/web/20170704124039/https://www.wired.com/1996/12/ffmassalin/ |archive-date=2017-07-04}}&lt;/ref&gt;
}}

[[Category:Computer science]]
[[Category:Operating system technology]]

{{comp-sci-stub}}</text>
      <sha1>5m58pqvc4f9jpshhwgw1ww38ed2l90n</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computing by century</title>
    <ns>14</ns>
    <id>51875616</id>
    <revision>
      <id>971488394</id>
      <parentid>959883906</parentid>
      <timestamp>2020-08-06T13:04:23Z</timestamp>
      <contributor>
        <username>Allforrous</username>
        <id>12120664</id>
      </contributor>
      <comment>new key for [[Category:Technology by century]]: "" using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="263" xml:space="preserve">This category is for '''[[computer science]]''' by '''century'''

[[Category:Computer science| 01]]
[[Category:History of computer science| ]]
[[Category:History of computing| ]]
[[Category:Science by century| Computer science]]
[[Category:Technology by century]]</text>
      <sha1>fzg4rat10fg02ywm55o59twqqp4vgyc</sha1>
    </revision>
  </page>
  <page>
    <title>Critical code studies</title>
    <ns>0</ns>
    <id>34549363</id>
    <revision>
      <id>1003415612</id>
      <parentid>974259940</parentid>
      <timestamp>2021-01-28T21:51:29Z</timestamp>
      <contributor>
        <username>IznoRepeat</username>
        <id>12897086</id>
      </contributor>
      <minor/>
      <comment>remove deprecated : syntax for refbegin lists, remove ref=harv, gen fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10547" xml:space="preserve">{{Use dmy dates|date=April 2020}}
{{Use Oxford spelling|date=April 2020}}
'''Critical code studies''' ('''CCS''') is an emerging academic subfield, related to [[software studies]],{{sfn|Manovich|2013|p=42}} [[digital humanities]],{{sfn|Eyman|2015|p=58}} [[cultural studies]], [[computer science]], [[human–computer interface]], and the [[do-it-yourself]] [[maker culture]]. Its primary focus is on the cultural significance of [[computer code]], without excluding or focusing solely upon the code's functional purpose. According to Mark C. Marino, it {{quote|is an approach that applies critical hermeneutics to the interpretation of computer code, program architecture, and documentation within a socio-historical context. CCS holds that lines of code are not value-neutral and can be analyzed using the theoretical approaches applied to other semiotic systems in addition to particular interpretive methods developed particularly for the discussions of programs.{{sfn|Marino|2006}}}}

As introduced by Marino, critical code studies was initially a method by which scholars "can read and explicate code the way we might explicate a work of literature",{{sfn|Marino|2006}} but the concept also draws upon{{citation needed|date=April 2020}} [[Espen Aarseth]]'s conception of a cybertext as a "mechanical device for the production and consumption of verbal signs",{{sfn|Aarseth|1997|p=21}} arguing that in order to understand a digital artifact we must also understand the constraints and capabilities of the authoring tools used by the creator of the artifact, as well as the memory storage and interface required for the user to experience the digital artifact.

Evidence that critical code studies has gained momentum since 2006 include{{original research inline|date=April 2020}} an article by Matthew Kirschenbaum in ''[[The Chronicle of Higher Education]]'',&lt;ref&gt;{{cite news |last=Kirschenbaum |first=Matthew |date=23 January 2009 |title=Where Computer Science and Cultural Studies Collide |url=http://chronicle.com/article/Where-Computer-Science/14806/ |url-access=subscription |work=The Chronicle of Higher Education |access-date=6 April 2020}}&lt;/ref&gt; CCS sessions at the [[Modern Language Association]] in 2011 that were "packed" with attendees,&lt;ref&gt;{{cite news |last=Howard |first=Jennifer |date=9 January 2011 |title=Hard Times Sharpen the MLA's Lens on Labor and the Humanities |url=http://chronicle.com/article/Hard-Times-Sharpen-the-MLAs/125905/ |work=The Chronicle of Higher Education |access-date=6 April 2020}}&lt;/ref&gt; several academic conferences devoted wholly to critical code studies, and a book devoted to the explication of a single line of computer code, titled ''10 PRINT CHR$(205.5+RND(1));&amp;nbsp;: GOTO 10''.{{sfn|Montfort|Baudoin|Bell|Bogost|2013}}

== See also ==
{{Portal|Society|Technology}}
* [[Critical legal studies]]
* [[Critical theory]]
* [[Hermeneutics]]

== References ==
=== Footnotes ===
{{reflist|22em}}

=== Bibliography ===
{{refbegin|35em|indent=yes}}
* {{cite book
|last=Aarseth
|first=Espen
|author-link=Espen Aarseth
|year=1997
|title=Cybertext: Perspectives on Ergodic Literature
|location=Baltimore, Maryland
|publisher=Johns Hopkins University Press
|isbn=978-0-8018-5579-5
}}
* {{cite book
|last=Eyman
|first=Douglas
|year=2015
|title=Digital Rhetoric: Theory, Method, Practice
|location=Ann Arbor, Michigan
|publisher=University of Michigan Press
|doi=10.2307/j.ctv65swm2
|doi-access=free
|isbn=978-0-472-90011-4
}}
* {{cite book
|last=Manovich
|first=Lev
|author-link=Lev Manovich
|year=2013
|title=Software Takes Command
|url=https://issuu.com/bloomsburypublishing/docs/9781623566722_web
|location=New York
|publisher=Bloomsbury Academic
|isbn=978-1-62356-672-2
|access-date=6 April 2020
}}
* {{cite journal
|last=Marino
|first=Mark C.
|year=2006
|title=Critical Code Studies
|url=https://electronicbookreview.com/essay/critical-code-studies/
|journal=Electronic Book Review
|issn=1553-1139
|access-date=6 April 2020
}}
* {{cite book
|last1=Montfort
|first1=Nick
|author1-link=Nick Montfort
|last2=Baudoin
|first2=Patsy
|last3=Bell
|first3=John
|last4=Bogost
|first4=Ian
|author4-link=Ian Bogost
|last5=Douglass
|first5=Jeremy
|last6=Marino
|first6=Mark C.
|last7=Mateas
|first7=Michael
|last8=Reas
|first8=Casey
|author8-link=Casey Reas
|last9=Sample
|first9=Mark
|last10=Vawter
|first10=Noah
|year=2013
|title=10 PRINT CHR$(205.5+RND(1));&amp;nbsp;: GOTO 10
|url=https://mitpress.mit.edu/books/10-print-chr2055rnd1-goto-10
|location=Cambridge, Massachusetts
|publisher=MIT Press
|isbn=978-0-262-01846-3
|access-date=30 November 2018
}}
{{refend}}

== Further reading ==
{{refbegin|35em|indent=yes}}
* {{cite book
|last=Berry
|first=David M.
|year=2008
|title=Copy, Rip, Burn: The Politics of Copyleft and Open Source
|url=https://archive.org/details/copyripburnpolit0000berr
|url-access=registration
|location=London
|publisher=Pluto Press
|doi=10.2307/j.ctt183q67g
|isbn=978-1-84964-455-6
}}
* {{cite book
|last=Berry
|first=David M.
|author-mask={{long dash}}
|year=2011
|title=The Philosophy of Software: Code and Mediation in the Digital Age
|location=Basingstoke, England
|publisher=Palgrave Macmillan
|doi=10.1057/9780230306479
|isbn=978-0-230-24418-4
}}
* {{cite thesis
|last=Black
|first=Maurice J.
|year=2002
|title=The Art of Code
|type=PhD dissertation
|location=Philadelphia
|publisher=University of Pennsylvania
|oclc=244972113
|id={{ProQuest|305507258}}
}}
* {{cite book
|last1=Chopra
|first1=Samir
|last2=Dexter
|first2=Scott D.
|year=2008
|title=Decoding Liberation: The Promise of Free and Open Source Software
|location=New York
|publisher=Routledge
|doi=10.4324/9780203942147
|isbn=978-0-203-94214-7
}}
* {{cite journal
|last=Chun
|first=Wendy Hui Kyong
|author-link=Wendy Hui Kyong Chun
|year=2008
|title=On 'Sourcery,' or Code as Fetish
|url=https://repository.library.brown.edu/studio/item/bdr:405433/
|journal=Configurations
|volume=16
|issue=3
|pages=299–324
|doi=10.1353/con.0.0064
|issn=1080-6520
|access-date=5 April 2020
}}
* {{cite book
|last=Chun
|first=Wendy Hui Kyong
|author-link=Wendy Hui Kyong Chun
|author-mask={{long dash}}
|year=2011
|title=Programmed Visions: Software and Memory
|location=Cambridge, Massachusetts
|publisher=MIT Press
|isbn=978-0-262-01542-4
}}
* {{cite book
|last=Fuller
|first=Matthew
|author-link=Matthew Fuller (author)
|year=2003
|title=Behind the Blip: Essays on the Culture of Software
|location=New York
|publisher=Autonomedia
|isbn=978-1-57027-139-7
}}
* {{cite book
|year=2008
|editor-last=Fuller
|editor-first=Matthew
|editor-link=Matthew Fuller (author)
|editor-mask={{long dash}}
|title=Software Studies: A Lexicon
|location=Cambridge, Massachusetts
|publisher=MIT Press
|isbn=978-0-262-06274-9
}}
* {{cite journal
|last=Hayles
|first=N. Katherine
|s2cid=16194046
|author-link=N. Katherine Hayles
|year=2004
|title=Print Is Flat, Code Is Deep: The Importance of Media-Specific Analysis
|url=http://www.cws.illinois.edu/IPRHDigitalLiteracies/Hayles.pdf
|journal=Poetics Today
|volume=25
|issue=1
|pages=67–90
|doi=10.1215/03335372-25-1-67
|issn=1527-5507
|access-date=5 April 2020
}}
* {{cite book
|last=Heim
|first=Michael
|author-link=Michael R. Heim
|year=1987
|title=Electric Language: A Philosophical Study of Word Processing
|url=https://archive.org/details/electriclanguage00heim
|url-access=registration
|location=New Haven, Connecticut
|publisher=Yale University Press
|isbn=978-0-300-03835-4
}}
* {{cite journal
|last=Kirschenbaum
|first=Matthew G.
|year=2004
|title=Extreme Inscription: Towards a Grammatology of the Hard Drive
|url=http://observatory.constantvzw.org/books/vol13_2_06.pdf
|journal=TEXT Technology
|issue=2
|pages=91–125
|issn=1053-900X
|access-date=5 April 2020
}}
* {{cite book
|last=Kirschenbaum
|first=Matthew G.
|author-mask={{long dash}}
|year=2008
|title=Mechanisms: New Media and the Forensic Imagination
|location=Cambridge, Massachusetts
|publisher=MIT Press
|isbn=978-0-262-11311-3
}}
* {{cite book
|last1=Kitchin
|first1=Rob
|author1-link=Rob Kitchin
|last2=Dodge
|first2=Martin
|year=2011
|title=Code/Space: Software and Everyday Life
|location=Cambridge, Massachusetts
|publisher=MIT Press
|isbn=978-0-262-04248-2
}}
* {{cite book
|last=Kittler
|first=Friedrich A.
|author-link=Friedrich Kittler
|year=1997
|editor-last=Johnston
|editor-first=John
|title=Literature, Media, Information Systems: Essays
|location=Amsterdam
|publisher=Overseas Publishers Association
|isbn=978-90-5701-071-2
}}
* {{cite book
|last=Kittler
|first=Friedrich A.
|author-link=Friedrich Kittler
|author-mask={{long dash}}
|year=1999
|title=Gramophone, Film, Typewriter
|translator1-last=Winthrop-Young
|translator1-first=Geoffrey
|translator2-last=Wutz
|translator2-first=Michael
|location=Stanford, California
|publisher=Stanford University Press
|isbn=978-0-8047-3232-1
}}
* {{cite web
|last=Mackenzie
|first=Adrian
|year=2003
|title=The Problem of Computer Code: Leviathan or Common Power
|url=https://www.lancaster.ac.uk/staff/mackenza/papers/code-leviathan.pdf
|location=Lancaster, England
|publisher=Lancaster University
|access-date=6 April 2020
}}
* {{cite book
|last=Mackenzie
|first=Adrian
|author-mask={{long dash}}
|year=2006
|title=Cutting Code: Software and Sociality
|journal=Internet Research Annual
|series=Digital Formations
|volume=30
|location=Oxford
|publisher=Peter Lang
|isbn=978-0-8204-7823-4
|issn=1526-3169
}}
* {{cite book
|last=Manovich
|first=Lev
|author-link=Lev Manovich
|year=2001
|title=The Language of New Media
|location=Cambridge, Massachusetts
|publisher=MIT Press
|isbn=978-0-262-13374-6
}}
* {{cite web
|last1=Manovich
|first1=Lev
|author1-link=Lev Manovich
|last2=Douglass
|first2=Jeremy
|year=2009
|title=Visualizing Temporal Patterns in Visual Media
|url=http://softwarestudies.com/cultural_analytics/visualizing_temporal_patterns.pdf
|access-date=10 October 2009
}}
* {{cite book
|last1=Montfort
|first1=Nick
|author1-link=Nick Montfort
|last2=Bogost
|first2=Ian
|author2-link=Ian Bogost
|year=2009
|title=Racing the Beam: The Atari Video Computer System
|title-link=Racing the Beam
|location=Cambridge, Massachusetts
|publisher=MIT Press
|isbn=978-0-262-01257-7
}}
* {{cite book
|last=Wardrip-Fruin
|first=Noah
|author-link=Noah Wardrip-Fruin
|year=2009
|title=Expressive Processing: Digital Fictions, Computer Games, and Software Studies
|title-link=Expressive Processing
|location=Cambridge, Massachusetts
|publisher=MIT Press
|isbn=978-0-262-01343-7
}}
{{refend}}

[[Category:Computer science]]
[[Category:Cultural studies]]
[[Category:Technology in society]]</text>
      <sha1>fzzcbjkxgcsni1ejg27ql0ks4741vxs</sha1>
    </revision>
  </page>
  <page>
    <title>Computational social choice</title>
    <ns>0</ns>
    <id>51245349</id>
    <revision>
      <id>1007058475</id>
      <parentid>994379597</parentid>
      <timestamp>2021-02-16T07:19:34Z</timestamp>
      <contributor>
        <username>Erel Segal</username>
        <id>7637243</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="16633" xml:space="preserve">{{primary|date=July 2017}}
{{expert needed|1=Game theory|date=November 2016}}
'''Computational social choice''' is a field at the intersection of [[social choice theory]], [[theoretical computer science]], and the analysis of [[multi-agent system]]s.&lt;ref name=":1"&gt;{{Cite book|url=https://books.google.com/books?id=nMHgCwAAQBAJ|title=Handbook of Computational Social Choice|last=Brandt|first=Felix|last2=Conitzer|first2=Vincent|last3=Endriss|first3=Ulle|last4=Lang|first4=Jérôme|last5=Procaccia|first5=Ariel D.|date=2016-04-25|publisher=Cambridge University Press|isbn=9781107060432}}&lt;/ref&gt; It consists of the analysis of problems arising from the aggregation of [[preference]]s of a group of agents from a computational perspective. In particular, computational social choice is concerned with the efficient computation of outcomes of [[Voting system|voting rules]], with the computational complexity of various forms of [[Tactical voting|manipulation]], and issues arising from the problem of [[Knowledge representation and reasoning|representing]] and eliciting preferences in combinatorial settings.

== Winner determination ==
The usefulness of a particular [[voting system]] can be severely limited if it takes a very long time to calculate the winner of an election. Therefore, it is important to design fast [[algorithm]]s that can evaluate a voting rule when given [[ballot]]s as input. As is common in [[computational complexity theory]], an algorithm is thought to be efficient if it takes [[polynomial time]]. Many popular voting rules can be evaluated in polynomial time in a straightforward way (i.e., counting), such as the [[Borda count]], [[approval voting]], or the [[Plurality voting system|plurality rule]]. For rules such as the [[Schulze method]] or [[ranked pairs]], more sophisticated algorithms can be used to show polynomial runtime.&lt;ref&gt;{{Cite journal|last=Schulze|first=Markus|date=2010-07-11|title=A new monotonic, clone-independent, reversal symmetric, and condorcet-consistent single-winner election method|journal=Social Choice and Welfare|volume=36|issue=2|pages=267–303|doi=10.1007/s00355-010-0475-4}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Brill|first=Markus|last2=Fischer|first2=Felix|date=2012-01-01|title=The Price of Neutrality for the Ranked Pairs Method|url=http://dl.acm.org/citation.cfm?id=2900728.2900912|journal=Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence|series=AAAI'12|pages=1299–1305}}&lt;/ref&gt; Certain voting systems, however, are computationally difficult to evaluate.&lt;ref name=":0"&gt;{{Cite journal|last=Bartholdi III|first=J.|last2=Tovey|first2=C. A.|last3=Trick|first3=M. A.|author3-link= Michael Trick |date=1989-04-01|title=Voting schemes for which it can be difficult to tell who won the election|journal=Social Choice and Welfare|volume=6|issue=2|pages=157–165|doi=10.1007/BF00303169}}&lt;/ref&gt; In particular, winner determination for the [[Kemeny-Young method]], [[Dodgson's method]], and [[Young's method]] are all NP-hard problems.&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite journal|last=Hemaspaandra|first=Edith|last2=Spakowski|first2=Holger|last3=Vogel|first3=Jörg|date=2005-12-16|title=The complexity of Kemeny elections|journal=Theoretical Computer Science|volume=349|issue=3|pages=382–391|doi=10.1016/j.tcs.2005.08.031|doi-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Hemaspaandra|first=Edith|last2=Hemaspaandra|first2=Lane A.|last3=Rothe|first3=Jörg|year=1997|title=Exact Analysis of Dodgson Elections: Lewis Carroll's 1876 Voting System is Complete for Parallel Access to NP|journal=J. ACM|volume=44|issue=6|pages=806–825|doi=10.1145/268999.269002|arxiv=cs/9907036}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Rothe|first=Jörg|last2=Spakowski|first2=Holger|last3=Vogel|first3=Jörg|date=2003-06-06|title=Exact Complexity of the Winner Problem for Young Elections|journal=Theory of Computing Systems|volume=36|issue=4|pages=375–386|doi=10.1007/s00224-002-1093-z|arxiv=cs/0112021}}&lt;/ref&gt; This has led to the development of [[approximation algorithm]]s and [[Parameterized complexity|fixed-parameter tractable algorithms]] to improve the theoretical calculation of such problems.&lt;ref&gt;{{Cite journal|last=Caragiannis|first=Ioannis|last2=Covey|first2=Jason A.|last3=Feldman|first3=Michal|author3-link= Michal Feldman |last4=Homan|first4=Christopher M.|last5=Kaklamanis|first5=Christos|last6=Karanikolas|first6=Nikos|last7=Procaccia|first7=Ariel D.|last8=Rosenschein|first8=Jeffrey S.|date=2012-08-01|title=On the approximability of Dodgson and Young elections|journal=Artificial Intelligence|volume=187|pages=31–51|doi=10.1016/j.artint.2012.04.004|doi-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Ailon|first=Nir|last2=Charikar|first2=Moses|last3=Newman|first3=Alantha|date=2008-11-01|title=Aggregating Inconsistent Information: Ranking and Clustering|journal=J. ACM|volume=55|issue=5|pages=23:1–23:27|doi=10.1145/1411509.1411513}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|title=Fixed-Parameter Algorithms for Kemeny Scores|last=Betzler|first=Nadja|last2=Fellows|first2=Michael R.|last3=Guo|first3=Jiong|last4=Niedermeier|first4=Rolf|last5=Rosamond|first5=Frances A.|date=2008-06-23|publisher=Springer Berlin Heidelberg|isbn=9783540688655|editor-last=Fleischer|editor-first=Rudolf|series=Lecture Notes in Computer Science|pages=60–71|doi=10.1007/978-3-540-68880-8_8|editor-last2=Xu|editor-first2=Jinhui|citeseerx = 10.1.1.145.9310}}&lt;/ref&gt;

== Hardness of manipulation ==
By the [[Gibbard–Satterthwaite theorem|Gibbard-Satterthwaite theorem]], all non-trivial voting rules can be [[Tactical voting|manipulated]] in the sense that voters can sometimes achieve a better outcome by misrepresenting their preferences, that is, they submit a non-truthful [[ballot]] to the voting system. Social choice theorists have long considered ways to circumvent this issue, such as the proposition by Bartholdi, Tovey, and Trick in 1989 based on computational complexity theory.&lt;ref&gt;{{Cite journal|last=Bartholdi|first=J. J.|last2=Tovey|first2=C. A.|last3=Trick|first3=M. A.|title=The computational difficulty of manipulating an election|journal=Social Choice and Welfare|volume=6|issue=3|pages=227–241|doi=10.1007/BF00295861|year=1989}}&lt;/ref&gt; They considered the [[Copeland's method|second-order Copeland rule]] (which can be evaluated in polynomial time), and proved that it is [[NP-completeness|NP-complete]] for a voter to decide, given knowledge of how everyone else has voted, whether it is possible to manipulate in such a way as to make some favored candidate the winner. The same property holds for [[single transferable vote]].&lt;ref&gt;{{Cite journal|last=Bartholdi|first=John J.|last2=Orlin|first2=James B.|title=Single transferable vote resists strategic voting|journal=Social Choice and Welfare|volume=8|issue=4|pages=341–354|doi=10.1007/BF00183045|year=1991|citeseerx=10.1.1.127.97}}&lt;/ref&gt;

Hence, assuming the widely believed hypothesis that [[P versus NP problem|P ≠ NP]], there are instances where polynomial time is not enough to establish whether a beneficial manipulation is possible. Because of this, the voting rules that come with an NP-hard manipulation problem are "resistant" to manipulation. One should note that these results only concern the [[Worst-case execution time|worst-case]]: it might well be possible that a manipulation problem is usually easy to solve, and only requires superpolynomial time on very unusual inputs.&lt;ref&gt;{{Cite journal|last=Faliszewski|first=Piotr|last2=Procaccia|first2=Ariel D.|date=2010-09-23|title=AI's War on Manipulation: Are We Winning?|url=http://www.aaai.org/ojs/index.php/aimagazine/article/view/2314|journal=AI Magazine|volume=31|issue=4|pages=53–64|doi=10.1609/aimag.v31i4.2314|citeseerx=10.1.1.205.2873}}&lt;/ref&gt;

== Other topics ==
{{Technical|section|date=July 2017}}
===Tournament solutions=== 
A [[tournament solution]] is a rule that assigns to every [[Tournament (graph theory)|tournament]] a set of winners. Since a preference profile induces a tournament through its [[Majority|majority relation]], every tournament solution can also be seen as a voting rule which only uses information about the outcomes of pairwise majority contests.&lt;ref&gt;{{Cite journal|last=Fishburn|first=P.|date=1977-11-01|title=Condorcet Social Choice Functions|journal=SIAM Journal on Applied Mathematics|volume=33|issue=3|pages=469–489|doi=10.1137/0133030}}&lt;/ref&gt; Many tournament solutions have been proposed, and computational social choice theorists have studied the complexity of the associated winner determination problems.&lt;ref&gt;{{Cite book|url=https://books.google.com/?id=P9Q-AAAAIAAJ|title=Topics on tournaments|last=Moon|first=John W.|date=1968-01-01|publisher=Holt, Rinehart and Winston}}&lt;/ref&gt;&lt;ref name=":1" /&gt; 
===Preference restrictions=== 
Restricted preference domains, such as [[Single peaked preferences|single-peaked]] or [[Single crossing condition|single-crossing]] preferences, are an important area of study in [[social choice theory]], since preferences from these domains avoid the [[Voting paradox|Condorcet paradox]] and thus can circumvent impossibility results like [[Arrow's impossibility theorem|Arrow's theorem]] and the [[Gibbard–Satterthwaite theorem|Gibbard-Satterthwaite theorem]].&lt;ref&gt;{{Cite journal|last=Black|first=Duncan|date=1948-01-01|title=On the Rationale of Group Decision-making|jstor=1825026|journal=Journal of Political Economy|volume=56|issue=1|pages=23–34|doi=10.1086/256633}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Rothstein|first=P.|date=1990-12-01|title=Order restricted preferences and majority rule|journal=Social Choice and Welfare|volume=7|issue=4|pages=331–342|doi=10.1007/BF01376281}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=y_rkX6QWOYMC|title=Social Choice and Individual Values|last=Arrow|first=Kenneth J.|date=2012-06-26|publisher=Yale University Press|isbn=978-0300186987}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Sen|first=Amartya|last2=Pattanaik|first2=Prasanta K|date=1969-08-01|title=Necessary and sufficient conditions for rational choice under majority decision|journal=Journal of Economic Theory|volume=1|issue=2|pages=178–202|doi=10.1016/0022-0531(69)90020-9}}&lt;/ref&gt; From a computational perspective, such domain restrictions are useful to speed up winner determination problems, both computationally hard single-winner and multi-winner rules can be computed in polynomial time when preferences are structured appropriately.&lt;ref&gt;{{Cite journal|last=Elkind|first=Edith|author-link=Edith Elkind|last2=Lackner|first2=Martin|last3=Peters|first3=Dominik|date=2016-07-01|title=Preference Restrictions in Computational Social Choice: Recent Progress|url=http://www.ijcai.org/Proceedings/16/Papers/601.pdf|journal=Proceedings of the 25th International Conference on Artificial Intelligence|series=IJCAI'16|pages=4062–4065}}&lt;/ref&gt;&lt;ref name=":2"&gt;{{Cite journal|last=Brandt|first=Felix|last2=Brill|first2=Markus|last3=Hemaspaandra|first3=Edith|last4=Hemaspaandra|first4=Lane|date=2015-01-01|title=Bypassing Combinatorial Protections: Polynomial-Time Algorithms for Single-Peaked Electorates|journal=Journal of Artificial Intelligence Research|volume=53|pages=439–496|doi=10.1613/jair.4647|doi-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=N.|first=Betzler|last2=A.|first2=Slinko|last3=J.|first3=Uhlmann|year=2013|title=On the Computation of Fully Proportional Representation|url=http://www.jair.org/papers/paper3896.html|journal=Journal of Artificial Intelligence Research|volume=47|issue=2013|pages=475–519|bibcode=2014arXiv1402.0580B|arxiv=1402.0580|doi=10.1613/jair.3896}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Skowron|first=Piotr|last2=Yu|first2=Lan|last3=Faliszewski|first3=Piotr|last4=Elkind|first4=Edith|author4-link=Edith Elkind|date=2015-03-02|title=The complexity of fully proportional representation for single-crossing electorates|journal=Theoretical Computer Science|volume=569|pages=43–57|doi=10.1016/j.tcs.2014.12.012|arxiv=1307.1252}}&lt;/ref&gt; On the other hand, manipulation problem also tend to be easy on these domains, so complexity shields against manipulation are less effective.&lt;ref name=":2" /&gt;&lt;ref&gt;{{Cite journal|last=Faliszewski|first=Piotr|last2=Hemaspaandra|first2=Edith|last3=Hemaspaandra|first3=Lane A.|last4=Rothe|first4=Jörg|date=2011-02-01|title=The shield that never was: Societies with single-peaked preferences are more open to manipulation and control|journal=Information and Computation|volume=209|issue=2|pages=89–107|doi=10.1016/j.ic.2010.09.001|arxiv=0909.3257}}&lt;/ref&gt; Another computational problem associated with preference restrictions is that of recognizing when a given preference profile belongs to some restricted domain. This task is polynomial time solvable in many cases, including for single-peaked and single-crossing preferences, but can be hard for more general classes.&lt;ref&gt;{{Cite arxiv|last=Peters|first=Dominik|date=2016-02-25|title=Recognising Multidimensional Euclidean Preferences|eprint=1602.08109|class=cs.GT}}&lt;/ref&gt;&lt;ref name=":3"&gt;{{Cite journal|last=Doignon|first=J. P.|last2=Falmagne|first2=J. C.|date=1994-03-01|title=A Polynomial Time Algorithm for Unidimensional Unfolding Representations|journal=Journal of Algorithms|volume=16|issue=2|pages=218–233|doi=10.1006/jagm.1994.1010}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last=Escoffier|first=Bruno|last2=Lang|first2=Jérôme|last3=Öztürk|first3=Meltem|date=2008-01-01|title=Single-peaked Consistency and Its Complexity|url=http://dl.acm.org/citation.cfm?id=1567281.1567363|journal=Proceedings of the 2008 Conference on ECAI 2008: 18th European Conference on Artificial Intelligence|pages=366–370|isbn=9781586038915}}&lt;/ref&gt;
==={{Anchor|multiwinner}}Multiwinner elections===
While most traditional voting rules focus on selecting a single winner, many situations require selecting multiple winners. This is the case when a fixed-size [[parliament]] or a [[committee]] is to be elected, though multiwinner voting rules can also be used to select a set of [[Recommender system|recommendations]] or [[Facility location problem|facilities]] or a shared bundle of items. Work in computational social choice has focused on defining such voting rules, understanding their properties, and studying the complexity of the associated winner determination problems.&lt;ref&gt;{{Cite book|last=Skowron|first=Piotr|last2=Faliszewski|first2=Piotr|last3=Lang|first3=Jerome|date=2015-01-01|title=Finding a Collective Set of Items: From Proportional Multirepresentation to Group Recommendation|url=http://dl.acm.org/citation.cfm?id=2886521.2886617|journal=Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence|volume=1402|series=AAAI'15|pages=2131–2137|isbn=978-0262511292|bibcode=2014arXiv1402.3044S|arxiv=1402.3044}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last=Elkind|first=Edith|author-link=Edith Elkind|last2=Faliszewski|first2=Piotr|last3=Skowron|first3=Piotr|last4=Slinko|first4=Arkadii|date=2014-01-01|title=Properties of Multiwinner Voting Rules|url=http://dl.acm.org/citation.cfm?id=2615731.2615743|journal=Proceedings of the 2014 International Conference on Autonomous Agents and Multi-agent Systems|volume=1506|series=AAMAS '14|pages=53–60|isbn=9781450327381|bibcode=2015arXiv150602891E|arxiv=1506.02891}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Procaccia|first=Ariel D.|last2=Rosenschein|first2=Jeffrey S.|last3=Zohar|first3=Aviv|date=2007-04-19|title=On the complexity of achieving proportional representation|journal=Social Choice and Welfare|volume=30|issue=3|pages=353–362|doi=10.1007/s00355-007-0235-2}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last=Lu|first=Tyler|last2=Boutilier|first2=Craig|date=2011-01-01|title=Budgeted Social Choice: From Consensus to Personalized Decision Making|journal=Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence|series=IJCAI'11|pages=280–286|doi=10.5591/978-1-57735-516-8/IJCAI11-057|isbn=9781577355137}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Skowron|first=Piotr|last2=Faliszewski|first2=Piotr|last3=Slinko|first3=Arkadii|date=2015-05-01|title=Achieving fully proportional representation: Approximability results|journal=Artificial Intelligence|volume=222|pages=67–103|doi=10.1016/j.artint.2015.01.003|arxiv=1312.4026}}&lt;/ref&gt;

== See also ==
*[[Algocracy]]
*[[Algorithmic game theory]]
*[[Algorithmic mechanism design]]
*[[Fair cake-cutting|Cake-cutting]]
*[[Fair division]]
*[[Hedonic game]]s

== References ==
{{Reflist|2}}

== External links ==
* [http://www.illc.uva.nl/COMSOC/ The COMSOC website], offering a collection of materials related to computational social choice, such as academic workshops, PhD theses, and a mailing list.

[[Category:Social choice theory]]
[[Category:Voting theory]]
[[Category:Computer science]]</text>
      <sha1>d2su067om2h7qjqkgpdzkltij7hxd57</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer science by country</title>
    <ns>14</ns>
    <id>52508038</id>
    <revision>
      <id>992043964</id>
      <parentid>937652068</parentid>
      <timestamp>2020-12-03T04:51:02Z</timestamp>
      <contributor>
        <username>SomeRandomPasserby</username>
        <id>24207291</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="152" xml:space="preserve">{{Commons category|Computer science by country}}
{{Container category}}
[[Category:Computer science| ]]
[[Category:Science and technology by country| ]]</text>
      <sha1>h1322tcqqc6pppysn9ebiaorsduxa5v</sha1>
    </revision>
  </page>
  <page>
    <title>Computer science in sport</title>
    <ns>0</ns>
    <id>25852537</id>
    <revision>
      <id>928065917</id>
      <parentid>926156140</parentid>
      <timestamp>2019-11-26T16:09:40Z</timestamp>
      <contributor>
        <username>Signimu</username>
        <id>15609787</id>
      </contributor>
      <comment>/* Further reading */ remove predatory journal</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9745" xml:space="preserve">'''Computer science in sport''' is an interdisciplinary discipline that has its goal in combining the theoretical as well as practical aspects and methods of the areas of [[Information technology|informatics]] and [[sport science]]. The main emphasis of the [[interdisciplinarity]] is placed on the application and use of computer-based but also mathematical techniques in sport science, aiming in this way at the support and advancement of theory and practice in sports.&lt;ref&gt;{{cite journal |last1=Link |first1=D. |last2=Lames |first2=M. |title=Sport Informatics - Historical Roots, Interdisciplinarity and Future Developments |journal=International Journal of Computer Science in Sport |date=2009 |volume=8 |issue=Edition 2 |pages=68–87}}&lt;/ref&gt; The reason why [[computer science]] has become an important partner for sport science is mainly connected with "the fact that the use of data and media, the design of models, the analysis of systems etc. increasingly requires the support of suitable tools and concepts which are developed and available in computer science".&lt;ref&gt;{{cite journal |author=Arnold Baca |title=Computer science in sport: an overview of history, present fields and future applications (part I) |year=2006}} IJCSS Special Edition 2/2006, 25-35.&lt;/ref&gt;

== Historical background ==
Going back in history, computers in sports were used for the first time in the 1960s, when the main purpose was to accumulate sports information. [[Database]]s were created and expanded in order to launch documentation and dissemination of publications like articles or books that contain any kind of knowledge related to sports science. Until the mid-1970s also the first organization in this area called IASI (International Association for Sports Information) was formally established. Congresses and meetings were organized more often with the aim of standardization and rationalization of sports documentation. Since at that time this area was obviously less computer-oriented, specialists talk about sports information rather than sports informatics when mentioning the beginning of this field of science.

Based on the progress of computer science and the invention of more powerful computer hardware in the 1970s, also the real history of computer science in sport began.&lt;ref&gt;{{cite journal |author=Jürgen Perl |title=Computer science in sport: an overview of history, present fields and future applications (part II) |year=2006}} IJCSS Special Edition 2/2006, 36-46.&lt;/ref&gt; This was as well the first time when this term was officially used and the initiation of a very important evolution in sports science.

In the early stages of this area statistics on biomechanical data, like different kinds of forces or rates, played a major role. Scientists started to analyze sports games by collecting and looking at such values and features in order to interpret them. Later on, with the continuous improvement of computer hardware - in particular microprocessor speed – many new scientific and computing paradigms were introduced, which were also integrated in computer science in sport. Specific examples are [[Computer model|modeling]] as well as [[simulation]], but also [[pattern recognition]], design, and (sports) [[data mining]].&lt;ref&gt;{{cite journal|author1=Bahadorreza Ofoghi |author2=John Zeleznikow |author3=Clare MacMahon |author4=Markus Raab |title=Data mining in elite sports: A review and a framework |year=2013 |journal=Measurement in Physical Education and Exercise Science | volume=17 | issue=3 |doi=10.1080/1091367X.2013.805137 |pages=171–186}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author1=Iztok Fister Jr. |author2=Karin Ljubič |author3=Ponnuthrai Nagaratnam Suganthan |author4=Matjaž Perc |author5=Iztok Fister |title=Computational intelligence in sports: Challenges and opportunities within a new research domain |year=2015 |journal=Applied Mathematics and Computation | volume=262 |doi=10.1016/j.amc.2015.04.004 |pages=178–186}}&lt;/ref&gt;

As another result of this development, the term 'computer science in sport' has been added in the encyclopedia of sports science in 2004.

== Areas of research ==
The importance and strong influence of computer science as an interdisciplinary partner for sport and sport science is mainly proven by the research activities in computer science in sport. The following IT concepts are thereby of particular interest:

* [[Data acquisition]] and [[data processing]]
* Databases and [[expert system]]s
* Modelling (mathematical, IT based, biomechanical, physiological)
* Simulation (interactive, animation etc.)
* Presentation

Based on the fields from above, the main areas of research in computer science in sport include amongst others:

* [[Training]] and coaching
* [[Biomechanics]]
* [[Sports equipment]] and technology
* Computer-aided applications (software, hardware) in sports
* [[Ubiquitous computing]] in sports
* [[Multimedia]] and [[Internet]]
* Documentation
* Education

== Research communities ==
A clear demonstration for the evolution and propagation towards computer science in sport is also the fact that nowadays people do research in this area all over the world. Since the 1990s many new national and international organizations regarding the topic of computer science in sport were established. These associations are regularly organizing congresses and workshops with the aim of dissemination as well as exchange of scientific knowledge and information on all sort of topics regarding the interdisciplinary discipline.

=== Historical survey ===
As a first example, in [[Australia]] and [[New Zealand]] scientists have built up the MathSport group of [[ANZIAM]] (Australia and New Zealand Industrial and Applied Mathematics), which since 1992 organizes biennial meetings, initially under the name "Mathematics and Computers in Sport Conferences", and now "[[MathSport]]".&lt;ref&gt;[http://www.anziam.org.au/MathSport MathSport], www.anziam.org.au&lt;/ref&gt; Main topics are mathematical models and computer applications in sports, as well as coaching and teaching methods based on informatics.

The European community was also among the leading motors of the emergence of the field. Some workshops on this topic were successfully organized in Germany since the late 1980s. In 1997 the first international meeting on computer science in sport was held in Cologne. The main aim was to spread out and share applications, ideas and concepts of the use of computers in sports, which should also make a contribution to the creation of internationalization and thus to boost research work in this area.

Since then, such international symposia took place every two years all over Europe. As the first conferences were a raving success, it was decided to go even further and the foundation of an organization was the logical consequence. This step was accomplished in 2003, when the International Association of Computer Science in Sport (IACSS) was established during the 4th international symposium in Barcelona, when Prof. Jürgen Perl was also chosen as the first president. A few years earlier, the first international e-journal on this topic (International Journal of Computer Science in Sport) was released already. The internationalization is confirmed moreover by the fact that three conferences already took place outside of Europe - in [[Calgary]] ([[Canada]]) in 2007, [[Canberra]] ([[Australia]]) in 2009 and [[Shanghai]] ([[China]]) in 2011. During the symposium in Calgary additionally the president position changed - it has been assigned to Prof. Arnold Baca, who has been re-elected in 2009 and 2011. The following Symposia on Computer Science in Sport took place in Europe again, in [[Istanbul]] ([[Turkey]]) in 2013 and in [[Loughborough]] ([[UK]]) in 2015. In 2017 the 11th Symposium of Computer Science in Sport took place in [[Constance]] ([[Germany]]). During the conference in Istanbul Prof. Martin Lames was elected as president of the IACSS. He was re-elected in 2015, 2017 and 2019.
The 12th International Symposium of Computer Science in Sports was held in [[Moscow]] ([[Russia]]) from 8 to 10 July 2019: https://iacss2019.ru/

=== National organizations ===
In addition to the international associations from above, currently the following national associations on computer science in sport exist (if available, the web addresses are also given):

* Austrian Association of Computer Science in Sport - http://www.sportinformatik.at
* British Association of Computer Science in Sport and Exercise
* Chinese Association of Computer Science in Sport
* Croatian Association of Computer Science in Sport
* Section Computer Science in Sport of the German Association of Sport Science - http://www.dvs-sportinformatik.de (in German)
* Swiss Association of Computer Science in Sport SACSS - http://sacss.org
* Indian Federation of Computer Science in Sport - http://www.ifcss.in
* Portuguese Association of Computer Science in Sport
* Turkish Association of Computer Science in Sport
* Russian Association of Computer Science in Sport - https://www.racss.ru/

== References ==
{{reflist|2}}

== Further reading ==
* Baca, A. (2015). Computer Science in Sport - Research and practice, Routledge. {{ISBN|978-1-315-88178-2}}

== External links ==
* [http://www.anziam.org.au/MathSport/ MathSport - ANZIAM (Australia and New Zealand Industrial and Applied Mathematics)]
* [https://web.archive.org/web/20090803130839/http://www.ecss.de/ ECSS (European College of Sport Science)]
* [http://www.sportsengineering.co.uk ISEA (International Sports Engineering Association)]
* [http://www.iacss.org IACSS (International Association of Computer Science in Sport)]

{{DEFAULTSORT:Computer Science In Sport}}
[[Category:Computer science|Sport]]
[[Category:Sports science]]</text>
      <sha1>kaxnfny4rcwo6lqo14fzu9ejq54rsio</sha1>
    </revision>
  </page>
  <page>
    <title>Trace cache</title>
    <ns>0</ns>
    <id>51997537</id>
    <revision>
      <id>997031474</id>
      <parentid>997031270</parentid>
      <timestamp>2020-12-29T18:15:15Z</timestamp>
      <contributor>
        <ip>67.198.37.16</ip>
      </contributor>
      <comment>/* Necessity */ missing articles</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9564" xml:space="preserve">[[File:TraceCache.png|thumb|Working of a trace cache|456x456px]]
In [[computer architecture]], a '''trace cache''' or '''execution trace cache''' is a specialized [[instruction cache]] which stores the dynamic stream of [[instruction (computer science)|instructions]] known as '''trace'''. It helps in increasing the instruction fetch [[bandwidth (computing)|bandwidth]] and decreasing power consumption (in the case of [[Intel]] [[Pentium 4]]) by storing traces of instructions that have already been fetched and decoded.&lt;ref name=":0" /&gt; A '''trace processor'''&lt;ref&gt;Eric Rotenberg, Quinn Jacobson, Yiannakis Sazeides, and James E. Smith. [http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.150.3091&amp;rank=1&amp;q=trace%20processor&amp;osm=&amp;ossid= Trace Processors]. Proceedings of the''30th IEEE/ACM International Symposium on Microarchitecture (MICRO-30)'', pp. 138-148, December 1997&lt;/ref&gt; is an architecture designed around the trace cache and processes the instructions at trace level granularity. The formal mathematical theory of traces is described by [[trace monoid]]s.

== Background ==
The earliest academic publication of trace cache was "Trace Cache: a Low Latency Approach to High Bandwidth Instruction Fetching".&lt;ref name=":0"&gt;{{Cite journal|last=Rotenberg|first=Eric|last2=Bennett|first2=Steve|last3=Smith|first3=James E.|last4=Rotenberg|first4=Eric|date=1996-01-01|title=Trace Cache: a Low Latency Approach to High Bandwidth Instruction Fetching|url=http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.140.2177|journal=In Proceedings of the 29th International Symposium on Microarchitecture|pages=24–34}}&lt;/ref&gt; This widely acknowledged paper was presented by Eric Rotenberg, Steve Bennett, and Jim Smith at 1996 [[International Symposium on Microarchitecture]] (MICRO) conference. An earlier publication is US patent 5381533,&lt;ref&gt;{{Citation|last=Peleg|first=Alexander|title=Dynamic flow instruction cache memory organized around trace segments independent of virtual address line|date=Jan 10, 1995|url=http://www.google.com/patents/US5381533|last2=Weiser|first2=Uri|accessdate=2016-10-18}}&lt;/ref&gt; by Alex Peleg and Uri Weiser of Intel, "Dynamic flow instruction cache memory organized around trace segments independent of virtual address line", a continuation of an application filed in 1992, later abandoned.

== Necessity  ==
Wider [[superscalar processor]]s demand multiple instructions to be fetched in a single cycle for higher performance. Instructions to be fetched are not always in contiguous memory locations ([[basic block]]s) because of [[branch instruction|branch]] and [[jump instruction|jump]] instructions. So processors need additional logic and hardware support to fetch and align such instructions from non-contiguous basic blocks. If multiple branches are predicted  as ''not-taken'', then processors can fetch instructions from multiple contiguous basic blocks in a single cycle. However, if any of the branches is predicted as ''taken'', then processor should fetch instructions from the taken path in that same cycle. This limits the fetch capability of a processor.
[[File:BasicBlocks.png|thumb|Basic blocks of a simple [[if-else]] loop|240x240px]]
Consider these four basic blocks (&lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt;, &lt;code&gt;D&lt;/code&gt;) as shown in the figure that correspond to a simple [[if-else]] loop. These blocks will be stored [[Contiguous data storage|contiguous]]ly as &lt;code&gt;ABCD&lt;/code&gt; in the memory. If the branch &lt;code&gt;D&lt;/code&gt; is predicted ''not-taken,'' the fetch unit can fetch the basic blocks &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt; which are placed contiguously. However, if &lt;code&gt;D&lt;/code&gt; is predicted ''taken'', the fetch unit has to fetch &lt;code&gt;A&lt;/code&gt;,&lt;code&gt;B&lt;/code&gt;,&lt;code&gt;D&lt;/code&gt; which are non-contiguously placed. Hence, fetching these blocks which are non contiguously placed, in a single cycle will be very difficult. So, in situations like these trace cache comes in aid to the processor.

Once fetched, the trace cache stores the instructions in their dynamic sequence. When these instructions are encountered again, the trace cache allows the instruction fetch unit of a processor to fetch several basic blocks from it without having to worry about branches in the execution flow. Instructions will be stored in the trace cache either after they have been decoded, or as they are retired. However, instruction sequence is speculative if they are stored just after decode stage.

== Trace structure ==
A trace, also called a dynamic instruction sequence, is an entry in the trace cache. It can be characterized by ''maximum number of instructions'' and ''maximum basic blocks''. Traces can start at any dynamic instruction. Multiple traces can have same starting instruction i.e., same starting [[program counter]] (PC) and instructions from different basic blocks as per the branch outcomes. For the figure above,  ABC and ABD are valid traces. They both start at the same PC (address of A) and have different basic blocks as per D's prediction.

Traces usually terminate when one of the following occurs:
# Trace got filled with allowable ''maximum number of instructions'' 
# Trace has allowable maximum basic blocks
# Return instructions
# Indirect branches
# System calls

=== Trace control information ===
A single trace will have following information:
* Starting PC - PC of the first instruction in trace  
* Branch flag - ( ''maximum basic blocks -1'') branch predictions
* Branch mask - number of branches in the trace and whether trace ends in a branch or not
* Trace fall through - Next PC if last instruction is ''not-taken'' branch or not a branch
* Trace target - address of last branch's taken target

== Trace cache design ==
Following are the factors that need to be considered while designing a trace cache.
* Trace selection policies -  ''maximum number of instructions'' and  ''maximum basic blocks in a trace''
* [[Cache associativity|Associativity]] - number of ways a cache can have 
* Cache indexing method - concatenation or [[XOR]] with PC bits
* Path associativity - traces with same starting PC but with different basic blocks can be mapped to different sets  
* Trace cache fill choices -
*# After decode stage (speculative)
*# After retire stage
A trace cache is not on the critical path of instruction fetch&lt;ref name=":1"&gt;Leon Gu; Dipti Motiani (October 2003). [https://www.cs.cmu.edu/afs/cs/academic/class/15740-f03/www/lectures/TraceCache_slides.pdf "Trace Cache"] (PDF). Retrieved2013-10-06.
&lt;/ref&gt;

== Hit/miss logic ==
Trace lines are stored in the trace cache based on the PC of the first instruction in the trace and a set of branch predictions. This allows for storing different trace paths that start on the same address, each representing different branch outcomes. This method of tagging helps to provide path associativity to the trace cache. Other method can include having only starting PC as tag in trace cache. In the instruction fetch stage of a [[instruction pipeline|pipeline]], the current PC along with a set of branch predictions is checked in the trace cache for a [[cache hit|hit]]. If there is a hit, a trace line is supplied to fetch unit which does not have to go to a regular cache or to memory for these instructions. The trace cache continues to feed the fetch unit until the trace line ends or until there is a [[misprediction]] in the pipeline. If there is a miss, a new trace starts to be built.

The Pentium 4's execution trace cache stores [[micro-operations]] resulting from decoding [[X86 instruction listings|x86 instructions]], providing also the functionality of a micro-operation cache. Having this, the next time an instruction is needed, it does not have to be decoded into micro-ops again.&lt;ref&gt;[[Agner Fog]] (2014-02-19). [http://www.agner.org/optimize/microarchitecture.pdf "The microarchitecture of Intel, AMD and VIA CPUs: An optimization guide for assembly programmers and compiler makers"] (PDF). ''agner.org''. Retrieved 2014-03-21.&lt;/ref&gt;

== Disadvantages ==
The disadvantages of trace cache are:
# Redundant instruction storage between trace cache and instruction cache and within trace cache itself.&lt;ref&gt;{{Cite web|url=http://webcache.googleusercontent.com/search?q=cache:gljZlApiEfsJ:www.cs.virginia.edu/~mc2zk/cs451/mco_tc.ppt+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us|title=Trace Cache|last=Co|first=Michele|date=|website=|publisher=www.cs.virginia.edu|access-date=2016-10-21}}&lt;/ref&gt; 
# Power inefficiency and hardware complexity&lt;ref name=":1" /&gt;

=== Execution trace cache ===
Within the L1 cache of the [[NetBurst]] CPUs, Intel incorporated its execution trace cache.&lt;ref&gt;https://pdfs.semanticscholar.org/presentation/cfcc/9d5a7480c4ea87e77084386d74aaff9a1ee1.pdf&lt;/ref&gt;&lt;ref&gt;https://web.archive.org/web/20160306140603/http://www.xbitlabs.com/articles/cpu/print/replay.html&lt;/ref&gt; It stores decoded [[micro-operation]]s, so that when executing a new instruction, instead of fetching and decoding the instruction again, the CPU directly accesses the decoded micro-ops from the trace cache, thereby saving considerable time. Moreover, the micro-ops are cached in their predicted path of execution, which means that when instructions are fetched by the CPU from the cache, they are already present in the correct order of execution. Intel later introduced a similar but simpler concept with [[Sandy Bridge]] called [[micro-operation cache]] (UOP cache).

== See also ==
* [[Branch trace]]
* [[CPU cache]]
* [[Instruction cycle]]
* [[Trace monoid]]

== References ==
{{Reflist}}

[[Category:Computer science]]</text>
      <sha1>ejopxo9qny38fhxmf6d0svhmc4prnw1</sha1>
    </revision>
  </page>
  <page>
    <title>Instance selection</title>
    <ns>0</ns>
    <id>53279262</id>
    <revision>
      <id>882670974</id>
      <parentid>880472259</parentid>
      <timestamp>2019-02-10T17:24:39Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: title, template type. Add: series, volume, doi, chapter. Removed parameters. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6482" xml:space="preserve">{{cleanup|date=March 2017|reason=Article needs linked into other articles in WP.}}

'''Instance selection''' (or dataset reduction, or dataset condensation) is an important [[data pre-processing]] step that can be applied in many [[machine learning]] (or [[data mining]]) tasks.&lt;ref name=GARCIA_2015&gt;S. García, J. Luengo, and F. Herrera, Data preprocessing in data mining. Springer, 2015.&lt;/ref&gt; Approaches for instance selection can be applied for reducing the original dataset to a manageable volume, leading to a reduction of the computational resources that are necessary for performing the learning process. Algorithms of instance selection can also be applied for removing noisy instances, before applying learning algorithms. This step can improve the accuracy in classification problems.

Algorithm for instance selection should identify a subset of the total available data to achieve the original purpose of the data mining (or machine learning) application as if the whole data had been used. Considering this, the optimal outcome of IS would be the minimum data subset that can accomplish the same task with no performance loss, in comparison with the performance achieved when the task is performed using the whole available data. Therefore, every instance selection strategy should deal with a trade-off between the reduction rate of the dataset and the classification quality.

== Instance selection algorithms ==

The literature provides several different algorithms for instance selection. They can be distinguished from each other according to several different criteria. Considering this, instance selection algorithms can be grouped in two main classes, according to what instances they select: algorithms that preserve the instances at the boundaries of classes and algorithms that preserve the internal instances of the classes. Within the category of algorithms that select instances at the boundaries it is possible to cite DROP3,&lt;ref name=DROP_2000&gt;D. R. Wilson and T. R. Martinez, Reduction techniques for instance-based learning algorithms, Machine learning, vol. 38, no. 3, pp. 257–286, 2000.&lt;/ref&gt; ICF&lt;ref name=ICF_2002&gt;H. Brighton and C. Mellish, Advances in instance selection for instance-based learning algorithms, Data mining and knowledge discovery, vol. 6, no. 2, pp. 153–172, 2002.&lt;/ref&gt; and LSBo.&lt;ref name=LSBo_LSSm_2015&gt;E. Leyva, A. González, and R. Pérez, Three new instance selection methods based on local sets: A comparative study with several approaches from a bi-objective perspective, Pattern Recognition, vol. 48, no. 4, pp. 1523–1537, 2015.&lt;/ref&gt; On the other hand, within the category of algorithms that select internal instances, it is possible to mention ENN&lt;ref name=ENN_1972&gt;D. L. Wilson, “Asymptotic properties of nearest neighbor rules using edited data,” Systems, Man and Cybernetics, IEEE Transactions on, no. 3, pp. 408–421, 1972.&lt;/ref&gt; and LSSm.&lt;ref name=LSBo_LSSm_2015 /&gt; In general, algorithm such as ENN and LSSm are used for removing harmful (noisy) instances from the dataset. They do not reduce the data as the algorithms that select border instances, but they remove instances at the boundaries that have a negative impact on the data mining task. They can be used by other instance selection algorithms, as a filtering step. For example, the ENN algorithm is used by DROP3 as the first step, and the LSSm algorithm is used by LSBo.

There is also another group of algorithms that adopt different selection criteria. For example, the algorithms LDIS,&lt;ref name=LDIS_2015&gt;Carbonera, Joel Luis, and Mara Abel. A density-based approach for instance selection. IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI), 2015.&lt;/ref&gt; CDIS&lt;ref name=CDIS_2016&gt;Carbonera, Joel Luis, and Mara Abel. A novel density-based approach for instance selection. IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI), 2016.&lt;/ref&gt; and XLDIS&lt;ref&gt;{{Citation|last=Carbonera|first=Joel Luís|chapter=An Efficient Approach for Instance Selection|date=2017|pages=228–243|publisher=Springer International Publishing|isbn=9783319642826|doi=10.1007/978-3-319-64283-3_17|title=Big Data Analytics and Knowledge Discovery|volume=10440|series=Lecture Notes in Computer Science}}&lt;/ref&gt; select the densest instances in a given arbitrary neighborhood. The selected instances can include both, border and internal instances. The LDIS and CDIS algorithms are very simple and select subsets that are very representative of the original dataset. Besides that, since they search by the representative instances in each class separately, they are faster (in terms of time complexity and effective running time) than other algorithms, such as DROP3 and ICF.

Besides that, there is a third category of algorithms that, instead of selecting actual instances of the dataset, select prototypes (that can be synthetic instances). In this category it is possible to include PSSA,&lt;ref&gt;{{Citation|last=Carbonera|first=Joel Luís|title=An Efficient Prototype Selection Algorithm Based on Spatial Abstraction|date=2018|work=Big Data Analytics and Knowledge Discovery|pages=177–192|publisher=Springer International Publishing|isbn=9783319985381|last2=Abel|first2=Mara|doi=10.1007/978-3-319-98539-8_14}}&lt;/ref&gt; PSDSP&lt;ref&gt;{{Citation|last=Carbonera|first=Joel Luís|title=An Efficient Prototype Selection Algorithm Based on Dense Spatial Partitions|date=2018|work=Artificial Intelligence and Soft Computing|pages=288–300|publisher=Springer International Publishing|isbn=9783319912615|last2=Abel|first2=Mara|doi=10.1007/978-3-319-91262-2_26}}&lt;/ref&gt; and PSSP.&lt;ref name="Carbonera"&gt;{{Cite book|last=Carbonera|first=Joel Luis|last2=Abel|first2=Mara|date=November 2017|title=Efficient Prototype Selection Supported by Subspace Partitions|journal=2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)|publisher=IEEE|doi=10.1109/ictai.2017.00142|isbn=9781538638767}}&lt;/ref&gt; The three algorithms adopt the notion of spatial partition (a hyperrectangle) for identifying similar instances and extract prototypes for each set of similar instances. In general, these approaches can also be modified for selecting actual instances of the datasets. The algorithm ISDSP&lt;ref name="Carbonera"/&gt; adopts a similar approach for selecting actual instances (instead of prototypes).

==References==
{{reflist}}

[[Category:Machine learning]]
[[Category:Data mining]]
[[Category:Computer science]]</text>
      <sha1>i82bfd1n2ufbhmp36q87hqpkzltszpu</sha1>
    </revision>
  </page>
  <page>
    <title>Viola–Jones object detection framework</title>
    <ns>0</ns>
    <id>14669989</id>
    <revision>
      <id>985334147</id>
      <parentid>981481531</parentid>
      <timestamp>2020-10-25T10:30:15Z</timestamp>
      <contributor>
        <ip>102.167.148.169</ip>
      </contributor>
      <comment>Removed false assertion that the Viola–Jones object detection framework was the first object detection framework to work in real time.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14792" xml:space="preserve">{{cleanup rewrite|date=February 2015}}
The '''Viola–Jones object detection framework''' is an [[object detection]] framework which was proposed in 2001 by [[Paul Viola]] and [[Michael Jones (scientist)|Michael Jones]].&lt;ref&gt;[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.6807 Rapid object detection using a boosted cascade of simple features]&lt;/ref&gt;&lt;ref&gt;[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.110.4868 Viola, Jones: Robust Real-time Object Detection, IJCV 2001] See pages 1,3.&lt;/ref&gt; Although it can be trained to detect a variety of object classes, it was motivated primarily by the problem of [[face detection]].

== Problem description ==

The problem to be solved is detection of faces in an image. A human can do this easily, but a computer needs precise instructions and constraints.  To make the task more manageable, Viola–Jones requires full view frontal upright faces. Thus in order to be detected, the entire face must point towards the camera and should not be tilted to either side. While it seems these constraints could diminish the algorithm's utility somewhat, because the detection step is most often followed by a recognition step, in practice these limits on pose are quite acceptable.

== Components of the framework ==
[[Image:Prm VJ fig1 featureTypesWithAlpha.png|thumb|right|Example rectangle features shown relative to the enclosing detection window]]

=== Feature types and evaluation ===
The characteristics of Viola–Jones algorithm which make it a good detection algorithm are:
* Robust – very high detection rate (true-positive rate) &amp; very low false-positive rate always.
* Real time – For practical applications at least 2 frames per second must be processed.
* Face detection only (not recognition) - The goal is to distinguish faces from non-faces (detection is the first step in the recognition process).

The algorithm has four stages:
# Haar Feature Selection
# Creating an Integral Image
# Adaboost Training
# Cascading Classifiers

The features sought by the detection framework universally involve the sums of image pixels within rectangular areas. As such, they bear some resemblance to [[Haar-like feature|Haar basis functions]], which have been used previously in the realm of image-based object detection.&lt;ref&gt;C. Papageorgiou, M. Oren and T. Poggio. A General Framework for Object Detection. ''International Conference on Computer Vision'', 1998&lt;/ref&gt; However, since the features used by Viola and Jones all rely on more than one rectangular area, they are generally more complex. The figure on the right illustrates the four different types of features used in the framework. The value of any given feature is the sum of the pixels within clear rectangles subtracted from the sum of the pixels within shaded rectangles. Rectangular features of this sort are primitive when compared to alternatives such as [[steerable filter]]s. Although they are sensitive to vertical and horizontal features, their feedback is considerably coarser.

[[File:Haar Feature that looks similar to the bridge of the nose is applied onto the face.jpg|thumb|right|Haar Feature that looks similar to the bridge of the nose is applied onto the face]]
[[File:Haar Feature that looks similar to the eye region which is darker than the upper cheeks is applied onto a face.jpg|thumb|right|Haar Feature that looks similar to the eye region which is darker than the upper cheeks is applied onto a face]]
[[File:3rd and 4th kind of Haar Feature.jpg|thumb|right|3rd and 4th kind of Haar Feature]]

==== Haar Features ====
All human faces share some similar properties. These regularities may be matched using '''Haar Features'''.

A few properties common to human faces:
* The eye region is darker than the upper-cheeks.
* The nose bridge region is brighter than the eyes.

Composition of properties forming matchable facial features:
* Location and size: eyes, mouth, bridge of nose
* Value: oriented gradients of pixel intensities

The four features matched by this algorithm are then sought in the image of a face (shown at right).

Rectangle features:
* Value = Σ (pixels in black area) - Σ (pixels in white area)
* Three types: two-, three-, four-rectangles, Viola &amp; Jones used two-rectangle features
* For example: the difference in brightness between the white &amp; black rectangles over a specific area
* Each feature is related to a special location in the sub-window

==== Summed area table ====
An image representation called the [[summed area table|integral image]] evaluates rectangular features in ''constant'' time, which gives them a considerable speed advantage over more sophisticated alternative features. Because each feature's rectangular area is always adjacent to at least one other rectangle, it follows that any two-rectangle feature can be computed in six array references, any three-rectangle feature in eight, and any four-rectangle feature in nine.

=== Learning algorithm ===

The speed with which features may be evaluated does not adequately compensate for their number, however. For example, in a standard 24x24 pixel sub-window, there are a total of {{math|1=''M'' = {{nscn|162336}}}}&lt;ref&gt;{{Cite web|url=https://stackoverflow.com/questions/1707620/viola-jones-face-detection-claims-180k-features|title=Viola-Jones' face detection claims 180k features|website=stackoverflow.com|access-date=2017-06-27}}&lt;/ref&gt; possible features, and it would be prohibitively expensive to evaluate them all when testing an image. Thus, the object detection framework employs a variant of the learning algorithm [[AdaBoost]] to both select the best features and to train classifiers that use them. This algorithm constructs a “strong” classifier as a linear combination of weighted simple “weak” classifiers.

: &lt;math&gt;h(\mathbf{x}) = \sgn\left(\sum_{j=1}^M \alpha_j h_j (\mathbf{x})\right)&lt;/math&gt;

Each weak classifier is a threshold function based on the feature &lt;math&gt;f_j&lt;/math&gt;.

: &lt;math&gt;h_j(\mathbf{x}) = 
\begin{cases}
-s_j &amp;\text{if } f_j &lt; \theta_j\\
s_j &amp;\text{otherwise}
\end{cases}&lt;/math&gt;

The threshold value &lt;math&gt;\theta_j&lt;/math&gt; and the polarity &lt;math&gt;s_j \in \pm 1&lt;/math&gt; are determined in the training, as well as the coefficients &lt;math&gt;\alpha_j&lt;/math&gt;.

Here a simplified version of the learning algorithm is reported:&lt;ref&gt;R. Szeliski, ''Computer Vision, algorithms and applications'', Springer&lt;/ref&gt;

'''Input:''' Set of {{mvar|N}} positive and negative training images with their labels &lt;math&gt;{(\mathbf{x}^i,y^i)}&lt;/math&gt;. If image {{mvar|i}} is a face &lt;math&gt;y^i=1&lt;/math&gt;, if not &lt;math&gt;y^i=-1&lt;/math&gt;.
# Initialization: assign a weight &lt;math&gt;w^i_{1}=\frac{1}{N}&lt;/math&gt; to each image {{mvar|i}}.
# For each feature &lt;math&gt;f_j&lt;/math&gt; with &lt;math&gt;j = 1,...,M&lt;/math&gt;
## Renormalize the weights such that they sum to one.
## Apply the feature to each image in the training set, then find the optimal threshold and polarity &lt;math&gt;\theta_j,s_j&lt;/math&gt; that minimizes the weighted classification error. That is &lt;math&gt;\theta_j,s_j = \arg\min_{\theta,s} \;\sum_{i=1}^N w^i_{j} \varepsilon^i_{j}&lt;/math&gt; where &lt;math&gt;\varepsilon^i_{j} = 
\begin{cases}
0 &amp;\text{if }y^i = h_j(\mathbf{x}^i,\theta_j,s_j)\\
1 &amp;\text{otherwise}
\end{cases}
&lt;/math&gt;
## Assign a weight &lt;math&gt;\alpha_j&lt;/math&gt; to &lt;math&gt;h_j&lt;/math&gt; that is inversely proportional to the error rate. In this way best classifiers are considered more.
## The weights for the next iteration, i.e. &lt;math&gt;w_{j+1}^i&lt;/math&gt;, are reduced for the images {{mvar|i}} that were correctly classified.
# Set the final classifier to &lt;math&gt;h(\mathbf{x}) = \sgn\left(\sum_{j=1}^{M} \alpha_j h_j(\mathbf{x})\right)&lt;/math&gt;

=== Cascade architecture ===

* On average only 0.01% of all sub-windows are positive (faces)
* Equal computation time is spent on all sub-windows
* Must spend most time only on potentially positive sub-windows.
* A simple 2-feature classifier can achieve almost 100% detection rate with 50% FP rate.
* That classifier can act as a 1st layer of a series to filter out most negative windows
* 2nd layer with 10 features can tackle “harder” negative-windows which survived the 1st layer, and so on...
* A cascade of gradually more complex classifiers achieves even better detection rates. The evaluation of the strong classifiers generated by the learning process can be done quickly, but it isn't fast enough to run in real-time. For this reason, the strong classifiers are arranged in a cascade in order of complexity, where each successive classifier is trained only on those selected samples which pass through the preceding classifiers. If at any stage in the cascade a classifier rejects the sub-window under inspection, no further processing is performed and continue on searching the next sub-window. The cascade therefore has the form of a degenerate tree. In the case of faces, the first classifier in the cascade – called the attentional operator – uses only two features to achieve a false negative rate of approximately 0% and a false positive rate of 40%.&lt;ref&gt;[http://research.microsoft.com/~viola/Pubs/Detect/violaJones_IJCV.pdf Viola, Jones: Robust Real-time Object Detection, IJCV 2001] See page 11.&lt;/ref&gt; The effect of this single classifier is to reduce by roughly half the number of times the entire cascade is evaluated.

In cascading, each stage consists of a strong classifier. So all the features are grouped into several stages where each stage has certain number of features.

The job of each stage is to determine whether a given sub-window is definitely not a face or may be a face. A given sub-window is immediately discarded as not a face if it fails in any of the stages.

A simple framework for cascade training is given below:

* f = the maximum acceptable false positive rate per layer.
* d = the minimum acceptable detection rate per layer.
* Ftarget = target overall false positive rate.
* P = set of positive examples.
* N = set of negative examples.

 F(0) = 1.0; D(0) = 1.0; i = 0
 
 '''while''' F(i) &gt; Ftarget
     '''increase''' i
     n(i) = 0; F(i)= F(i-1)
 
     '''while''' F(i) &gt; f &amp;times; F(i-1)
         '''increase''' n(i)
         use P and N to train a classifier with n(I) features using [[AdaBoost]]
         Evaluate current cascaded classifier on validation set to determine F(i) and D(i)
         '''decrease''' threshold for the ith classifier (i.e. how many weak classifiers need to accept for strong classifier to accept)
             '''until''' the current cascaded classifier has a detection rate of at least d &amp;times; D(i-1) (this also affects F(i))
     N = ∅
     '''if''' F(i) &gt; Ftarget '''then''' 
         evaluate the current cascaded detector on the set of non-face images 
         and put any false detections into the set N.

The cascade architecture has interesting implications for the performance of the individual classifiers. Because the activation of each classifier depends entirely on the behavior of its predecessor, the false positive rate for an entire cascade is:

: &lt;math&gt;F = \prod_{i=1}^K f_i.&lt;/math&gt;

Similarly, the detection rate is:

: &lt;math&gt;D = \prod_{i=1}^K d_i.&lt;/math&gt;

Thus, to match the false positive rates typically achieved by other detectors, each classifier can get away with having surprisingly poor performance. For example, for a 32-stage cascade to achieve a false positive rate of {{10^|-6}}, each classifier need only achieve a false positive rate of about 65%. At the same time, however, each classifier needs to be exceptionally capable if it is to achieve adequate detection rates. For example, to achieve a detection rate of about 90%, each classifier in the aforementioned cascade needs to achieve a detection rate of approximately 99.7%.&lt;ref&gt;{{cite book |last1=Torbert |first1=Shane |title=Applied Computer Science |date=2016 |publisher=Springer |pages=122–131 |edition=2nd}}&lt;/ref&gt;

== Using Viola–Jones for object tracking ==

In videos of moving objects, one need not apply object detection to each frame. Instead, one can use tracking algorithms like the [[Kanade–Lucas–Tomasi feature tracker|KLT algorithm]] to detect salient features within the detection bounding boxes and track their movement between frames. Not only does this improve tracking speed by removing the need to re-detect objects in each frame, but it improves the robustness as well, as the salient features are more resilient than the Viola-Jones detection framework to rotation and photometric changes.&lt;ref&gt;[http://in.mathworks.com/help/vision/examples/face-detection-and-tracking-using-the-klt-algorithm.html Face Detection and Tracking using the KLT algorithm]&lt;/ref&gt;

== References ==
&lt;references/&gt;

== External links ==

* [http://www.slideshare.net/wolf/avihu-efrats-viola-and-jones-face-detection-slides/ Slides Presenting the Framework]
* [http://mathworld.wolfram.com/HaarFunction.html Information Regarding Haar Basis Functions]
* [https://sites.google.com/site/leeplus/publications/learningsurfcascadeforfastandaccurateobjectdetection Extension of Viola–Jones framework using SURF feature]
* [http://www.burgsys.com/mumi-image-mining-community.php IMMI - Rapidminer Image Mining Extension] - open-source tool for image mining
* [http://www.vision.caltech.edu/html-files/EE148-2005-Spring/pprs/viola04ijcv.pdf Robust Real-Time Face Detection]
* [http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6269796 An improved algorithm on Viola-Jones object detector]
* [https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G2-nFaIAAAAJ&amp;citation_for_view=G2-nFaIAAAAJ:u5HHmVD_uO8C Citations of the Viola–Jones algorithm in Google Scholar]
* {{YouTube|WfdYYNamHZ8|Video lecture on Viola–Jones algorithm}} - Adaboost Explanation from ppt by Qing Chen, Discovery Labs, University of Ottawa and a video lecture by Ramsri Goutham.

=== Implementations ===
* [http://etd.dtu.dk/thesis/223656/ep08_93.pdf Implementing the Viola–Jones Face Detection Algorithm] by Ole Helvig Jensen
* MATLAB: [http://www.mathworks.com/matlabcentral/fileexchange/29437-viola-jones-object-detection], [http://in.mathworks.com/help/vision/ref/vision.cascadeobjectdetector-class.html]
* OpenCV: implemented as &lt;code&gt;cvHaarDetectObjects()&lt;/code&gt;.
** [https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html Haar Cascade Detection in OpenCV]
** [http://docs.opencv.org/doc/user_guide/ug_traincascade.html Cascade Classifier Training in OpenCV]

{{DEFAULTSORT:Viola-Jones object detection framework}}
[[Category:Object recognition and categorization]]
[[Category:Face recognition]]
[[Category:Articles with example code]]
[[Category:Articles with example MATLAB/Octave code]]
[[Category:Articles with example pseudocode]]
[[Category:Gesture recognition]]
[[Category:Computer science]]
[[Category:Computer vision]]</text>
      <sha1>hy44w1yg7sojxqstcla3ji08xnib7bn</sha1>
    </revision>
  </page>
  <page>
    <title>Reduction Operator</title>
    <ns>0</ns>
    <id>51669182</id>
    <revision>
      <id>997324349</id>
      <parentid>975742657</parentid>
      <timestamp>2020-12-31T00:17:25Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: hdl added to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="19223" xml:space="preserve">In [[computer science]], the '''reduction operator'''&lt;ref&gt;Reduction Clause&lt;/ref&gt; is a type of [[Operator (computer programming)|operator]] that is commonly used in [[Parallel computing|parallel programming]] to reduce the elements of an array into a single result. Reduction operators are [[Associative property|associative]] and often (but not necessarily) [[Commutative property|commutative]].&lt;ref name=":1"&gt;Solihin&lt;/ref&gt;&lt;ref name=":0"&gt;Chandra p. 59&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Cole|first=Murray|year=2004|title=Bringing skeletons out of the closet: a pragmatic manifesto for skeletal parallel programming|journal=Parallel Computing|volume=30|issue=3|page=393|doi=10.1016/j.parco.2003.12.002|url=https://www.pure.ed.ac.uk/ws/files/13653174/1_s2.0_S0167819104000080_main.pdf}}&lt;/ref&gt; The reduction of sets of elements is an integral part of programming models such as [[MapReduce|Map Reduce]], where a reduction operator is applied ([[Map (higher-order function)|mapped]]) to all elements before they are reduced. Other [[parallel algorithm]]s use reduction operators as primary operations to solve more complex problems. Many reduction operators can be used for broadcasting to distribute data to all processors.

==Theory==
A reduction operator can help break down a task into various partial tasks by calculating partial results which can be used to obtain a final result. It allows certain serial operations to be performed in parallel and the number of steps required for those operations to be reduced. A reduction operator stores the result of the partial tasks into a private copy of the variable. These private copies are then merged into a shared copy at the end.

An operator is a reduction operator if:
* It can reduce an array to a single scalar value.&lt;ref name=":1" /&gt;
* The final result should be obtainable from the results of the partial tasks that were created.&lt;ref name=":1" /&gt;
These two requirements are satisfied for commutative and associative operators that are applied to all array elements.

Some operators which satisfy these requirements are addition, multiplication, and some logical operators (and, or, etc.).

A reduction operator &lt;math&gt;\oplus&lt;/math&gt; can be applied in constant time on an input set &lt;math&gt;V = \{v_0 = \begin{pmatrix} e_0^0 \\ \vdots \\ e_0^{m-1}\end{pmatrix}, v_1 = \begin{pmatrix} e_1^0 \\ \vdots \\ e_1^{m-1}\end{pmatrix}, \dots, v_{p-1} = \begin{pmatrix} e_{p-1}^0 \\ \vdots \\ e_{p-1}^{m-1}\end{pmatrix}\}&lt;/math&gt;of &lt;math&gt;p&lt;/math&gt; vectors with &lt;math&gt;m&lt;/math&gt; elements each. The result &lt;math&gt;r&lt;/math&gt; of the operation is the combination of the elements &lt;math&gt;r = \begin{pmatrix} e_0^0 \oplus e_1^0 \oplus \dots \oplus e_{p-1}^0 \\ \vdots \\ e_0^{m-1} \oplus e_1^{m-1} \oplus \dots \oplus e_{p-1}^{m-1}\end{pmatrix} = \begin{pmatrix} \bigoplus_{i=0}^{p-1} e_i^0 \\ \vdots \\ \bigoplus_{i=0}^{p-1} e_i^{m-1} \end{pmatrix}&lt;/math&gt; and has to be stored at a specified root processor at the end of the execution. If the result &lt;math&gt;r&lt;/math&gt; has to be available at every processor after the computation has finished, it is often called Allreduce. An optimal sequential linear-time algorithm for reduction can apply the operator successively from front to back, always replacing two vectors with the result of the operation applied to all its elements, thus creating an instance that has one vector less. It needs &lt;math&gt;(p-1)\cdot m &lt;/math&gt; steps until only &lt;math&gt;r&lt;/math&gt; is left. Sequential algorithms can not perform better than linear time, but parallel algorithms leave some space left to optimize.

=== Example ===
Suppose we have an array &lt;math&gt;[2, 3, 5, 1, 7, 6, 8, 4]&lt;/math&gt;. The sum of this array can be computed serially by sequentially reducing the array into a single sum using the '+' operator. Starting the summation from the beginning of the array yields:

&lt;math&gt;\Bigg( \bigg( \Big( \big(\, (\, (2 + 3) + 5 ) + 1 \big) + 7\Big) + 6 \bigg) + 8\Bigg) + 4 = 36&lt;/math&gt;

Since '+' is both commutative and associative, it is a reduction operator. Therefore this reduction can be performed in parallel using several cores, where each core computes the sum of a subset of the array, and the reduction operator merges the results. Using a [[binary tree]] reduction would allow 4 cores to compute &lt;math&gt;(2 + 3)&lt;/math&gt;, &lt;math&gt;(5 + 1)&lt;/math&gt;, &lt;math&gt;(7 + 6)&lt;/math&gt;, and &lt;math&gt;(8 + 4)&lt;/math&gt;. Then two cores can compute &lt;math&gt;(5 + 6)&lt;/math&gt; and &lt;math&gt;(13 + 12)&lt;/math&gt;, and lastly a single core computes &lt;math&gt;(11 + 25) = 36&lt;/math&gt;. So a total of 4 cores can be used to compute the sum in &lt;math&gt;\log_{2}8 = 3&lt;/math&gt; steps instead of the &lt;math&gt;7&lt;/math&gt; steps required for the serial version. This parallel binary tree technique computes &lt;math&gt;\big(\,(2 + 3) + (5 + 1)\,\big) + \big(\,(7 + 6) + (8 + 4)\,\big)&lt;/math&gt;. Of course the result is the same, but only because of the associativity of the reduction operator. The commutativity of the reduction operator would be important if there were a master core distributing work to several processors, since then the results could arrive back to the master processor in any order. The property of commutativity guarantees that the result will be the same.

=== Nonexample ===

[[Matrix multiplication]] is '''not''' a reduction operator since the operation is not commutative. If processes were allowed to return their matrix multiplication results in any order to the master process, the final result that the master computes will likely be incorrect if the results arrived out of order. However, note that matrix multiplication is associative, and therefore the result would be correct as long as the proper ordering were enforced, as in the binary tree reduction technique.

== Algorithms ==
=== Binomial tree algorithms ===
Regarding parallel algorithms, there are two main models of parallel computation, the [[Parallel random-access machine|parallel random access machine]] as an extension of the RAM with shared memory between processing units and the [[Bulk synchronous parallel|bulk synchronous parallel computer]] which takes communication and [[Synchronization (computer science)|synchronization]] into account. Both models have different implications for the [[Time complexity|time-complexity]], therefore two algorithms will be shown.

==== PRAM-algorithm ====
This algorithm represents a widely spread method to handle inputs where &lt;math&gt;p&lt;/math&gt; is a power of two. The reverse procedure is often used for broadcasting elements.&lt;ref&gt;{{Cite journal|last1=Bar-Noy|first1=Amotz|last2=Kipnis|first2=Shlomo|title=Broadcasting multiple messages in simultaneous send/receive systems|journal=Discrete Applied Mathematics|volume=55|issue=2|pages=95–105|doi=10.1016/0166-218x(94)90001-9|year=1994}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Santos|first=Eunice E.|title=Optimal and Efficient Algorithms for Summing and Prefix Summing on Parallel Machines|journal=Journal of Parallel and Distributed Computing|volume=62|issue=4|pages=517–543|doi=10.1006/jpdc.2000.1698|year=2002}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Slater|first1=P.|last2=Cockayne|first2=E.|last3=Hedetniemi|first3=S.|date=1981-11-01|title=Information Dissemination in Trees|journal=SIAM Journal on Computing|volume=10|issue=4|pages=692–701|doi=10.1137/0210052|issn=0097-5397}}&lt;/ref&gt;[[File:Binomial tree.gif|thumb|436x436px|
Visualization of the algorithm with p = 8, m = 1, and addition as the reduction operator
]]
: '''for''' &lt;math&gt;k \gets 0&lt;/math&gt; '''to''' &lt;math&gt;\lceil\log_2 p\rceil - 1&lt;/math&gt; '''do'''
:: '''for''' &lt;math&gt;i \gets 0&lt;/math&gt; '''to''' &lt;math&gt;p - 1&lt;/math&gt; '''do in parallel'''
::: '''if''' &lt;math&gt;p_i&lt;/math&gt;  '''is active then'''
:::: '''if bit''' &lt;math&gt;k&lt;/math&gt; '''of''' &lt;math&gt;i&lt;/math&gt; '''is set then'''
::::: '''set''' &lt;math&gt;p_i&lt;/math&gt; '''to inactive'''
:::: '''else if''' &lt;math&gt;i + 2^k &lt; p&lt;/math&gt; 
::::: &lt;math&gt;x_i \gets x_i \oplus^{\star} x_{i+2^k}&lt;/math&gt;
The binary operator for vectors is defined element-wise such that &lt;math&gt;\begin{pmatrix} e_i^0 \\ \vdots \\ e_i^{m-1}\end{pmatrix} \oplus^\star \begin{pmatrix} e_j^0 \\ \vdots \\ e_j^{m-1}\end{pmatrix} = \begin{pmatrix} e_i^0 \oplus e_j^0 \\ \vdots \\ e_i^{m-1} \oplus e_j^{m-1} \end{pmatrix}&lt;/math&gt;. The algorithm further assumes that in the beginning &lt;math&gt;x_i = v_i&lt;/math&gt; for all &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;p&lt;/math&gt; is a power of two and uses the processing units &lt;math&gt;p_0, p_1,\dots p_{n-1}&lt;/math&gt;. In every iteration, half of the processing units become inactive and do not contribute to further computations. The figure shows a visualization of the algorithm using addition as the operator. Vertical lines represent the processing units where the computation of the elements on that line take place. The eight input elements are located on the bottom and every animation step corresponds to one parallel step in the execution of the algorithm. An active processor &lt;math&gt;p_i&lt;/math&gt; evaluates the given operator on the element &lt;math&gt;x_i&lt;/math&gt; it is currently holding and &lt;math&gt;x_j&lt;/math&gt; where &lt;math&gt;j&lt;/math&gt; is the minimal index fulfilling &lt;math&gt;j &gt; i&lt;/math&gt;, so that &lt;math&gt;p_j&lt;/math&gt; is becoming an inactive processor in the current step. &lt;math&gt;x_i&lt;/math&gt; and &lt;math&gt;x_j&lt;/math&gt; are not necessarily elements of the input set &lt;math&gt;X&lt;/math&gt; as the fields are overwritten and reused for previously evaluated expressions. To coordinate the roles of the processing units in each step without causing additional communication between them, the fact that the processing units are indexed with numbers from &lt;math&gt;0&lt;/math&gt; to &lt;math&gt;p-1&lt;/math&gt; is used. Each processor looks at its &lt;math&gt;k&lt;/math&gt;-th least significant bit and decides whether to get inactive or compute the operator on its own element and the element with the index where the &lt;math&gt;k&lt;/math&gt;-th bit is not set. The underlying communication pattern of the algorithm is a binomial tree, hence the name of the algorithm.

Only  &lt;math&gt;p_0&lt;/math&gt; holds the result in the end, therefore it is the root processor. For an Allreduce-operation the result has to be distributed, which can be done by appending a broadcast from &lt;math&gt;p_0&lt;/math&gt;. Furthermore, the number &lt;math&gt;p&lt;/math&gt; of processors is restricted to be a power of two. This can be lifted by padding the number of processors to the next power of two. There are also algorithms that are more tailored for this use-case.&lt;ref&gt;{{Cite book|last1=Rabenseifner|first1=Rolf|last2=Träff|first2=Jesper Larsson|date=2004-09-19|title=More Efficient Reduction Algorithms for Non-Power-of-Two Number of Processors in Message-Passing Parallel Systems|journal=Recent Advances in Parallel Virtual Machine and Message Passing Interface|volume=3241|series=Lecture Notes in Computer Science|language=en|publisher=Springer, Berlin, Heidelberg|pages=36–46|doi=10.1007/978-3-540-30218-6_13|isbn=9783540231639}}&lt;/ref&gt;

===== Runtime analysis =====
The main loop is executed &lt;math&gt;\lceil\log_2 p\rceil&lt;/math&gt; times, the time needed for the part done in parallel is in &lt;math&gt;\mathcal{O}(m)&lt;/math&gt; as a processing unit either combines two vectors or becomes inactive. Thus the parallel time &lt;math&gt;T(p, m)&lt;/math&gt; for the PRAM is &lt;math&gt;T(p, m) = \mathcal{O}(\log(p) \cdot m)&lt;/math&gt;. The strategy for handling read and write conflicts can be chosen as restrictive as an exclusive read and exclusive write (EREW). The speedup &lt;math&gt;S(p, m)&lt;/math&gt; of the algorithm is &lt;math&gt;S(p, m) \in \mathcal{O}\left(\frac{T_{seq}}{T(p, m)}\right) = \mathcal{O}\left(\frac{p}{\log(p)}\right)&lt;/math&gt; and therefore the [[Analysis of parallel algorithms|efficiency]] is &lt;math&gt;E(p, m) \in \mathcal{O}\left(\frac{S(p, m)}{p}\right) = \mathcal{O}\left(\frac{1}{\log(p)}\right)&lt;/math&gt;. The efficiency suffers because of the fact that half of the active processing units become inactive after each step, so &lt;math&gt;\frac{p}{2^i}&lt;/math&gt; units are active in step &lt;math&gt;i&lt;/math&gt;.

==== Distributed memory algorithm ====
In contrast to the PRAM-algorithm, in the [[distributed memory]] model memory is not shared between processing units and data has to be exchanged explicitly between processing units. Therefore, data has to be exchanged explicitly between units, as can be seen in the following algorithm.
: '''for''' &lt;math&gt;k \gets 0&lt;/math&gt; '''to''' &lt;math&gt;\lceil\log_2 p\rceil - 1&lt;/math&gt; '''do'''
:: '''for''' &lt;math&gt;i \gets 0&lt;/math&gt; '''to''' &lt;math&gt;p - 1&lt;/math&gt; '''do in parallel'''
::: '''if''' &lt;math&gt;p_i&lt;/math&gt;  '''is active then'''
:::: '''if bit''' &lt;math&gt;k&lt;/math&gt; '''of''' &lt;math&gt;i&lt;/math&gt; '''is set then'''
::::: '''send''' &lt;math&gt;x_i&lt;/math&gt; '''to''' &lt;math&gt;p_{i-2^k}&lt;/math&gt;
::::: '''set''' &lt;math&gt;p_k&lt;/math&gt; '''to inactive'''
:::: '''else if''' &lt;math&gt;i + 2^k &lt; p&lt;/math&gt;
::::: '''receive''' &lt;math&gt;x_{i+2^k}&lt;/math&gt; 
::::: &lt;math&gt;x_i \gets x_i \oplus^\star x_{i+2^k}&lt;/math&gt;
The only difference between the distributed algorithm and the PRAM version is the inclusion of explicit communication primitives, the operating principle stays the same.

===== Runtime analysis =====
The communication between units leads to some overhead. A simple analysis for the algorithm uses the BSP-model and incorporates the time &lt;math&gt;T_{start}&lt;/math&gt; needed to initiate communication and &lt;math&gt;T_{byte}&lt;/math&gt; the time needed to send a byte. Then the resulting runtime is &lt;math&gt;\Theta((T_{start} + n \cdot T_{byte})\cdot log(p))&lt;/math&gt;, as &lt;math&gt;m&lt;/math&gt; elements of a vector are sent in each iteration and have size &lt;math&gt;n&lt;/math&gt; in total.

=== Pipeline-algorithm ===
[[File:Pipeline reduce.gif|thumb|476x476px|Visualization of the pipeline-algorithm with p = 5, m = 4 and addition as the reduction operator.]]For distributed memory models, it can make sense to use pipelined communication. This is especially the case when &lt;math&gt;T_{start}&lt;/math&gt; is small in comparison to &lt;math&gt;T_{byte}&lt;/math&gt;. Usually, [[Pipeline (computing)|linear pipelines]] split data or a tasks into smaller pieces and process them in stages. In contrast to the binomial tree algorithms, the pipelined algorithm uses the fact that the vectors are not inseparable, but the operator can be evaluated for single elements:&lt;ref&gt;{{Cite journal|last1=Bar-Noy|first1=A.|last2=Kipnis|first2=S.|date=1994-09-01|title=Designing broadcasting algorithms in the postal model for message-passing systems|journal=Mathematical Systems Theory|language=en|volume=27|issue=5|pages=431–452|doi=10.1007/BF01184933|issn=0025-5661|citeseerx=10.1.1.54.2543|s2cid=42798826}}&lt;/ref&gt;

:'''for''' &lt;math&gt;k \gets 0&lt;/math&gt; '''to''' &lt;math&gt;p+m-3&lt;/math&gt; '''do'''
:: '''for''' &lt;math&gt;i \gets 0&lt;/math&gt; '''to''' &lt;math&gt;p - 1&lt;/math&gt; '''do in parallel'''
::: '''if''' &lt;math&gt;i \leq k &lt; i+m \land i \neq p-1&lt;/math&gt;
:::: '''send''' &lt;math&gt;x_i^{k-i} &lt;/math&gt; '''to''' &lt;math&gt;p_{i+1} &lt;/math&gt;
::: '''if''' &lt;math&gt;i-1 \leq k &lt; i-1+m \land i \neq 0&lt;/math&gt;
:::: '''receive''' &lt;math&gt;x_{i-1}^{k+i-1}&lt;/math&gt; '''from''' &lt;math&gt;p_{i-1}&lt;/math&gt;
:::: &lt;math&gt;x_{i}^{k+i-1} \gets x_{i}^{k+i-1} \oplus x_{i-1}^{k+i-1}&lt;/math&gt; 
It is important to note that the send and receive operations have to be executed concurrently for the algorithm to work. The result vector is stored at &lt;math&gt;p_{p-1}&lt;/math&gt; at the end. The associated animation shows an execution of the algorithm on vectors of size four with five processing units. Two steps of the animation visualize one parallel execution step.

==== Runtime analysis ====
The number of steps in the parallel execution are &lt;math&gt;p + m -2&lt;/math&gt;, it takes &lt;math&gt;p-1&lt;/math&gt; steps until the last processing unit receives its first element and additional &lt;math&gt;m-1&lt;/math&gt; until all elements are received. Therefore, the runtime in the BSP-model is &lt;math&gt;T(n, p, m) = \left(T_{start} + \frac{n}{m}\cdot T_{byte}\right)(p+m-2)&lt;/math&gt;, assuming that &lt;math&gt;n&lt;/math&gt; is the total byte-size of a vector.

Although &lt;math&gt;m&lt;/math&gt; has a fixed value, it is possible to logically group elements of a vector together and reduce &lt;math&gt;m&lt;/math&gt;. For example, a problem instance with vectors of size four can be handled by splitting the vectors into the first two and last two elements, which are always transmitted and computed together. In this case, double the volume is sent each step, but the number of steps has roughly halved. It means that the parameter &lt;math&gt;m&lt;/math&gt; is halved, while the total byte-size &lt;math&gt;n&lt;/math&gt; stays the same. The runtime &lt;math&gt;T(p)&lt;/math&gt; for this approach depends on the value of &lt;math&gt;m&lt;/math&gt;, which can be optimized if &lt;math&gt;T_{start}&lt;/math&gt; and &lt;math&gt;T_{byte}&lt;/math&gt; are known. It is optimal for &lt;math&gt;m = \sqrt{\frac{n \cdot (p-2)\cdot T_{byte}}{T_{start}}}&lt;/math&gt;, assuming that this results in a smaller &lt;math&gt;m&lt;/math&gt; that divides the original one.

== Applications ==
Reduction is one of the main [[collective operation|collective operations]] implemented in the [[Message Passing Interface]], where performance of the used algorithm is important and evaluated constantly for different use cases.&lt;ref&gt;{{Cite journal|last1=Pješivac-Grbović|first1=Jelena|last2=Angskun|first2=Thara|last3=Bosilca|first3=George|last4=Fagg|first4=Graham E.|last5=Gabriel|first5=Edgar|last6=Dongarra|first6=Jack J.|date=2007-06-01|title=Performance analysis of MPI collective operations|journal=Cluster Computing|language=en|volume=10|issue=2|pages=127–143|doi=10.1007/s10586-007-0012-0|s2cid=2142998|issn=1386-7857}}&lt;/ref&gt;
Operators can be used as parameters for &lt;code&gt;MPI_Reduce&lt;/code&gt; and &lt;code&gt;MPI_Allreduce&lt;/code&gt;, with the difference that the result is available at one (root) processing unit or all of them. 
[[MapReduce]] relies heavily on efficient reduction algorithms to process big data sets, even on huge clusters.&lt;ref&gt;{{Cite journal|last=Lämmel|first=Ralf|title=Google's MapReduce programming model — Revisited|journal=Science of Computer Programming|volume=70|issue=1|pages=1–30|doi=10.1016/j.scico.2007.07.001|year=2008}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Senger|first1=Hermes|last2=Gil-Costa|first2=Veronica|last3=Arantes|first3=Luciana|last4=Marcondes|first4=Cesar A. C.|last5=Marín|first5=Mauricio|last6=Sato|first6=Liria M.|last7=da Silva|first7=Fabrício A.B.|date=2016-06-10|title=BSP cost and scalability analysis for MapReduce operations|journal=Concurrency and Computation: Practice and Experience|language=en|volume=28|issue=8|pages=2503–2527|doi=10.1002/cpe.3628|issn=1532-0634|hdl=10533/147670|hdl-access=free}}&lt;/ref&gt;

Some parallel [[Sorting algorithm|sorting]] algorithms use reductions to be able to handle very big data sets.&lt;ref&gt;{{Cite arxiv|last1=Axtmann|first1=Michael|last2=Bingmann|first2=Timo|last3=Sanders|first3=Peter|last4=Schulz|first4=Christian|date=2014-10-24|title=Practical Massively Parallel Sorting|eprint=1410.6754|class=cs.DS}}&lt;/ref&gt;

== See also ==
* [[Fold (higher-order function)]]

==References==
{{Reflist}}

==Books==
* {{cite book|last1=Chandra|first1=Rohit|title=Parallel Programming in OpenMP|url=https://archive.org/details/parallelprogramm00chan_654|url-access=limited|date=2001|publisher=Morgan Kaufmann|isbn=1558606718|pages=[https://archive.org/details/parallelprogramm00chan_654/page/n75 59]–77}}
* {{cite book|last1=Solihin|first1=Yan|title=Fundamentals of Parallel Multicore Architecture|date=2016|publisher=CRC Press|isbn=978-1-4822-1118-4|page=75}}

==External links ==
*[https://www.dartmouth.edu/~rc/classes/intro_openmp/reduction_clause.html Reduction Clause], Reference to reduction clause
[[Category:Computer science]]</text>
      <sha1>0w22u938msofhsdxy5b08ry5r9t71b3</sha1>
    </revision>
  </page>
  <page>
    <title>Social cloud computing</title>
    <ns>0</ns>
    <id>50218929</id>
    <revision>
      <id>967293501</id>
      <parentid>938832330</parentid>
      <timestamp>2020-07-12T11:39:38Z</timestamp>
      <contributor>
        <username>Akarasulu</username>
        <id>5272428</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6784" xml:space="preserve">{{Orphan|date=April 2016}}

'''Social cloud computing''', also '''peer-to-peer social cloud computing''', is an area of computer science that generalizes [[cloud computing]] to include the sharing, bartering and renting of computing resources across peers whose owners and operators are verified through a [[social network]] or [[reputation system]].&lt;ref&gt;{{cite book|last1=Gupta|first1=Minaxi|last2=Judge|first2=Paul|last3=Ammar|first3=Mostafa|title=A Reputation System for Peer-to-peer Networks|journal=Proceedings of the 13th International Workshop on Network and Operating Systems Support for Digital Audio and Video|date=1 January 2003|pages=144–152|doi=10.1145/776322.776346|publisher=ACM|isbn=978-1581136944|citeseerx=10.1.1.13.5964}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Chard|first1=K.|last2=Caton|first2=S.|last3=Rana|first3=O.|last4=Bubendorfer|first4=K.|title=Social Cloud: Cloud Computing in Social Networks|journal=2010 IEEE 3rd International Conference on Cloud Computing|date=1 July 2010|pages=99–106|doi=10.1109/CLOUD.2010.28|isbn=978-1-4244-8207-8|citeseerx=10.1.1.225.9508}}&lt;/ref&gt; It expands cloud computing past the confines of formal commercial data centers operated by cloud providers to include anyone interested in participating within the cloud services [[sharing economy]]. This in turn leads to more options, greater economies of scale, while bearing additional advantages for hosting data and computing services closer to the edge where they may be needed most.&lt;ref&gt;{{cite journal|last1=Babaoglu|first1=Ozalp|title=Escape From the Data Center: The Promise of Peer-to-Peer Cloud Computing|journal=IEEE Spectrum|date=September 22, 2014|url=https://spectrum.ieee.org/computing/networks/escape-from-the-data-center-the-promise-of-peertopeer-cloud-computing}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Anderson|first1=David P.|last2=Fedak|first2=Gilles|title=The Computational and Storage Potential of Volunteer Computing|journal=Proceedings of the Sixth IEEE International Symposium on Cluster Computing and the Grid|date=1 January 2006|pages=73–80|doi=10.1109/CCGRID.2006.101|url=http://dl.acm.org/citation.cfm?id=1134996|publisher=IEEE Computer Society|arxiv=cs/0602061|isbn=978-0-7695-2585-3|citeseerx=10.1.1.115.8349}}&lt;/ref&gt;

==Research==
[[Peer-to-peer]] (P2P) computing and networking to enable decentralized cloud computing has been an area of research for sometime.&lt;ref&gt;{{cite book|last1=Veiga|first1=Luis|last2=Rodrigues|first2=Rodrigo|last3=Ferreira|first3=Paulo|title=GiGi: An Ocean of Gridlets on a "Grid-for-the-Masses"|journal=Proceedings of the Seventh IEEE International Symposium on Cluster Computing and the Grid|date=1 January 2007|pages=783–788|doi=10.1109/CCGRID.2007.54|url=http://dl.acm.org/citation.cfm?id=1252179|publisher=IEEE Computer Society|isbn=978-0-7695-2833-5}}&lt;/ref&gt; Social cloud computing intersects [[peer-to-peer cloud computing]] with [[social computing]] to verify peer and peer owner reputation thus providing security and quality of service assurances to users. On demand computing environments may be constructed and altered statically or dynamically across peers on the Internet based on their available resources and verified reputation to provide such assurances.

==Applications==
Social cloud computing has been highlighted as a potential benefit to large-scale computing, video gaming, and media streaming.&lt;ref&gt;{{cite book|last1=Babaoglu|first1=Ozalp|last2=Marzolla|first2=Moreno|last3=Tamburini|first3=Michelle|title=Design and Implementation of a P2P Cloud System|journal=Proceedings of the 27th Annual ACM Symposium on Applied Computing|date=March 2012|pages=412–417|doi=10.1145/2245276.2245357|url=http://www.cs.unibo.it/babaoglu/papers/pdf/acm-sac-2012.pdf|publisher=ACM|isbn=9781450308571|citeseerx=10.1.1.307.6956}}&lt;/ref&gt; The tenets of social cloud computing has been most famously employed in the [[Berkeley Open Infrastructure for Network Computing]] (BOINC), making the service the largest computing grid in the world.&lt;ref&gt;{{Cite web |title = Largest computing grid |url = http://www.guinnessworldrecords.com/world-records/largest-computing-grid |website = Guinness World Records |accessdate=28 March 2017}}&lt;/ref&gt; Another service that uses social cloud computing is Subutai. Subutai allows peer-to-peer sharing of computing resources globally or within a select permissioned network.&lt;ref&gt;{{cite web|title=What is Subutai?|url=https://subutai.io|website=Subutai|accessdate=28 March 2017}}&lt;/ref&gt;

==Challenges==
Many challenges arise when moving from a traditional cloud infrastructure, to a social cloud environment.&lt;ref&gt;{{cite web|title=Peer-to-Peer Cloud Computing|url=http://www.cs.unibo.it/babaoglu/papers/pdf/P2Pclouds.pdf|accessdate=28 March 2017}}&lt;/ref&gt;

===Availability of computational resources===

In the case of traditional cloud computing, availability on demand is essential for many cloud customers.  Social Cloud Computing doesn't provide this availability guarantee because in a P2P environment, peers are mobile devices which may enter or leave the P2P network at any time, or PCs which have a primary purpose that can override the P2P computation at any time.  The only relatively successful use cases as of recent years are those which do not require real time results, only computation power for a small subset or module of a larger algorithm or data set.

===Trust and security===

Unlike large scale data centers and company brand image, people may be less likely to trust peers vs. a large company like Google or Amazon.  Running some sort of computation with sensitive information would then need to be encrypted properly and the overhead of that encryption may reduce the usefulness of the P2P offloading. When resources are distributed in small pieces to many peers for computations, inherent trust must be placed in the client, regardless of the encryption that may be promised to the client.

===Reliability===

Similar to availability, reliability of computations must be consistent and uniform.  If computations offloaded to the client are continuously interrupted, some mechanism for detecting this must be in place such that the client may know the computation is tainted or needs to be completely re-run.  In P2P social computing, reliable expected computation power is difficult to achieve because the speed of the client calculation may depend on how much the client is using the end device.  Some ways of overcoming this may be to only allow computations to occur at night, or during specified times the client resources will not be in use.

==See also==
* [[Berkeley Open Infrastructure for Network Computing]]
* [https://subutai.io Subutai P2P Edge Cloud Platform]

==References==
{{Reflist}}

[[Category:Computer science]]
[[Category:Cloud computing]]
[[Category:Social media]]</text>
      <sha1>3spqwz0f2dvopx7adlmmdj5udbco94n</sha1>
    </revision>
  </page>
  <page>
    <title>Transition (computer science)</title>
    <ns>0</ns>
    <id>53650506</id>
    <revision>
      <id>994626828</id>
      <parentid>985708564</parentid>
      <timestamp>2020-12-16T18:15:22Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 17 templates: del empty params (5×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="13527" xml:space="preserve">[[File:Transition en-03.png|alt=|thumb|The aim of a transition is to provide a seamless, consistent quality, e.g., [[Quality of service|QoS]] in a communication system.]]
'''Transition''' refers to a computer science paradigm in the context of [[communication systems]] which describes the change of communication mechanisms, i.e., functions of a communication system, in particular, service and [[Communications protocol|protocol]] components. In a transition, communication mechanisms within a system are replaced by functionally comparable mechanisms with the aim to ensure the highest possible quality, e.g., as captured by the [[quality of service]].

== Idea and functional principle ==
[[File:Transition en-05.png|alt=|thumb|Transitions and the subsequent adaptation of communication systems enable the optimization of the communication quality despite changing conditions.]]
Transitions enable communication systems to adapt to changing conditions during runtime. This change in conditions can, for example, be a rapid increase in the load on a certain service that may be caused, e.g., by large gatherings of people with mobile devices. A transition often impacts multiple mechanisms at different communication layers of a [[OSI model|layered architecture]].

Mechanisms are given as conceptual elements of a networked communication system and are linked to specific functional units, for example, as a service or protocol component. In some cases, a mechanism can also comprise an entire protocol. For example on the transmission layer, LTE can be regarded as such a mechanism. Following this definition, there exist numerous communication mechanisms that are partly equivalent in their basic functionality, such as [[Wi-Fi]], [[Bluetooth]] and [[ZigBee]] for local wireless networks and UMTS and [[LTE (telecommunication)|LTE]] for broadband wireless connections. For example, LTE and Wi-Fi have equivalent basic functionality, but they are technologically significantly different in their design and operation. Mechanisms affected by transitions are often components of a protocol or service. For example, in case of video streaming/transmission, the use of different video data encoding can be carried out depending on the available data transmission rate. These changes are controlled and implemented by transitions; A research example is a context-aware video adaptation service to support mobile video applications.&lt;ref&gt;S. Wilk, D. Stohr, and W. Effelsberg. 2016. A Content-Aware Video Adaptation Service to Support Mobile Video. ACM Trans. Multimedia Comput. Commun. Appl. 12, 5s, Article 82 (November 2016)&lt;/ref&gt; Through analyzing the current processes in a communication system, it is possible to determine which transitions need to be executed at which communication layer in order to meet the quality requirements. In order for communication systems to adapt to the respective framework conditions, architectural approaches of self-organizing, adaptive systems can be used, such as the MAPE cycle &lt;ref&gt;JO Kephart and DM Chess. The vision of autonomous computing. IEEE Computer, 1, pp. 41-50, 2003.&lt;/ref&gt; (Monitor-Analyze-Plan-Execute). This central concept of [[Autonomic computing|Autonomic Computing]] can be used to determine the state of the communication system, to analyze the monitoring data and to plan and execute the necessary transition(s). A central goal is that users do not consciously perceive a transition while running applications and that the functionality of the used services is perceived as smooth and fluid.

== Recent research ==
The study of new and fundamental design methods, models and techniques that enable automated, coordinated and cross-layer transitions between functionally similar mechanisms within a communication system is the main goal of a collaborative research center funded by the German research foundation (DFG). The DFG collaborative research center 1053 MAKI - Multi-mechanism Adaptation for the future Internet - focuses on research questions in the following areas: (i) Fundamental research on transition methods, (ii) Techniques for adapting transition-capable communication systems on the basis of achieved and targeted quality, and (iii) specific and exemplary transitions in communication systems as regarded from different technical perspectives.

A formalization of the concept of transitions that captures the features and relations within a communication system to express and optimize the decision making process that is associated with such a system is given in.&lt;ref&gt;{{Cite journal|last=Alt|first=Bastian|last2=Weckesser|first2=Markus|last3=Becker|first3=Christian|last4=Hollick|first4=Matthias|last5=Kar|first5=Sounak|last6=Klein|first6=Anja|last7=Klose|first7=Robin|last8=Kluge|first8=Roland|last9=Koeppl|first9=Heinz|display-authors=2|date=2019|title=Transitions: A Protocol-Independent View of the Future Internet|journal=Proceedings of the IEEE|volume=107|issue=4|pages=835–846|doi=10.1109/JPROC.2019.2895964|issn=0018-9219}}&lt;/ref&gt; The associated building blocks comprise (i) Dynamic [[Software product line|Software Product Lines]], (ii) [[Markov decision process|Markov Decision Processes]] and (iii) [[Utility]] Design. While Dynamic Software Product Lines provide a method to concisely capture a large configuration space and to specify run time variability of adaptive systems, Markov Decision Processes provide a mathematical tool to define and plan transitions between available communication mechanisms. Finally, utility functions quantify the performance of individual configurations of the transition-based communication system and provide the means to optimize the performance in such a system.

Applications of the idea of transitions have found their way to wireless sensor networks&lt;ref&gt;{{Cite journal|last=Kluge|first=Roland|last2=Stein|first2=Michael|last3=Giessing|first3=David|last4=Schürr|first4=Andy|last5=Mühlhäuser|first5=Max|date=2017|editor-last=Anjorin|editor-first=Anthony|editor2-last=Espinoza|editor2-first=Huáscar|title=cMoflon: Model-Driven Generation of Embedded C Code for Wireless Sensor Networks|journal=Modelling Foundations and Applications|volume=10376|series=Lecture Notes in Computer Science|language=en|publisher=Springer International Publishing|pages=109–125|doi=10.1007/978-3-319-61482-3_7|isbn=9783319614823}}&lt;/ref&gt; and mobile networks,&lt;ref&gt;{{Cite journal|last=Richerzhagen|first=N.|last2=Richerzhagen|first2=B.|last3=Hark|first3=R.|last4=Stingl|first4=D.|last5=Steinmetz|first5=R.|date=2016|title=Limiting the Footprint of Monitoring in Dynamic Scenarios through Multi-Dimensional Offloading|journal=2016 25th International Conference on Computer Communication and Networks (ICCCN)|pages=1–9|doi=10.1109/ICCCN.2016.7568539|isbn=978-1-5090-2279-3}}&lt;/ref&gt; distributed reactive programming,&lt;ref&gt;{{Cite journal|last=Mogk|first=Ragnar|last2=Baumgärtner|first2=Lars|last3=Salvaneschi|first3=Guido|last4=Freisleben|first4=Bernd|last5=Mezini|first5=Mira|date=2018|title=Fault-tolerant Distributed Reactive Programming|url=http://drops.dagstuhl.de/opus/volltexte/2018/9206/|journal=Schloss Dagstuhl - Leibniz-Zentrum für Informatik GMBH, Wadern/Saarbruecken, Germany|language=en|doi=10.4230/lipics.ecoop.2018.1}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Margara|first=A.|last2=Salvaneschi|first2=G.|date=2018|title=On the Semantics of Distributed Reactive Programming: The Cost of Consistency|journal=IEEE Transactions on Software Engineering|volume=44|issue=7|pages=689–711|doi=10.1109/TSE.2018.2833109|issn=0098-5589}}&lt;/ref&gt; WiFi firmware modification,&lt;ref&gt;{{Cite journal|last=Schulz|first=Matthias|last2=Wegemer|first2=Daniel|last3=Hollick|first3=Matthias|date=2018-09-01|title=The Nexmon firmware analysis and modification framework: Empowering researchers to enhance Wi-Fi devices|journal=Computer Communications|volume=129|pages=269–285|doi=10.1016/j.comcom.2018.05.015|issn=0140-3664}}&lt;/ref&gt; planning of autonomic computing systems,&lt;ref&gt;{{Cite journal|last=Pfannemueller|first=M.|last2=Krupitzer|first2=C.|last3=Weckesser|first3=M.|last4=Becker|first4=C.|date=2017|title=A Dynamic Software Product Line Approach for Adaptation Planning in Autonomic Computing Systems|journal=2017 IEEE International Conference on Autonomic Computing (ICAC)|pages=247–254|doi=10.1109/ICAC.2017.18|isbn=978-1-5386-1762-5}}&lt;/ref&gt; analysis of [[Content delivery network|CDNs]],&lt;ref&gt;Jeremias Blendin, Fabrice Bendfeldt, Ingmar Poese, Boris Koldehofe, and Oliver Hohlfeld. 2018. Dissecting Apple's Meta-CDN during an iOS Update. In Proceedings of the Internet Measurement Conference 2018 (IMC '18). ACM&lt;/ref&gt; flexible extensions of the ISO [[OSI model|OSI]] stack,&lt;ref&gt;{{Cite journal|last=Heuschkel|first=J.|last2=Wang|first2=L.|last3=Fleckstein|first3=E.|last4=Ofenloch|first4=M.|last5=Blöcher|first5=M.|last6=Crowcroft|first6=J.|last7=Mühlhäuser|first7=M.|date=2018|title=VirtualStack: Flexible Cross-layer Optimization via Network Protocol Virtualization|journal=2018 IEEE 43rd Conference on Local Computer Networks (LCN)|pages=519–526|doi=10.1109/LCN.2018.8638106|isbn=978-1-5386-4413-3}}&lt;/ref&gt; [[5G]] [[mmWave]] vehicular communications,&lt;ref&gt;{{Cite journal|last=Asadi|first=A.|last2=Müller|first2=S.|last3=Sim|first3=G. H.|last4=Klein|first4=A.|last5=Hollick|first5=M.|date=2018|title=FML: Fast Machine Learning for 5G mmWave Vehicular Communications|journal=IEEE INFOCOM 2018 - IEEE Conference on Computer Communications|pages=1961–1969|doi=10.1109/INFOCOM.2018.8485876|isbn=978-1-5386-4128-6}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Sim|first=G. H.|last2=Klos|first2=S.|last3=Asadi|first3=A.|last4=Klein|first4=A.|last5=Hollick|first5=M.|date=2018|title=An Online Context-Aware Machine Learning Algorithm for 5G mmWave Vehicular Communications|journal=IEEE/ACM Transactions on Networking|volume=26|issue=6|pages=2487–2500|doi=10.1109/TNET.2018.2869244|issn=1063-6692}}&lt;/ref&gt; the analysis of [[MapReduce]]-like parallel systems,&lt;ref&gt;{{Cite journal|last=KhudaBukhsh|first=W. R.|last2=Rizk|first2=A.|last3=Frömmgen|first3=A.|last4=Koeppl|first4=H.|date=2017|title=Optimizing stochastic scheduling in fork-join queueing models: Bounds and applications|journal=IEEE INFOCOM 2017 - IEEE Conference on Computer Communications|pages=1–9|doi=10.1109/INFOCOM.2017.8057013|isbn=978-1-5090-5336-0|arxiv=1612.05486}}&lt;/ref&gt; scheduling of [[Multipath TCP]],&lt;ref&gt;{{Cite journal|last=Frömmgen|first=Alexander|last2=Rizk|first2=Amr|last3=Erbshäußer|first3=Tobias|last4=Weller|first4=Max|last5=Koldehofe|first5=Boris|last6=Buchmann|first6=Alejandro|last7=Steinmetz|first7=Ralf|date=2017|title=A Programming Model for Application-defined Multipath TCP Scheduling|journal=Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference|series=Middleware '17|location=New York, NY, USA|publisher=ACM|pages=134–146|doi=10.1145/3135974.3135979|isbn=9781450347204}}&lt;/ref&gt; adaptivity for beam training in [[802.11ad]],&lt;ref&gt;{{Cite journal|last=Palacios|first=Joan|last2=Steinmetzer|first2=Daniel|last3=Loch|first3=Adrian|last4=Hollick|first4=Matthias|last5=Widmer|first5=Joerg|date=2018|title=Adaptive Codebook Optimization for Beam Training on Off-the-Shelf IEEE 802.11Ad Devices|journal=Proceedings of the 24th Annual International Conference on Mobile Computing and Networking|series=MobiCom '18|location=New York, NY, USA|publisher=ACM|pages=241–255|doi=10.1145/3241539.3241576|isbn=9781450359030}}&lt;/ref&gt; operator placement in dynamic user environments,&lt;ref&gt;{{Cite journal|last=Luthra|first=Manisha|last2=Koldehofe|first2=Boris|last3=Weisenburger|first3=Pascal|last4=Salvaneschi|first4=Guido|last5=Arif|first5=Raheel|date=2018|title=TCEP|journal=Proceedings of the 12th ACM International Conference on Distributed and Event-based Systems - DEBS '18|location=New York, New York, USA|publisher=ACM Press|pages=136–147|doi=10.1145/3210284.3210292|isbn=9781450357821}}&lt;/ref&gt; [[Dynamic Adaptive Streaming over HTTP|DASH]] video player analysis,&lt;ref&gt;{{Cite journal|last=Stohr|first=Denny|last2=Frömmgen|first2=Alexander|last3=Rizk|first3=Amr|last4=Zink|first4=Michael|last5=Steinmetz|first5=Ralf|last6=Effelsberg|first6=Wolfgang|date=2017|title=Where Are the Sweet Spots?: A Systematic Approach to Reproducible DASH Player Comparisons|journal=Proceedings of the 25th ACM International Conference on Multimedia|series=MM '17|location=New York, NY, USA|publisher=ACM|pages=1113–1121|doi=10.1145/3123266.3123426|isbn=9781450349062}}&lt;/ref&gt; [[adaptive bitrate streaming]]&lt;ref&gt;{{cite arxiv|last=Rizk|first=Amr|last2=Koeppl|first2=Heinz|last3=Steinmetz|first3=Ralf|last4=Ballard|first4=Trevor|last5=Alt|first5=Bastian|date=2019-01-17|title=CBA: Contextual Quality Adaptation for Adaptive Bitrate Video Streaming (Extended Version)|language=en|eprint=1901.05712|class=cs.MM}}&lt;/ref&gt; and [[complex event processing]] on mobile devices.&lt;ref&gt;{{Cite journal|last=Graubner|first=Pablo|last2=Thelen|first2=Christoph|last3=Körber|first3=Michael|last4=Sterz|first4=Artur|last5=Salvaneschi|first5=Guido|last6=Mezini|first6=Mira|last7=Seeger|first7=Bernhard|last8=Freisleben|first8=Bernd|date=2018|title=Multimodal Complex Event Processing on Mobile Devices|journal=Proceedings of the 12th ACM International Conference on Distributed and Event-based Systems|series=DEBS '18|location=New York, NY, USA|publisher=ACM|pages=112–123|doi=10.1145/3210284.3210289|isbn=9781450357821}}&lt;/ref&gt;

== References ==
{{Reflist}}

== External links ==
* [http://www.maki.tu-darmstadt.de/sfb_maki/ueber_maki/index.en.jsp MAKI]

[[Category:Computer science]]</text>
      <sha1>cn6mmzbudhrjxshxapivftkp0dc0035</sha1>
    </revision>
  </page>
  <page>
    <title>Symbolic execution</title>
    <ns>0</ns>
    <id>607674</id>
    <revision>
      <id>1004381212</id>
      <parentid>993761097</parentid>
      <timestamp>2021-02-02T09:44:01Z</timestamp>
      <contributor>
        <username>Snjkdn</username>
        <id>36944678</id>
      </contributor>
      <minor/>
      <comment>Update link to HTTPS</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="15430" xml:space="preserve">In [[computer science]], '''symbolic execution '''(also '''symbolic evaluation''' or '''symbex''') is a means of analyzing a program to determine what inputs cause each part of a program to execute.  An interpreter follows the program, assuming symbolic values for inputs rather than obtaining actual inputs as normal execution of the program would.  It thus arrives at expressions in terms of those symbols for expressions and variables in the program, and constraints in terms of those symbols for the possible outcomes of each conditional branch.

The field of [[symbolic simulation]] applies the same concept to hardware. [[Symbolic computation]] applies the concept to the analysis of mathematical expressions.

==Example==
Consider the program below, which reads in a value and fails if the input is 6.

&lt;syntaxhighlight lang="c" line="1"&gt;
int f() {
  ...
  y = read();
  z = y * 2;
  if (z == 12) {
    fail();
  } else {
    printf("OK");
  }
}
&lt;/syntaxhighlight&gt;

During a normal execution ("concrete" execution), the program would read a concrete input value (e.g., 5) and assign it to y. Execution would then proceed with the multiplication and the conditional branch, which would evaluate to false and print &lt;code&gt;OK&lt;/code&gt;.

During symbolic execution, the program reads a symbolic value (e.g., &lt;code&gt;λ&lt;/code&gt;) and assigns it to y. The program would then proceed with the multiplication and assign &lt;code&gt;λ * 2&lt;/code&gt; to &lt;code&gt;z&lt;/code&gt;. When reaching the &lt;code&gt;if&lt;/code&gt; statement, it would evaluate &lt;code&gt;λ * 2 == 12&lt;/code&gt;. At this point of the program, λ could take any value, and symbolic execution can therefore proceed along both branches, by "forking" two paths. Each path gets assigned a copy of the program state at the branch instruction as well as a path constraint. In this example, the path constraint is &lt;code&gt;λ * 2 == 12&lt;/code&gt; for the &lt;code&gt;then&lt;/code&gt; branch and &lt;code&gt;λ * 2 != 12&lt;/code&gt; for the &lt;code&gt;else&lt;/code&gt; branch. Both paths can be symbolically executed independently. When paths terminate (e.g., as a result of executing &lt;code&gt;fail()&lt;/code&gt; or simply exiting), symbolic execution computes a concrete value for λ by solving the accumulated path constraints on each path. These concrete values can be thought of as concrete test cases that can, e.g., help developers reproduce bugs. In this example, the [[constraint solver]] would determine that in order to reach the &lt;code&gt;fail()&lt;/code&gt; statement, λ would need to equal 6.

==Limitations==

===Path explosion===
Symbolically executing all feasible program paths does not scale to large programs. The number of feasible paths in a program grows exponentially with an increase in program size and can even be infinite in the case of programs with unbounded loop iterations.&lt;ref&gt;{{cite book|last=Anand|first=Saswat|author2=Patrice Godefroid |author3=Nikolai Tillmann |chapter=Demand-Driven Compositional Symbolic Execution|title=Tools and Algorithms for the Construction and Analysis of Systems|year=2008|volume=4963|pages=367–381|doi=10.1007/978-3-540-78800-3_28|series=Lecture Notes in Computer Science|isbn=978-3-540-78799-0}}&lt;/ref&gt;  Solutions to the ''path explosion'' problem generally use either heuristics for path-finding to increase code coverage,&lt;ref&gt;{{cite book|last=Ma|first=Kin-Keng|author2=Khoo Yit Phang |author3=Jeffrey S. Foster |author4=Michael Hicks |chapter=Directed Symbolic Execution|title=Proceedings of the 18th International Conference on Statis Analysis|year=2011|pages=95–111|chapter-url=http://dl.acm.org/citation.cfm?id=2041563|accessdate=2013-04-03|isbn=9783642237010}}&lt;/ref&gt; reduce execution time by parallelizing independent paths,&lt;ref&gt;{{cite book|last=Staats|first=Matt|author2=Corina Pasareanu |s2cid=9898522|chapter=Parallel symbolic execution for structural test generation|title=Proceedings of the 19th International Symposium on Software Testing and Analysis|year=2010|pages=183–194|doi=10.1145/1831708.1831732|isbn=9781605588230}}&lt;/ref&gt; or by merging similar paths.&lt;ref&gt;{{Cite book|chapter= Efficient State Merging in Symbolic Execution|publisher = ACM|title= Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation|date = 2012-01-01|location = New York, NY, USA|isbn = 978-1-4503-1205-9|pages = 193–204|series =&lt;!----&gt;|doi = 10.1145/2254064.2254088|first1 = Volodymyr|last1 = Kuznetsov|first2 = Johannes|last2 = Kinder|first3 = Stefan|last3 = Bucur|first4 = George|last4 = Candea|s2cid = 135107|citeseerx = 10.1.1.348.823}}&lt;/ref&gt;

===Program-dependent efficiency===
Symbolic execution is used to reason about a program path-by-path which is an advantage over reasoning about a program input-by-input as other testing paradigms use (e.g. [[Dynamic program analysis]]). However, if few inputs take the same path through the program, there is little savings over testing each of the inputs separately.

=== Memory aliasing ===

Symbolic execution is harder when the same memory location can be accessed through different names ([[aliasing]]). Aliasing cannot always be recognized statically, so the symbolic execution engine can't recognize that a change to the value of one variable also changes the other.&lt;ref name=DeMillo1991&gt;{{Cite journal| title = Constraint-Based Automatic Test Data Generation| journal = IEEE Transactions on Software Engineering| date = 1991-09-01| pages = 900–910| volume = 17| issue = 9| first1 = Rich| last1 = DeMillo| first2 = Jeff| last2 = Offutt| doi = 10.1109/32.92910}}&lt;/ref&gt;

=== Arrays ===

Since an array is a collection of many distinct values, symbolic executors must either treat the entire array as one value or treat each array element as a separate location. The problem with treating each array element separately is that a reference such as "A[i]" can only be specified dynamically, when the value for i has a concrete value.&lt;ref name=DeMillo1991 /&gt;

=== Environment interactions ===
Programs interact with their environment by performing system calls, receiving signals, etc. Consistency problems may arise when execution reaches components that are not under control of the symbolic execution tool (e.g., kernel or libraries). Consider the following example:&lt;syntaxhighlight lang="c" line="1"&gt;
int main()
{
  FILE *fp = fopen("doc.txt");
  ...
  if (condition) {
    fputs("some data", fp);
  } else {
    fputs("some other data", fp);
  }
  ...
  data = fgets(..., fp);
}
&lt;/syntaxhighlight&gt;This program opens a file and, based on some condition, writes different kind of data to the file. It then later reads back the written data. In theory, symbolic execution would fork two paths at line 5 and each path from there on would have its own copy of the file. The statement at line 11 would therefore return data that is consistent with the value of "condition" at line 5. In practice, file operations are implemented as system calls in the kernel, and are outside the control of the symbolic execution tool. The main approaches to address this challenge are:

'''Executing calls to the environment directly.''' The advantage of this approach is that it is simple to implement. The disadvantage is that the side effects of such calls will clobber all states managed by the symbolic execution engine. In the example above, the instruction at line 11 would return "some datasome other data" or "some other datasomedata" depending on the sequential ordering of the states.

'''Modeling the environment.''' In this case, the engine instruments the system calls with a model that simulates their effects and that keeps all the side effects in per-state storage. The advantage is that one would get correct results when symbolically executing programs that interact with the environment. The disadvantage is that one needs to implement and maintain many potentially complex models of system calls. Tools such as KLEE,&lt;ref&gt;{{Cite journal|title = KLEE: Unassisted and Automatic Generation of High-coverage Tests for Complex Systems Programs|url = http://dl.acm.org/citation.cfm?id=1855741.1855756|journal = Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation|date = 2008-01-01|pages = 209–224|series = OSDI'08|first1 = Cristian|last1 = Cadar|first2 = Daniel|last2 = Dunbar|first3 = Dawson|last3 = Engler}}&lt;/ref&gt; Cloud9, and Otter&lt;ref&gt;{{cite web|title=MultiOtter: Multiprocess Symbolic Execution|url=https://www.cs.umd.edu/~mwh/papers/multiotter.pdf|first1 = Jonathan|last1 = Turpie|first2 = Elnatan|last2 = Reisner|first3 = Jeffrey|last3 = Foster|first4 = Michael |last4 = Hicks}}&lt;/ref&gt; take this approach by implementing models for file system operations, sockets, IPC, etc.

'''Forking the entire system state.''' Symbolic execution tools based on virtual machines solve the environment problem by forking the entire VM state. For example, in S2E&lt;ref&gt;{{Cite journal|title = The S2E Platform: Design, Implementation, and Applications|journal = ACM Trans. Comput. Syst.|date = 2012-02-01|issn = 0734-2071|pages = 2:1–2:49|volume = 30|issue = 1|doi = 10.1145/2110356.2110358|first1 = Vitaly|last1 = Chipounov|first2 = Volodymyr|last2 = Kuznetsov|first3 = George|last3 = Candea|s2cid = 16905399}}&lt;/ref&gt; each state is an independent VM snapshot that can be executed separately. This approach alleviates the need for writing and maintaining complex models and allows virtually any program binary to be executed symbolically. However, it has higher memory usage overheads (VM snapshots may be large).

==Tools==
{| class="wikitable sortable"
|-
! Tool
! Target
! URL
! Can anybody use it/ Open source/ Downloadable
|-
| angr
| libVEX based (supporting x86, x86-64, ARM, AARCH64, MIPS, MIPS64, PPC, PPC64, and Java)
| http://angr.io/
| {{free | yes}} 
|-
| BE-PUM
| x86
| https://github.com/NMHai/BE-PUM
| {{free | yes}} 
|-
|BINSEC
|x86-32/ELF, with an experimental PE loader.
|http://binsec.gforge.inria.fr/tools
| {{free | yes}} 
|-
| ExpoSE
| [[JavaScript]]
| https://github.com/ExpoSEJS/ExpoSE
| {{free | yes}} 
|-
| FuzzBALL
| VineIL / Native
| http://bitblaze.cs.berkeley.edu/fuzzball.html
| {{free | yes}} 
|-
| Jalangi2
| [[JavaScript]]
| https://github.com/Samsung/jalangi2
| {{free | yes}} 
|-
| janala2
|Java
| https://github.com/ksen007/janala2
| {{free | yes}} 
|-
| JaVerT
| [[JavaScript]]
| https://www.doc.ic.ac.uk/~pg/publications/FragosoSantos2019JaVerT.pdf
| {{free | yes}}
|-
| JBSE
|Java
| https://github.com/pietrobraione/jbse
| {{free | yes}} 
|-
| jCUTE
|Java
| https://github.com/osl/jcute
| {{free | yes}} 
|-
| JPF
|Java
| http://babelfish.arc.nasa.gov/trac/jpf
| {{free | yes}} 
|-
| KeY
|Java
| http://www.key-project.org/
| {{free | yes}} 
|-
| Kite
| LLVM
| http://www.cs.ubc.ca/labs/isd/Projects/Kite/
| {{free | yes}} 
|-
| KLEE
| LLVM
| https://klee.github.io/
| {{free | yes}} 
|-
| Kudzu
| [[JavaScript]]
| http://webblaze.cs.berkeley.edu/2010/kudzu/kudzu.pdf
| {{proprietary|no}}
|-
|MPro
|[[Ethereum#Ethereum Virtual Machine|Ethereum Virtual Machine (EVM)]] / Native
|https://sites.google.com/view/smartcontract-analysis/home
| {{free | yes}} 
|-
| Manticore
| x86-64, ARMv7, [[Ethereum#Ethereum Virtual Machine|Ethereum Virtual Machine (EVM)]] / Native
| https://github.com/trailofbits/manticore/
| {{free | yes}} 
|-
| Mayhem
| Binary
| http://forallsecure.com
| {{proprietary|no}}
|-
| Mythril-Classic
| [[Ethereum#Ethereum Virtual Machine|Ethereum Virtual Machine (EVM)]] / Native
| https://github.com/ConsenSys/mythril-classic
| {{free | yes}} 
|-
| Otter
| C
| https://bitbucket.org/khooyp/otter/overview
| {{free | yes}} 
|-
| Oyente-NG
| [[Ethereum#Ethereum Virtual Machine|Ethereum Virtual Machine (EVM)]] / Native
| http://www.comp.ita.br/labsca/waiaf/papers/RafaelShigemura_paper_16.pdf
| {{proprietary | no}}
|-
| Pathgrind&lt;ref&gt;{{Cite book
| chapter= Exploiting Undefined Behaviors for Efficient Symbolic Execution
| title=ICSE Companion 2014: Companion Proceedings of the 36th International Conference on Software Engineering
| pages = 727–729
| doi = 10.1145/2591062.2594450
| year = 2014
| last1 = Sharma
| first1 = Asankhaya
| s2cid=10092664
| isbn = 9781450327688
}}&lt;/ref&gt;
| Native 32-bit Valgrind-based
| https://github.com/codelion/pathgrind
| {{free | yes}} 
|-
| Pex
| [[.NET Framework]]
| http://research.microsoft.com/en-us/projects/pex/
| {{proprietary|no}}
|-
| pysymemu
| x86-64 / Native
| https://github.com/feliam/pysymemu/
| {{free | yes}} 
|-
| Rosette
| Dialect of [[Racket (programming language)|Racket]]
| https://emina.github.io/rosette/
| {{free | yes}} 
|-
| Rubyx
| [[Ruby (programming language)|Ruby]]
| http://www.cs.umd.edu/~avik/papers/ssarorwa.pdf
| {{proprietary|no}}
|-
| S2E
| x86, x86-64, ARM / User and kernel-mode binaries
| http://s2e.systems/
| {{free | yes}} 
|-
| Symbolic PathFinder (SPF)
| Java Bytecode
| https://github.com/SymbolicPathFinder
| {{free|yes}} 
|-
| SymDroid
| [[Dalvik (software)|Dalvik]] bytecode
| http://www.cs.umd.edu/~jfoster/papers/symdroid.pdf
| {{proprietary|no}}
|-
| SymJS
| [[JavaScript]]
| http://www.cs.utah.edu/~ligd/publications/SymJS-FSE14.pdf
| {{proprietary|no}}
|-
| Triton
| x86 and x86-64
| https://triton.quarkslab.com
| {{free | yes}} 
|-
| Verifast
| C, Java
| https://people.cs.kuleuven.be/~bart.jacobs/verifast
| {{free | yes}}
|-
|}

==Earlier versions of the tools==

# EXE&lt;ref&gt;{{cite journal |last1=Cadar |first1=Cristian |last2=Ganesh |first2=Vijay |last3=Pawlowski |first3=Peter M. |last4=Dill |first4=David L. |last5=Engler |first5=Dawson R. |s2cid=10905673 |title=EXE: Automatically Generating Inputs of Death |journal=ACM Trans. Inf. Syst. Secur. |date=2008 |volume=12 |pages=10:1–10:38 |doi=10.1145/1455518.1455522 }}&lt;/ref&gt; is an earlier version of KLEE . EXE paper can be found [https://dblp.uni-trier.de/rec/bibtex/journals/tissec/CadarGPDE08 here].

==History==
The concept of symbolic execution was introduced academically with descriptions of: the Select system,&lt;ref&gt;Robert S. Boyer and Bernard Elspas and Karl N. Levitt SELECT--a formal system for testing and debugging programs by symbolic execution, Proceedings of the International Conference on Reliable Software, 1975,page 234--245,  Los Angeles, California&lt;/ref&gt;
the EFFIGY system,&lt;ref&gt;James C. King,Symbolic execution and program testing, Communications of the ACM, volume 19, number 7, 1976, 385--394&lt;/ref&gt;
the DISSECT system,&lt;ref&gt;William E. Howden, Experiments with a symbolic evaluation system, Proceedings, National Computer Conference, 1976.&lt;/ref&gt;
and Clarke's system.&lt;ref&gt;Lori A. Clarke, A program testing system, ACM 76: Proceedings of the Annual Conference, 1976, pages 488-491, Houston, Texas, United States&lt;/ref&gt;
See a [https://github.com/saswatanand/symexbib bibliography] of more technical papers published on symbolic execution.

==See also==

* [[Abstract interpretation]]
* [[Symbolic simulation]]
* [[Symbolic computation]]
* [[Concolic testing]]
* [[Control flow graph]]
* [[Dynamic recompilation]]

==References==
&lt;references/&gt;

==External links==
* [http://www.cs.umd.edu/~mwh/se-tutorial/symbolic-exec.pdf Symbolic Execution for finding bugs]
* [http://babelfish.arc.nasa.gov/trac/jpf/raw-attachment/wiki/presentations/start/ICSE2011Short.pptx Symbolic Execution and Software Testing presentation at NASA Ames]
* [https://ti.arc.nasa.gov/publications/3007/download/ Symbolic Execution for Software Testing in Practice – Preliminary Assessment]

{{DEFAULTSORT:Symbolic Execution}}
[[Category:Abstract interpretation]]
[[Category:Computer science]]</text>
      <sha1>0uulxo4ugbpoqo4b1dbjhvrp1c72doe</sha1>
    </revision>
  </page>
  <page>
    <title>Software</title>
    <ns>0</ns>
    <id>5309</id>
    <revision>
      <id>1009494579</id>
      <parentid>1009441263</parentid>
      <timestamp>2021-02-28T21:53:32Z</timestamp>
      <contributor>
        <username>GliderMaven</username>
        <id>8978739</id>
      </contributor>
      <comment>/* top */ link to an article on low level languages</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="33864" xml:space="preserve">{{other uses|Software (disambiguation)}}
{{redirect|Networked|the 2012 book|Networked: The New Social Operating System}}
{{pp-protected|small=yes}}
{{short description|Non-tangible executable component of a computer}}
[[File:Operating system placement (software).svg|thumb|upright|A diagram showing how the [[User (computing)|user]] interacts with [[application software]] on a typical [[desktop computer]]. The application software layer interfaces with the [[operating system]], which in turn communicates with the [[Personal computer hardware|hardware]]. The arrows indicate information flow.]]

'''Software''' is a collection of [[Instruction (computer science)|instructions]] and [[data (computing)|data]] that tell the [[computer]] how to work. This is in contrast to [[Computer hardware|physical hardware]], from which the system is built and actually performs the work. In [[computer science]] and [[software engineering]], computer software is all [[information]] processed by [[computer system]]s, including [[Computer program|program]]s and [[data]]. Computer software includes [[computer program]]s, [[Library (computing)|libraries]] and related non-executable [[Data (computing)|data]], such as [[Software documentation|online documentation]] or [[digital media]]. Computer hardware and software require each other and neither can be realistically used on its own.

At the [[low level language|lowest programming level]], [[executable code]] consists of [[Machine code|machine language]] instructions supported by an individual [[Microprocessor|processor]]—typically a [[central processing unit]] (CPU) or a [[graphics processing unit]] (GPU). A machine language consists of groups of [[Binary number|binary values]] signifying [[Instruction set architecture|processor instructions]] that change the state of the computer from its preceding state. For example, an instruction may change the value stored in a particular storage location in the computer—an effect that is not directly observable to the user. An instruction [[System call|may also invoke]] one of many [[Input/output|input or output operations]], for example displaying some text on a computer screen; causing state changes which should be visible to the [[User (computing)|user]]. The processor [[Instruction cycle|executes]] the instructions in the order they are provided, unless it is instructed to [[branch instruction|"jump" to a different instruction]], or is [[interrupt]]ed by the operating system. {{As of|2015}}, most [[personal computer]]s, [[smartphone]] devices and [[Server (computing)|servers]] have [[Multi-core processor|processors with multiple execution units]] or [[Multiprocessing|multiple processors performing computation]] together, and computing has become a much more [[Concurrent computing|concurrent]] activity than in the past.

The majority of software is written in [[high-level programming language]]s. They are easier and more efficient for programmers because they are closer to [[natural language]]s than machine languages.&lt;ref&gt;{{cite web|title=Compiler construction|url=http://www.cs.uu.nl/education/vak.php?vak=INFOMCCO|url-status=live|archive-url=https://web.archive.org/web/20131102143144/http://www.cs.uu.nl/education/vak.php?vak=INFOMCCO|archive-date=2 November 2013|df=dmy-all}}&lt;/ref&gt; High-level languages are translated into machine language using a [[compiler]] or an [[Interpreter (computing)|interpreter]] or a combination of the two. Software may also be written in a low-level [[assembly language]], which has strong correspondence to the computer's machine language instructions and is translated into machine language using an [[Assembly language|assembler]].

==History==
{{Main|History of software}}
An outline ([[algorithm]]) for what would have been the first piece of software was written by [[Ada Lovelace]] in the 19th century, for the planned [[Analytical Engine]].{{Sfn|Evans|2018|p=21}} She created [[Mathematical proof|proofs]] to show how the engine would calculate [[Bernoulli number|Bernoulli Numbers]].{{Sfn|Evans|2018|p=21}} Because of the proofs and the algorithm, she is considered the first computer programmer.&lt;ref name="Annals of the History of Computing"&gt;{{cite journal|last1=Fuegi|first1=J.|last2=Francis|first2=J.|date=2003|title=Lovelace &amp; Babbage and the creation of the 1843 'notes'|journal=Annals of the History of Computing|volume=25|issue=4|pages=16–26|doi=10.1109/MAHC.2003.1253887|s2cid=40077111|url=http://pdfs.semanticscholar.org/81bb/f32d2642a7a8c6b0a867379a4e9e99d872bc.pdf}}&lt;/ref&gt;&lt;ref name="Lovelace Google"&gt;{{Cite news|url=https://www.theguardian.com/technology/2012/dec/10/ada-lovelace-honoured-google-doodle|title=Ada Lovelace honoured by Google doodle|date=December 10, 2012|newspaper=The Guardian|access-date=25 November 2018}}&lt;/ref&gt;

The first theory about software—prior to the creation of computers as we know them today—was proposed by [[Alan Turing]] in his 1935 essay ''On Computable Numbers, with an Application to the Entscheidungsproblem'' (decision problem).

This eventually led to the creation of the academic fields of [[computer science]] and [[software engineering]]; Both fields study software and its creation. Computer science is the theoretical study of computer and software (Turing's essay is an example of computer science), whereas software engineering is the application of engineering and development of software.

However, prior to 1946, software was not yet the programs stored in the memory of stored-program digital computers, as we now understand it. The first electronic computing devices were instead rewired in order to "reprogram" them.

In 2000, Fred Shapiro, a librarian at the Yale Law School, published a letter revealing that [[John Wilder Tukey]]'s 1958 paper "The Teaching of Concrete Mathematics"&lt;ref name="Tukey_1958"/&gt;&lt;ref name="Beebe_2017"/&gt; contained the earliest known usage of the term "software" found in a search of [[JSTOR]]'s electronic archives, predating the [[OED]]'s citation by two years.&lt;ref name="Shapiro_2000"/&gt; This led many to credit Tukey with coining the term, particularly in obituaries published that same year,&lt;ref name="Leonhardt_2000"/&gt; although Tukey never claimed credit for any such coinage. In 1995, Paul Niquette claimed he had originally coined the term in October 1953, although he could not find any documents supporting his claim.&lt;ref name="Niquette_2006"/&gt; The earliest known publication of the term "software" in an engineering context was in August 1953 by Richard R. Carhart, in a [[Rand Corporation]] Research Memorandum.&lt;ref name="Carhart_1953"/&gt;

==Types==
{{See also|Software categories}}
[[File:BgeCarSc.jpg|thumb|250px|[[Blender Game Engine]], a [[free software]] program.]]

On virtually all computer platforms, software can be grouped into a few broad categories.

===Purpose, or domain of use===
{{Ecommerce}}
Based on the goal, computer software can be divided into:

* '''[[Application software]]''' &lt;br /&gt; which is software that uses the computer system to perform special functions or provide [[video game|entertainment functions]] beyond the basic operation of the computer itself. There are many different types of application software, because the range of tasks that can be performed with a modern computer is so large—see [[list of software]].
* '''[[System software]]''' &lt;br /&gt; which is software for managing '''[[computer hardware]]''' behaviour, as to provide basic functionalities that are required by users, or for other software to run properly, if at all. System software is also designed for providing a platform for running application software,&lt;ref&gt;{{cite web|url=http://home.olemiss.edu/~misbook/sfsysfm.htm|title=System Software|publisher=The University of Mississippi|archive-url=https://web.archive.org/web/20010530092843/http://home.olemiss.edu/~misbook/sfsysfm.htm|archive-date=30 May 2001|url-status=dead|df=dmy-all}}&lt;/ref&gt; and it includes the following:
**'''[[Operating system]]s''' &lt;br /&gt; which are essential collections of software that manage resources and provide common services for other software that runs "on top" of them. [[Supervisory program]]s, [[boot loader]]s, [[shell (computing)|shells]] and [[window system]]s are core parts of operating systems. In practice, an operating system comes bundled with additional software (including application software) so that a user can potentially do some work with a computer that only has one operating system.
** '''[[Device driver]]s''' &lt;br /&gt; which operate or control a particular type of device that is attached to a computer. Each device needs at least one corresponding device driver; because a computer typically has at minimum at least one input device and at least one output device, a computer typically needs more than one device driver.
** '''[[Software utility|Utilities]]''' &lt;br /&gt; which are computer [[Control Panel (Windows)|programs]] designed to assist users in the maintenance and care of their computers.
* '''[[Malicious software]]''' or '''malware''' &lt;br /&gt; which is software that is developed to harm and disrupt computers. As such, malware is undesirable. Malware is closely associated with computer-related crimes, though some malicious programs may have been designed as [[practical joke]]s.

===Nature or domain of execution===
* [[Desktop applications]] such as [[web browser]]s and [[Microsoft Office]], as well as [[smartphone]] and [[Tablet computer|tablet]] applications (called "[[mobile app|apps]]"). (There is a push in some parts of the software industry to merge desktop applications with mobile apps, to some extent. [[Windows 8]], and later [[Ubuntu Touch]], tried to allow the same style of application user interface to be used on desktops, laptops and mobiles.)
* [[JavaScript]] scripts are pieces of software traditionally embedded in [[web page]]s that are run directly inside the [[web browser]] when a web page is loaded without the need for a web browser plugin. Software written in other programming languages can also be run within the web browser if the software is either translated into JavaScript, or if a web browser plugin that supports that language is installed; the most common example of the latter is [[ActionScript]] scripts, which are supported by the [[Adobe Flash]] plugin.
* [[Server software]], including:
** [[Web application]]s, which usually run on the [[web server]] and output dynamically generated web pages to web browsers, using e.g. [[PHP]], [[Java (programming language)|Java]], [[ASP.NET]], or even [[Node.js|JavaScript that runs on the server]]. In modern times these commonly include some JavaScript to be run in the web browser as well, in which case they typically run partly on the server, partly in the web browser.
* [[Plug-in (computing)|Plugins]] and extensions are software that extends or modifies the functionality of another piece of software, and require that software be used in order to function;
* [[Embedded software]] resides as [[firmware]] within [[embedded system]]s, devices dedicated to a single use or a few uses such as [[car]]s and [[television]]s (although some embedded devices such as wireless chipsets can ''themselves'' be part of an ordinary, non-embedded computer system such as a PC or smartphone).&lt;ref&gt;{{cite web|title=Embedded Software—Technologies and Trends|url=http://www.computer.org/csdl/mags/so/2009/03/mso2009030014.html|publisher=IEEE Computer Society|date=May–June 2009|access-date=6 November 2013|url-status=live|archive-url=https://web.archive.org/web/20131028045823/http://www.computer.org/csdl/mags/so/2009/03/mso2009030014.html|archive-date=28 October 2013|df=dmy-all}}&lt;/ref&gt; In the embedded system context there is sometimes no clear distinction between the system software and the application software. However, some embedded systems run [[embedded operating system]]s, and these systems do retain the distinction between system software and application software (although typically there will only be one, fixed application which is always run).
* [[Microcode]] is a special, relatively obscure type of embedded software which tells the processor ''itself'' how to execute machine code, so it is actually a lower level than machine code. It is typically proprietary to the processor manufacturer, and any necessary correctional microcode software updates are supplied by them to users (which is much cheaper than shipping replacement processor hardware). Thus an ordinary programmer would not expect to ever have to deal with it.

===Programming tools===
{{Main|Programming tool}}
Programming tools are also software in the form of programs or applications that [[software developer]]s (also known as
''programmers, coders, hackers'' or ''software engineers'') use to create, [[Debugging|debug]], [[Software maintenance|maintain]] (i.e. improve or fix), or otherwise [[Technical support|support]] software.

Software is written in one or more programming languages; there are many programming languages in existence, and each has at least one implementation, each of which consists of its own set of programming tools. These tools may be relatively self-contained programs such as [[compiler]]s, [[debugger]]s, [[interpreter (computing)|interpreters]], [[linker (computing)|linkers]], and [[text editor]]s, that can be combined together to accomplish a task; or they may form an [[integrated development environment]] (IDE), which combines much or all of the functionality of such self-contained tools. IDEs may do this by either invoking the relevant individual tools or by re-implementing their functionality in a new way. An IDE can make it easier to do specific tasks, such as searching in files in a particular project. Many programming language implementations provide the option of using both individual tools or an IDE.

==Topics==
===Architecture===
{{See also|Software architecture}}
Users often see things differently from programmers. People who use modern general purpose computers (as opposed to [[embedded system]]s, [[analog computer]]s and [[supercomputer]]s) usually see three layers of software performing a variety of tasks: platform, application, and user software.

* '''Platform software''' &lt;br /&gt; The [[Platform (computing)|Platform]] includes the [[firmware]], [[device driver]]s, an [[operating system]], and typically a [[graphical user interface]] which, in total, allow a user to interact with the computer and its [[peripheral]]s (associated equipment). Platform software often comes bundled with the computer. On a [[Personal computer|PC]] one will usually have the ability to change the platform software.
* '''Application software''' &lt;br /&gt; [[Application software]] or Applications are what most people think of when they think of software. Typical examples include office suites and video games. [[Application software]] is often purchased separately from computer hardware. Sometimes applications are bundled with the computer, but that does not change the fact that they run as independent applications. Applications are usually independent programs from the operating system, though they are often tailored for specific platforms. Most users think of compilers, databases, and other "system software" as applications.
* '''User-written software''' &lt;br /&gt; [[End-user development]] tailors systems to meet users' specific needs. User software includes spreadsheet templates and [[word processor]] templates. Even email filters are a kind of user software. Users create this software themselves and often overlook how important it is. Depending on how competently the user-written software has been integrated into default application packages, many users may not be aware of the distinction between the original packages, and what has been added by co-workers.

===Execution===
{{Main|Execution (computing)}}
Computer software has to be "loaded" into the [[computer storage|computer's storage]] (such as the [[hard drive]] or [[Computer memory|memory]]). Once the software has loaded, the computer is able to ''execute'' the software. This involves passing [[instruction set architecture|instructions]] from the [[application software]], through the system software, to the hardware which ultimately receives the instruction as [[machine code]]. Each instruction causes the computer to carry out an operation—moving [[data (computing)|data]], carrying out a [[computation]], or altering the [[control flow]] of instructions.

Data movement is typically from one place in memory to another. Sometimes it involves moving data between memory and registers which enable high-speed data access in the CPU. Moving data, especially large amounts of it, can be costly. So, this is sometimes avoided by using "pointers" to data instead. Computations include simple operations such as incrementing the value of a variable data element. More complex computations may involve many operations and data elements together.&lt;!-- This section is simply too long for this article and needs to be compressed into the intro above, or moved to the article itself.

Instructions may be performed sequentially, conditionally, or iteratively. Sequential instructions are those operations that are performed one after another. Conditional instructions are performed such that different sets of instructions execute depending on the value(s) of some data. In some languages this is known as an "if" statement. Iterative instructions are performed repetitively and may depend on some data value. This is sometimes called a "loop." Often, one instruction may "call" another set of instructions that are defined in some other program or [[modular programming|module]]. When more than one computer processor is used, instructions may be executed simultaneously.

A simple example of the way software operates is what happens when a user selects an entry such as "Copy" from a menu. In this case, a conditional instruction is executed to copy text from data in a 'document' area residing in memory, perhaps to an intermediate storage area known as a 'clipboard' data area. If a different menu entry such as "Paste" is chosen, the software may execute the instructions to copy the text from the clipboard data area to a specific location in the same or another document in memory.

Depending on the application, even the example above could become complicated. The field of software engineering endeavors to manage the complexity of how software operates. This is especially true for software that operates in the context of a large or powerful [[computer system]].

Currently, almost the only limitations on the use of computer software in applications is the ingenuity of the designer/programmer. Consequently, large areas of activities (such as playing grand master-level chess) formerly assumed to be incapable of software simulation are now routinely programmed. The only area that has so far proved reasonably secure from software simulation is the realm of human art— especially, pleasing music and literature.{{Citation needed|date=June 2007}}

Kinds of software by operation: [[computer program]] as [[executable]], [[source code]] or [[scripting language|script]], [[computer configuration|configuration]].--&gt;

===Quality and reliability===
{{Main|Software quality|Software testing}}
Software quality is very important, especially for [[commercial software|commercial]] and system software like [[Microsoft Office]], [[Microsoft Windows]] and [[Linux]]. If software is faulty (buggy), it can delete a person's work, crash the computer and do other unexpected things. Faults and errors are called "[[Software bug|bugs]]" which are often discovered during alpha and beta testing. Software is often also a victim to what is known as [[software aging]], the progressive performance degradation resulting from a combination of unseen bugs.

Many bugs are discovered and eliminated (debugged) through [[software testing]]. However, software testing rarely—if ever—eliminates every bug; some programmers say that "every program has at least one more bug" (Lubarsky's Law).&lt;ref name="github"&gt;{{cite web | url=https://github.com/mark-watson/scripting-intelligence-book-examples/blob/master/part1/wikipedia_text/software.txt | title=scripting intelligence book examples | url-status=live | archive-url=https://web.archive.org/web/20151106154317/https://github.com/mark-watson/scripting-intelligence-book-examples/blob/master/part1/wikipedia_text/software.txt | archive-date=6 November 2015 | df=dmy-all | date=2018-05-09 }}&lt;/ref&gt; In the [[Waterfall model|waterfall]] method of software development, separate testing teams are typically employed, but in newer approaches, collectively termed [[agile software development]], developers often do all their own testing, and demonstrate the software to users/clients regularly to obtain feedback. Software can be tested through [[unit testing]], [[regression testing]] and other methods, which are done manually, or most commonly, automatically, since the amount of code to be tested can be quite large. For instance, [[NASA]] has extremely rigorous software testing procedures for many operating systems and communication functions. Many NASA-based operations interact and identify each other through command programs. This enables many people who work at NASA to check and evaluate functional systems overall. Programs containing command software enable hardware engineering and system operations to function much easier together.

===License===
{{Main|Software license}}
The software's license gives the user the right to use the software in the licensed environment, and in the case of [[free software license]]s, also grants other rights such as the right to make copies.

[[Proprietary software]] can be divided into two types:

* [[freeware]], which includes the category of "free trial" software or "[[freemium]]" software (in the past, the term [[shareware]] was often used for free trial/freemium software). As the name suggests, freeware can be used for free, although in the case of free trials or freemium software, this is sometimes only true for a limited period of time or with limited functionality.
* software available for a fee, often inaccurately termed "[[commercial software]]", which can only be legally used on purchase of a license.

[[Open-source software]], on the other hand, comes with a [[free software license]], granting the recipient the rights to modify and redistribute the software.

===Patents===
{{Main|Software patent|Software patent debate}}
Software patents, like other types of patents, are theoretically supposed to give an inventor an exclusive, time-limited license for a ''detailed idea (e.g. an algorithm) on how to implement'' a piece of software, or a component of a piece of software. Ideas for useful things that software could ''do'', and user ''requirements'', are not supposed to be patentable, and concrete implementations (i.e. the actual software packages implementing the patent) are not supposed to be patentable either—the latter are already covered by copyright, generally automatically. So software patents are supposed to cover the middle area, between requirements and concrete implementation. In some countries, a requirement for the claimed invention to have an effect on the physical world may also be part of the requirements for a software patent to be held valid—although since ''all'' useful software has effects on the physical world, this requirement may be open to debate. Meanwhile, American copyright law was applied to various aspects of the writing of the software code.&lt;ref&gt;Gerardo Con Díaz, "The Text in the Machine: American Copyright Law and the Many Natures of Software, 1974–1978,” ''Technology and Culture'' 57 (October 2016), 753–79.&lt;/ref&gt;

Software patents are controversial in the software industry with many people holding different views about them. One of the sources of controversy is that the aforementioned split between initial ideas and patent does not seem to be honored in practice by patent lawyers—for example the patent for [[Aspect-Oriented Programming]] (AOP), which purported to claim rights over ''any'' programming tool implementing the idea of AOP, howsoever implemented. Another source of controversy is the effect on innovation, with many distinguished experts and companies arguing that software is such a fast-moving field that software patents merely create vast additional litigation costs and risks, and actually retard innovation. In the case of debates about software patents outside the United States, the argument has been made that large American corporations and patent lawyers are likely to be the primary beneficiaries of allowing or continue to allow software patents.

==Design and implementation==
{{Main|Software development|Computer programming|Software engineering}}
Design and implementation of software varies depending on the complexity of the software. For instance, the design and creation of [[Microsoft Word]] took much more time than designing and developing [[Microsoft Notepad]] because the latter has much more basic functionality.

Software is usually designed and created (aka coded/written/programmed) in [[integrated development environment]]s (IDE) like [[Eclipse (software)|Eclipse]], [[IntelliJ IDEA|IntelliJ]] and [[Microsoft Visual Studio]] that can simplify the process and [[compiler|compile]] the software (if applicable). As noted in a different section, software is usually created on top of existing software and the [[application programming interface]] (API) that the underlying software provides like [[GTK+]], JavaBeans or [[Swing (Java)|Swing]]. Libraries (APIs) can be categorized by their purpose. For instance, the [[Spring Framework]] is used for implementing [[enterprise application]]s, the [[Windows Forms]] library is used for designing graphical user interface (GUI) applications like [[Microsoft Word]], and [[Windows Communication Foundation]] is used for designing [[web service]]s. When a program is designed, it relies upon the API. For instance, a Microsoft Windows desktop application might call API functions in the [[.NET Framework|.NET]] Windows Forms library like ''Form1.Close()'' and ''Form1.Show()''&lt;ref&gt;{{cite web |url=http://msdn.microsoft.com/en-us/library/default.aspx |title=MSDN Library |access-date=2010-06-14 |url-status=live |archive-url=https://web.archive.org/web/20100611204810/http://msdn.microsoft.com/en-us/library/default.aspx |archive-date=11 June 2010 |df=dmy-all }}&lt;/ref&gt; to close or open the application. Without these APIs, the programmer needs to write these functionalities entirely themselves. Companies like [[Oracle Corporation|Oracle]] and [[Microsoft]] provide their own APIs so that many applications are written using their [[Library (computing)|software libraries]] that usually have numerous APIs in them.

[[Data structure]]s such as [[hash table]]s, [[array data type|arrays]], and [[binary tree]]s, and [[algorithm]]s such as [[quicksort]], can be useful for creating software.

Computer software has special economic characteristics that make its design, creation, and distribution different from most other economic goods.{{Specify|Which characteristics?|date=May 2012}}&lt;ref&gt;{{cite journal |author=v. Engelhardt, Sebastian |year=2008 |url=https://ideas.repec.org/p/jrp/jrpwrp/2008-045.html |title=The Economic Properties of Software |journal=Jena Economic Research Papers |volume=2 |issue=2008–045 |url-status=live |archive-url=https://web.archive.org/web/20160105145954/https://ideas.repec.org/p/jrp/jrpwrp/2008-045.html |archive-date=5 January 2016 |df=dmy-all }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://dankaminsky.com/1999/03/02/69/ |title=Why Open Source Is The Optimum Economic Paradigm for Software |first=Dan |last=Kaminsky |year=1999 |url-status=live |archive-url=https://web.archive.org/web/20120522001231/http://dankaminsky.com/1999/03/02/69/ |archive-date=22 May 2012 |df=dmy-all }}&lt;/ref&gt;

A person who creates software is called a [[programmer]], [[software engineer]] or software developer, terms that all have a similar meaning. More informal terms for programmer also exist such as "coder" and "'''hacker'''"{{Spaced ndash}}although use of the latter word may cause confusion, because it is more often used to mean [[Security hacker|someone who illegally breaks into computer systems]].

==Industry and organizations==
{{Main|Software industry}}
A great variety of software companies and programmers in the world comprise a software industry. Software can be quite a profitable industry: [[Bill Gates]], the co-founder of [[Microsoft]] was the richest person in the world in 2009, largely due to his ownership of a significant number of shares in Microsoft, the company responsible for [[Microsoft Windows]] and [[Microsoft Office]] software products - both market leaders in their respective product categories.

Non-profit software organizations include the [[Free Software Foundation]], [[GNU Project]] and the [[Mozilla Foundation]]. Software standard organizations like the [[W3C]], [[IETF]] develop recommended software standards such as [[XML]], [[HTTP]] and [[HTML]], so that software can interoperate through these standards.

Other well-known large software companies include [[Google]], [[IBM]], [[Tata Consultancy Services|TCS]], [[Infosys]], [[Wipro]], [[HCL Technologies]], [[Oracle Corporation|Oracle]], [[Novell]], [[SAP AG|SAP]], [[NortonLifeLock|Symantec]], [[Adobe Systems]], [[Sidetrade]] and [[Corel]], while small companies often provide innovation.

==See also==
* [[Software release life cycle]]
* [[Independent software vendor]]
* [[Outline of software]]
* [[Software asset management]]
* [[Open-source software]]
{{Portal bar|Free and open-source software}}

==References==
{{reflist|refs=
&lt;ref name="Carhart_1953"&gt;{{cite book |author-last=Carhart |author-first=Richard |title=A survey of the current status of the electronic reliability problem |date=1953 |publisher=[[Rand Corporation]] |location=Santa Monica, CA |page=69 |url=https://www.rand.org/content/dam/rand/pubs/research_memoranda/2013/RM1131.pdf#79 |quote=[…] It will be recalled from Sec. 1.6 that the term ''personnel'' was defined to include people who come into direct contact with the hardware, from production to field use, i.e., people who assemble, inspect, pack, ship, handle, install, operate, and maintain electronic equipment. In any of these phases personnel failures may result in unoperational gear. As with the hardware factors, there is almost no quantitative data concerning these software or human factors in reliability: How many faults are caused by personnel, why they occur, and what can be done to remove the errors. […]}}&lt;/ref&gt;
&lt;ref name="Tukey_1958"&gt;{{cite journal |author-first=John Wilder |author-last=Tukey |author-link=John Wilder Tukey |title=The Teaching of Concrete Mathematics |journal=[[American Mathematical Monthly]] |publisher=[[Taylor &amp; Francis, Ltd.]] / [[Mathematical Association of America]] |volume=65 |issue=1 |pages=1–9, 2 |date=January 1958 |id={{CODEN|AMMYAE}} |issn=0002-9890 |doi=10.2307/2310294 |quote=[…] Today the "software" comprising the carefully planned interpretive routines, compilers, and other aspects of automative programming are at least as important to the modern electronic calculator as its "hardware" of tubes, transistors, wires, tapes, and the like. […]|jstor=2310294 }}&lt;/ref&gt;
&lt;ref name="Niquette_2006"&gt;{{citation |author-last=Niquette |author-first=R. Paul |date=2006 |title=Softword: Provenance for the Word 'Software |isbn=1-58922-233-4 |url=http://www.niquette.com/books/softword/tocsoft.html |access-date=2019-08-18 |url-status=live |archive-url=https://web.archive.org/web/20190808124650/http://www.niquette.com/books/softword/tocsoft.html |archive-date=2019-08-08}}&lt;/ref&gt;
&lt;ref name="Shapiro_2000"&gt;{{cite journal |author-last=Shapiro |author-first=Fred |date=2000 |title=Origin of the Term Software: Evidence from the JSTOR Electronic Journal Archive |journal=[[IEEE Annals of the History of Computing]] |volume=22 |issue=2 |pages=69–71 |doi=10.1109/mahc.2000.887997 |url=http://computer.org/annals/an2000/pdf/a2069.pdf |access-date=2013-06-25 |url-status=dead |archive-url=https://web.archive.org/web/20030605004419/http://computer.org/annals/an2000/pdf/a2069.pdf |archive-date=2003-06-05}}&lt;/ref&gt;
&lt;ref name="Leonhardt_2000"&gt;{{cite news |title=John Tukey, 85, Statistician; Coined the Word 'Software' |author-last=Leonhardt |author-first=David |newspaper=[[The New York Times]] |date=2000-07-28 |url=https://www.nytimes.com/2000/07/28/us/john-tukey-85-statistician-coined-the-word-software.html |access-date=2012-09-24}}&lt;/ref&gt;
&lt;ref name="Beebe_2017"&gt;{{cite book |author-first=Nelson H. F. |author-last=Beebe |title=The Mathematical-Function Computation Handbook - Programming Using the MathCW Portable Software Library |chapter=Chapter I - Integer arithmetic |date=2017-08-22 |location=Salt Lake City, UT, USA |publisher=[[Springer International Publishing AG]] |edition=1 |lccn=2017947446 |isbn=978-3-319-64109-6 |doi=10.1007/978-3-319-64110-2 |pages=969, 1035|s2cid=30244721 }}&lt;/ref&gt;
}}

===Sources===
*{{Cite book|url=https://books.google.com/books?id=C8ouDwAAQBAJ&amp;q=9780735211759&amp;pg=PP1|title=Broad Band: The Untold Story of the Women Who Made the Internet|last=Evans|first=Claire L.|publisher=Portfolio/Penguin|year=2018|isbn=9780735211759|location=New York}}

==External links==
{{Sister project links | wikt=software | commons=Special:Search/Software | b= | n= | s= | v=Computer Software | voy= |q=no}}
* {{curlie|Computers/Software}}&lt;!--ref name="github"/--&gt;

{{Software digital distribution platforms|state=collapsed}}
{{Authority control}}
{{Use dmy dates|date=May 2017}}

[[Category:Software| ]]
[[Category:Computer science]]
[[Category:Mathematical and quantitative methods (economics)]]</text>
      <sha1>dykxk7c60tllm97cb84c485vx481zlp</sha1>
    </revision>
  </page>
  <page>
    <title>Machine learning in bioinformatics</title>
    <ns>0</ns>
    <id>53970843</id>
    <revision>
      <id>1009994352</id>
      <parentid>979025830</parentid>
      <timestamp>2021-03-03T08:39:37Z</timestamp>
      <contributor>
        <username>Eudamonic</username>
        <id>36879710</id>
      </contributor>
      <comment>added Differentiable computing navbox</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="15704" xml:space="preserve">{{Use mdy dates|date=September 2017}}
'''[[Machine learning]]''', a subfield of [[computer science]] involving the development of algorithms that learn how to make predictions based on [[Database|data]], has a number of emerging applications in the field of [[bioinformatics]]. Bioinformatics deals with computational and mathematical approaches for understanding and processing biological data.&lt;ref&gt;{{cite journal 
| vauthors = Chicco D
| title = Ten quick tips for machine learning in computational biology 
| journal = BioData Mining
| volume = 10
| issue =  35
| pages = 35 
| date = December 2017 
| pmid = 29234465
| doi = 10.1186/s13040-017-0155-3
| pmc= 5721660}}&lt;/ref&gt;

Prior to the emergence of machine learning algorithms, bioinformatics algorithms had to be explicitly programmed by hand which, for problems such as [[protein structure prediction]], proves extremely difficult.&lt;ref name=":2"&gt;{{Cite journal|last=Yang|first=Yuedong|last2=Gao|first2=Jianzhao|last3=Wang|first3=Jihua|last4=Heffernan|first4=Rhys|last5=Hanson|first5=Jack|last6=Paliwal|first6=Kuldip|last7=Zhou|first7=Yaoqi|title=Sixty-five years of the long march in protein secondary structure prediction: the final stretch?|journal=Briefings in Bioinformatics|volume=19|issue=3|pages=482–494|doi=10.1093/bib/bbw129|pmid=28040746|pmc=5952956|date=May 2018}}&lt;/ref&gt; Machine learning techniques such as [[deep learning]] enable the algorithm to make use of automatic [[feature learning]] which means that based on the dataset alone, the algorithm can learn how to combine multiple [[Feature (machine learning)|features]] of the input data into a more abstract set of features from which to conduct further learning. This multi-layered approach to learning patterns in the input data allows such systems to make quite complex predictions when trained on large datasets. In recent years, the size and number of available biological datasets have skyrocketed, enabling bioinformatics researchers to make use of these machine learning systems.&lt;ref name=":0" /&gt; Machine learning has been applied to six biological domains: [[genomics]], [[proteomics]], [[microarrays]], [[systems biology]], [[evolution]], and [[text mining]].&lt;ref name=":0"&gt;{{Cite journal|last=Larrañaga|first=Pedro|last2=Calvo|first2=Borja|last3=Santana|first3=Roberto|last4=Bielza|first4=Concha|last5=Galdiano|first5=Josu|last6=Inza|first6=Iñaki|last7=Lozano|first7=José A.|last8=Armañanzas|first8=Rubén|last9=Santafé|first9=Guzmán|title=Machine learning in bioinformatics|journal=Briefings in Bioinformatics|volume=7|issue=1|pages=86–112|doi=10.1093/bib/bbk007|pmid=16761367|date=March 2006|doi-access=free}}&lt;/ref&gt;

== Applications ==

=== Genomics ===
[[File:Growth of GenBank.png|thumb|The exponential growth of GenBank, a genomic sequence database provided by the National center for Biotechnology Information (NCBI)]]
[[Genomics]] involves the study of the [[genome]], the complete [[DNA sequencing|DNA sequence]], of organisms. While genomic sequence data has historically been sparse due to the technical difficulty in sequencing a piece of DNA, the number of available sequences is growing exponentially.&lt;ref&gt;{{Cite web|url=https://www.ncbi.nlm.nih.gov/genbank/statistics/|title=GenBank and WGS Statistics|website=www.ncbi.nlm.nih.gov|language=en|access-date=2017-05-06}}&lt;/ref&gt; However, while [[raw data]] is becoming increasingly available and accessible, the biological interpretation of this data is occurring at a much slower pace.&lt;ref name=":1"&gt;{{Cite journal|last=Mathé|first=Catherine|last2=Sagot|first2=Marie-France|last3=Schiex|first3=Thomas|last4=Rouzé|first4=Pierre|date=October 1, 2002|title=Current methods of gene prediction, their strengths and weaknesses|journal=Nucleic Acids Research|volume=30|issue=19|pages=4103–4117|issn=1362-4962|pmc=140543|pmid=12364589|doi=10.1093/nar/gkf543}}&lt;/ref&gt; Therefore, there is an increasing need for the development of machine learning systems that can automatically determine the location of protein-encoding genes within a given DNA sequence.&lt;ref name=":1" /&gt; This is a problem in computational biology known as [[gene prediction]].

Gene prediction is commonly performed through a combination of what are known as extrinsic and intrinsic searches.&lt;ref name=":1" /&gt; For the extrinsic search, the input DNA sequence is run through a large database of sequences whose genes have been previously discovered and their locations annotated. A number of the sequence's genes can be identified by determining which strings of bases within the sequence are [[Homology (biology)|homologous]] to known gene sequences. However, given the limitation in size of the database of known and annotated gene sequences, not all the genes in a given input sequence can be identified through homology alone. Therefore, an intrinsic search is needed where a gene prediction program attempts to identify the remaining genes from the DNA sequence alone.&lt;ref name=":1" /&gt;

Machine learning has also been used for the problem of [[multiple sequence alignment]] which involves aligning many DNA or amino acid sequences in order to determine regions of similarity that could indicate a shared evolutionary history.&lt;ref name=":0" /&gt;
It can also be used to detect and visualize genome rearrangements.&lt;ref name="rearrang"&gt;{{cite journal|last=Pratas|first=D|author2=Silva, R|author3= Pinho, A|author4= Ferreira, P|title=An alignment-free method to find and visualise rearrangements between pairs of DNA sequences.|journal=Scientific Reports|date=May 18, 2015|volume=5|number=10203|pmid=25984837|doi=10.1038/srep10203|pages=10203|pmc=4434998|bibcode=2015NatSR...510203P}}&lt;/ref&gt;

=== Proteomics ===
[[File:C16orf95 protein secondary structure prediction.png|thumb|A protein's amino acid sequence annotated with the protein secondary structure. Each amino acid is labeled as either an alpha helix, a beta sheet, or a coil.]]
[[Protein]]s, strings of [[amino acid]]s, gain much of their function from [[protein folding]] in which they conform into a three-dimensional structure. This structure is composed of a number of layers of folding, including the [[Protein primary structure|primary structure]] (i.e. the flat string of amino acids), the [[Protein secondary structure|secondary structure]] ([[Alpha helix|alpha helices]] and [[beta sheet]]s), the [[Protein tertiary structure|tertiary structure]], and the [[Protein quaternary structure|quartenary structure]].

Protein secondary structure prediction is a main focus of this subfield as the further protein foldings (tertiary and quartenary structures) are determined based on the secondary structure.&lt;ref name=":2" /&gt; Solving the true structure of a protein is an incredibly expensive and time-intensive process, furthering the need for systems that can accurately predict the structure of a protein by analyzing the amino acid sequence directly.&lt;ref name=":2" /&gt;&lt;ref name=":0" /&gt; Prior to machine learning, researchers needed to conduct this prediction manually. This trend began in 1951 when Pauling and Corey released their work on predicting the hydrogen bond configurations of a protein from a polypeptide chain.&lt;ref&gt;{{Cite journal|last=Pauling|first=L.|last2=Corey|first2=R. B.|last3=Branson|first3=H. R.|date=April 1, 1951|title=The structure of proteins; two hydrogen-bonded helical configurations of the polypeptide chain|journal=Proceedings of the National Academy of Sciences of the United States of America|volume=37|issue=4|pages=205–211|issn=0027-8424|pmc=1063337|pmid=14816373|doi=10.1073/pnas.37.4.205|bibcode=1951PNAS...37..205P}}&lt;/ref&gt; Today, through the use of automatic feature learning, the best machine learning techniques are able to achieve an accuracy of 82-84%.&lt;ref name=":2" /&gt;&lt;ref name=":3" /&gt; The current state-of-the-art in secondary structure prediction uses a system called DeepCNF (deep convolutional neural fields) which relies on the machine learning model of [[artificial neural network]]s to achieve an accuracy of approximately 84% when tasked to classify the amino acids of a protein sequence into one of three structural classes (helix, sheet, or coil).&lt;ref name=":3"&gt;{{cite journal|last=Wang|first=Sheng|last2=Peng|first2=Jian|last3=Ma|first3=Jianzhu|last4=Xu|first4=Jinbo|date=December 1, 2015|title=Protein secondary structure prediction using deep convolutional neural fields|journal=Scientific Reports|volume=6|pages=18962|arxiv=1512.00843|bibcode=2016NatSR...618962W|doi=10.1038/srep18962|pmid=26752681|pmc=4707437}}&lt;/ref&gt; The theoretical limit for three-state protein secondary structure is 88–90%.&lt;ref name=":2" /&gt;

Machine learning has also been applied to proteomics problems such as [[Side chain|protein side-chain]] prediction, [[Turn (biochemistry)|protein loop]] modeling, and [[protein contact map]] prediction.&lt;ref name=":0" /&gt;

=== Microarrays ===
Microarrays, a type of [[lab-on-a-chip]], are used for automatically collecting data about large amounts of biological material. Machine learning can aid in the analysis of this data, and it has been applied to expression pattern identification, classification, and genetic network induction.&lt;ref name=":0" /&gt;
[[File:DNA-microarray analysis.jpg|thumb|A DNA-microarray analysis of Burkitt's lymphoma and diffuse large B-cell lymphoma (DLBCL) is shown and identifies differences in gene expression patterns.]]
This technology is especially useful for monitoring the expression of genes within a genome, aiding in diagnosing different types of cancer based on which genes are expressed.&lt;ref name=":4"&gt;{{Cite journal|last=Pirooznia|first=Mehdi|last2=Yang|first2=Jack Y.|last3=Yang|first3=Mary Qu|last4=Deng|first4=Youping|date=2008|title=A comparative study of different machine learning methods on microarray gene expression data|journal=BMC Genomics|volume=9|issue=1|pages=S13|doi=10.1186/1471-2164-9-S1-S13|issn=1471-2164|pmc=2386055|pmid=18366602}}&lt;/ref&gt; One of the main problems in this field is identifying which genes are expressed based on the collected data.&lt;ref name=":0" /&gt; In addition, due to the huge number of genes on which data is collected by the microarray, there is a large amount of irrelevant data to the task of expressed gene identification, further complicating this problem. Machine learning presents a potential solution to this problem as various classification methods can be used to perform this identification. The most commonly used methods are [[radial basis function network]]s, [[deep learning]], [[Naive Bayes classifier|Bayesian classification]], [[decision tree]]s, and [[random forest]].&lt;ref name=":4" /&gt;

=== Systems biology ===
Systems biology focuses on the study of the emergent behaviors from complex interactions of simple biological components in a system. Such components can include molecules such as DNA, RNA, proteins, and metabolites.&lt;ref&gt;{{Cite web|url=http://journal.frontiersin.org/researchtopic/2362/machine-learning-in-molecular-systems-biology|title=Machine Learning in Molecular Systems Biology|website=Frontiers|language=en|access-date=2017-06-09}}&lt;/ref&gt;

Machine learning has been used to aid in the modelling of these complex interactions in biological systems in domains such as genetic networks, signal transduction networks, and metabolic pathways.&lt;ref name=":0" /&gt; [[Graphical model|Probabilistic graphical models]], a machine learning technique for determining the structure between different variables, are one of the most commonly used methods for modeling genetic networks.&lt;ref name=":0" /&gt; In addition, machine learning has been applied to systems biology problems such as identifying [[DNA binding site|transcription factor binding sites]] using a technique known as [[Markov chain|Markov chain optimization]].&lt;ref name=":0" /&gt; [[Genetic algorithm]]s, machine learning techniques which are based on the natural process of evolution, have been used to model genetic networks and regulatory structures.&lt;ref name=":0" /&gt;

Other systems biology applications of machine learning include the task of enzyme function prediction, high throughput microarray data analysis, analysis of genome-wide association studies to better understand markers of disease, protein function prediction.&lt;ref&gt;{{Cite journal|last=d'Alché-Buc|first=Florence|last2=Wehenkel|first2=Louis|date=2008|title=Machine Learning in Systems Biology|journal=BMC Proceedings|volume=2|issue=4|pages=S1|doi=10.1186/1753-6561-2-S4-S1|pmid=19091048|pmc=2654969|issn=1753-6561}}&lt;/ref&gt;

=== Stroke Diagnosis ===
Machine learning methods for analysis of [[neuroimaging]] data are used to help diagnose [[stroke]]. Three-dimensional [[Convolutional neural network|CNN]] and [[Support-vector machine|SVM]] methods are often used. 
&lt;ref name="stroke1"&gt;{{cite journal |last1=Jiang |first1=Fei |title=Artificial intelligence in healthcare: past, present and future |journal=BMJ Journals Stroke and Vascular Neurology |date=2017 |volume=2 |issue=4 |pages=230–243 |doi=10.1136/svn-2017-000101 |pmid=29507784 |pmc=5829945 |url=https://svn.bmj.com/content/svnbmj/2/4/230.full.pdf |accessdate=23 January 2019}}&lt;/ref&gt;

=== Text mining ===
The increase in available biological publications led to the issue of the increase in difficulty in searching through and compiling all the relevant available information on a given topic across all sources. This task is known as [[knowledge extraction]]. This is necessary for biological data collection which can then in turn be fed into machine learning algorithms to generate new biological knowledge.&lt;ref name=":0" /&gt;&lt;ref name=":5"&gt;{{Cite journal|last=Krallinger|first=Martin|last2=Erhardt|first2=Ramon Alonso-Allende|last3=Valencia|first3=Alfonso|date=March 15, 2005|title=Text-mining approaches in molecular biology and biomedicine|journal=Drug Discovery Today|volume=10|issue=6|pages=439–445|doi=10.1016/S1359-6446(05)03376-3|pmid=15808823}}&lt;/ref&gt; Machine learning can be used for this knowledge extraction task using techniques such as [[natural language processing]] to extract the useful information from human-generated reports in a database. [[Text Nailing]], an alternative approach to machine learning, capable of extracting features from clinical narrative notes was introduced in 2017.

This technique has been applied to the search for novel drug targets, as this task requires the examination of information stored in biological databases and journals.&lt;ref name=":5" /&gt; Annotations of proteins in protein databases often do not reflect the complete known set of knowledge of each protein, so additional information must be extracted from biomedical literature. Machine learning has been applied to automatic annotation of the function of genes and proteins, determination of the [[Protein targeting|subcellular localization of a protein]], analysis of [[Gene expression|DNA-expression arrays]], large-scale [[List of protein interactions|protein interaction]] analysis, and molecule interaction analysis.&lt;ref name=":5" /&gt;

Another application of text mining is the detection and visualization of distinct DNA regions given sufficient reference data.&lt;ref name="sing"&gt;{{cite book|last=Pratas|first=D|author2=Hosseini, M|author3=Silva, R|author4= Pinho, A|author5= Ferreira, P|title=Visualization of Distinct DNA Regions of the Modern Human Relatively to a Neanderthal Genome|journal=Iberian Conference on Pattern Recognition and Image Analysis. Springer|volume=10255|pages=235–242|date= June 20–23, 2017|doi=10.1007/978-3-319-58838-4_26|series=Lecture Notes in Computer Science|isbn=978-3-319-58837-7}}&lt;/ref&gt;

==References==
{{reflist}}

__FORCETOC__

{{Differentiable computing}}

[[Category:Machine learning]]
[[Category:Bioinformatics]]
[[Category:Computer science]]
[[Category:Biology]]</text>
      <sha1>s31epi3ze9zeyn01aqm5lgbzjkwrxq6</sha1>
    </revision>
  </page>
  <page>
    <title>Lempel-Ziv complexity</title>
    <ns>0</ns>
    <id>54061907</id>
    <revision>
      <id>1008511085</id>
      <parentid>1007447937</parentid>
      <timestamp>2021-02-23T17:45:06Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Alter: template type. Add: pmid, doi, page, volume, journal, pmc, year, authors 1-2. Removed proxy or dead URL that duplicated free-DOI or unique identifier. | [[WP:UCB|Use this bot]]. [[WP:DBUG|Report bugs]]. | Suggested by Headbomb | Pages linked from cached Wikipedia:WikiProject_Academic_Journals/Journals_cited_by_Wikipedia/Sandbox | via #UCB_webform_linked 246/705</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9628" xml:space="preserve">The '''Lempel-Ziv complexity''' was first presented in the article ''On the Complexity of Finite Sequences'' (IEEE Trans. On IT-22,1 1976), by two Israeli computer scientists, [[Abraham Lempel]] and [[Jacob Ziv]]. This complexity measure is related to [[Kolmogorov complexity]], but the only function it uses is the recursive copy (i.e., the shallow copy).

The underlying mechanism in this complexity measure is the starting point for some algorithms for [[lossless data compression]], like [[LZ77 and LZ78|LZ77, LZ78]] and [[Lempel–Ziv–Welch|LZW]]. Even though it is based on an elementary principle of words copying, this complexity measure is not too restrictive in the sense that it satisfies the main qualities expected by such a measure: sequences with a certain regularity do not have a too large complexity, and the complexity grows as the sequence grows in length and irregularity.

The Lempel-Ziv complexity can be used to measure the repetitiveness of binary sequences and text, like song lyrics or prose. [[Fractal dimension]] estimates of real-world data have also been shown to correlate with Lempel-Ziv complexity.&lt;ref&gt;{{cite journal|title=Burns &amp; Rajan (2015) Combining complexity measures of EEG data: multiplying measures reveal previously hidden information. F1000Research. 4:137.|year=2015|pmc=4648221|last1=Burns|first1=T.|last2=Rajan|first2=R.|journal=F1000Research|volume=4|page=137|doi=10.12688/f1000research.6590.1|pmid=26594331}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=A Mathematical Approach to Correlating Objective Spectro-Temporal Features of Non-linguistic Sounds With Their Subjective Perceptions in Humans|year=2019|pmid=31417350|url=https://pubmed.ncbi.nlm.nih.gov/31417350/|last1=Burns|first1=T.|last2=Rajan|first2=R.|journal=Frontiers in Neuroscience|volume=13|page=794|doi=10.3389/fnins.2019.00794|pmc=6685481}}&lt;/ref&gt;

== Principle ==
Let S be a binary sequence, of length n, for which we have to compute the Lempel-Ziv complexity, denoted C(S). The sequence is read from the left.

Imagine you have a delimiting line, which can be moved in the sequence during the calculation. At first, this line is set just after the first symbol, at the beginning of the sequence. This initial position is called position 1, from where we have to move it to a position 2, which is considered the initial position for the next step (and so on). We have to move the delimiter (starting in position 1) the further possible to the right, so that the sub-word between position 1 and the delimiter position be a word of the sequence that starts before the position 1 of the delimiter.

As soon as the delimiter is set on a position where this condition is not met, we stop, move the delimiter to this position, and start again by marking this position as a new initial position (i.e., position 1). Keep iterating until the end of the sequence. The Lempel-Ziv complexity corresponds to the number of iterations needed to finish this procedure.

Said differently, the Lempel-Ziv complexity is the number of different sub-strings (or sub-words) encountered as the binary sequence is viewed as a stream (from left to right).

== Formal explanations ==
The method proposed by Lempel and Ziv uses three notions: reproducibility, producibility and exhaustive history of a sequence, that we defined here.

=== Notations ===
Let S be a binary sequence of length n (i.e., n symbols taking value 0 or 1). Let S(i,j), with &lt;math&gt;1\leq i,j\leq n&lt;/math&gt;, be the sub-word of S from index i to index j (if j&lt;i, S(i,j) is the empty string). The length n of S is denoted l(S), and a sequence Q is said to be a fixed prefix of S if:

&lt;math&gt;\exists j&lt;{\text{l(S), s.t. S(1,j) = Q .}}&lt;/math&gt;

=== Reproducibility and producibility ===
&lt;imagemap&gt;Image:Reproductibilité1.svg|200px|thumb|Example of reproducibility [http://upload.wikimedia.org/wikipedia/commons/a/ad/Reproductibilit%C3%A91.svg Click here] &lt;/imagemap&gt;

On the one hand, a sequence S of length n is said to be reproducible from its prefix S(1,j) when S(j+1,n) is a sub-word of S(1,n-1). This is denoted S(1,j)→S.

Said differently, S is reproducible from its prefix S(1,j) if the rest of the sequence, S(j+1,n), is nothing but a copy of another sub-word (starting at an index i &lt; j+1) of S(1,n-1).

To prove that the sequence S can be reproduced by one of its prefix S(1,j), you have to show that:

&lt;math&gt;\exists p\leq j, {\text{ s.t.  }}S(j+1,n)=S(p,l(S(j+1,n))+p-1)&lt;/math&gt;

&lt;imagemap&gt;Image:Productibilité.svg|200px|thumb|Example of Productibility [https://upload.wikimedia.org/wikipedia/commons/1/13/Productibilit%C3%A9.svg Click here] &lt;/imagemap&gt;

On the other hand, the producibility, is defined from the reproducibility : a sequence S is producible from its prefix S(1,j) if S(1,n-1) is reproducible from S(1,j). This is denoted S(1,j)⇒S. Said differently, S(j+1,n-1) has to be a copy of another sub-word of S(1,n-2). The last symbol of S can be a new symbol (but could not be), possibly leading to the production of a new sub-word (hence the term producibility).

&lt;imagemap&gt;Image:Prod_reprod1.svg|200px|thumb|Comparison between reproducibility and producibility [https://upload.wikimedia.org/wikipedia/commons/8/87/Prod_reprod1.svg Click here] &lt;/imagemap&gt;

=== Exhaustive history and complexity ===
From the definition of productibility, the empty string Λ=S(1,0) ⇒ S(1,1). So by a recursive production process, at step i we have S(1,hi) ⇒ S(1,hi+1), so we can build S from its prefixes. And as S(1,i) ⇒ S(1,i+1) (with hi+1 =hi + 1) is always true, this production process of S takes at most n=l(S) steps. Let m, &lt;math&gt;1\leq {\text{m}}\leq l(S)&lt;/math&gt;, be the number of steps necessary for this product process of S. S can be written in a decomposed form, called history of S, and denoted H(S), defined like this:

&lt;math&gt;H(S)=S(1,h_{1})S(h_{1}+1,h_{2})\dotsm S(h_{{m-1}}+1,h_{m})&lt;/math&gt;
&lt;math&gt;H_{i}(S)=S(h_{{i-1}}+1,h_{i}),i=1,2\dotsm m,
{\text{where}  }\; h_{0}=0,h_{1}=1,h_{m}=l(S),{\text{ is called component of } H(S)}.
&lt;/math&gt;

&lt;imagemap&gt;Image:Hist_exh&amp;complexite1.svg|200px|thumb|Comparison between reproductibility and productibility [https://upload.wikimedia.org/wikipedia/commons/3/3c/Hist_exh%26complexite1.svg Click here] &lt;/imagemap&gt;

A component of S, Hi(S), is said to be exhaustive if S(1,hi) is the longest sequence produced by S(1,hi-1) (i.e., S(1,hi-1) ⇒ S(1,hi)) but so that S(1,hi-1) does not produce S(1,hi) (denoted ).&lt;math&gt;S(1,h_{i}-1)\nrightarrow S(1,h_{i})&lt;/math&gt; The index p which allows to have the longest production is called pointer.

The history of S is said to be exhaustive if all its component are exhaustive, except possibly the last one. From the definition, one can show that any sequence S has only one exhaustive history, and this history is the one with the smallest number of component from all the possible histories of S. Finally, the number of component of this unique exhaustive history of S is called the Lempel-Ziv complexity of S.

== Algorithm ==
Hopefully, there exists a very efficient method for computing this complexity, in a linear number of operation (&lt;math&gt;\mathcal{O}(n)&lt;/math&gt; for &lt;math&gt;n=l(S)&lt;/math&gt; length of the sequence S).

A formal description of this method is given by the following [[algorithm]]:
* i = p - 1, p is the pointer (see above)
* u is the length of the current prefix
* v is the length of the current component for the current pointer p
* vmax is the final length used for the current component (largest on all the possible pointers p)
* and C is the Lempel-Ziv Complexity, incremented iteratively.

&lt;syntaxhighlight lang="pascal"&gt;
// S is a binary sequence of size n
i := 0
C := 1
u := 1
v := 1
vmax := v
while u + v &lt;= n do
   if S[i + v] = S[u + v] then
      v := v + 1
   else
      vmax := max(v, vmax)
      i := i + 1
      if i = u then  // all the pointers have been treated
         C := C + 1
         u := u + vmax
         v := 1
         i := 0
         vmax := v
      else
         v := 1
      end if
   end if
end while
if v != 1 then
    C := C+1
end if
&lt;/syntaxhighlight&gt;

== Notes and references ==

=== References ===
{{Reflist}}

=== Bibliography ===
* Abraham Lempel and Jacob Ziv, « On the Complexity of Finite Sequences », IEEE Trans. on Information Theory, January 1976, p.&amp;nbsp;75–81, vol. 22, n°1

=== Application ===
* [https://pudding.cool/2017/05/song-repetition/ « Are Pop Lyrics Getting More Repetitive? », By Colin Morris], is a blog post explaining how to use the Lempel-Ziv complexity to measure repetitiveness of song lyrics [https://colinmorris.github.io/pop-compression/ (with source code available)].
* Burns &amp; Rajan (2015) Combining complexity measures of EEG data: multiplying measures reveal previously hidden information. F1000Research. 4:137. [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4648221/] (with public MATLAB code available).
* Burns &amp; Rajan (2019) A Mathematical Approach to Correlating Objective Spectro-Temporal Features of Non-linguistic Sounds With Their Subjective Perceptions in Humans. Frontiers in Neuroscience 13:794. [https://www.frontiersin.org/articles/10.3389/fnins.2019.00794/full] (with public MATLAB code available).

== External links ==
* [https://stackoverflow.com/questions/41336798/lempel-ziv-compression-algorithm-implemention Example of a Python implementation and discussion on StackOverflow #41336798]
* [https://GitHub.com/Naereen/Lempel-Ziv_Complexity Open-Source (MIT) implementation on Python and Cython on GitHub] [https://pypi.org/project/Lempel-Ziv_Complexity/ available on PyPi]

[[Category:Computer science]]
[[Category:Computability theory]]
[[Category:Information theory]]</text>
      <sha1>ds4eqylnzyn7j6gmkugxwwxsfjtpbcd</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum image processing</title>
    <ns>0</ns>
    <id>54074489</id>
    <revision>
      <id>1000315735</id>
      <parentid>990822079</parentid>
      <timestamp>2021-01-14T16:32:55Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Fix REFPUNCT + other minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="19767" xml:space="preserve">{{Underlinked|date=March 2019}}

'''Quantum image processing''' (QIMP) is primarily devoted to using [[quantum computing]] and [[quantum information processing]] to create and work with [[quantum image]]s.&lt;ref name="Venegas-Andraca2005"&gt;{{cite thesis |last= Venegas-Andraca |first= Salvador E.|date= 2005 |title= Discrete Quantum Walks and Quantum Image Processing|type= DPhil thesis|publisher= The University of Oxford|url= https://ora.ox.ac.uk/objects/uuid:2baab08b-ee68-4ce5-8e68-8201f086a1ba}}&lt;/ref&gt;&lt;ref name="Iliyasu Towards 2013"&gt;{{cite journal |title=Towards realising secure and efficient image and video processing applications on quantum computers |journal=Entropy |volume=15 |issue=8 |pages=2874–2974 |year=2013 |last1=Iliyasu |first1=A.M.|bibcode=2013Entrp..15.2874I |doi=10.3390/e15082874 |doi-access=free }}&lt;/ref&gt; Due to some of the astounding properties inherent to quantum computation, notably [[Quantum entanglement|entanglement]] and parallelism, it is anticipated that QIP technologies will offer capabilities and performances that are, as yet, unrivaled by their traditional equivalents. These improvements could be in terms of computing speed, guaranteed security, and minimal storage requirements, etc.&lt;ref name="Iliyasu Towards 2013"/&gt;&lt;ref name="Yan Quantum 2017"&gt;{{cite journal |title=Quantum image processing: A review of advances in its security technologies |journal=International Journal of Quantum Information |volume=15 |issue=3 |pages=1730001–44 |year=2017 |last1=Yan |first1=F.|last2=Iliyasu |first2=A.M.|last3=Le |first3=P.Q.|doi=10.1142/S0219749917300017 |bibcode=2017IJQI...1530001Y |doi-access=free }}&lt;/ref&gt;

==Background==

Vlasov's work&lt;ref name="Vlasov Quantum 2003"&gt;{{cite journal|last1=Vlasov|first1=A.Y.|year=1997|title=Quantum computations and images recognition|url=https://archive.org/details/arxiv-quant-ph9703010|arxiv=quant-ph/9703010|bibcode=1997quant.ph..3010V}}&lt;/ref&gt; in 1997 focused on the use of a quantum system to recognize [[orthogonal images]]. This was followed by efforts using [[quantum algorithms]] to search specific patterns in [[binary image]]s&lt;ref name="Schutzhold Pattern 2003"&gt;{{cite journal |title=Pattern recognition on a quantum computer |journal=Physical Review A |volume=67 |issue=6 |pages=062311 |year=2003 |last1=Schutzhold |first1=R.|arxiv=quant-ph/0208063 |doi=10.1103/PhysRevA.67.062311 |bibcode=2003PhRvA..67f2311S }}&lt;/ref&gt; and detect the posture of certain targets.&lt;ref name="Beach Quantum 2003"&gt;{{cite journal |title=Quantum image processing (QuIP) |journal=Proceedings of the 32nd Applied Imagery Pattern Recognition Workshop |pages=39–40 |year=2003 |last1=Beach |first1=G.|last2=Lomont |first2=C.|last3=Cohen |first3=C.|doi=10.1109/AIPR.2003.1284246 |isbn=0-7695-2029-4 |s2cid=32051928 }}&lt;/ref&gt; Notably, more optics-based interpretation for quantum imaging were initially experimentally demonstrated in &lt;ref&gt;{{cite journal |title=Optical imaging by means of two-photon quantum entanglement |journal=Physical Review A |volume=52 |issue=5 |pages=R3429–R3432 |year=1995 |last1=Pittman |first1=T.B.|last2=Shih |first2=Y.H.|last3=Strekalov |first3=D.V.|bibcode=1995PhRvA..52.3429P |doi=10.1103/PhysRevA.52.R3429 |pmid=9912767 }}&lt;/ref&gt; and formalized in &lt;ref name="Lugiato quantum 2002"&gt;{{cite journal |title=Quantum imaging |journal=Journal of Optics B |volume=4 |issue=3 |pages=S176–S183 |year=2002 |last1=Lugiato |first1=L.A.|last2=Gatti |first2=A.|last3=Brambilla |first3=E.|doi=10.1088/1464-4266/4/3/372 |bibcode=2002JOptB...4S.176L |arxiv=quant-ph/0203046 |s2cid=9640455 }}&lt;/ref&gt; after seven years. In 2003, Venegas-Andraca and Bose presented Qubit Lattice, the first published general model for storing, processing and retrieving images using quantum systems.&lt;ref name="Venegas-AndracaIJCAI2003"&gt;{{cite journal |title=Quantum Computation and Image Processing: New Trends in Artificial Intelligence |journal=Proceedings of the 2003 IJCAI International Conference on Artificial Intelligence |pages=1563–1564 |year=2003 |last1=Venegas-Andraca |first1=S.E.|last2=Bose|first2=S.|url=https://www.ijcai.org/Proceedings/03/Papers/276.pdf}}&lt;/ref&gt;&lt;ref name="Venegas Storing 2003"&gt;{{cite journal |title=Storing, processing, and retrieving an image using quantum mechanics |journal=Proceedings of SPIE Conference of Quantum Information and Computation |volume=5105 |pages=134–147 |year=2003 |last1=Venegas-Andraca |first1=S.E.|last2=Bose |first2=S.|editor3-first=Howard E |editor3-last=Brandt |editor2-first=Andrew R |editor2-last=Pirich |editor1-first=Eric |editor1-last=Donkor |bibcode=2003SPIE.5105..137V |doi=10.1117/12.485960 |series=Quantum Information and Computation |s2cid=120495441 }}&lt;/ref&gt; Later on, in 2005, Lattorre proposed another kind of representation, called the Real Ket,&lt;ref name="Latorre Image 2005"&gt;{{cite journal |title=Image compression and entanglement |url=https://archive.org/details/arxiv-quant-ph0510031 |arxiv=quant-ph/0510031 |year=2005 |last1=Latorre |first1=J.I.|bibcode=2005quant.ph.10031L }}&lt;/ref&gt; whose purpose was to encode quantum images as a basis for further applications in QIMP. Furthermore, in 2010 Venegas-Andraca and Ball presented a method for storing and retrieving [[Well-known text representation of geometry|binary geometrical shapes]] in quantum mechanical systems in which it is shown that maximally entangled qubits can be used to reconstruct images without using any additional information.&lt;ref name="Venegas-Andraca2010"&gt;{{cite journal |title=Processing Images in Entangled Quantum Systems |journal=Quantum Informatiom Processing |volume=9  |issue=1 |pages=1–11 |year=2010 |last1=Venegas-Andraca |first1=S.E.|last2=Ball |first2=J.|doi=10.1007/s11128-009-0123-z |s2cid=34988263 }}&lt;/ref&gt;

Technically, these pioneering efforts with the subsequent studies related to them can be classified into three main groups:&lt;ref name="Yan Quantum 2017"/&gt;

#Quantum-assisted digital image processing (QDIP): These applications aim at improving digital or classical image processing tasks and applications.&lt;ref name="Iliyasu Towards 2013"/&gt;
#Optics-based quantum imaging (OQI)&lt;ref name="Pittman Optical 1995"&gt;{{cite journal |title=Quantum imaging|journal= Progress in Optics |volume=51 |issue=7 |pages=251–348 |year=2008 |last1=Gatti |first1=A. |last2=Brambilla |first2=E. |doi= 10.1016/S0079-6638(07)51005-X }}&lt;/ref&gt;
#Classically-inspired quantum image processing (QIP)&lt;ref name="Iliyasu Towards 2013"/&gt;

A survey of quantum image representation has been published in.&lt;ref name="Yan2016"&gt;{{cite journal |title=A survey of quantum image representations |journal=Quantum Informatiom Processing |volume=15 |issue=1 |pages=1–35 |year=2016 |last1=Yan |first1=F.|last2=Iliyasu |first2=A.M.|last3=Venegas-Andraca |first3=S.E.|   bibcode=2016QuIP...15....1Y|doi=10.1007/s11128-015-1195-6 |s2cid=31229136 }}&lt;/ref&gt; Furthermore, the recently published book ''Quantum Image Processing'' &lt;ref name="Yan2020"&gt;{{cite book |last1=Yan |first1= Fei| last2=Venegas-Andraca |first2= Salvador E.|date= 2020|title= Quantum Image Processing|url= https://www.springer.com/gp/book/9789813293304 |publisher= Springer|isbn= 978-9813293304}}&lt;/ref&gt; provides a comprehensive introduction to quantum image processing, which focuses on extending conventional image processing tasks to the quantum computing frameworks. It summarizes the available quantum image representations and their operations, reviews the possible quantum image applications and their implementation, and discusses the open questions and future development trends.

==Quantum image manipulations==

A lot of the effort in QIMP has been focused on designing algorithms to manipulate the position and color information encoded using the ﬂexible representation of quantum images (FRQI) and its many variants. For instance, FRQI-based fast geometric transformations including (two-point) swapping, flip, (orthogonal) rotations&lt;ref name="Le Fast 2010"&gt;{{cite journal |title= Multi-dimensional color image storage and retrieval for a normal arbitrary quantum superposition state |journal= IAENG International Journal of Applied Mathematics |volume=40 |issue=3 |pages=113–123 |year=2010 |last1=Le |first1=P. |last2=Iliyasu |first2=A. |last3= Dong |first3=F. |last4= Hirota |first4=K. }}&lt;/ref&gt; and restricted geometric transformations to constrain these operations to a specified area of an image&lt;ref name="Le Strategies 2011"&gt;{{cite journal |title= Strategies for designing geometric transformations on quantum images |journal= Theoretical Computer Science |volume=412 |issue=15 |pages=1406–1418 |year=2011 |last1=Le |first1=P. |last2=Iliyasu |first2=A. |last3= Dong |first3=F. |last4= Hirota |first4=K. |url=https://core.ac.uk/download/pdf/82724999.pdf|doi= 10.1016/j.tcs.2010.11.029 }}&lt;/ref&gt; were initially proposed. Recently, NEQR-based quantum image translation to map the position of each picture element in an input image into a new position in an output image&lt;ref name="Wang Quantum 2015"&gt;{{cite journal |title= Quantum image translation |journal= Quantum Information Processing |volume=14 |issue=5 |pages=1589–1604 |year=2015 |last1=Wang |first1=J. |last2=Jiang |first2=N. |last3= Wang |first3=L. |doi= 10.1007/s11128-014-0843-6 |bibcode= 2015QuIP...14.1589W |s2cid= 33839291 }}&lt;/ref&gt; and quantum image scaling to resize a quantum image&lt;ref name="Jiang Quantum 2015"&gt;{{cite journal |title= Quantum image scaling up based on nearest-neighbor interpolation with integer scaling ratio |journal= Quantum Information Processing |volume=14 |issue=11 |pages=4001–4026 |year=2015 |last1=Jiang |first1=N. |last2=Wang |first2=J. |last3= Mu |first3=Y. |doi= 10.1007/s11128-015-1099-5 |bibcode= 2015QuIP...14.4001J |s2cid= 30804812 }}&lt;/ref&gt; were discussed. While FRQI-based general form of color transformations were first proposed by means of the single [[Quantum logic gate|qubit gates]] such as X, Z, and H gates.&lt;ref&gt;{{cite journal |title= Efficient colour transformations on quantum image |journal= Journal of Advanced Computational Intelligence and Intelligent Informatics |volume=15 |issue=6 |pages=698–706 |year=2011 |last1=Le |first1=P. |last2= Iliyasu |first2=A. |last3= Dong |first3=F. |last4= Hirota |first4=K. |doi= 10.20965/jaciii.2011.p0698 }}&lt;/ref&gt; Later, MCQI-based channel of interest (CoI) operator to entail shifting the grayscale value of the preselected color channel and the channel swapping (CS) operator to swap the grayscale values between two channels were fully discussed in.&lt;ref name="Sun Multi 2014"&gt;{{cite journal |title= Multi-channel information operations on quantum images |journal= Journal of Advanced Computational Intelligence and Intelligent Informatics |volume=18 |issue=2 |pages=140–149 |year=2014 |last1=Sun |first1=B. |last2=Iliyasu |first2=A. |last3= Yan |first3=F. |last4= Garcia |first4=J. |last5= Dong |first5=F. |last6= Al-Asmari |first6=A.|doi= 10.20965/jaciii.2014.p0140 }}&lt;/ref&gt;

To illustrate the feasibility and capability of QIMP algorithms and application, researchers always prefer to simulate the digital image processing tasks on the basis of the QIRs that we already have. By using the basic quantum gates and the aforementioned operations, so far, researchers have contributed to quantum image feature extraction,&lt;ref name="Zhang Local 2015"&gt;{{cite journal |title= Local feature point extraction for quantum images |journal= Quantum Information Processing |volume=14 |issue=5 |pages=1573–1588 |year=2015 |last1=Zhang |first1=Y. |last2=Lu |first2=K. |last3= Xu |first3=K. |last4= Gao |first4=Y. |last5= Wilson |first5=R. |doi= 10.1007/s11128-014-0842-7 |bibcode= 2015QuIP...14.1573Z |s2cid= 20213446 }}&lt;/ref&gt; quantum image segmentation,&lt;ref name="Caraiman Histogram 2014"&gt;{{cite journal |title= Histogram-based segmentation of quantum images |journal= Theoretical Computer Science |volume=529 |pages=46–60 |year=2014 |last1=Caraiman |first1=S. |last2=Manta |first2=V. |doi= 10.1016/j.tcs.2013.08.005 |doi-access=free }}&lt;/ref&gt; quantum image morphology,&lt;ref name="Yuan Quantum 2015"&gt;{{cite journal |title= Quantum morphology operations based on quantum representation model |journal= Quantum Information Processing |volume=14 |issue=5 |pages=1625–1645 |year=2015 |last1=Yuan |first1=S. |last2=Mao |first2=X. |last3= Li |first3=T. |last4= Xue |first4=Y. |last5= Chen |first5=L. |last6= Xiong |first6=Q.|doi= 10.1007/s11128-014-0862-3 |bibcode= 2015QuIP...14.1625Y |s2cid= 44828546 }}&lt;/ref&gt; quantum image comparison,&lt;ref name="Yan A 2013"&gt;{{cite journal |title= A parallel comparison of multiple pairs of images on quantum computers |journal= International Journal of Innovative Computing and Applications |volume=5 |issue=4 |pages=199–212 |year=2013 |last1=Yan |first1=F. |last2=Iliyasu |first2=A. |last3= Le |first3=P. |last4= Sun |first4=B. |last5= Dong |first5=F. |last6= Hirota |first6=K.|doi= 10.1504/IJICA.2013.062955 }}&lt;/ref&gt; quantum image filtering,&lt;ref name="Caraiman Quantum 2013"&gt;{{cite journal |title= Quantum image filtering in the frequency domain |journal= Advances in Electrical and Computer Engineering |volume=13 |issue=3 |pages=77–84 |year=2013 |last1=Caraiman |first1=S. |last2=Manta |first2=V. |doi= 10.4316/AECE.2013.03013 |doi-access=free }}&lt;/ref&gt; quantum image classification,&lt;ref name="Ruan Quantum 2016"&gt;{{cite journal |title= Quantum computation for large-scale image classification |journal= Quantum Information Processing |volume=15 |issue=10|pages=4049–4069 |year=2016 |last1=Ruan |first1=Y. |last2=Chen |first2=H. |last3= Tan |first3=J. |url=https://www.researchgate.net/publication/305644388|doi= 10.1007/s11128-016-1391-z |bibcode= 2016QuIP...15.4049R |s2cid= 27476075 }}&lt;/ref&gt; quantum image stabilization,&lt;ref name="Yan Strategy 2016"&gt;{{cite journal |title= Strategy for quantum image stabilization |journal= Science China Information Sciences |volume=59 |issue= 5 |pages=052102 |year=2016 |last1=Yan |first1=F. |last2=Iliyasu |first2=A. |last3= Yang |first3=H. |last4= Hirota |first4=K. |doi= 10.1007/s11432-016-5541-9 |doi-access=free }}&lt;/ref&gt; among others. In particular, QIMP-based security technologies have attracted extensive interest of researchers as presented in the ensuing discussions. Similarly, these advancements have led to many applications in the areas of watermarking,&lt;ref name="Iliyasu Watermarking 2012"&gt;{{cite journal |title= Watermarking and authentication of quantum images based on restricted geometric transformations |journal= Information Sciences |volume=186 |issue=1|pages=126–149 |year=2012 |last1=Iliyasu |first1=A. |last2=Le |first2=P. |last3= Dong |first3=F. |last4= Hirota |first4=K. |doi= 10.1016/j.ins.2011.09.028 }}&lt;/ref&gt;&lt;ref name="Heidari Watermarking 2016"&gt;{{cite journal |title= A Novel Lsb based Quantum Watermarking |journal= International Journal of Theoretical Physics |volume= 55 |issue=10 |pages=4205–4218 |year=2016|last1=Heidari |first1=S. |last2=Naseri |first2=M. |doi= 10.1007/s10773-016-3046-3 |bibcode= 2016IJTP...55.4205H |s2cid= 124870364 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |title= A quantum watermark protocol |journal= International Journal of Theoretical Physics |volume=52 |issue=2|pages=504–513 |year=2013 |last1=Zhang |first1=W. |last2=Gao |first2=F. |last3= Liu |first3=B. |last4= Jia |first4=H. |bibcode=2013IJTP...52..504Z |doi=10.1007/s10773-012-1354-9 |s2cid= 122413780 }}&lt;/ref&gt; encryption,&lt;ref name="Zhou Quantum 2013"&gt;{{cite journal |title= Quantum image encryption and decryption algorithms based on quantum image geometric transformations. International |journal= Journal of Theoretical Physics |volume=52 |issue=6|pages=1802–1817 |year=2013 |last1=Zhou |first1=R. |last2=Wu |first2=Q. |last3= Zhang |first3=M. |last4= Shen |first4=C. |doi= 10.1007/s10773-012-1274-8 |s2cid= 121269114 }}&lt;/ref&gt; and [[steganography]]&lt;ref name="Jiang Lsb 2015"&gt;{{cite journal |title= Lsb based quantum image steganography algorithm |journal= International Journal of Theoretical Physics |volume=55 |issue=1|pages=107–123 |year=2015 |last1=Jiang |first1=N. |last2=Zhao |first2=N. |last3= Wang |first3=L. |doi= 10.1007/s10773-015-2640-0 |s2cid= 120009979 }}&lt;/ref&gt; etc., which form the core security technologies highlighted in this area.

In general, the work pursued by the researchers in this area are focused on expanding the applicability of QIMP to realize more classical-like digital image processing algorithms; propose technologies to physically realize the QIMP hardware; or simply to note the likely challenges that could impede the realization of some QIMP protocols.

==Quantum image transform==
By encoding and processing the image information in quantum-mechanical systems, a framework of quantum image processing is presented, where a pure quantum state encodes the image information: to encode the pixel values in the probability amplitudes and the pixel positions in the computational basis states.
Given an image &lt;math&gt;F=(F_{i,j})_{M \times L}&lt;/math&gt;, where &lt;math&gt;F_{i,j}&lt;/math&gt; represents the pixel value at position &lt;math&gt;(i,j)&lt;/math&gt; with &lt;math&gt;i = 1,\dots,M&lt;/math&gt; and &lt;math&gt;j = 1,\dots,L&lt;/math&gt;, a vector &lt;math&gt;\vec{f}&lt;/math&gt; with &lt;math&gt;ML&lt;/math&gt; elements can be formed by letting the first &lt;math&gt;M&lt;/math&gt; elements of &lt;math&gt;\vec{f}&lt;/math&gt; be the first column of &lt;math&gt;F&lt;/math&gt;, the next &lt;math&gt;M&lt;/math&gt; elements the second column, etc.

A large class of image operations is linear, e.g., unitary transformations, convolutions, and linear filtering.
In the quantum computing, the linear transformation can be represented as &lt;math&gt;|g\rangle =\hat{U} |f\rangle &lt;/math&gt; with the input image state &lt;math&gt;|f\rangle &lt;/math&gt; and the output image state &lt;math&gt;|g\rangle &lt;/math&gt;. A unitary transformation can be implemented as a unitary evolution.
Some basic and commonly used image transforms (e.g., the Fourier, Hadamard, and Haar wavelet transforms) can be expressed in the form &lt;math&gt;G=PFQ&lt;/math&gt;, with the resulting image &lt;math&gt;G&lt;/math&gt; and a row (column) transform matrix &lt;math&gt; P (Q)&lt;/math&gt;. The corresponding unitary operator &lt;math&gt;\hat{U}&lt;/math&gt; can then be written as &lt;math&gt; \hat{U}={Q}^T \otimes {P}&lt;/math&gt;. Several commonly used two-dimensional image transforms, such as the Haar wavelet, Fourier, and Hadamard transforms, are experimentally demonstrated on a quantum computer,&lt;ref name="2017_Yao"/&gt; with exponential speedup over their classical counterparts. In addition, a novel highly efficient quantum algorithm is proposed and experimentally implemented for detecting the boundary between different regions of a picture: It requires only one single-qubit gate in the processing stage, independent of the size of the picture.

==See also==
* [[Quantum computing]]
* [[Quantum image]]

==References==
{{Reflist|30em|refs=

&lt;ref name="2017_Yao"&gt;{{cite journal | last1 = Yao | first1 = Xi-Wei | last2 = Wang | first2 = Hengyan  | last3 = Liao | first3 = Zeyang  | last4 = Chen | first4 = Ming-Cheng  | last5 = Pan | first5 = Jian  | last6 = Li | first6 = Jun  | last7 = Zhang | first7 = Kechao  | last8 = Lin | first8 = Xingcheng  | last9 = Wang | first9 = Zhehui  | last10 = Luo | first10 = Zhihuang  | last11 = Zheng | first11 = Wenqiang  | last12 = Li | first12 = Jianzhong  | last13 = Zhao | first13 = Meisheng | last14 = Peng | first14 = Xinhua  | last15 = Suter | first15 = Dieter | display-authors = 5 | date = 2017-09-11 | title = Quantum Image Processing and Its Application to Edge Detection: Theory and Experiment | journal = [[Physical Review X]] | language = en | volume = 7 | issue = 3 | pages = 31041 | arxiv = 1801.01465 | bibcode = 2017PhRvX...7c1041Y | doi = 10.1103/physrevx.7.031041 | s2cid = 119205332 | issn = 2160-3308 | lccn = 2011201149 | oclc = 706478714 | ref = 2017_Yao | df = dmy-all}}&lt;/ref&gt;

}}

[[Category:Computer science]]
[[Category:Quantum computing]]
[[Category:Image processing]]</text>
      <sha1>0yuaxyjfnue4l9ibfb3v7qtkqqfiyxa</sha1>
    </revision>
  </page>
  <page>
    <title>Computational human modeling</title>
    <ns>0</ns>
    <id>54690679</id>
    <revision>
      <id>933624860</id>
      <parentid>933610048</parentid>
      <timestamp>2020-01-02T03:42:37Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Unr}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1079" xml:space="preserve">{{orphan|date=July 2017}}
{{Unr|date=January 2020}}
'''Computational human modeling''' is an interdisciplinary [[computational science]] that links the diverse fields of [[artificial intelligence]], [[cognitive science]], and [[computer vision]] with [[machine learning]], [[mathematics]], and [[cognitive psychology]].

Computational human modeling emphasizes descriptions of human for A.I. research and applications.

==Major topics==
Research in computational human modeling can include computer vision studies on identify ([[face recognition]]), attributes (gender, age, skin color), expressions, geometry (3D face modeling, 3D body modeling), and activity (pose, gaze, actions, and social interactions).

==See also==
* [[Activity recognition]]
* [[Computational theory of mind]]
* [[Emotion recognition]]
* [[Facial recognition system]]
* [[Three-dimensional face recognition]]

{{DEFAULTSORT:Computational Human Modeling}}
[[Category:Computer science]]
[[Category:Artificial intelligence]]
[[Category:Humanoids]]
[[Category:Humanoid robots]]
[[Category:Cognitive science]]</text>
      <sha1>tkuvvuhou1yyoqylt69e17czii1aapk</sha1>
    </revision>
  </page>
  <page>
    <title>Boolean</title>
    <ns>0</ns>
    <id>212335</id>
    <revision>
      <id>989021889</id>
      <parentid>989021832</parentid>
      <timestamp>2020-11-16T16:38:09Z</timestamp>
      <contributor>
        <username>Hunter1471</username>
        <id>30819112</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/184.187.12.47|184.187.12.47]] ([[User talk:184.187.12.47|talk]]) to last revision by JayBeeEll</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1603" xml:space="preserve">{{Wiktionary|Boolean|Booleans|boolean}}

Any kind of logic, function, expression, or theory based on the work of [[George Boole]] is considered '''Boolean'''.  

Related to this, "Boolean" may refer to:

* [[Boolean data type]], a form of data with only two possible values (usually "true" and "false")
* [[Boolean algebra]], a logical calculus of truth values or set membership
* [[Boolean algebra (structure)]], a set with operations resembling logical ones
* [[Boolean domain]], a set consisting of exactly two elements whose interpretations include ''false'' and ''true''
* [[Boolean circuit]], a mathematical model for digital logical circuits.
* [[Boolean expression]], an expression in a programming language that produces a Boolean value when evaluated
* [[Boolean function]], a function that determines Boolean values or operators
* [[Boolean model (probability theory)]], a model in stochastic geometry
* [[Boolean network]], a certain network consisting of a set of Boolean variables whose state is determined by other variables in the network
* [[Boolean processor]], a 1-bit variable computing unit 
* [[Boolean ring]], a mathematical ring for which ''x''&lt;sup&gt;2&lt;/sup&gt; = ''x'' for every element ''x''
* [[Boolean satisfiability problem]],  the problem of determining if there exists an interpretation that satisfies a given Boolean formula
* [[Boolean prime ideal theorem]], a theorem which states that ideals in a Boolean algebra can be extended to prime ideals

==See also==
*[[Binary (disambiguation)]]

{{Disambiguation}}
[[Category:Broad-concept articles]]
[[Category:Computer science]]</text>
      <sha1>emonlgc3stf0gbcnzpsg9hjy61wq2mx</sha1>
    </revision>
  </page>
  <page>
    <title>Nuclear computation</title>
    <ns>0</ns>
    <id>56237732</id>
    <revision>
      <id>1014128521</id>
      <parentid>945585799</parentid>
      <timestamp>2021-03-25T10:09:16Z</timestamp>
      <contributor>
        <ip>2406:3400:213:70C0:9DF6:7E57:88CE:1BEA</ip>
      </contributor>
      <comment>updated the typo in the URL for the implementation example in C++</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3985" xml:space="preserve">{{Multiple issues|
{{refimprove article|date=January 2018}}
{{notability|date=January 2018}}
}}

'''Nuclear computation''' is a type of computation which allows [[Thread (computing)|threads]] to either spawn new threads or converge many threads to one. The aim of nuclear computation is to take advantage of threading abilities of modern [[multi-core processor]]s where the trend is to increase their hardware ability to compute more threads then their earlier generation processors.&lt;ref&gt;Howard, Jason, et al. "A 48-core IA-32 message-passing processor with DVFS in 45nm CMOS." Solid-State Circuits Conference Digest of Technical Papers (ISSCC), 2010 IEEE International. IEEE, 2010.&lt;/ref&gt;&lt;ref&gt;Ferry, David, et al. "A real-time scheduling service for parallel tasks." Real-Time and Embedded Technology and Applications Symposium (RTAS), 2013 IEEE 19th. IEEE, 2013.&lt;/ref&gt;

Nuclear computation focuses on real time processing for things like multimedia such as processing audio where a real time deadline (the sample rate in Hz) exists. For that reason it should not [[Blocking (computing)|block]] and computational processes which alter shared memory must be atomic (excuted in one clock cycle without locking).

Nuclear computation allows a computational thread to use thread fission to turn one thread into many or thread fusion to turn many threads into one.

== Analogy to nuclear reactions ==

As the name "nuclear computation" implies, there is an analogy between nuclear reactions and nuclear computation.

=== The nuclear fission analogy ===

In nuclear physics, atoms decay or react where the atom's nucleus splits, producing several atoms. In nuclear computation, a computational thread splits into several processing threads.

=== The nuclear fusion analogy ===

In nuclear physics, atoms may react together to fuse where several atomic nuclei may fuse into one nucleus. In nuclear computation, several computational threads fuse into one processing thread.

=== Component analogy ===

{| class="wikitable"
|+
!Nuclear computation
!Nuclear physics
|-
|processing thread
|atomic nucleus
|-
|signalling and memory copy (between threads)
|energy release (from the nuclear reaction between nucleii)
|}

=== Speed ===

Nuclear explosions are fast and lockless. Which suggests some requirements :
* lockless
* parallel
* ordered
* light weight
* low latency

== Description ==

=== Thread fission ===

Conceptually fission computation can cause a chain reaction, where one thread can signal many threads to start processing and they too may signal other threads to start processing. It is possible to starve the computer, where the computer runs out of resources and halts - either due to a lack of memory, power or disk resources.

=== Thread fusion ===

Fusion computation is a type of threshold triggered computation, where several threads signal the single waiting thread, which begins execution once the required number of thread signals exceed the threshold of the waiting thread.

== Implementation examples ==
{| class="wikitable"
|+
!Link
!Programming language
!License
|-
|[https://github.com/flatmax/nuclear-processing Nuclear processing]
|C++
|Free license with sticky copyright
|}

== History ==
A previous analogy between nuclear reactions and computation were termed [[loop fission and fusion]] which were forms of [[compiler]] preprocessing. Loop fission (loop distribution) allowed one computational loop to be broken into separate loops by a compiler at compile time. Loop fusion (loop jamming) allowed many computational loops to be combined into one by the compiler at compiler time. These processes were not directly under the control of the programmer and were decided and controlled by the compiler.
In contrast to loop fission and fusion, nuclear computation fission and fusion are directly under the control of the programmer or the program at run time.

== See also ==

*[[Concurrency pattern]]

==References==
&lt;references /&gt;

[[Category:Computer science]]</text>
      <sha1>qsohz8vzreuybrs36t3obofl01jrgyq</sha1>
    </revision>
  </page>
  <page>
    <title>Supnick matrix</title>
    <ns>0</ns>
    <id>10573340</id>
    <revision>
      <id>998431627</id>
      <parentid>824761868</parentid>
      <timestamp>2021-01-05T10:14:37Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <comment>/* References */ 10.2307/1970124</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2835" xml:space="preserve">A '''Supnick matrix''' or '''Supnick array''' &amp;ndash; named after Fred Supnick of the [[City College of New York]], who introduced the notion in 1957 &amp;ndash; is a [[Monge array]] which is also a [[symmetric matrix]].

== Mathematical definition ==

A Supnick matrix is a square [[Monge array]] that is symmetric around the [[main diagonal]].

An ''n''-by-''n'' [[matrix (mathematics)|matrix]] is a Supnick matrix if, for all ''i'', ''j'', ''k'', ''l'' such that if
:&lt;math&gt;1\le i &lt; k\le n&lt;/math&gt; and &lt;math&gt;1\le j &lt; l\le n&lt;/math&gt;
then
:&lt;math&gt;a_{ij} + a_{kl} \le a_{il} + a_{kj}\,&lt;/math&gt;

and also

:&lt;math&gt;a_{ij} = a_{ji}. \,&lt;/math&gt;

A logically equivalent definition is given by Rudolf &amp; Woeginger who in 1995 proved that

:''A matrix is a Supnick matrix [[iff]] it can be written as the sum of a sum matrix ''S'' and a non-negative linear combination of LL-UR block matrices.''

The ''sum matrix'' is defined in terms of a sequence of ''n'' real numbers {α&lt;sub&gt;''i''&lt;/sub&gt;}:

:&lt;math&gt;
S = [s_{ij}] = [\alpha_i + \alpha_j]; \,
&lt;/math&gt;

and an ''LL-UR block matrix'' consists of two symmetrically placed rectangles in the lower-left and upper right corners for which ''a&lt;sub&gt;ij&lt;/sub&gt;''&amp;nbsp;=&amp;nbsp;1, with all the rest of the matrix elements equal to zero.

== Properties ==

Adding two Supnick matrices together will result in a new Supnick matrix (Deineko and Woeginger 2006).

Multiplying a Supnick matrix by a non-negative [[real number]] produces a new Supnick matrix (Deineko and Woeginger 2006).

If the [[distance matrix]] in a [[traveling salesman problem]] can be written as a Supnick matrix, that particular instance of the problem admits an easy solution (even though the problem is, in general, [[NP hard]]).

== References ==
*{{cite journal|last = Supnick|first = Fred|title = Extreme Hamiltonian Lines|journal = Annals of Mathematics |series=Second Series|volume = 66|issue = 1|date = July 1957|pages = 179–201|jstor=1970124|doi=10.2307/1970124}}
*{{cite journal|last = Woeginger|first = Gerhard J.| authorlink = Gerhard J. Woeginger |title = Computational Problems without Computation|journal =  Nieuwarchief|volume = 5|issue = 4|date = June 2003|pages = 140–147|url = http://www.nieuwarchief.nl/serie5/deel04/jun2003/pdf/woeginger.pdf}}
* {{cite journal | title = Some problems around travelling salesmen, dart boards, and euro-coins | first1 = Vladimir G. | last1 = Deineko | first2 =  Gerhard J. | last2 = Woeginger | author2-link = Gerhard J. Woeginger | journal = Bulletin of the European Association for Theoretical Computer Science | publisher = [[European Association for Theoretical Computer Science|EATCS]] | volume = 90 |date=October 2006 | issn = 0252-9742 | pages = 43–52 | url = http://alexandria.tue.nl/openaccess/Metis211810.pdf | format = PDF }}

[[Category:Computer science]]
[[Category:Matrices]]</text>
      <sha1>rt5ib2co39ucgfx95lalw4k6b3c37l9</sha1>
    </revision>
  </page>
  <page>
    <title>Jaro–Winkler distance</title>
    <ns>0</ns>
    <id>6782835</id>
    <revision>
      <id>1007724689</id>
      <parentid>1006733344</parentid>
      <timestamp>2021-02-19T16:27:46Z</timestamp>
      <contributor>
        <ip>194.34.206.37</ip>
      </contributor>
      <comment>/* Jaro Similarity */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6985" xml:space="preserve">{{About|the measure|other uses|Jaro (disambiguation){{!}}Jaro}}

In [[computer science]] and [[statistics]], the '''Jaro–Winkler distance''' is a [[string metric]] measuring an [[edit distance]] between two sequences. It is a variant proposed in 1990 by [[William E. Winkler]] of the '''Jaro distance''' metric (1989, [[Matthew A. Jaro]]).

The Jaro–Winkler distance uses a [[prefix]] scale &lt;math&gt;p&lt;/math&gt; which gives more favourable ratings to strings that match from the beginning for a set prefix length &lt;math&gt;\ell&lt;/math&gt;.

The lower the Jaro–Winkler distance for two strings is, the more similar the strings are. The score is normalized such that 1 means an exact match and 0 means there is no similarity. The '''Jaro–Winkler similarity''' is the inversion, (1 − Jaro–Winkler distance).

Although often referred to as a ''distance metric'', the Jaro–Winkler distance is not a [[metric (mathematics)|metric]] in the mathematical sense of that term because it does not obey the [[triangle inequality]].

== Definition ==

=== Jaro Similarity ===
The Jaro Similarity &lt;math&gt;sim_j&lt;/math&gt; of two given strings &lt;math&gt;s_1&lt;/math&gt; and &lt;math&gt;s_2&lt;/math&gt; is

: &lt;math&gt;sim_j = \left\{

\begin{array}{l l}
  0 &amp; \text{if }m = 0\\
  \frac{1}{3}\left(\frac{m}{|s_1|} + \frac{m}{|s_2|} + \frac{m-t}{m}\right) &amp; \text{otherwise} \end{array} \right.&lt;/math&gt;

Where:

* &lt;math&gt;|s_i|&lt;/math&gt; is the length of the string &lt;math&gt;s_i&lt;/math&gt;;
* &lt;math&gt;m&lt;/math&gt; is the number of ''matching characters'' (see below);
* &lt;math&gt;t&lt;/math&gt; is the number of ''transpositions'' (see below).

Two characters from &lt;math&gt;s_1&lt;/math&gt; and &lt;math&gt;s_2&lt;/math&gt; respectively, are considered ''matching'' only if they are the same and not farther than &lt;math&gt;\left\lfloor\frac{\max(|s_1|,|s_2|)}{2}\right\rfloor-1&lt;/math&gt; characters apart.

Each character of &lt;math&gt;s_1&lt;/math&gt; is compared with all its matching characters in &lt;math&gt;s_2&lt;/math&gt;. The number of matching (but different sequence order) characters divided by 2 defines the number of ''transpositions''.
For example, in comparing CRATE with TRACE, only 'R'   'A'   'E'  are the matching characters, i.e. m=3. Although 'C', 'T' appear in both strings, they are farther apart than 1 (the result of &lt;math&gt;\lfloor\tfrac{5}{2}\rfloor - 1&lt;/math&gt;).  Therefore, t=0 . In DwAyNE versus DuANE the matching letters are already in the same order D-A-N-E, so no transpositions are needed.

=== Jaro–Winkler Similarity ===
Jaro–Winkler similarity uses a [[prefix]] scale &lt;math&gt;p&lt;/math&gt; which gives more favorable ratings to strings that match from the beginning for a set prefix length &lt;math&gt;\ell&lt;/math&gt;. Given two strings &lt;math&gt;s_1&lt;/math&gt; and &lt;math&gt;s_2&lt;/math&gt;, their Jaro–Winkler similarity &lt;math&gt;sim_w&lt;/math&gt; is:

: &lt;math&gt;sim_w = sim_j + \ell p (1 - sim_j),&lt;/math&gt;

where:
* &lt;math&gt;sim_j&lt;/math&gt; is the Jaro similarity for strings &lt;math&gt;s_1&lt;/math&gt; and &lt;math&gt;s_2&lt;/math&gt;
* &lt;math&gt;\ell&lt;/math&gt; is the length of common prefix at the start of the string up to a maximum of 4 characters
* &lt;math&gt;p&lt;/math&gt; is a constant [[scaling factor]] for how much the score is adjusted upwards for having common prefixes. &lt;math&gt;p&lt;/math&gt; should not exceed 0.25 (i.e. 1/4, with 4 being the maximum length of the prefix being considered), otherwise the similarity could become larger than 1. The standard value for this constant in Winkler's work is &lt;math&gt;p = 0.1&lt;/math&gt;

The Jaro–Winkler distance &lt;math&gt;d_w&lt;/math&gt; is defined as &lt;math&gt;d_w = 1 - sim_w&lt;/math&gt;.

Although often referred to as a ''distance metric'', the Jaro–Winkler distance is not a [[metric (mathematics)|metric]] in the mathematical sense of that term because it does not obey the [[triangle inequality]].&lt;ref&gt;{{cite web|url=http://richardminerich.com/tag/jaro-winkler/|title=Jaro-Winkler «  Inviting Epiphany|website=RichardMinerich.com|access-date=12 June 2017}}&lt;/ref&gt; The Jaro–Winkler distance also does not satisfy the identity axiom &lt;math&gt; d(x,y)=0 \leftrightarrow x = y&lt;/math&gt;.

== Relationship with other edit distance metrics ==
{{main|Edit distance}}There are other popular measures of [[edit distance]], which are calculated using a different set of allowable edit operations. For instance,
* the [[Levenshtein distance]] allows deletion, insertion and substitution;
* the [[Damerau–Levenshtein distance]] allows insertion, deletion, substitution, and the [[Transposition (mathematics)|transposition]] of two adjacent characters;
* the [[Longest common subsequence problem|longest common subsequence]] (LCS) distance allows only insertion and deletion, not substitution;
* the [[Hamming distance]] allows only substitution, hence, it only applies to strings of the same length.
[[Edit distance]] is usually defined as a parameterizable metric calculated with a specific set of allowed edit operations, and each operation is assigned a cost (possibly infinite). This is further generalized by DNA [[sequence alignment]] algorithms such as the [[Smith–Waterman algorithm]], which make an operation's cost depend on where it is applied.

== See also ==
* [[Record linkage]]
* [[Census]]

== Footnotes ==
{{Reflist}}

== References ==
* {{cite journal | last=Cohen |first=W. W. |last2=Ravikumar |first2=P. |last3=Fienberg |first3=S. E. |year=2003 |title=A comparison of string distance metrics for name-matching tasks |journal=KDD Workshop on Data Cleaning and Object Consolidation |volume=3 |pages=73–8 |url=https://www.cs.cmu.edu/afs/cs/Web/People/wcohen/postscript/kdd-2003-match-ws.pdf}}
* {{cite journal | author = Jaro, M. A. | author-link = Matthew A. Jaro | title = Advances in record linkage methodology as applied to the 1985 census of Tampa Florida | journal = Journal of the American Statistical Association | year = 1989 | volume = 84 | issue = 406 |pages=414–20| doi = 10.1080/01621459.1989.10478785 }}
* {{cite journal |author=Jaro, M. A. |title=Probabilistic linkage of large public health data file  |journal= Statistics in Medicine |year=1995 |volume=14 |issue=5–7 |pages=491–8  |pmid=7792443 |doi=10.1002/sim.4780140510}}
* {{cite journal
  | author = Winkler, W. E.
  | author-link = William E. Winkler
  | title = String Comparator Metrics and Enhanced Decision Rules in the Fellegi-Sunter Model of Record Linkage
  | journal = Proceedings of the Section on Survey Research Methods
  | publisher = American Statistical Association
  | pages = 354–359
  | year = 1990
  | url = https://files.eric.ed.gov/fulltext/ED325505.pdf }}

* {{cite journal | author = Winkler, W. E. | author-link = William E. Winkler | title = Overview of Record Linkage and Current Research Directions | journal = Research Report Series, RRS | year = 2006 | url = https://www.census.gov/srd/papers/pdf/rrs2006-02.pdf}}

== External links ==
* [https://web.archive.org/web/19990822155334/http://www.census.gov/geo/msb/stand/strcmp.c strcmp.c - Original C implementation by the author of the algorithm]

{{Strings}}

{{DEFAULTSORT:Jaro-Winkler distance}}
[[Category:String metrics]]
[[Category:Computer science]]</text>
      <sha1>rvmohwagjc9ztoqv2bot56rbodrvwwq</sha1>
    </revision>
  </page>
  <page>
    <title>Category:String (computer science)</title>
    <ns>14</ns>
    <id>33512329</id>
    <revision>
      <id>857097678</id>
      <parentid>832016417</parentid>
      <timestamp>2018-08-29T15:10:35Z</timestamp>
      <contributor>
        <username>Allforrous</username>
        <id>12120664</id>
      </contributor>
      <comment>Commons and Cat main templates.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="113" xml:space="preserve">{{Commons}}
{{Cat main}}

[[Category:Data types]]
[[Category:Sequences and series]]
[[Category:Computer science]]</text>
      <sha1>n2ilywhtx5rh9j70zi5m3epaj7gqtff</sha1>
    </revision>
  </page>
  <page>
    <title>Literal (computer programming)</title>
    <ns>0</ns>
    <id>1908624</id>
    <revision>
      <id>990770227</id>
      <parentid>975799079</parentid>
      <timestamp>2020-11-26T11:51:50Z</timestamp>
      <contributor>
        <username>Tea2min</username>
        <id>36029</id>
      </contributor>
      <comment>/* See also */ + [[Hexadecimal floating-point literal]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3711" xml:space="preserve">{{short description|Notation for representing a fixed value in source code}}
In [[computer science]], a '''literal''' is a notation for representing a fixed [[Value (computer science)|value]] in [[source code]].&lt;ref&gt;{{Cite book |last=Donovan |first=John |author-link=John J. Donovan |title=Systems programming |publisher=McGraw-Hill |isbn=978-0-07-017603-4 |year=1972 |oclc=298763|page=45 |url=https://archive.org/details/systemsprogrammi00don_xk6 }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://www.ibm.com/support/knowledgecenter/SSQ2R2_14.2.0/com.ibm.ent.asm.zos.doc/asmr102056.htm |title=Literals |author=&lt;!--Not stated--&gt; |website=IBM Knowledge Center |access-date=13 May 2020 }}&lt;/ref&gt;  Almost all programming languages have notations for atomic values such as [[integer (computer science)|integer]]s, [[floating-point number]]s, and [[string (computer science)|string]]s, and usually for [[Boolean datatype|booleans]] and [[Character (computing)|characters]]; some also have notations for [[enumerated type|elements of enumerated types]] and compound values such as [[Array data structure|arrays]], [[record (computer science)|record]]s, and [[object (computer science)|object]]s. An [[anonymous function]] is a literal for the [[function type]].

In contrast to literals, [[Variable (programming)|variables]] or [[constant (computer science)|constant]]s are symbols that can take on one of a class of fixed values, the constant being constrained not to change. Literals are often used to initialize variables, for example, in the following, 1 is an integer literal and the three letter string in "cat" is a string literal:

&lt;syntaxhighlight lang="java"&gt;
int a = 1;
string s = "cat";
&lt;/syntaxhighlight&gt;

In [[lexical analysis]], literals of a given type are generally a token type, with a grammar rule, like "a [[string of digits]]" for an integer literal. Some literals are specific [[keyword (programming)|keywords]], like &lt;code&gt;true&lt;/code&gt; for the boolean literal "true".

In some [[Object (computer science)|object]]-oriented languages (like [[ECMAScript]]), objects can also be represented by literals. Methods of this object can be specified in the object literal using [[function literals]]. The brace notation below, which is also used for array literals, is typical for object literals:  
&lt;syntaxhighlight lang="javascript"&gt;
{"cat", "dog"}
{name: "cat", length: 57}
&lt;/syntaxhighlight&gt;

==Literals of objects==
In [[ECMAScript]] (as well as its implementations [[JavaScript]] or [[ActionScript]]), an object with methods can be written using the object literal like this:
&lt;syntaxhighlight lang="ecmascript"&gt;
var newobj = {
  var1: true,
  var2: "very interesting",
  method1: function () {
    alert(this.var1)
  },
  method2: function () {
    alert(this.var2)
  }
};
newobj.method1();
newobj.method2();
&lt;/syntaxhighlight&gt;

These object literals are similar to [[anonymous class]]es in other languages like [[Java (programming language)|Java]].

The [[JSON]] data interchange format is based on a subset of the JavaScript object literal syntax, with some additional restrictions (among them requiring all keys to be quoted, and disallowing functions and everything else except data literals). Because of this, ''almost'' every valid JSON document (except for some subtleties with escaping) is also valid JavaScript code, a fact exploited in the [[JSONP]] technique.

==See also==
* [[Character literal]]
* [[Function literal]]
* [[Here document]] – a file literal or stream literal
* [[Hexadecimal floating-point literal]]
* [[Integer literal]]
* [[String literal]]

== References ==
{{Reflist}}

{{DEFAULTSORT:Literal (Computer Science)}}
[[Category:Programming constructs]]
[[Category:Computer science]]</text>
      <sha1>hiihwnqb13t3kr7m8ivcdp1u7ocfvx6</sha1>
    </revision>
  </page>
  <page>
    <title>Matching wildcards</title>
    <ns>0</ns>
    <id>57373293</id>
    <revision>
      <id>998044981</id>
      <parentid>993780339</parentid>
      <timestamp>2021-01-03T15:00:10Z</timestamp>
      <contributor>
        <username>Artoria2e5</username>
        <id>18040497</id>
      </contributor>
      <comment>/* Non-recursive algorithms */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14351" xml:space="preserve">In [[computer science]], an algorithm for '''matching wildcards''' (also known as '''globbing''') is useful in comparing text strings that may contain [[wildcard character|wildcard syntax]].&lt;ref&gt;{{cite web| title=Wildcard characters| publisher=[[ScienceDirect]]| year=2018| url=http://help.sciencedirect.com/Content/st_wildcards.htm}}&lt;/ref&gt; Common uses of these algorithms include [[command-line interface]]s, e.g. the [[Bourne shell]]&lt;ref&gt;{{cite book| last= Quigley| first=Ellie| title=UNIX Shell Programming QuickStart| publisher=InformIT.com| year=2005| url=http://www.informit.com/articles/article.aspx?p=350778&amp;seqNum=4}}&lt;/ref&gt; or [[Microsoft Windows]] command-line&lt;ref&gt;{{cite web| title=MS-DOS and Windows Wildcard Characters| publisher=[[Microsoft Developer Network]] Library| url=https://msdn.microsoft.com/en-us/library/ms690414(v=vs.85).aspx}}&lt;/ref&gt; or text editor or file manager, as well as the interfaces for some search engines&lt;ref&gt;{{cite web| title=Apache Lucene - Query Parser Syntax| publisher=[[Apache Lucene]] 2.9.4 Documentation| year=2006| url=https://lucene.apache.org/core/2_9_4/queryparsersyntax.html#Wildcard%20Searches}}&lt;/ref&gt; and databases.&lt;ref&gt;{{cite web| title=SQL Wildcards| publisher=[[W3Schools]]| year=2018| url=https://www.w3schools.com/sql/sql_wildcards.asp}}&lt;/ref&gt; Wildcard matching is a subset of the problem of matching [[regular expressions]] and [[string matching]] in general.&lt;ref&gt;{{cite web| last=Goyvaerts| first=Jan| title=Welcome to Regular-Expressions.info| publisher=RegularExpressions.info| year=2018| url=https://www.regular-expressions.info/}}&lt;/ref&gt;

== The problem ==
A wildcard matcher tests a wildcard pattern ''p'' against an input string ''s''. It performs an ''anchored'' match, returns true only when ''p'' matches the entirety of ''s''.

The pattern can be based on any common syntax (see [[globbing]]), but on Windows programmers tend to only discuss a simplified syntax supported by the native C runtime:&lt;ref&gt;{{cite web |title=Wildcard Expansion |url=https://docs.microsoft.com/en-us/cpp/cpp/wildcard-expansion |website=docs.microsoft.com |language=en-us}}&lt;/ref&gt;&lt;ref name=Krauss/&gt;
* No escape characters are defined
* Wildcards: {{code|?}} matches exactly one occurrence of any character. {{code|*}} matches arbitrary many (including zero) occurrences of any character.

This article mainly discusses the Windows formulation of the problem, unless otherwise stated.

=== Definition ===
Stated in zero-based indices, the wildcard-matching problem can be defined recursively as:
:&lt;math&gt;
\begin{aligned}
m_{00} &amp;= (p_{0} = t_{0}) \\
m_{0j} &amp;= (p_{j-1} = \text{`*'}) \land m_{0,j-1}\\
m_{i0} &amp; = \text{false} \\
m_{ij} &amp;=
\begin{cases}
  m_{i-1, j-1}  &amp; \text{for}\; p_{i-1} = t_{j-1} \lor p_{i-1} = \text{`?'}\\
  m_{i, j-1} \lor m_{i-1, j} &amp; \text{for}\; p_{i-1} = \text{`*'}\\
  \text{false}  &amp; \text{for}\; p_{i-1} \neq t_{j-1}
\end{cases} &amp; &amp; \quad  \text{for}\; 1 \leq i \le |p|, 1 \leq j \le |t|.
\end{aligned}
&lt;/math&gt;

where ''m&lt;sub&gt;ij&lt;/sub&gt;'' is the result of matching the pattern ''p'' against the text ''t'' truncated at ''i'' and ''j'' characters respectively. This is the formulation used by Richter's algorithm and the ''Snippets'' algorithm found in Cantatore's collection.&lt;ref name=Rich/&gt;&lt;ref name=Cantatore/&gt; This description is similar to the [[Levenshtein distance]].
&lt;!-- Are you a computer scientist? Do you want to prove that the algorithms are right? Call 1-8000-FRAMA-C today and write this predicate in ACSL! --&gt;

=== Related problems ===

Directly related problems in computer science include:
* Pattern matching with don't cares or gaps, an unanchored string search with only the equiavelent of {{code|?}} defined.&lt;ref&gt;{{cite journal |last1=Iliopoulos |first1=Costas S. |last2=Rahman |first2=M. Sohel |title=Pattern Matching Algorithms with Don't Cares |journal=SOFSEM 2007: Theory and Practice of Computer Science, 33rd Conference on Current Trends in Theory and Practice of Computer Science |date=2007 |url=https://pdfs.semanticscholar.org/fd93/e240369270e3f2958de515dcb42a53647de2.pdf |location=Harrachov, Czech Republic}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Clifford |first1=Peter |last2=Clifford |first2=Raphaël |title=Simple deterministic wildcard matching |journal=Information Processing Letters |date=January 2007 |volume=101 |issue=2 |pages=53–54 |doi=10.1016/j.ipl.2006.08.002}}&lt;/ref&gt;
* Pattern matching with wildcards, an unanchored string search with the equiavelent of both wildcards defined. Has an exponential runtime unless a length-bound is given in the pattern matching with flexible wildcards variant.&lt;ref&gt;{{cite journal |last1=Wu |first1=Xindong |last2=Qiang |first2=Ji-Peng |last3=Xie |first3=Fei |title=Pattern Matching with Flexible Wildcards |journal=Journal of Computer Science and Technology |date=12 September 2014 |volume=29 |issue=5 |pages=740–750 |doi=10.1007/s11390-014-1464-3}}&lt;/ref&gt;

== History ==
Early algorithms for matching wildcards often relied on [[recursion]], but the technique was criticized on grounds of performance&lt;ref name=Cantatore/&gt; and reliability&lt;ref name=Krauss&gt;{{cite magazine| last=Krauss| first=Kirk| title=Matching Wildcards: An Algorithm| magazine=[[Dr. Dobb's Journal]]| year=2008| url=http://www.drdobbs.com/architecture-and-design/matching-wildcards-an-algorithm/210200888}}&lt;/ref&gt; considerations. Non-recursive algorithms for matching wildcards have gained favor in light of these considerations.

Among both recursive and non-recursive algorithms, strategies for performing the pattern matching operation vary widely, as evidenced among the variety of example algorithms referenced below. [[Test case]] development and performance optimization techniques have been demonstrably brought to bear on certain algorithms, particularly those developed by critics of the recursive algorithms.

== Recursive algorithms ==
The recursion generally happens on matching &lt;code&gt;*&lt;/code&gt; when there is more suffix to match against. This is a form of [[backtracking]], also done by some regular expression matchers.

* [[Rich Salz]]' [[wildmat]] algorithm (sh-like syntax)&lt;ref name=wildmat&gt;{{cite web| last=Salz| first=Rich| title=wildmat.c| publisher=[[GitHub]]| year=1991| url=https://github.com/trevor/transmission/blob/master/libtransmission/wildmat.c}}&lt;/ref&gt;
* Filip's algorithm&lt;ref&gt;{{cite web| author=Filip| title=Compare strings with wildcard| publisher=[[Stack Overflow]]| year=2014| url=https://stackoverflow.com/questions/23457305/compare-strings-with-wildcard}}&lt;/ref&gt; and Vignesh Murugesan's Algorithm&lt;ref&gt;{{cite web| last=Murugesan| first=Vignesh| year=2014| title=WildCard Matching algorithm| url=https://vigneshmurugesan.wordpress.com/2014/03/13/wildcard-matching-algorithm/}}&lt;/ref&gt;
* Martin Richter's algorithm&lt;ref name=Rich&gt;{{cite web| author=Deadlock| title=Wildcard Matching Recursive Algorithm C++| publisher=[[Stack Overflow]]| year=2015| url=https://stackoverflow.com/questions/31962321/wildcard-matching-recursive-algorithm-c}}&lt;/ref&gt; (identical to ''Snippets'' and related to the 7-zip algorithm)&lt;ref name="kurt"/&gt;
* C library [[fnmatch]] implementations (supports &lt;code&gt;[...]&lt;/code&gt; and multibyte character sets):
** [[Guido van Rossum]]'s BSD libc fnmatch,&lt;ref&gt;{{cite web |last1=van Rossum |first1=Guido |title=freebsd/lib/libc/gen/fnmatch.c |url=https://github.com/lattera/freebsd/blob/master/lib/libc/gen/fnmatch.c |accessdate=21 November 2019 |date=20 November 2019}}&lt;/ref&gt; also part of Apple libc&lt;ref&gt;{{cite web| title=fnmatch.c| publisher=opensource.apple.com| year=1999| url=https://opensource.apple.com/source/Libc/Libc-167/gen.subproj/fnmatch.c.auto.html}}&lt;/ref&gt;
** [[Glibc]] fnmatch&lt;ref&gt;{{cite web |title=fnmatch_internal.c |url=https://github.com/bminor/glibc/blob/master/posix/fnmatch_loop.c |publisher=Beren Minor's Mirrors |date=21 November 2019}}&lt;/ref&gt;

The general form of these algorithms are the same. On recursion the algorithm slices the input into substrings, and considers a match to have happened when ONE of the substrings return a positive match. For {{code|dowild("*X", "abcX")}}, it would greedily call {{code|dowild("X", "abcX")}}, {{code|dowild("X", "bcX")}}, {{code|dowild("X", "cX")}} and {{code|dowild("X", "X")}}. They usually differ by less-important things like support for features and by more important factors such as minor but highly effective optimizations. Some of them include:
* The ABORT signal against over-recursion (Lars Mathiesen 1991). While it is correct to naively recurse by the entire rest of the strings (pattern and text) on &lt;code&gt;*&lt;/code&gt; and making sure that ONE of the substrings return a positive match, the running time becomes exponential for rejecting a match with many &lt;code&gt;*&lt;/code&gt; in the text. Lars Mathiesen changes the return to three classes, match, no-match, and ABORT (no match possible at all for asterisk recursion.) The ABORT value is returned when the text is consumed too early or when another asterisk match has failed, guaranteeing a linear performance with respect to the number of asterisks. (The overall complexity is additionally quadratic to the number of characters left to match.)&lt;ref name=wildmat/&gt; Git/Rsync's wildmatch ABORT also covers invalid inputs.&lt;ref name=wildmatch&gt;{{cite web |title=git/git: wildmatch.c |url=https://github.com/git/git/blob/master/wildmatch.c |website=GitHub|date=2020-01-20 }}&lt;/ref&gt; The new INN uwildmat does the same.&lt;ref name=uwildmat/&gt;
* Asterisk advancement in recursion. This wildmatch tweak is relatively more minor. It applies to when the recursion wants to match "*X" on "abcX": when an asterisk is followed by a literal like "X", it is obvious that only the last comparison with equal lengths would have a chance of producing a match.&lt;ref name=wildmatch&gt;{{cite web |title=git/git: wildmatch.c |url=https://github.com/git/git/blob/master/wildmatch.c |website=GitHub|date=2020-01-20 }}&lt;/ref&gt; This is seen earlier in uwildmat in 2000&lt;ref name=uwildmat&gt;{{cite web |title=uwildmat.c in trunk/lib – INN |url=https://inn.eyrie.org/trac/browser/trunk/lib/uwildmat.c |website=inn.eyrie.org |accessdate=27 November 2019}}&lt;/ref&gt; and more implicitly in van Rossum's fnmatch for {{code|FNM_PATHNAME}}.

Martin Richter's algorithm is an exception to this pattern, although the overall operation is equivalent. On * it recurses into increasing ''either'' of the indexes, following the dynamic programming formulation of the problem. The "ABORT" technique is applicable to it as well.&lt;ref name=Rich/&gt; On typical patterns (as tested by Cantatore) it is slower than the greedy-call implementations.&lt;ref name=Cantatore/&gt;

The recursive algorithms are in general easier to reason about, and with the ABORT modification they perform acceptably in terms of worst-case complexity. On strings without * they take linear-to-string-size time to match since there is a fixed one-to-one relation.

== Non-recursive algorithms ==
The following are developed by critics of the recursive algorithms:
* [[Krauss wildcard-matching algorithm|Kirk J. Krauss's wildcard-matching algorithm]], used by IBM&lt;ref name=Krauss/&gt;&lt;ref&gt;{{cite web| last=Krauss| first=Kirk| title=Matching Wildcards: An Improved Algorithm for Big Data| publisher=Develop for Performance| year=2018| url=http://www.developforperformance.com/MatchingWildcards_AnImprovedAlgorithmForBigData.html}}&lt;/ref&gt;
* Alessandro Cantatore's collection of wildcard matching algorithms&lt;ref name=Cantatore&gt;{{cite web| last=Cantatore| first=Alessandro| title=Wildcard matching algorithms| year=2003| url=http://xoomer.virgilio.it/acantato/dev/wildcard/wildmatch.html}}&lt;/ref&gt;
* Dogan Kurt's iterative matcher and slower NFA matcher.&lt;ref name="kurt"&gt;{{cite web |last1=Kurt |first1=Dogan |title=Wildcard Matching Methods |url=http://dodobyte.com/wildcard.html}}&lt;/ref&gt;
* Siler's incorrect algorithm (fails {{code|MATCH("da*da*da*", "daaadabadmanda")}})&lt;ref&gt;{{cite web| author=Siler| title=Recursive solutions for glob pattern matching| publisher=[[Stack Overflow]]| year=2013| url=https://stackoverflow.com/questions/30823596/recursive-solutions-for-glob-pattern-matching}}&lt;/ref&gt;

The following is not:
* Jack Handy's incorrect algorithm&lt;ref&gt;{{cite web| last=Handy| first=Jack| title=Wildcard string compare (globbing}| publisher=[[Code Project]]| year=2005| url=https://www.codeproject.com/Articles/1088/Wildcard-string-compare-globbing}}&lt;/ref&gt; (fails {{code|MATCH("*?", "xx")}})

The iterative functions above implement backtracking by saving an old set of pattern/text pointers, and reverting to it should a match fails. According to Kurt, since only one successful match is required, only one such set needs to be saved.&lt;ref name="kurt"/&gt;

In addition, the problem of wildcard matching can be converted into [[regular expression]] matching using a naive [[Glob_(programming)#Compared_to_regular_expressions|text-replacement approach]]. Although non-recursive regular expression matchers such as [[Thompson's construction]] are less used in practice due to lack of backreference support, wildcard matching in general does not come with a similarly rich set of features. (In fact, many of the algorithms above only has support for {{code|?}} and {{code|*}}.) The Russ Cox implementation of Thompson NFA can be trivially modified for such.&lt;ref&gt;{{cite web |last1=Cox |first1=Ross |title=Regular Expression Matching Can Be Simple And Fast |url=https://swtch.com/~rsc/regexp/regexp1.html}}&lt;/ref&gt; Gustavo Navarro's {{abbr|BDM|Backward DAWG Match}}-based nrgrep algorithm provides a more steamlined implementation with emphasis on efficient suffixes.&lt;ref&gt;{{cite journal |last1=Navarro |first1=Gonzalo |title=NR‐grep: a fast and flexible pattern‐matching tool |journal=Software: Practice and Experience |date=10 November 2001 |volume=31 |issue=13 |pages=1265–1312 |doi=10.1002/spe.411 |url=https://users.dcc.uchile.cl/~gnavarro/ps/spe01.pdf}}&lt;/ref&gt; See also {{section link|regular expression|implementations}}.

== See also ==
* [[Pattern matching]]
* [[Pattern calculus]]
* [[Glob (programming)]]
* [[Wildcard character]]
* [[List of algorithms]]

== References ==
{{reflist}}

[[Category:Computer file formats]]
[[Category:Computer science]]
[[Category:Computing commands]]
[[Category:History of human–computer interaction]]
[[Category:Pattern matching]]
[[Category:Software architecture]]
[[Category:User interface techniques]]
[[Category:User interfaces]]</text>
      <sha1>qnlejqn440kh7p9fr0bga0ndybn9vbi</sha1>
    </revision>
  </page>
  <page>
    <title>Krauss wildcard-matching algorithm</title>
    <ns>0</ns>
    <id>57373227</id>
    <revision>
      <id>946312521</id>
      <parentid>928185586</parentid>
      <timestamp>2020-03-19T11:47:12Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>/* History */[[User:Monkbot/task_14: repair improper use of publisher params in cs1 templates|Task 14]]:  cs1 template fixes: misused |publisher= (0×/2×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5212" xml:space="preserve">In [[computer science]], the '''Krauss wildcard-matching algorithm''' is a [[pattern matching]] algorithm. Based on the [[wildcard character|wildcard syntax]] in common use, e.g. in the [[Microsoft Windows]] [[command-line interface]], the algorithm provides a non-[[Recursion|recursive]] mechanism for matching patterns in software applications, based on syntax simpler than that typically offered by [[regular expression]]s.

== History ==
The algorithm is based on a history of development, correctness and performance testing, and programmer feedback that began with an unsuccessful search for a reliable non-recursive algorithm for matching wildcards. An initial algorithm, implemented in a single while loop, quickly prompted comments from software developers, leading to improvements.&lt;ref&gt;{{cite magazine| last=Krauss| first=Kirk| title=Matching Wildcards: An Algorithm| magazine=[[Dr. Dobb's Journal]]| year=2008| url=http://www.drdobbs.com/architecture-and-design/matching-wildcards-an-algorithm/210200888}}&lt;/ref&gt; Ongoing comments and suggestions&lt;ref&gt;{{cite web| title=wild card searching| publisher=alt.os.development| year=2008| url=https://groups.google.com/forum/#!topic/alt.os.development/8-rIaarASu8}}&lt;/ref&gt;&lt;ref&gt;{{cite web| last=T.J.| title=wild card matching in text string| year=2014| publisher=Stack Overflow| url=https://stackoverflow.com/questions/21409588/wild-card-matching-in-text-string}}&lt;/ref&gt; culminated in a revised algorithm still implemented in a single while loop but refined based on a collection of [[test case]]s and a [[profiling (computer programming)|performance profiler]].&lt;ref&gt;{{cite magazine| last=Krauss| first=Kirk| title=Matching Wildcards: An Empirical Way to Tame an Algorithm| magazine=[[Dr. Dobb's Journal]]| year=2014| url=http://www.drdobbs.com/architecture-and-design/matching-wildcards-an-empirical-way-to-t/240169123}}&lt;/ref&gt; The experience tuning the single while loop using the profiler prompted development of a two-loop strategy that achieved further performance gains, particularly in situations involving empty input strings or input containing no wildcard characters.&lt;ref&gt;{{cite web| last=Krauss| first=Kirk| title=Matching Wildcards: An Improved Algorithm for Big Data| publisher=Develop for Performance| year=2018| url=http://www.developforperformance.com/MatchingWildcards_AnImprovedAlgorithmForBigData.html}}&lt;/ref&gt; The two-loop algorithm is available for use by the [[open-source software]] development community, under the terms of the [[Apache License]] v. 2.0, and is accompanied by test case code.

== Usage ==
The algorithm made available under the Apache license is implemented in both [[Pointer (computer programming)|pointer]]-based [[C++]] and portable C++ (implemented without pointers). The test case code, also available under the Apache license, can be applied to any algorithm that provides the pattern matching operations below. The implementation as coded is unable to handle [[Variable-width encoding|multibyte character sets]] and poses problems when the text being searched may contain multiple incompatible character sets.

=== Pattern matching operations ===
The algorithm supports three pattern matching operations:
* A one-to-one match is performed between the pattern and the source to be checked for a match, with the exception of asterisk ([[*]]) or question mark ([[?]]) characters in the pattern.
* An asterisk ([[*]]) character matches any sequence of zero or more characters.
* A question mark ([[?]]) character matches any single character.

== Examples ==
* ''*foo*''  	  matches any string containing "foo".
* ''mini*''       matches any string that begins with "mini" (including the string "mini" itself).
* ''???*''        matches any string of three or more letters.

== Applications ==
The original algorithm has been ported to the [[DataFlex]] programming language by Larry Heiges&lt;ref&gt;{{cite web| work=Data Access Worldwide Code Library| last=Heiges| first=Larry| title=Text compare function - generalTextCompare.txt| year=2008| url=https://support.dataaccess.com/Forums/showthread.php?1064-Text-compare-function-generalTextCompare-txt-(0-1)}}&lt;/ref&gt; for use with [[Visual DataFlex|Data Access Worldwide]] code library. It has been posted on GitHub in modified form as part of a log file reader.&lt;ref&gt;{{cite web| last=Deniskore| work=Popular repositories| title=Deniskore/wildcard/CLogReader.cpp| publisher=GitHub| year=2013| url=https://github.com/Deniskore/wildcard/blob/master/CLogReader.cpp}} Lines 173-279.&lt;/ref&gt; The 2014 algorithm is part of the Unreal Model Viewer built into the Epic Games [[Unreal Engine]] [[game engine]].&lt;ref&gt;{{cite web| last=gildor2| work=Unreal Engine Model Viewer (UE Viewer)| title=UModel/Core/Core.cpp| publisher=GitHub| year=2016| url=https://github.com/gildor2/UModel/blob/master/Core/Core.cpp}} Lines 334-435.&lt;/ref&gt;&lt;ref&gt;{{cite web| last=gildor2| work=Unreal Engine Model Viewer (UE Viewer)| title=History for UModel/Core/Core.cpp| year=2016| url=https://github.com/gildor2/UModel/commits/master/Core/Core.cpp}}&lt;/ref&gt;

== See also ==
* [[pattern matching]]
* [[glob (programming)]]
* [[wildmat]]

== References ==
{{reflist}}

[[Category:Algorithms]]
[[Category:Computer science]]</text>
      <sha1>msjfbuek97r6xnvuzgc4ca51iegsebs</sha1>
    </revision>
  </page>
  <page>
    <title>Prefetching</title>
    <ns>0</ns>
    <id>1806683</id>
    <revision>
      <id>1000910668</id>
      <parentid>888091858</parentid>
      <timestamp>2021-01-17T09:38:07Z</timestamp>
      <contributor>
        <username>Shhhnotsoloud</username>
        <id>11521989</id>
      </contributor>
      <comment>Clean up. Remove dabconcept tag since the article appears to be a stub already</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1159" xml:space="preserve">{{unreferenced|date=March 2018}}
'''Prefetching''' in computer science is a technique for speeding up fetch operations by beginning a fetch operation whose result is expected to be needed soon.  Usually this is before it is ''known'' to be needed, so there is a risk of wasting time by prefetching data that will not be used.  The technique can be applied in several circumstances:

* [[Cache prefetching]], a speedup technique used by computer processors where instructions or data are fetched before they are needed
* [[Prefetch input queue]] (PIQ), in computer architecture, pre-loading machine code from memory
* [[Link prefetching]], a web mechanism for prefetching links
* [[Prefetcher]] technology in modern releases of Microsoft Windows
* [[Cache control instruction#Prefetch|prefetch instructions]], for example provided by
** &lt;code&gt;PREFETCH&lt;/code&gt;, an [[X86 instruction listings|X86 instruction]] in computing
* [[Prefetch buffer]], a feature of DDR SDRAM memory
* [[Paging#Anticipatory paging|Swap prefetch]], in computer operating systems, anticipatory paging

==See also==
*{{Wiktionary-inline}}


{{compu-sci-stub}}
[[Category:Computer science]]</text>
      <sha1>1l15d0kgtag12obmuwxxe2nev658xx8</sha1>
    </revision>
  </page>
  <page>
    <title>Virtual environment</title>
    <ns>0</ns>
    <id>648134</id>
    <revision>
      <id>949973576</id>
      <parentid>877156372</parentid>
      <timestamp>2020-04-09T15:52:43Z</timestamp>
      <contributor>
        <username>Giraffedata</username>
        <id>105732</id>
      </contributor>
      <comment>sentence fragment, active voice</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1123" xml:space="preserve">{{Multiple issues|{{refimprove|date=July 2018}}{{context|date=July 2018}}}}

{{Distinguish|Virtual Reality}}

A '''virtual environment''' is a networked application that allows a user to interact with both the computing environment and the work of other users.  Email, chat, web-based document sharing applications are all examples of virtual environments.  Simply put, it is a networked common operating space.  Once the fidelity of the virtual environment is such that it "creates a psychological state in which the individual perceives himself or herself as existing within the virtual environment" (Blascovich, 2002, pg 129) then the virtual environment (VE) had progressed into the realm of [[immersion (virtual reality)|immersive]] virtual environments (IVEs).

== References ==

Blascovich, J. (2002).  [https://link.springer.com/chapter/10.1007/978-1-4471-0277-9_8 Social Influence within Immersive Virtual Environments].  In R. Schroeder (Ed.), The Social Life of Avatars:  Presence and Interaction in Shared Virtual Environments (pp. 127-145). London: Springer.



{{Comp-sci-stub}}

[[Category:Computer science]]</text>
      <sha1>scujoghzi7j1ev9q1nbifn3w1n4ohec</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer science suffixes</title>
    <ns>14</ns>
    <id>50427518</id>
    <revision>
      <id>857230281</id>
      <parentid>718647167</parentid>
      <timestamp>2018-08-30T11:32:15Z</timestamp>
      <contributor>
        <username>Allforrous</username>
        <id>12120664</id>
      </contributor>
      <comment>Commons template and check categories.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="73" xml:space="preserve">{{Commons}}

[[Category:Suffixes]]
[[Category:Computer science|suffixes]]</text>
      <sha1>1dwy89z5a2dfl1rsytlgl9245h31umn</sha1>
    </revision>
  </page>
  <page>
    <title>CLEVER score</title>
    <ns>0</ns>
    <id>58469254</id>
    <revision>
      <id>960111159</id>
      <parentid>948553851</parentid>
      <timestamp>2020-06-01T05:15:33Z</timestamp>
      <contributor>
        <username>Cewbot</username>
        <id>23646674</id>
      </contributor>
      <minor/>
      <comment>[[User:Cewbot/log/20150916/configuration|Normalize {{Multiple issues}}]]: Remove {{Multiple issues}} for only 1 maintenance template(s): Notability</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1037" xml:space="preserve">{{Orphan|date=September 2018}}
{{notability|date=September 2018}}

The CLEVER ('''C'''ross '''L'''ipschitz '''E'''xtreme '''V'''alue for n'''E'''twork '''R'''obustness) score is a way of measuring the robustness of an [[artificial neural network]] towards [[Deep learning#Cyberthreat|adversarial attacks]].&lt;ref&gt;{{cite arXiv |last=Weng |first=Tsui-Wei |date=2018 |title=Evaluating the robustness of neural networks: An extreme value theory approach |class=stat.ML |eprint=1801.10578}}&lt;/ref&gt;
It was developed by a team at the [[MIT-IBM Watson AI Lab]] and first presented at the 2018 [[International Conference on Learning Representations]].&lt;ref&gt;{{cite web |url=https://www.ibm.com/blogs/research/2018/05/clever-adversarial-attack/ |title=A CLEVER Way to Resist Adversarial Attack |last= |first= |date=May 2, 2018 |website= |publisher= |access-date=September 12, 2018 |quote=}}&lt;/ref&gt;

== References ==
{{Reflist}}

[[Category:Computer science]]
[[Category:Deep learning]]
[[Category:Artificial neural networks]]


{{Computer-science-stub}}</text>
      <sha1>9gb2qdibyhtt61e18999oqsoieq45gf</sha1>
    </revision>
  </page>
  <page>
    <title>Reachability analysis</title>
    <ns>0</ns>
    <id>58402395</id>
    <revision>
      <id>1000310430</id>
      <parentid>909780488</parentid>
      <timestamp>2021-01-14T16:05:08Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Fix REFPUNCT + other minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="11817" xml:space="preserve">{{short description|Solution to the reachability problem in distributed systems (computer science)}}
'''Reachability analysis''' is a solution to the [[reachability problem]] in the particular context of distributed systems. It is used to determine which global states can be reached by a distributed system which consists of a certain number of local entities that communicated by the exchange of messages.

== Overview ==

Reachability analysis was introduced in a paper of 1978 for the analysis and verification of [[communication protocols]].&lt;ref name="Boch78"&gt;{{Cite journal| last1 = Bochmann| first1 = G.v. |  title = Finite State Description of Communication Protocols, Computer Networks, Vol. 2 (1978), pp. 361-372 }}&lt;/ref&gt; This paper was inspired by a paper by Bartlett et al. of 1968 &lt;ref&gt;K.A. Bartlett, R.A. Scantlebury and P.T. Wilkinson, A note on reliable full-duplex transmission over half- duplex links, C.ACM 12, 260 (1969).&lt;/ref&gt; which presented the [[alternating bit protocol]] using finite-state modeling of the protocol entities, and also pointed out that a similar protocol described earlier had a design flaw. This protocol belongs to the [[Link layer]] and, under certain assumptions, provides as service the correct data delivery without loss nor duplication, despite the occasional presence of message corruption or loss.

For reachability analysis, the local entities are modeled by their states and transitions. An entity changes state when it sends a message, consumes a received message, or performs an interaction at its local service interface. The global state &lt;math&gt;s = (s_1, s_2, ..., s_n, medium)&lt;/math&gt;  of a system with n entities &lt;ref&gt;Note: In the case of protocol analysis, there are normally only two entities.&lt;/ref&gt; is determined by the states &lt;math&gt; s_i&lt;/math&gt;  (i=1, ... n) of the entities and the state of the communication &lt;math&gt;medium&lt;/math&gt;. In the simplest case, the medium between two entities is modeled by two FIFO queues in opposite directions, which contain the messages in transit (that are sent, but not yet consumed).  Reachability analysis considers the possible behavior of the distributed system by analyzing all possible sequences of state transitions of the entities, and the corresponding global states reached.&lt;ref&gt;Note: The corruption or loss of a message is modeled as a state transition of the &lt;math&gt;medium&lt;/math&gt;.&lt;/ref&gt;

The result of reachability analysis is a global state transition graph (also called reachability graph) which shows all global states of the distributed system that are reachable from the initial global state, and all possible sequences of send, consume and service interactions performed by the local entities. However, in many cases this transition graph is unbounded and can not be explored completely. The transition graph can be used for checking general design flaws of the protocol (see below), but also for verifying that the sequences of service interactions by the entities correspond to the requirements given by the global service specification of the system.&lt;ref name="Boch78"/&gt;

== Protocol properties ==

''Boundedness:'' The global state transition graph is bounded if the number of messages that may be in transit is bounded and the number states of all entities is bounded. The question whether the number of messages remains bounded in the case of finite state entities is in general [[undecidable problem|not decidable]].&lt;ref&gt;M.G.Gouda, E.G.Manning, Y.T.Yu: On the progress of communication between two finite state machines, [https://doi.org/10.1016/S0019-9958(84)80014-5 doi]&lt;/ref&gt; One usually truncates the exploration of the transition graph when the number of messages in transit reaches a given threshold.

The following are design flaws:

* ''Global deadlock:'' The system is in a global deadlock if all entities wait for the consumption of a message and no message is in transit. Absence of global deadlocks can be verified by checking that no state in the reachability graph is a global deadlock.
* ''Partial deadlocks:'' An entity is in a deadlocked state if it waits for the consumption of a message and the system is in a global state where such a message is not in transit and will never be sent in any global state that can be reached in the future. Such a non-local property can be verified by performing [[model checking]] on the reachability graph.
* ''Unspecified reception:'' An entity has an unspecified reception if the next message to be consumed is not expected by the behavior specification of the entity in its current state. The absence of this condition can be verified by checking all states in the reachability graph.

== An example ==

[[File:Example architecture.svg|thumb|The diagram shows two protocol entities and the messages exchanged between them.]]

[[File:Dynamic behavior of the two protocol entities.svg|thumb|The diagram shows two finite state machines that define the dynamic behavior of the respective protocol entities.]]

[[File:Reachability analysis - global behavior of this protocol system.svg|thumb|This diagram shows a state machine model of the global system consisting of the two protocol entities and two FIFO channels used for the exchange of messages between them.]]

As an example, we consider the system of two protocol entities that exchange the messages ''ma'', ''mb'', ''mc'' and ''md'' with one another, as shown in the first diagram. The protocol is defined by the behavior of the two entities, which is given in the second diagram in the form of two state machines. Here the symbol "!" means sending a message, and "?" means consuming a received message. The initial states are the states "1".

The third diagram shows the result of the reachability analysis for this protocol in the form of a global state machine. Each global state has four components: the state of protocol entity A (left), the state of the entity B (right) and the messages in transit in the middle (upper part: from A to B; lower part: from B to A). Each transition of this global state machine corresponds to one transition of protocol entity A or entity B. The initial state is [1, - - , 1] (no messages in transit).

One sees that this example has a bounded global state space - the maximum number of messages that may be in transit at the same time is two. This protocol has a global deadlock, which is the state [2, - - , 3]. If one removes the transition of A in state 2 for consuming message ''mb'', there will be an unspecified reception in the global states [2, ''ma mb'' ,3] and [2, - ''mb'' ,3].

== Message transmission ==

The design of a protocol has to be adapted to the properties of the underlying communication medium, to the possibility that the communication partner fails, and to the mechanism used by an entity to select the next message for consumption. The communication medium for protocols at the [[Link layer|Link level]] is normally not reliable and allows for erroneous reception and message loss (modeled as a state transition of the medium). Protocols using the Internet IP service should also deal with the possibility of out-of-order delivery. Higher-level protocols normally use a session-oriented Transport service which means that the medium provides reliable FIFO transmission of messages between any pair of entities. However, in the analysis of [[distributed algorithm]]s, one often takes into account the possibility that some entity fails completely, which is normally detected (like a loss of message in the medium) by a [[Timeout (computing)|timeout]] mechanism when an expected message does not arrive.

Different assumptions have been made about whether an entity can select a particular message for consumption when several messages have arrived and are ready for consumption. The basic models are the following:

* ''Single input queue:'' Each entity has a single FIFO queue where incoming messages are stored until they are consumed. Here the entity has no selection power and has to consume the first message in the queue.
* ''Multiple queues:'' Each entity has multiple FIFO queues, one for each communicating partner. Here the entity has the possibility to decide, depending on its state, from which queue (or queues) the next input message should be consumed.
* ''Reception pool:'' Each entity has a single pool where received messages are stored until they are consumed. Here the entity has the power to decide, depending on its state, which type of message should be consumed next (and wait for a message if none has been received yet), or possibly consume one from a set of message types (in order to deal with alternatives).

The original paper identifying the problem of unspecified receptions,&lt;ref&gt;P. Zafiropulo, C. West, H. Rudin, D. Cowan, D. Brand : Towards analyzing and synthesizing protocols, IEEE Transactions on Communications ( Volume: 28, Issue: 4, Apr 1980 )&lt;/ref&gt; and much of the subsequent work, assumed a single input queue.&lt;ref&gt;Note: The SAVE construct of [[Specification and Description Language|SDL]] can be used to indicate that certain types of messages should not be consumed in the current state, but saved for future processing.&lt;/ref&gt; Sometimes, unspecified receptions are introduced by a [[race condition]], which means that two messages are received and their order is not defined (which is often the case if they come from different partners). Many of these design flaws disappear when multiple queues or reception pools are used.&lt;ref&gt;M.F. Al-hammouri and G.v. Bochmann : Realizability of service specifications, Proc. System Analysis and Modelling (SAM) conference 2018, Copenhagen, LNCS, Springer&lt;/ref&gt; With the systematic use of reception pools, reachability analysis should check for partial deadlocks and messages remaining forever in the pool (without being consumed by the entity) &lt;ref&gt;C. Fournet, T. Hoare, S. K. Rajamani, and J. Rehof : Stuck-free Conformance, Proc. 16th Intl. Conf. on Computer Aided Verification (CAV’04), LNCS, vol. 3114, Springer, 2004&lt;/ref&gt;

== Practical issues ==

Most of the work on protocol modeling use [[finite-state machine]]s (FSM) to model the behavior of the distributed entities (see also [[Communicating finite-state machine]]s). However, this model is not powerful enough to model message parameters and local variables. Therefore often so-called extended FSM models are used, such as supported by languages like [[Specification and Description Language|SDL]] or [[UML state machine]]s. Unfortunately, reachability analysis becomes much more complex for such models.

A practical issue of reachability analysis is the so-called ″state space explosion″. If the two entities of a protocol have 100 states each, and the medium may include 10 types of messages, up to two in each direction, then the number of global states in the reachability graph is bound by the number 100 x 100 x (10 x 10) x (10 x 10) which is 100 million. Therefore a number of tools have been developed to automatically perform reachability analysis and model checking on the reachability graph. We mention only two examples: The [[SPIN model checker]] and a toolbox for the [[construction and analysis of distributed processes]].

== Further reading ==
* [[Communication protocols]]
* [http://spinroot.com/gerard/popd.html Gerald Holzmann: Design and Validation of Computer Protocols], [[Prentice Hall]], 1991.
* G.v. Bochmann, D. Rayner and C.H. West: Some notes on the history of protocol engineering, Computer Networks journal, 54 (2010), pp 3197–3209.

== References and notes ==
&lt;!-- Inline citations added to your article will automatically display here. See https://en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

[[Category:Communications protocols| ]]
[[Category:Computer science]]
[[Category:Theory of computation]]</text>
      <sha1>rpezwo5sr6boxknt05fz1qzfjcs2ezt</sha1>
    </revision>
  </page>
  <page>
    <title>Programmer</title>
    <ns>0</ns>
    <id>23716</id>
    <revision>
      <id>1015205405</id>
      <parentid>1015205228</parentid>
      <timestamp>2021-03-31T05:10:38Z</timestamp>
      <contributor>
        <username>AngryHarpy</username>
        <id>36731198</id>
      </contributor>
      <comment>Reverting edit(s) by [[Special:Contributions/193.119.56.230|193.119.56.230]] ([[User_talk:193.119.56.230|talk]]) to rev. 1015203928 by ClueBot NG: [[WP:VANDAL|Vandalism]] [[w:en:WP:RW|(RW 16.1)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="19373" xml:space="preserve">{{Short description|Person who writes computer software}}
{{About|people who write computer software}}
{{Redirect|Coder|someone who performs coding in the social sciences|Coding (social sciences)|someone who performs medical coding|Clinical coder|the unincorporated community in Pennsylvania|Coder, Pennsylvania}}
{{Multiple issues|
{{original research|date=January 2021}}
{{cite check|date=September 2020}}
}}
{{Use dmy dates|date=September 2018}}
{{Infobox occupation
|name=Computer programmer
|image=File:Two women operating ENIAC (full resolution).jpg
|caption=[[Jean Bartik|Betty Jennings]] and [[Frances Spence|Fran Bilas]], part of the first [[ENIAC]] programming team
|official_names= Computer Programmer
|type=[[Profession]]
|activity_sector=[[Information technology]], [[Software industry]]
|competencies=Writing and debugging computer code, documentation tasks.  Some design and development work is often performed.
|formation=Varies from apprenticeship to bachelor's degree in related field
}}
A '''computer programmer''', sometimes called a '''software developer''', a '''programmer''' or more recently a '''coder''' (especially in more informal contexts), is a person who creates [[computer software]]. The term ''computer programmer'' can refer to a specialist in one area of [[computers]], or to a generalist who writes code for many kinds of software.

A programmer's most often-used [[computer language]] (e.g., [[Assembly language|Assembly]], [[COBOL]], [[C (programming language)|C]], [[C++]], [[C Sharp (programming language)|C#]], [[JavaScript (programming language)|JavaScript]], [[Lisp (programming language)|Lisp]], [[Python programming language|Python]], [[Java (programming language)|Java]]) may be prefixed to the term ''programmer''. Some who work with [[web programming]] languages also prefix their titles with ''web''.

==History==
[[File:Ada Lovelace portrait.jpg|thumb|200px|right|[[Ada Lovelace]] is considered by many to be the first computer programmer.&lt;ref name="Fuegi-Francis-2003" /&gt;]]
British [[count]]ess and mathematician [[Ada Lovelace]] is often considered to be the first computer programmer, as she was the first to publish part of a program (specifically an [[algorithm]]) intended for implementation on [[Charles Babbage]]'s [[analytical engine]], in October 1842. The algorithm was used to calculate [[Bernoulli number]]s.&lt;ref name="Fuegi-Francis-2003"&gt;{{Cite journal |last1=Fuegi |first1=J. |last2=Francis |first2=J. |date=October–December 2003 |title=Lovelace &amp; Babbage and the creation of the 1843 'notes' |journal=IEEE Annals of the History of Computing |volume=25 |issue=4 |pages=16–26 |doi=10.1109/MAHC.2003.1253887}}&lt;/ref&gt;  Because Babbage's machine was never completed as a functioning standard in Lovelace's time, she never had the opportunity to see the algorithm in action.

The first person to execute a program on a functioning, modern, electronic computer was the [[computer scientist]] [[Konrad Zuse]], in 1941.

The [[ENIAC]] programming team, consisting of [[Kathleen Antonelli|Kay McNulty]], [[Jean Bartik|Betty Jennings]], [[Betty Holberton|Betty Snyder]], [[Marlyn Meltzer|Marlyn Wescoff]], [[Frances Spence|Fran Bilas]] and [[Ruth Teitelbaum|Ruth Lichterman]] were the first regularly working programmers.&lt;ref&gt;{{cite web|url=http://eniacprogrammers.org/eniac-programmers-project/memorials/ |title=Memorials |publisher=Eniacprogrammers.org |access-date=13 March 2021}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://abcnews.go.com/Technology/story?id=3951187&amp;page=1 |title=ABC News: First Computer Programmers Inspire Documentary |publisher=Abcnews.go.com |date=2007-12-04 |access-date=13 March 2021}}&lt;/ref&gt;

==The software industry==
{{Main|Software industry}}
The first company founded specifically to provide software products and services was the [[Computer Usage Company]], in 1955.  Before that time, computers were programmed either by customers or the few commercial computer manufacturers of the time, such as [[Sperry Rand]] and [[IBM]].&lt;ref&gt;{{cite journal|author=Elmer C. Kubie|date=Summer 1994|title=Recollections of the first software company|journal=[[Annals of the History of Computing]]|volume=16|issue=2|pages=65–71|doi=10.1109/85.279238|s2cid=5733812}}&lt;/ref&gt;

The [[software industry]] expanded in the early 1960s, almost immediately after computers were first sold in mass-produced quantities. Universities, governments, and businesses created a demand for software. Many of these programs were written in-house by full-time staff programmers; some were distributed between users of a particular machine for no charge, while others were sold on a commercial basis. Other firms, such as [[Computer Sciences Corporation]] (founded in 1959) also started to grow. Computer manufacturers soon started bundling [[operating systems]], [[system software]] and [[programming environments]] with their machines; the [[IBM 1620]] came with the 1620 Symbolic Programming System and [[Fortran|FORTRAN]].&lt;ref&gt;{{Cite web|date=2003-01-23|title=IBM Archives: 1620 Data Processing System|url=https://www.ibm.com/ibm/history/exhibits/mainframe/mainframe_PP1620.html|access-date=2021-03-17|website=www.ibm.com|language=en-US}}&lt;/ref&gt;

The industry expanded greatly with the rise of the [[personal computer]] (PC) in the mid-1970s, which brought computing to the average office worker. In the following years the PC also helped create a constantly-growing market for games, applications and utilities software. This resulted in increased demand for software developers for that period of time.&lt;ref&gt;{{Cite web|last=Bureau|first=US Census|title=Occupations in Information Technology|url=https://www.census.gov/library/publications/2016/acs/acs-35.html|access-date=2021-03-21|website=The United States Census Bureau|language=EN-US}}&lt;/ref&gt;

In the early years of the 21st century, another successful [[business model]] has arisen for hosted software, called [[software-as-a-service]], or SaaS. From the point of view of producers of some [[proprietary software]], SaaS reduces the concerns about [[Software copyright|unauthorized copying]], since it can only be accessed through the Web, and by definition, no [[client software]] is loaded onto the end user's PC. SaaS is typically run out of the [[Cloud computing|cloud]].{{citation needed|date=October 2020}}

==Nature of the work==
Computer programmers write, test, [[debug]], and maintain the detailed instructions, called [[computer programs]], that computers must follow to perform their functions. Programmers also conceive, design, and test logical structures for solving problems by computer. Many technical innovations in programming&amp;nbsp;— advanced computing technologies and sophisticated new languages and programming tools&amp;nbsp;— have redefined the role of a programmer and elevated much of the programming work done today. Job titles and descriptions may vary, depending on the organization.&lt;ref name="bls-ooh" /&gt;

Programmers work in many settings, including corporate [[information technology]] (IT) departments, big [[software companies]], small service firms and government entities of all sizes. Many professional programmers also work for consulting companies at client sites as [[Independent contractor|contractors]]. [[License|Licensing]] is not typically required to work as a programmer, although [[professional certification]]s are commonly held by programmers. Programming is widely considered a [[profession]] (although some{{Who|date=March 2011}} authorities disagree on the grounds that only careers with legal licensing requirements count as a profession).&lt;ref name="bls-ooh" /&gt;

Programmers' work varies widely depending on the type of business for which they are writing programs. For example, the instructions involved in updating financial records are very different from those required to duplicate conditions on an aircraft for pilots training in a flight simulator. Simple programs can be written in a few hours, more complex ones may require more than a year of work, while others are never considered 'complete' but rather are continuously improved as long as they stay in use. In most cases, several programmers work together as a team under a senior programmer's supervision.{{citation needed|date=September 2020}}

Programmers write programs according to the specifications determined primarily by more senior programmers and by [[systems analyst]]s. After the design process is complete, it is the job of the programmer to convert that design into a logical series of instructions that the computer can follow. The programmer codes these instructions in one of many programming languages. Different programming languages are used depending on the purpose of the program. [[COBOL]], for example, is commonly used for business applications that typically run on [[Mainframe computer|mainframe]] and [[minicomputer|midrange]] computers, whereas [[Fortran]] is used in science and engineering. [[C++]] and [[Python (Programming Language)|Python]] are widely used for both scientific and business applications. [[Java (programming language)|Java]], [[C Sharp (programming language)|C#]], [[JavaScript|JS]]  and [[PHP]] are popular programming languages for Web and business applications. Programmers generally know more than one programming language and, because many languages are similar, they often can learn new languages relatively easily. In practice, programmers often are referred to by the language they know, e.g. as ''Java programmers'', or by the type of function they perform or the environment in which they work: for example, ''[[database]] programmers'', ''mainframe programmers'', or [[web developers]].{{citation needed|date=September 2020}}

When making changes to the [[source code]] that programs are made up of, programmers need to make other programmers aware of the task that the routine is to perform. They do this by inserting comments in the [[source code]] so that others can understand the program more easily and by [[Software documentation|documenting their code]]. To save work, programmers often use [[Library (computing)|libraries]] of basic code that can be modified or customized for a specific application. This approach yields more reliable and consistent programs and increases programmers' productivity by eliminating some routine steps.{{citation needed|date=September 2020}}

===Testing and debugging===
Programmers test a program by running it and looking for [[Software bug|bugs]] (errors). As they are identified, the programmer usually makes the appropriate corrections, then rechecks the program until an acceptably low level and severity of bugs remain. This process is called [[Software testing|testing]] and [[debugging]]. These are important parts of every programmer's job. Programmers may continue to fix these problems throughout the life of a program. Updating, repairing, modifying, and expanding existing programs is sometimes called ''maintenance programming''. Programmers may contribute to [[user guide]]s and [[online help]], or they may work with [[technical writers]] to do such work.

===Application versus system programming===
Computer programmers often are grouped into two broad types: application programmers and systems programmers. Application programmers write programs to handle a specific job, such as a program to track inventory within an organization. They also may revise existing packaged software or customize generic applications which are frequently purchased from [[independent software vendor]]s. Systems programmers, in contrast, write programs to maintain and control computer systems software, such as [[operating systems]] and [[database management systems]]. These workers make changes in the instructions that determine how the network, workstations, and [[Central processing unit|CPU]] of the system handle the various jobs they have been given and how they communicate with peripheral equipment such as [[Computer printer|printers]] and [[Data storage device|disk drives]].

=== Qualifications and skills ===
A programmer needs to have technical expertise with certain aspects of computing. Some positions will require a degree in a relevant field such as computer science, information technology, engineering, programming, or other related studies. An ideal programmer is a one who possesses hands-on experience with key programming languages such as [[C++]], [[C Sharp (programming language)|C#]], [[PHP]], [[Java (programming language)|Java]], [[C (programming language)|C]], [[JavaScript]], [[Visual Basic]], and [[Python (programming language)|Python]].

===Types of software===
Programmers may work directly with experts from different fields to create software&amp;nbsp;– either programs designed for specific clients or packaged software for general use&amp;nbsp;– ranging from [[video game]]s to educational software to programs for [[desktop publishing]] or financial applications. Programming of packaged software constitutes one of the most rapidly growing segments of the computer services industry. Some companies or organizations – even small ones – have set up their own IT team to ensure the design and development of in-house software to answer to very specific needs from their internal end-users, especially when existing software are not suitable or too expensive. This is, for example, the case in [[research laboratories]].{{citation needed|date=May 2014}}

In some organizations, particularly small ones, people commonly known as ''programmer analysts'' are responsible for both the systems analysis and the actual programming work. The transition from a mainframe environment to one that is based primarily on [[personal computers]] (PCs) has blurred the once rigid distinction between the programmer and the user. Increasingly, adept end-users are taking over many of the tasks previously performed by programmers. For example, the growing use of packaged software, such as spreadsheet and database management software packages, allows users to write simple programs to access data and perform calculations.{{citation needed|date=May 2014}}

In addition, the rise of the Internet has made [[web development]] a huge part of the programming field. Currently, more software applications are [[web application]]s that can be used by anyone with a [[web browser]].{{citation needed|date=May 2014}} Examples of such applications include the [[Google]] search service, the [[Outlook.com]] e-mail service, and the [[Flickr]] photo-sharing service.

Programming editors, also known as [[source code editor]]s, are text editors that are specifically designed for programmers or developers for writing the source code of an application or a program. Most of these editors include features useful for programmers, which may include color [[syntax highlighting]], auto indentation, [[auto-complete]], bracket matching, [[Syntax checker|syntax check]], and allows [[plug-in (computing)|plug-in]]s. These features aid the users during coding, [[debugging]] and testing.&lt;ref&gt;{{Cite web|url=https://www.bbc.co.uk/education/guides/zgmpr82/revision/4|title=BBC Bitesize - GCSE Computer Science - Programming software and the IDE - Revision 4|website=www.bbc.co.uk|language=en-GB|access-date=13 March 2021}}&lt;/ref&gt;

==Globalization==
{{Globalize|section|USA|2name=the United States|date=December 2010}}

===Market changes in the UK===
According to BBC News, 17% of computer science students could not find work in their field 6 months after graduation in 2009 which was the highest rate of the university subjects surveyed while 0% of medical students were unemployed in the same survey.&lt;ref&gt;{{cite web|url=https://www.bbc.co.uk/news/10477551|title='One in 10' UK graduates jobless|first=Martin|last=Shankleman|date=1 July 2010|via=www.bbc.co.uk|access-date=13 March 2021}}&lt;/ref&gt;

===Market changes in the US===
After the crash of the [[dot-com bubble]] (1999–2001) and the [[Great Recession]] (2008), many U.S. programmers were left without work or with lower wages.&lt;ref name="bls-dotcom-2009"&gt;{{cite journal |last1=Mann |first1=Amar |last2=Nunes |first2=Tony |title=After the Dot-Com Bubble: Silicon Valley High-Tech Employment and Wages in 2001 and 2008 |journal=Regional Report, U.S. Bureau of Labor Statistics |date=August 2009 |pages=1–8 |url=https://www.bls.gov/opub/btn/archive/after-the-dot-com-bubble-silicon-valley-high-tech-employment-and-wages-in-2001-and-2008.pdf |access-date=13 March 2021}}&lt;/ref&gt; In addition, enrollment in computer-related degrees and other STEM degrees (STEM attrition)&lt;ref&gt;{{Cite web|url=https://nces.ed.gov/pubsearch/pubsinfo.asp?pubid=2014001rev|title=STEM Attrition: College Students’ Paths Into and Out of STEM Fields|date=26 November 2013|website=nces.ed.gov|access-date=13 March 2021}}&lt;/ref&gt; in the US has been dropping for years, especially for women,&lt;ref&gt;{{Cite web|url=https://developers.hp.com/public/blog/hp-international-womens-week-women-computer-science-dropping-1980s|title=hp's Developer Portal &amp;#124; HP International Women's Week: Women in Computer Science dropping since 1980s|website=developers.hp.com|access-date=13 March 2021}}&lt;/ref&gt; which, according to Beaubouef and Mason,&lt;ref&gt;{{cite journal |last1=Beaubouef |first1=Theresa |last2=Mason |first2=John |title=Why the high attrition rate for computer science students: some thoughts and observations |journal=ACM SIGCSE Bulletin |date=June 2005 |volume=37 |issue=2 |pages=103–106 |doi=10.1145/1083431.1083474}}&lt;/ref&gt; could be attributed to a lack of general interest in science and mathematics and also out of an apparent fear that programming will be subject to the same pressures as manufacturing and agriculture careers. The U.S. Bureau of Labor Statistics Occupational Outlook 2014-24 predicts a decline for Computer Programmers of -8 percent, then for 2016-26 predicts a decline of -7 percent, and finally predicts a decline of -9 percent from 2019 to 2029.&lt;ref name="bls-ooh"&gt;{{cite web|url=https://www.bls.gov/ooh/computer-and-information-technology/computer-programmers.htm|title=Computer Programmers : Occupational Outlook Handbook: : U.S. Bureau of Labor Statistics|website=www.bls.gov|access-date=13 March 2021}}&lt;/ref&gt;

==See also==
{{Portal|Computer programming}}
* [[Game programmer]]
* [[List of programmers]]
* [[Software development process]]
* [[Software engineering]]
* [[System administrator]]
{{Clear}}

==References==
{{Reflist|30em}}

==Further reading==
* [[Gerald Weinberg|Weinberg, Gerald M.]], ''The Psychology of Computer Programming'', New York: Van Nostrand Reinhold, 1971
* An experiential study of the nature of programming work: Lucas, Rob. [http://www.newleftreview.org/?view=2836 "Dreaming in Code"] ''New Left Review'' 62, March–April 2010, pp.&amp;nbsp;125–132.
* {{cite book |title=Coders: The Making of a New Tribe and the Remaking of the World |year=2019 |first=Clive |last=Thompson |publisher=Penguin Press |isbn=978-0735220560}}

==External links==
* The [[US Department of Labor]] description of:
** [http://www.bls.gov/ooh/computer-and-information-technology/computer-programmers.htm Computer programmers]
** [http://www.bls.gov/ooh/computer-and-information-technology/software-developers.htm Software developers]

{{Authority control}}

[[Category:Computer occupations]]
[[Category:Computer science]]
[[Category:Software industry]]
[[Category:Information technology]]</text>
      <sha1>c8es3w3ovtrv8gyutc64t60v8jzbg79</sha1>
    </revision>
  </page>
  <page>
    <title>OpenCV</title>
    <ns>0</ns>
    <id>2056516</id>
    <revision>
      <id>1011992803</id>
      <parentid>997730600</parentid>
      <timestamp>2021-03-14T00:31:11Z</timestamp>
      <contributor>
        <username>Tom.Bot</username>
        <id>28901961</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} ([[d:Q165277|1 ID]] from [[Wikidata]]), [[WP:GenFixes]] on</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10487" xml:space="preserve">{{Short description|Computer vision library}}
{{primary sources|date=November 2012}}
{{Infobox software
| title =
| name = OpenCV
| logo = [[Image:OpenCV Logo with text svg version.svg|180px]]&lt;!-- Image name is enough --&gt;
| logo size =
| logo alt =
| logo caption =
| screenshot = &lt;!-- Image name is enough --&gt;
| screenshot size =
| screenshot alt =
| caption =
| collapsible =
| author = [[Intel Corporation]], [[Willow Garage]], Itseez
| developer =
| released = {{Start date and age|2000|06|df=yes}}
| discontinued =
| latest release version = 4.5.1
| latest release date = {{Start date and age|2020|12|22|df=yes}}
| latest preview version =
| latest preview date = 
| programming language = [[C (programming language)|C]]/[[C++]]
| operating system = [[Cross-platform]]
| platform = 
| size = ~200 MB &lt;!-- 2.4.13 for Linux, unpacked --&gt;
| language =
| language count = &lt;!-- Number only --&gt;
| language footnote =
| genre = Library
| license = [[Apache license]]
| alexa =
| website = {{URL|//opencv.org}}
| standard =
| AsOf =
}}
'''OpenCV''' (''Open Source Computer Vision Library'') is a [[library (computing)|library of programming functions]] mainly aimed at real-time [[computer vision]].&lt;ref&gt;{{cite journal|last1=Pulli|first1=Kari|last2=Baksheev|first2=Anatoly|last3=Kornyakov|first3=Kirill|last4=Eruhimov|first4=Victor|title=Realtime Computer Vision with OpenCV|url=http://dl.acm.org/citation.cfm?id=2206309|journal=Queue|pages=40:40–40:56|doi=10.1145/2181796.2206309|date=1 April 2012|volume=10|issue=4|doi-access=free}}&lt;/ref&gt; Originally developed by [[Intel Corporation|Intel]], it was later supported by [[Willow Garage]] then Itseez (which was later acquired by Intel&lt;ref&gt;Intel acquires Itseez: https://opencv.org/intel-acquires-itseez.html&lt;/ref&gt;). The library is [[cross-platform]] and free for use under the [[open-source software|open-source]] [[Apache License|Apache 2 License]]. Starting with 2011, OpenCV features GPU acceleration for real-time operations.&lt;ref&gt;{{Cite web|title=CUDA|url=https://opencv.org/platforms/cuda/|access-date=2020-10-15|website=opencv.org}}&lt;/ref&gt;

==History==
Officially launched in 1999 the OpenCV project was initially an [[Intel Research Lablets|Intel Research]] initiative to advance [[central processing unit|CPU]]-intensive applications, part of a series of projects including [[Real-time computing|real-time]] [[ray tracing (graphics)|ray tracing]] and [[3D Display|3D display]] walls.&lt;ref name="KaehlerBradski2016"&gt;{{cite book|author1=Adrian Kaehler|author2=Gary Bradski|title=Learning OpenCV 3: Computer Vision in C++ with the OpenCV Library|url=https://books.google.com/books?id=SKy3DQAAQBAJ&amp;pg=PT26|date=14 December 2016|publisher=O'Reilly Media|isbn=978-1-4919-3800-3|pages=26ff}}&lt;/ref&gt; The main contributors to the project included a number of optimization experts in Intel Russia, as well as Intel's Performance Library Team. In the early days of OpenCV, the goals of the project were described&lt;ref&gt;{{cite book|last1=Bradski|first1=Gary|last2=Kaehler|first2=Adrian|title=Learning OpenCV: Computer vision with the OpenCV library|publisher=O'Reilly Media, Inc.|date=2008|pages=6}}&lt;/ref&gt; as:
&lt;blockquote&gt;
* Advance vision research by providing not only open but also [[Code optimization|optimized code]] for basic vision infrastructure. No more [[reinventing the wheel]].
* Disseminate vision knowledge by providing a common infrastructure that developers could build on, so that code would be more readily readable and transferable.
*Advance vision-based commercial applications by making [[Portability (computer science)|portable]], performance-optimized code available for free – with a license that did not require code to be open or free itself.
&lt;/blockquote&gt;

The first alpha version of OpenCV was released to the public at the [[Conference on Computer Vision and Pattern Recognition|IEEE Conference on Computer Vision and Pattern Recognition]] in 2000, and five betas were released between 2001 and 2005. The first 1.0 version was released in 2006. A version 1.1 "pre-release" was released in October 2008.

The second major release of the OpenCV was in October 2009. OpenCV&amp;nbsp;2 includes major changes to the [[C++]] interface, aiming at easier, more type-safe patterns, new functions, and better implementations for existing ones in terms of performance (especially on multi-core systems). Official releases now occur every six months&lt;ref&gt;OpenCV change logs: http://code.opencv.org/projects/opencv/wiki/ChangeLog {{Webarchive|url=https://web.archive.org/web/20130115212624/http://code.opencv.org/projects/opencv/wiki/ChangeLog |date=2013-01-15 }}&lt;/ref&gt; and development is now done by an independent Russian team supported by commercial corporations.

In August 2012, support for OpenCV was taken over by a non-profit foundation OpenCV.org, which maintains a developer&lt;ref&gt;OpenCV Developer Site: http://code.opencv.org {{Webarchive|url=https://archive.is/20130113084234/http://code.opencv.org/ |date=2013-01-13 }}&lt;/ref&gt; and user site.&lt;ref&gt;OpenCV User Site: http://opencv.org/&lt;/ref&gt;

On May 2016, Intel signed an agreement to acquire Itseez,&lt;ref&gt;{{Cite news|url=https://newsroom.intel.com/editorials/intel-acquires-computer-vision-for-iot-automotive/|title=Intel Acquires Computer Vision for IOT, Automotive {{!}} Intel Newsroom|work=Intel Newsroom|access-date=2018-11-26|language=en-US}}&lt;/ref&gt; a leading developer of OpenCV.&lt;ref&gt;{{Cite news|url=http://www.ewdn.com/2016/05/31/intel-acquires-russian-computer-vision-company-itseez/|title=Intel acquires Russian computer vision company Itseez|date=2016-05-31|work=East-West Digital News|access-date=2018-11-26|language=en-US}}&lt;/ref&gt;

In July 2020, OpenCV announced and began a Kickstarter campaign for the [https://opencv.org/introducing-oak-spatial-ai-powered-by-opencv/ OpenCV AI Kit], a series of hardware modules and additions to OpenCV supporting Spatial AI.

== Applications ==
[[Image:OfxOpenCV.png|thumb|right|[[openFrameworks]] running the OpenCV add-on example]]
OpenCV's application areas include:

* 2D and 3D feature toolkits
* [[Egomotion]] estimation
* [[Facial recognition system]]
* [[Gesture recognition]]
* [[Human–computer interaction]] (HCI)
* [[Mobile robotics]]
* Motion understanding
* [[Object detection]]
* [[Segmentation (image processing)|Segmentation]] and recognition
* [[Stereopsis]] stereo vision: depth perception from 2 cameras
* [[Structure from motion]] (SFM)
* [[Video tracking|Motion tracking]]
* [[Augmented reality]]

To support some of the above areas, OpenCV includes a statistical [[machine learning]] library that contains:

* [[Boosting (meta-algorithm)|Boosting]]
* [[Decision tree learning]]
* [[Gradient boosting]] trees
* [[Expectation-maximization algorithm]]
* [[k-nearest neighbor algorithm]]
* [[Naive Bayes classifier]]
* [[Artificial neural network]]s
* [[Random forest]]
* [[Support vector machine]] (SVM)
* [[Deep neural network]]s (DNN)&lt;ref name=DNN&gt;OpenCV: http://opencv.org/opencv-3-3.html&lt;/ref&gt;

==Programming language==
OpenCV is written in [[C++]] and its primary interface is in C++, but it still retains a less comprehensive though extensive older [[C (programming language)|C interface]]. All of the new developments and algorithms appear in the C++ interface. There are bindings in [[Python (programming language)|Python]], [[Java (programming language)|Java]] and [[MATLAB]]/[[GNU Octave|OCTAVE]]. The API for these interfaces can be found in the online documentation.&lt;ref name=Cdocs&gt;OpenCV C interface: http://docs.opencv.org&lt;/ref&gt; Wrappers in several programming languages have been developed to encourage adoption by a wider audience. In version 3.4, [[JavaScript]] bindings for a selected subset of OpenCV functions was released as OpenCV.js, to be used for web platforms.&lt;ref&gt;[https://docs.opencv.org/3.4.0/df/d0a/tutorial_js_intro.html Introduction to OpenCV.js and Tutorials]&lt;/ref&gt;

==Hardware acceleration==

If the library finds Intel's [[Integrated Performance Primitives]] on the system, it will use these proprietary optimized routines to accelerate itself.

A [[CUDA]]-based [[graphics processing unit|GPU]] interface has been in progress since September 2010.&lt;ref name=OpenCVGPU&gt;Cuda GPU port: http://opencv.org/platforms/cuda.html {{Webarchive|url=https://web.archive.org/web/20160521200940/http://opencv.org/platforms/cuda.html |date=2016-05-21 }}&lt;/ref&gt;

An [[OpenCL]]-based [[graphics processing unit|GPU]] interface has been in progress since October 2012,&lt;ref name=OpenCVOCL&gt;OpenCL Announcement: http://opencv.org/opencv-v2-4-3rc-is-under-way.html&lt;/ref&gt; documentation for version 2.4.13.3 can be found at docs.opencv.org.&lt;ref name=OpenCVOCL2.4.5&gt;OpenCL-accelerated Computer Vision API Reference: http://docs.opencv.org/modules/ocl/doc/ocl.html&lt;/ref&gt;

== OS support ==
OpenCV runs on the following desktop operating systems: [[Microsoft Windows|Windows]], [[Linux]], [[macOS]], [[FreeBSD]], [[NetBSD]], [[OpenBSD]]. OpenCV runs on the following mobile operating systems: [[Android (operating system)|Android]], [[iOS]], [[Maemo]],&lt;ref name=Maemo_Port&gt;Maemo port: https://garage.maemo.org/projects/opencv&lt;/ref&gt; [[BlackBerry 10]].&lt;ref&gt;BlackBerry 10 (partial port): https://github.com/blackberry/OpenCV&lt;/ref&gt; The user can get official releases from [[SourceForge]] or take the latest sources from [[GitHub]].&lt;ref&gt;{{Cite web | url=https://github.com/Itseez/opencv |title = GitHub - opencv/Opencv: Open Source Computer Vision Library  |date = 21 May 2020}}&lt;/ref&gt; OpenCV uses [[CMake]].

==See also==
{{Portal|Free and open-source software}}
* [[AForge.NET]], a computer vision library for the [[Common Language Runtime]] ([[.NET Framework]] and [[Mono (software)|Mono]]).
* [[ROS (Robot Operating System)]]. OpenCV is used as the primary vision package in ROS.
* [[VXL]], an alternative library written in C++.
* [[CVIPtools]], a complete GUI-based computer-vision and image-processing software environment, with C function libraries, a COM-based DLL, along with two utility programs for algorithm development and batch processing.
* [[OpenNN]], an open-source [[artificial neural network|neural networks]] library written in C++.
*[[List of free and open-source software packages|List of free and open source software packages]]

==References==
{{Reflist}}

{{Image processing software}}
{{Authority control}}

[[Category:Computer vision software]]
[[Category:C++ libraries]]
[[Category:Gesture recognition]]
[[Category:Computer science]]
[[Category:Software using the Apache license]]</text>
      <sha1>ghsy0bviqym6rszeayn5kxv0wtot6d8</sha1>
    </revision>
  </page>
  <page>
    <title>Information and computer science</title>
    <ns>0</ns>
    <id>8431748</id>
    <revision>
      <id>1000831080</id>
      <parentid>1000812918</parentid>
      <timestamp>2021-01-16T23:19:56Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Citation needed}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12796" xml:space="preserve">{{refimprove|date=November 2015}}
{{original synthesis|date=June 2016}}
[[File:CISLab.jpg |thumb |393px |A lab in which ''computer and information science'' (CIS) is studied.]]
'''Information and computer science''' ('''ICS''') or '''computer and information science''' ('''CIS''') (plural forms, i.e., ''sciences'', may also be used) is a field that emphasizes ''both'' [[computing]] and [[informatics]], upholding the strong association between the fields of [[information science]]s and [[computer science]]s and treating [[computer]]s as a tool rather than a field.

''Information science'' is one with a [[Information science#Early beginnings|long history]],{{Citation needed|date=January 2021}} unlike the relatively [[History of computer science|very young]] field of computer science, and is primarily concerned with gathering, storing, disseminating, sharing and protecting any and all forms of information. It is a broad field, covering a myriad of different areas but is often referenced alongside computer science because of the incredibly useful nature of computers and computer programs in helping those studying and doing research in the field – particularly in helping to analyse data&lt;ref&gt;http://www.anderson.ucla.edu/faculty/jason.frand/teacher/technologies/palace/datamining.htm&lt;/ref&gt; and in spotting patterns too broad for a human to intuitively perceive. While information science is sometimes confused with information theory, the two have vastly different subject matter. Information theory focuses on one particular mathematical concept of information while information science is focused on all aspects of the processes and techniques of information.

''Computer science'', in contrast, is less focused on information and its different states, but more, in a very broad sense, on the use of computers – both in theory and practice – to design and implement [[algorithm]]s in order to aid the processing of information during the different states described above. It has strong foundations in the field of mathematics, as the very first recognised practitioners of the field were renowned mathematicians such as [[Alan Turing]].

Information science and computing began to converge in the 1950s and 1960s, as information scientists started to realize the many ways computers would improve information storage and retrieval.

==Terminology==
Due to the distinction between computers and computing, some of the research groups refer to ''computing'' or ''datalogy''. The French refer to computer science as the term ''[[:fr:Informatique |informatique]]''. The term ''information and communications technology'' (ICT), refers to how humans communicate with using machines and computers, making a distinction from ''information and computer science'', which is how computers use and gain information.

Informatics is also distinct from ''computer science'', which encompasses the study of logic and low-level computing issues.

==Education==
Universities may confer degrees of ICS and CIS, not to be confused with a more specific [[Bachelor of Computer Science]] or respective graduate computer science degrees.

The QS World University Rankings is one of the most widely recognised and distinguished university comparisons. They ranked the top 10 universities for ''computer science'' and ''[[information system]]s'' in 2015. 

They are:
* Massachusetts Institute of Technology (MIT)
* Stanford University
* University of Oxford
* Carnegie Mellon University
* Harvard University
* University of California, Berkeley (UCB)
* University of Cambridge
* The Hong Kong University of Science and Technology
* Swiss Federal Institute of Technology (ETH Zurich)
* Princeton University&lt;ref&gt;{{Cite web |url=http://www.topuniversities.com/university-rankings/university-subject-rankings/2015/computer-science-information-systems#sorting=rank+region=+country=+faculty=+stars=false+search= |title=QS World University Rankings by Subject 2015 – Computer Science &amp; Information Systems |date= |access-date= |website= |publisher= |last= |first=}}&lt;/ref&gt;

A Computer Information Science degree gives students both network and computing knowledge which is needed to design, develop, and assist information systems which helps to solve business problems and to support business problems and to support business operations and decision making at a managerial level also.

==Areas of information and computer science==
Due to the nature of this field, many topics are also shared with [[computer science]] and [[information system]]s.

The discipline of ''Information and Computer Science'' spans a vast range of areas from basic computer science theory (algorithms and computational logic)  to in depth analysis of data manipulation and use within technology.&lt;ref&gt;{{Cite web |url=https://www.cs.mtu.edu/~john/whatiscs.html |title=What is Computer Science? |date= |access-date= |website= |publisher= |last= |first=}}&lt;/ref&gt;

===Programming theory===
The process of taking a given algorithm and encoding it into a language that can be understood and executed by a computer. There are many different types of programming languages and various different types of computers, however, they all have the same goal: to turn algorithms into machine code.&lt;ref&gt;{{Cite web |title=What Is Programming? – Problem Solving with Algorithms and Data Structures |url=http://interactivepython.org/runestone/static/pythonds/Introduction/WhatIsProgramming.html |website=interactivepython.org |access-date=2015-11-19}}&lt;/ref&gt;

Popular programming languages used within the academic study of CIS include, but are not limited to: Java, Python, C#, C++, Perl, Ruby, Pascal, Swift, Visual Basic.

===Information and information systems===
The academic study of software and hardware systems that process large quantities and data, support large scale data management and how data can be used.&lt;ref&gt;{{Cite web |title=information system |url=http://www.britannica.com/topic/information-system |website=Encyclopædia Britannica |access-date=2015-11-19}}&lt;/ref&gt; This is where the field is unique from the standard study of computer science. The area of information systems focuses on the networks of hardware and software that are required to process, manipulate and distribute such data.

===Computer systems and organisations===
The process of analysing computer architecture and various logic circuits. This involves looking at low level computer processes at bit level computation. This is an in-depth look into the hardware processing of a computational system, involving looking at the basic structure of a computer and designing such systems.&lt;ref&gt;{{Cite web |title=What is Computer Architecture? – Definition from Techopedia |url=https://www.techopedia.com/definition/26757/computer-architecture |website=Techopedia.com |access-date=2015-11-19}}&lt;/ref&gt; This can also involve evaluating complex circuit diagrams, and being able to construct these to solve a main problem.

The main purpose behind this area of study is to achieve an understanding of how computers function on a basic level, often through tracing machine operations.

===Machines, languages, and computation===
This is the study into fundamental computer algorithms, which are the basis to computer programs. Without algorithms, no computer programs would exist.&lt;ref&gt;{{Cite web |title=What is a computer algorithm? |url=http://computer.howstuffworks.com/question717.htm |website=HowStuffWorks |access-date=2015-11-19}}&lt;/ref&gt; This also involves the process of looking into various mathematical functions behind computational algorithms, basic theory and functional (low level) programming.

In an academic setting, this area would introduce the fundamental mathematical theorems and functions behind theoretical computer science which are the building blocks for other areas in the field. Complex topics such as; proofs, algebraic functions and sets will be introduced during studies of CIS.

== Developments ==
Information and computer science is a field that is rapidly developing with job prospects for students being extremely promising with 75.7% of graduates gaining employment.&lt;ref&gt;{{Cite web |title=What can I do With My Degree? |url=http://www.prospects.ac.uk/options_computer_science.htm |website=Prospects |access-date=2015-11-19}}&lt;/ref&gt; Also the IT industry employs one in twenty of the workforce with it predicted to increase nearly five times faster than the average of the UK and between 2012 and 2017 more than half a million people will be needed within the industry and the fact that nine out of ten tech firms are suffering from candidate shortages which is having a negative impact on their business as it delays the creation and development of new products,&lt;ref&gt;{{Cite web |title=Computer science graduates: why do they top unemployment tables? |url=https://www.theguardian.com/higher-education-network/blog/2013/sep/16/computer-science-graduates-unemployment-bme |website=The Guardian |access-date=2015-11-19}}&lt;/ref&gt; and it's predicted in the US that in the next decade there will be more than one million jobs in the technology sector than computer science graduates to fill them.&lt;ref&gt;{{Cite web |title=A Push to Boost Computer Science Learning Even at an Early Age |url=https://www.npr.org/sections/alltechconsidered/2014/02/17/271151462/a-push-to-boost-computer-science-learning-even-at-an-early-age |website=NPR |access-date=2015-11-19}}&lt;/ref&gt; Because of this programming is now being taught at an earlier age with an aim to interest students from a young age into computer and information science hopefully leading more children to study this at a higher level. For example, children in England will now be exposed to computer programming at the age of 5 due to an updated national curriculum.&lt;ref&gt;{{Cite web |title=Teaching our children to code: a quiet revolution |url=https://www.telegraph.co.uk/technology/news/10410036/Teaching-our-children-to-code-a-quiet-revolution.html |website=The Telegraph |access-date=2015-11-19}}&lt;/ref&gt;

==Employment==
Due to the wide variety of jobs that now involve computer and information science related tasks, it is difficult to provide a comprehensive list of possible jobs in this area, but some of the key areas are artificial intelligence, software engineering and computer networking and communication. Work in this area also tends to require sufficient understanding of mathematics and science.&lt;ref&gt;{{Cite web |title=What is Computer Science |url=https://www.cs.mtu.edu/~john/whatiscs.html |access-date=2015-11-19}}&lt;/ref&gt; Moreover, jobs that having a CIS degree can lead to, include: systems analyst, network administrator, system architect, information systems developer, web programmer, or software developer.

The earning potential for CIS graduates is quite promising. A 2013 survey from the National Association of Colleges and Employers (NACE) found that the average starting salary for graduates who earned a degree in a computer related field was $59,977, up 4.3% from the prior year. This is higher than other popular degrees such as business ($54,234), education ($40,480) and math and sciences ($42,724).&lt;ref&gt;{{Cite web |title=Starting Salaries for New College Graduates |url=http://www.naceweb.org/uploadedFiles/NACEWeb/Research/Salary_Survey/Reports/salary-survey-april-2013-executive-summary.pdf |access-date=2015-11-26}}&lt;/ref&gt; Furthermore, Payscale ranked 129 college degrees based on their graduates earning potential with engineering, math, science, and technology fields dominating the ranking. With eight computer related degrees appearing among the top 30. With the lowest starting salary for these jobs being $49,900.&lt;ref&gt;{{Cite web |title=Computer science major ranks No. 8 for salary potential |url=http://www.networkworld.com/article/2169997/data-center/computer-science-major-ranks-no--8-for-salary-potential.htm |website=Network World |access-date=2015-11-19 }}{{Dead link|date=January 2020 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; A Rasmussen College article describes various jobs CIS graduates may obtain with software applications developers at the top making a median income of  $98,260.&lt;ref&gt;{{Cite web |url=http://www.rasmussen.edu/degrees/technology/blog/entry-level-computer-science-jobs/ |title=8 Entry-Level Computer Science Jobs that are Actually Hiring! |website=www.rasmussen.edu |access-date=2017-02-28}}&lt;/ref&gt;

According to the National Careers Service an Information Scientist can expect to earn £24,000+ per year as a starting salary.&lt;ref&gt;{{Cite web |title=Job Titles – Information Scientist |url=https://nationalcareersservice.direct.gov.uk/advice/planning/jobprofiles/Pages/informationscientist.aspx |access-date=2015-12-10}}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Information science]]
[[Category:Computer science]]</text>
      <sha1>m38a2zhjo2xe84cwc4p4n0dhxkvimnf</sha1>
    </revision>
  </page>
  <page>
    <title>Reactive synthesis</title>
    <ns>0</ns>
    <id>60078637</id>
    <revision>
      <id>1000310671</id>
      <parentid>885708813</parentid>
      <timestamp>2021-01-14T16:06:31Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Fix REFPUNCT + other minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="940" xml:space="preserve">'''Reactive synthesis''' (or '''temporal synthesis''') is the field of [[computer science]] that studies automatic generation of state machines (e.g. [[Moore machine]]s) from high-level specifications (e.g. formulas in [[linear temporal logic]]). "Reactivity" highlights the fact that the synthesized machine interacts with the user, reading an input and producing an output, and never stops its operation.

The synthesis problem was introduced by [[Alonzo Church]] in 1962,&lt;ref&gt;{{cite news| first=Alonzo | last=Church | author-link=Alonzo Church | title=Logic, arithmetic, and automata | journal=[[International Congress of Mathematicians]] | date=1962 | pages=23–35 }}&lt;/ref&gt; with specifications being formulas in [[monadic second-order logic]] and state machines in the form of digital circuits.

== See also ==
* [[Program synthesis]]
* [[Model checking]]

== References ==
{{reflist}}

[[Category:Computer science]]
[[Category:Logic]]</text>
      <sha1>ce51vqm9ruiq8tarjqo1rip04nxgg23</sha1>
    </revision>
  </page>
  <page>
    <title>Computer science</title>
    <ns>0</ns>
    <id>5323</id>
    <revision>
      <id>1013943356</id>
      <parentid>1013942990</parentid>
      <timestamp>2021-03-24T09:20:55Z</timestamp>
      <contributor>
        <username>CommanderWaterford</username>
        <id>39203244</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/58.71.215.193|58.71.215.193]] ([[User talk:58.71.215.193|talk]]) ([[WP:HG|HG]]) (3.4.10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="64134" xml:space="preserve">{{pp-move-indef}}
{{Redirect|Computer sciences|the American corporation|Computer Sciences Corporation}}
{{short description|Study of the foundations and applications of computation}}
{{Use mdy dates|date=October 2017}}
&lt;div class="thumb tright"&gt;
&lt;div class="thumbinner" style="width:300px;"&gt;
{| style="border:1px solid #ccc;"
|-
| [[File:Lambda_calculus-Church_numerals.png|144px|alt=Expression for Church numerals in lambda calculus|Programming language theory|link=Programming language theory]]
| [[File:Sorting quicksort anim.gif|144px|alt=Plot of a quicksort algorithm|Computational complexity theory|link=Computational complexity theory]]
|-
| [[File:Activemarker2.PNG|144px|alt=Example of Computer animation produced using Motion capture|Artificial intelligence|link=Artificial intelligence]]
| [[File:Half Adder.svg|144px|alt=Half-adder circuit|Computer architecture|link=Computer architecture]]
|}
&lt;div class="thumbcaption"&gt;Computer science deals with the theoretical foundations of information, algorithms and the architectures of its computation as well as practical techniques for their application.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
{{TopicTOC-Computer science}}

'''Computer science''' is the study of [[Algorithm|algorithmic processes]], [[Automata theory|computational machines]] and computation itself.&lt;ref&gt;{{Cite web|title=What is Computer Science? - Computer Science.The University of York|url=https://www.cs.york.ac.uk/undergraduate/what-is-cs/|access-date=2020-06-11|website=www.cs.york.ac.uk}}&lt;/ref&gt; As a discipline, computer science spans a range of topics from theoretical studies of [[algorithm]]s, [[Theory of computation|computation]] and [[Information theory|information]] to the practical issues of implementing computational systems in [[Computer architecture|hardware]] and [[Computer programming|software]].&lt;ref&gt;{{cite web |url=http://wordnetweb.princeton.edu/perl/webwn?s=computer%20scientist |title=WordNet Search—3.1 |publisher=Wordnetweb.princeton.edu |access-date=14 May 2012}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=Definition of computer science {{!}} Dictionary.com|url=https://www.dictionary.com/browse/computer-science|access-date=2020-06-11|website=www.dictionary.com|language=en}}&lt;/ref&gt;

Its fields can be divided into theoretical and [[practical disciplines]]. For example, the [[theory of computation]] concerns abstract [[models of computation]] and general classes of [[computational problem|problems]] that can be solved using them, while [[Computer graphics (computer science)|computer graphics]] or [[computational geometry]] emphasize more specific applications. [[Algorithm]]s and [[data structures]] have been called the heart of computer science.&lt;ref&gt;{{Cite book|last=Harel, David.|url=http://worldcat.org/oclc/876384882|title=Algorithmics The Spirit of Computing|date=2014|publisher=Springer Berlin|isbn=978-3-642-44135-6|oclc=876384882}}&lt;/ref&gt; [[Programming language theory]] considers approaches to the description of computational processes, while [[computer programming]] involves the use of them to create [[complex system]]s. [[Computer architecture]] describes construction of computer components and computer-operated equipment. [[Artificial intelligence]] aims to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, [[Automated planning and scheduling|planning]] and [[Computational learning theory|learning]] found in humans and animals. A digital computer is capable of simulating various [[information processing|information processes]].&lt;ref&gt;{{Cite web|last=|first=|date=2006-05-25|title=COMPUTER SCIENCE: THE DISCIPLINE|url=http://www.idi.ntnu.no/emner/dif8916/denning.pdf|url-status=live|archive-url=https://web.archive.org/web/20060525195404/http://www.idi.ntnu.no/emner/dif8916/denning.pdf|archive-date=May 25, 2006|access-date=2021-01-04}}&lt;/ref&gt; The fundamental concern of computer science is determining what can and cannot be automated.&lt;ref&gt;{{Cite web|last=The MIT Press|title=What Can Be Automated? Computer Science and Engineering Research Study {{!}} The MIT Press|url=https://mitpress.mit.edu/books/what-can-be-automated|url-status=live|archive-url=|archive-date=|access-date=|website=mitpress.mit.edu|language=en}}&lt;/ref&gt; Computer scientists usually focus on academic research. The [[Turing Award]] is generally recognized as the highest distinction in computer sciences.
{{TOClimit|4}}

==History==
{{main|History of computer science}}
{{History of computing}}
[[File:Babbage40.png|upright|thumb|[[Charles Babbage]], sometimes referred to as the "father of computing".&lt;ref&gt;{{cite web|url=http://www.cbi.umn.edu/about/babbage.html|title=Charles Babbage Institute: Who Was Charles Babbage?|website=cbi.umn.edu|access-date=28 December 2016}}&lt;/ref&gt; ]]
[[File:Ada lovelace.jpg|upright|thumb|[[Ada Lovelace]] published the first [[algorithm]] intended for processing on a computer.&lt;ref&gt;{{cite web|url=http://www.computerhistory.org/babbage/adalovelace/|title=Ada Lovelace {{!}} Babbage Engine {{!}} Computer History Museum|website=www.computerhistory.org|access-date=28 December 2016}}&lt;/ref&gt; ]]

The earliest foundations of what would become computer science predate the invention of the modern [[digital computer]]. Machines for calculating fixed numerical tasks such as the [[abacus]] have existed since antiquity, aiding in computations such as multiplication and division. [[Algorithm]]s for performing computations have existed since antiquity, even before the development of sophisticated computing equipment. 

[[Wilhelm Schickard]] designed and constructed the first working [[mechanical calculator]] in 1623.&lt;ref&gt;{{cite web|title=Wilhelm Schickard – Ein Computerpionier|url=http://www.fmi.uni-jena.de/fmimedia/Fakultaet/Institute+und+Abteilungen/Abteilung+f%C3%BCr+Didaktik/GDI/Wilhelm+Schickard.pdf|language = de}}&lt;/ref&gt; In 1673, [[Gottfried Leibniz]] demonstrated a digital mechanical calculator, called the [[Stepped Reckoner]].&lt;ref&gt;{{cite web|title=A Brief History of Computing|url=http://blogs.royalsociety.org/history-of-science/2012/06/25/history-of-computing/|first = Fiona|last = Keates|work = The Repository|publisher = The Royal Society|date = 25 June 2012}}&lt;/ref&gt; Leibniz may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. In 1820, [[Charles Xavier Thomas|Thomas de Colmar]] launched the [[mechanical calculator]] industry&lt;ref group=note&gt;In 1851&lt;/ref&gt; when he invented his simplified [[arithmometer]], the first calculating machine strong enough and reliable enough to be used daily in an office environment. [[Charles Babbage]] started the design of the first ''automatic mechanical calculator'', his [[Difference Engine]], in 1822, which eventually gave him the idea of the first ''programmable mechanical calculator'', his [[Analytical Engine]].&lt;ref&gt;{{cite web|title=Science Museum, Babbage's Analytical Engine, 1834-1871 (Trial model)|url=https://collection.sciencemuseumgroup.org.uk/objects/co62245/babbages-analytical-engine-1834-1871-trial-model-analytical-engines|access-date=2020-05-11}}&lt;/ref&gt; He started developing this machine in 1834, and "in less than two years, he had sketched out many of the [[wikt:Special:Search/salient|salient]] features of the modern computer".&lt;ref name="Hyman1982"&gt;{{cite book |author=Anthony Hyman |title=Charles Babbage, pioneer of the computer |url=https://archive.org/details/charlesbabbagepi0000hyma |url-access=registration |year=1982}}&lt;/ref&gt; "A crucial step was the adoption of a punched card system derived from the [[Jacquard loom]]"&lt;ref name="Hyman1982" /&gt; making it infinitely programmable.&lt;ref group=note&gt;"The introduction of punched cards into the new engine was important not only as a more convenient form of control than the drums, or because programs could now be of unlimited extent, and could be stored and repeated without the danger of introducing errors in setting the machine by hand; it was important also because it served to crystallize Babbage's feeling that he had invented something really new, something much more than a sophisticated calculating machine." [[#COLLIER|Bruce Collier]], 1970&lt;/ref&gt; In 1843, during the translation of a French article on the Analytical Engine, [[Ada Lovelace]] wrote, in one of the many notes she included, an algorithm to compute the [[Bernoulli number]]s, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer.&lt;ref&gt;{{cite web|url=http://www.scottlan.edu/Lriddle/women/ada-love.htm |title=A Selection and Adaptation From Ada's Notes found in Ada, The Enchantress of Numbers," by Betty Alexandra Toole Ed.D. Strawberry Press, Mill Valley, CA |access-date=4 May 2006 |url-status=dead |archive-url=https://web.archive.org/web/20060210172109/http://www.scottlan.edu/lriddle/women/ada-love.htm |archive-date=February 10, 2006 }}&lt;/ref&gt; Around 1885, [[Herman Hollerith]] invented the [[tabulating machine|tabulator]], which used [[punched card]]s to process statistical information; eventually his company became part of [[IBM]]. Following Babbage, although unaware of his earlier work, [[Percy Ludgate]] in 1909 published &lt;ref&gt;{{Cite web |url=https://scss.tcd.ie/SCSSTreasuresCatalog/miscellany/TCD-SCSS-X.20121208.002/TCD-SCSS-X.20121208.002.pdf/ |title=The John Gabriel Byrne Computer Science Collection |access-date=August 8, 2019 |archive-url=https://web.archive.org/web/20190416071721/https://www.scss.tcd.ie/SCSSTreasuresCatalog/miscellany/TCD-SCSS-X.20121208.002/TCD-SCSS-X.20121208.002.pdf |archive-date=April 16, 2019 |url-status=dead }}&lt;/ref&gt; the 2nd of the only two designs for mechanical analytical engines in history. In 1937, one hundred years after Babbage's impossible dream, [[Howard H. Aiken|Howard Aiken]] convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business&lt;ref&gt;"In this sense Aiken needed IBM, whose technology included the use of punched cards, the accumulation of numerical data, and the transfer of numerical data from one register to another", [[#AIKEN|Bernard Cohen]], p.44 (2000)&lt;/ref&gt; to develop his giant programmable calculator, the [[Harvard Mark I|ASCC/Harvard Mark I]], based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as "Babbage's dream come true".&lt;ref&gt;[[#ORIGINS|Brian Randell]], p. 187, 1975&lt;/ref&gt;

During the 1940s, with the development of new and more powerful [[computing]] machines such as the [[Atanasoff–Berry computer]] and [[ENIAC]], the term ''computer'' came to refer to the machines rather than their human predecessors.&lt;ref&gt;The [[Association for Computing Machinery]] (ACM) was founded in 1947.&lt;/ref&gt; As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study [[computation]] in general. In 1945, [[IBM]] founded the Watson Scientific Computing Laboratory at [[Columbia University]] in [[New York City]]. The renovated fraternity house on Manhattan's West Side was IBM's first laboratory devoted to pure science. The lab is the forerunner of IBM's Research Division, which today operates research facilities around the world.&lt;ref&gt;{{cite web|url=https://www.ibm.com/ibm/history/history/year_1945.html |title=IBM Archives: 1945 |publisher=Ibm.com |access-date=2019-03-19}}&lt;/ref&gt; Ultimately, the close relationship between IBM and the university was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946.&lt;ref&gt;{{cite web|url=https://www.ibm.com/ibm/history/ibm100/us/en/icons/compsci/ |title=IBM100 – The Origins of Computer Science |publisher=Ibm.com |date=1995-09-15 |access-date=2019-03-19}}&lt;/ref&gt; Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s.&lt;ref name="Denning_cs_discipline"/&gt;&lt;ref&gt;{{cite web |url=http://www.cl.cam.ac.uk/conference/EDSAC99/statistics.html |title=Some EDSAC statistics |publisher=University of Cambridge |access-date=19 November 2011}}&lt;/ref&gt; The world's first computer science degree program, the [[Cambridge Diploma in Computer Science]], began at the [[University of Cambridge]] [[Cambridge Computer Lab|Computer Laboratory]] in 1953. The first computer science department in the United States was formed at [[Purdue University]] in 1962.&lt;ref&gt;{{cite web |url=http://www.cs.purdue.edu/about/conte.html |title=Computer science pioneer Samuel D. Conte dies at 85 |date=July 1, 2002 |publisher=Purdue Computer Science |access-date=December 12, 2014}}&lt;/ref&gt; Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.{{see also|History of computing|History of informatics}}

==Etymology==
{{see also|Informatics#Etymology}}

Although first proposed in 1956,&lt;ref name="Tedre2014"&gt;{{cite book|last=Tedre|first=Matti|title=The Science of Computing: Shaping a Discipline|publisher=Taylor and Francis / CRC Press|year=2014}}&lt;/ref&gt; the term "computer science" appears in a 1959 article in ''[[Communications of the ACM]]'',&lt;ref name="Fine_1959"&gt;
{{cite journal
 |author=Louis Fine
 |year=1959
 |title=The Role of the University in Computers, Data Processing, and Related Fields
 |journal=Communications of the ACM
 |volume=2 |issue=9 |pages=7–14
 |doi=10.1145/368424.368427
|s2cid=6740821
 }}&lt;/ref&gt;
in which Louis Fein argues for the creation of a ''Graduate School in Computer Sciences'' analogous to the creation of [[Harvard Business School]] in 1921,&lt;ref&gt;{{cite web|title=Stanford University Oral History|url=http://library.stanford.edu/guides/stanford-university-oral-history|publisher=Stanford University|access-date=May 30, 2013}}&lt;/ref&gt; justifying the name by arguing that, like [[management science]], the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.&lt;ref name="Fine_1959"/&gt;
His efforts, and those of others such as [[numerical analysis|numerical analyst]] [[George Forsythe]], were rewarded: universities went on to create such departments, starting with Purdue in 1962.&lt;ref&gt;[[Donald Knuth]] (1972). ''[http://www.stanford.edu/dept/ICME/docs/history/forsythe_knuth.pdf "George Forsythe and the Development of Computer Science"]''. ''Comms. ACM''. {{webarchive |url=https://web.archive.org/web/20131020200802/http://www.stanford.edu/dept/ICME/docs/history/forsythe_knuth.pdf |date=October 20, 2013 }}&lt;/ref&gt; Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed.&lt;ref&gt;{{cite web |author=Matti Tedre |year=2006 |url=http://epublications.uef.fi/pub/urn_isbn_952-458-867-6/urn_isbn_952-458-867-6.pdf |title=The Development of Computer Science: A Sociocultural Perspective |page=260 |access-date=December 12, 2014}}&lt;/ref&gt; Certain departments of major universities prefer the term ''computing science'', to emphasize precisely that difference. Danish scientist [[Peter Naur]] suggested the term ''datalogy'',&lt;ref&gt;
{{cite journal
 |author=Peter Naur
 |year=1966
 |title=The science of datalogy
 |journal=Communications of the ACM
 |volume=9 |issue=7 |page=485
 |doi=10.1145/365719.366510
|s2cid=47558402
 }}&lt;/ref&gt; to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is [[data science]]; this is now used for a [[multi-disciplinary]] field of data analysis, including statistics and databases.

In the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the ''Communications of the ACM''—''turingineer'', ''turologist'', ''flow-charts-man'', ''applied meta-mathematician'', and ''applied [[epistemology|epistemologist]]''.&lt;ref&gt;{{cite journal |date=&lt;!-- missing! --&gt; |volume=1 |issue=4 |page=6| doi = 10.1145/368796.368802|last1=Weiss |first1=E.A. |title=Letters to the editor |journal= Communications of the ACM |last2=Corley |first2=Henry P.T. |s2cid=5379449 }}&lt;/ref&gt; Three months later in the same journal, ''comptologist'' was suggested, followed next year by ''hypologist''.&lt;ref&gt;Communications of the ACM 2(1):p.4&lt;/ref&gt; The term ''computics'' has also been suggested.&lt;ref&gt;IEEE Computer 28(12): p.136&lt;/ref&gt; {{anchor|Name of the field in Europe}}In Europe, terms derived from contracted translations of the expression "automatic information" (e.g. "informazione automatica" in Italian) or "information and mathematics" are often used, e.g. ''informatique'' (French), ''Informatik'' (German), ''informatica'' (Italian, Dutch), ''informática'' (Spanish, Portuguese), ''informatika'' ([[Slavic languages]] and [[Hungarian language|Hungarian]]) or ''pliroforiki'' (''πληροφορική'', which means informatics) in [[Greek language|Greek]]. Similar words have also been adopted in the UK (as in ''the School of Informatics of the University of Edinburgh'').&lt;ref&gt;P. Mounier-Kuhn, ''L'Informatique en France, de la seconde guerre mondiale au Plan Calcul. L'émergence d'une science'', Paris, PUPS, 2010, ch. 3 &amp; 4.&lt;/ref&gt;  "In the U.S., however, [[informatics]] is linked with applied computing, or computing in the context of another domain."&lt;ref&gt;{{cite web|last=Groth |first=Dennis P. |url=http://cacm.acm.org/magazines/2010/2/69363-why-an-informatics-degree |title=Why an Informatics Degree? |date = February 2010|work= Communications of the ACM |publisher=Cacm.acm.org}}&lt;/ref&gt;

A folkloric quotation, often attributed to—but almost certainly not first formulated by—[[Edsger W. Dijkstra|Edsger Dijkstra]], states that "computer science is no more about computers than astronomy is about telescopes."&lt;ref group=note&gt;See the entry
"[[q:Computer science|Computer science]]" on Wikiquote for the history of this quotation.&lt;/ref&gt; The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of [[computer engineering]], while the study of commercial [[computer system]]s and their deployment is often called information technology or [[information system]]s. However, there has been much cross-fertilization of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as philosophy, [[cognitive science]], [[computational linguistics|linguistics]], [[mathematics]], [[physics]], [[biology]], [[Earth science]], [[computational statistics|statistics]], and [[logic]].

Computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science.&lt;ref name="Denning_cs_discipline" /&gt; Early computer science was strongly influenced by the work of mathematicians such as [[Kurt Gödel]], [[Alan Turing]], [[John von Neumann]], [[Rózsa Péter]] and [[Alonzo Church]] and there continues to be a useful interchange of ideas between the two fields in areas such as [[mathematical logic]], [[category theory]], [[domain theory]], and [[algebra]].&lt;ref name="Tedre2014"/&gt;

The relationship between Computer Science and Software Engineering is a contentious issue, which is further muddied by [[Software engineer#Use of the title "Engineer"|disputes]] over what the term "Software Engineering" means, and how computer science is defined.&lt;ref&gt;{{Cite journal | last1 = Tedre | first1 = M. | title = Computing as a Science: A Survey of Competing Viewpoints | doi = 10.1007/s11023-011-9240-4 | journal = Minds and Machines | volume = 21 | issue = 3 | pages = 361–387 | year = 2011 | s2cid = 14263916 }}&lt;/ref&gt; [[David Parnas]], taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.&lt;ref&gt;{{Cite journal | last1 = Parnas | first1 = D.L. | journal = Annals of Software Engineering | volume = 6 | pages = 19–37 | year = 1998 | doi = 10.1023/A:1018949113292|title=Software engineering programmes are not computer science programmes| s2cid = 35786237 }}, p. 19: "Rather than treat software engineering as a subfield of computer science, I treat it as an element of the set, Civil Engineering, Mechanical Engineering, Chemical Engineering, Electrical Engineering, […]"&lt;/ref&gt;

The academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with [[computational science]]. Both types of departments tend to make efforts to bridge the field educationally if not across all research.

==Philosophy==
{{main|Philosophy of computer science}}
A number of computer scientists have argued for the distinction of three separate paradigms in computer science. [[Peter Wegner]] argued that those paradigms are science, technology, and mathematics.&lt;ref&gt;{{cite conference |author=Wegner, P. |title=Research paradigms in computer science—Proceedings of the 2nd international Conference on Software Engineering |location=San Francisco, California, United States |date=October 13–15, 1976 |publisher=IEEE Computer Society Press, Los Alamitos, CA}}&lt;/ref&gt; [[Peter J. Denning|Peter Denning]]'s working group argued that they are theory, abstraction (modeling), and design.&lt;ref&gt;{{Cite journal | last1 = Denning | first1 = P.J. | last2 = Comer | first2 = D.E. | last3 = Gries | first3 = D. | last4 = Mulder | first4 = M.C. | last5 = Tucker | first5 = A. | last6 = Turner | first6 = A.J. | last7 = Young | first7 = P.R. | title = Computing as a discipline | journal = Communications of the ACM | volume = 32 | pages = 9–23 | date = January 1989 | doi = 10.1145/63238.63239| s2cid = 723103 }}&lt;/ref&gt; Amnon H. Eden described them as the "rationalist paradigm" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs [[deductive reasoning]]), the "technocratic paradigm" (which might be found in engineering approaches, most prominently in software engineering), and the "scientific paradigm" (which approaches computer-related artifacts from the empirical perspective of [[natural science]]s, identifiable in some branches of [[artificial intelligence]]).&lt;ref&gt;{{Cite journal | first1 = A.H. | title = Three Paradigms of Computer Science | journal = [[Minds and Machines]] | last1 = Eden | volume = 17 | issue = 2 | year = 2007 | url = http://www.eden-study.org/articles/2007/three_paradigms_of_computer_science.pdf | doi = 10.1007/s11023-007-9060-8 | pages = 135–167 | url-status=dead | archive-url = https://web.archive.org/web/20160215100211/http://www.eden-study.org/articles/2007/three_paradigms_of_computer_science.pdf | archive-date = February 15, 2016 | df = mdy-all | citeseerx = 10.1.1.304.7763 | s2cid = 3023076 }}&lt;/ref&gt;
Computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.&lt;ref&gt;{{cite encyclopedia |last1=Turner |first1=Raymond |last2=Angius |first2=Nicola |editor1-last=Zalta |editor1-first=Edward N. |title=The Philosophy of Computer Science |encyclopedia=The Stanford Encyclopedia of Philosophy |date=2019 |url=https://plato.stanford.edu/archives/spr2019/entries/computer-science/}}&lt;/ref&gt;

==Fields==
{{Quote
|text=Computer science is no more about computers than astronomy is about telescopes.
|author=[[Edsger Dijkstra]]
}}
{{further|Outline of computer science}}
As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.&lt;ref name="CSAB1997"&gt;{{cite web|publisher=Computing Sciences Accreditation Board|title=Computer Science as a Profession|url=http://www.csab.org/comp_sci_profession.html |date=May 28, 1997| access-date=23 May 2010 |archive-url = https://web.archive.org/web/20080617030847/http://www.csab.org/comp_sci_profession.html |archive-date = June 17, 2008}}&lt;/ref&gt;&lt;ref&gt;{{cite book |author=Committee on the Fundamentals of Computer Science: Challenges and Opportunities, National Research Council |title=Computer Science: Reflections on the Field, Reflections from the Field|url=http://www.nap.edu/catalog.php?record_id=11106#toc|publisher=National Academies Press|isbn=978-0-309-09301-9|year=2004}}&lt;/ref&gt;
[[CSAB (professional organization)|CSAB]], formerly called Computing Sciences Accreditation Board—which is made up of representatives of the [[Association for Computing Machinery]] (ACM), and the [[IEEE Computer Society]] (IEEE CS)&lt;ref&gt;{{cite web |url=http://www.csab.org/ |title=CSAB Leading Computer Education |publisher=CSAB |date=August 3, 2011 |access-date=19 November 2011}}&lt;/ref&gt;—identifies four areas that it considers crucial to the discipline of computer science: ''theory of computation'', ''algorithms and data structures'', ''programming methodology and languages'', and ''computer elements and architecture''. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and [[symbolic computation]] as being important areas of computer science.&lt;ref name="CSAB1997"/&gt;

===Theoretical computer science===
{{main|Theoretical computer science}}
''Theoretical Computer Science'' is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. Its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.

====Theory of computation====

{{main|Theory of computation}}

According to [[Peter J. Denning|Peter Denning]], the fundamental question underlying computer science is, "What can be automated?"&lt;ref name="Denning_cs_discipline"&gt;{{cite journal | last=Denning | first=Peter J. | author-link=Peter J. Denning | year=2000 | title=Computer Science: The Discipline | url=http://www.idi.ntnu.no/emner/dif8916/denning.pdf | journal=Encyclopedia of Computer Science |archive-url = https://web.archive.org/web/20060525195404/http://www.idi.ntnu.no/emner/dif8916/denning.pdf |archive-date = May 25, 2006}}&lt;/ref&gt; Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, [[computability theory]] examines which computational problems are solvable on various theoretical [[models of computation]]. The second question is addressed by [[computational complexity theory]], which studies the time and space costs associated with different approaches to solving a multitude of computational problems.

The famous [[P versus NP problem|P = NP?]] problem, one of the [[Millennium Prize Problems]],&lt;ref&gt;[http://www.claymath.org/millennium/P_vs_NP/ Clay Mathematics Institute] P = NP {{webarchive |url=https://web.archive.org/web/20131014194456/http://www.claymath.org/millennium/P_vs_NP/ |date=October 14, 2013 }}&lt;/ref&gt; is an open problem in the theory of computation.

{| style="border:1px solid #ccc; text-align:center; margin:auto;" cellspacing="15"
|-
| [[File:DFAexample.svg|130px]]
| [[File:Syntax_tree.svg|96px]]
| &lt;math&gt;M= \{ X : X \not\in X \}&lt;/math&gt;
| [[File:Complexity classes.svg|120px]]
|-
| [[Automata theory]]
| [[Formal language]]s
| [[Computability theory]]
| [[Computational complexity theory]]
|-
| [[File:Interaction_Net_as_Configuration.png|96px]]
| [[File:Blochsphere.svg|96px]]
| [[File:XNOR ANSI Labelled.svg]]
| [[File:Kellerautomat.svg|96px]]
|-
| [[Models of computation]]
| [[Quantum computer|Quantum computing theory]]
| [[Circuit_(computer_science)|Logic circuit theory]]
| [[Cellular automata]]
|}

====Information and coding theory====

{{main|Information theory|Coding theory}}

Information theory, closely related to [[probability]] and [[statistics]], is related to the quantification of information. This was developed by [[Claude Shannon]] to find fundamental limits on [[signal processing]] operations such as compressing data and on reliably storing and communicating data.&lt;ref&gt;{{cite web |date=October 14, 2002 |last=P. Collins |first=Graham |title=Claude E. Shannon: Founder of Information Theory |url=http://www.scientificamerican.com/article.cfm?id=claude-e-shannon-founder |work=Scientific American |access-date=December 12, 2014}}&lt;/ref&gt;
Coding theory is the study of the properties of [[code]]s (systems for converting information from one form to another) and their fitness for a specific application. Codes are used for [[data compression]], [[cryptography]], [[error detection and correction]], and more recently also for [[Linear network coding|network coding]]. Codes are studied for the purpose of designing efficient and reliable [[data transmission]] methods.
&lt;ref&gt;Van-Nam Huynh; Vladik Kreinovich; Songsak Sriboonchitta; 2012. Uncertainty Analysis in Econometrics with Applications. Springer Science &amp; Business Media. p. 63. {{ISBN|978-3-642-35443-4}}.&lt;/ref&gt;

{| style="border:1px solid #ccc; text-align:center; margin:auto;" cellspacing="15"
|-
| [[File:Hamming.jpg|96px]]
| [[File:Binary symmetric channel.svg|96px]]
| [[File:Digitalteilchen.svg|96px]]
| [[File:H0 h1 fehler.jpg|96px]]
| [[File:Mandelpart2_red.png|96px]]
|-
| [[Coding theory]]
| [[Channel capacity]]
| [[Algorithmic information theory]]
| [[Signal detection theory]]
| [[Kolmogorov complexity]]
|}

====Data structures and algorithms====

{{main|Data structure|Algorithm}}Data structures and algorithms are the studies of commonly used computational methods and their computational efficiency.

{| style="border:1px solid #ccc; text-align:center; margin:auto;" cellspacing="15"
|-
| {{math|''O''(''n''&lt;sup&gt;2&lt;/sup&gt;)}}
| [[File:Sorting quicksort anim.gif|96px]]
| [[File:Tree_(computer_science).svg|96px]]
| [[File:TSP Deutschland 3.png|96px]]
| [[File:SimplexRangeSearching.svg|96px]]
| [[File:Contraction_vertices.jpg|96px]]
|-
| [[Analysis of algorithms]]
| [[Algorithmics|Algorithm design]]
| [[Data structures]]
| [[Combinatorial optimization]]
| [[Computational geometry]]
| [[Randomized algorithms]]
|}

====Programming language theory and formal methods====
{{main|Programming language theory|Formal methods}}
Programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of [[programming language]]s and their individual [[Programming language#Elements|features]]. It falls within the discipline of computer science, both depending on and affecting [[mathematics]], software engineering, and [[linguistics]]. It is an active research area, with numerous dedicated academic journals.

Formal methods are a particular kind of [[Mathematics|mathematically]] based technique for the [[formal specification|specification]], development and [[formal verification|verification]] of software and [[computer hardware|hardware]] systems.&lt;ref&gt;Phillip A. Laplante, 2010. Encyclopedia of Software Engineering Three-Volume Set (Print). CRC Press. p. 309. {{ISBN|978-1-351-24926-3}}.&lt;/ref&gt; The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and [[life-critical system]]s, where safety or [[computer security|security]] is of utmost importance. Formal methods are best described as the application of a fairly broad variety of [[theoretical computer science]] fundamentals, in particular [[logic in computer science|logic]] calculi, [[formal language]]s, [[automata theory]], and [[program semantics]], but also [[type systems]] and [[algebraic data types]] to problems in software and hardware specification and verification.

{| style="border:1px solid #ccc; text-align:center; margin:auto;" cellspacing="15"
|-
| [[File:IF-THEN-ELSE-END_flowchart.svg|96px]]
| &lt;math&gt;\Gamma\vdash x: \text{Int}&lt;/math&gt;
| [[File:Compiler.svg|96px]]
| [[File:Python add5 syntax.svg|96px]]
| [[File:Prop-tableau-1.svg|96px]]
| [[File:Coq plus comm screenshot.jpg|96px]]
|-
| [[Semantics (computer science)|Formal semantics]]
| [[Type theory]]
| [[Compiler construction|Compiler design]]
| [[Programming language]]s
| [[Formal verification]]
| [[Automated theorem proving]]
|}

===Computer systems and computational processes===

====Artificial intelligence====
{{main|Artificial intelligence|Bio-inspired computing}}
Artificial intelligence (AI) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. From its origins in [[cybernetics]] and in the [[History of artificial intelligence|Dartmouth Conference]] (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as [[applied mathematics]], [[Mathematical logic|symbolic logic]], [[semiotics]], [[electrical engineering]], [[philosophy of mind]], [[neurophysiology]], and [[social intelligence]]. AI is associated in the popular mind with [[Robotics|robotic development]], but the main field of practical application has been as an embedded component in areas of [[software development]], which require computational understanding. The starting point in the late 1940s was [[Alan Turing]]'s question "Can computers think?", and the question remains effectively unanswered, although the [[Turing test]] is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.

{| style="border:1px solid #ccc; text-align:center; margin:auto;" cellspacing="15"
|-
| [[File:Nicolas P. Rougier's rendering of the human brain.png|96px]]
| [[File:Human eye, rendered from Eye.png|96px]]
| [[File:Colored_neural_network.svg|96px]]
| [[File:Markov_Decision_Process.svg|96px]]
|-
| [[Computational learning theory]]
| [[Computer vision]]
| [[Artificial neural network|Neural networks]]
| [[Automated planning and scheduling|Planning and scheduling]]
|-
| [[File:english.png|96px]]
| [[File:Knight's_tour.svg|96px]]
| [[File:Ackley.gif|96px]]
| [[File:AutonomicSystemModel.png|96px]]
|-
| [[Natural language processing]]
| [[Algorithmic game theory|Computational game theory]]
| [[Evolutionary computation]]
| [[Autonomic computing]]
|-
| [[File:neuron.svg|96px]]
| [[File:KnnClassification.svg|96px]]
| [[File:ROS_C_logo.jpg|100px]]
| [[File:Rule_alignment.gif|96px]]
|-
| [[Knowledge representation and reasoning|Representation and reasoning]]
| [[Pattern recognition]]
| [[Robotics]]
| [[Swarm intelligence]]
|}

====Computer architecture and organization====
{{main|Computer architecture|Computer organisation|Computer engineering}}
Computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory.&lt;ref&gt;{{cite web|last=A. Thisted|first=Ronald|title=Computer Architecture |url=http://galton.uchicago.edu/~thisted/Distribute/comparch.pdf|publisher=The University of Chicago|date=April 7, 1997}}&lt;/ref&gt; Computer engineers study [[computational logic]] and design of [[computer hardware]], from individual [[Processor (computing)|processor]] components, [[microcontroller]]s, [[personal computer]]s to [[supercomputer]]s and [[embedded system]]s. The term “architecture” in computer literature can be traced to the work of Lyle R. Johnson and [[Fred Brooks|Frederick P. Brooks, Jr.]], members of the Machine Organization department in IBM's main research center in 1959.

{| style="border:1px solid #ccc; text-align:center; margin:auto;" cellspacing="15"
|-
| [[File:ABasicComputer.gif|96px]]
| [[File:Intel_Core2_arch.svg|96px]]
| [[File:SIMD.svg|96px]]
| [[File:Z80_arch.svg|96px]]
|-
| [[Processor (computing)|Processing unit]]
| [[Microarchitecture]]
| [[Multiprocessing]]
| [[Processor design]]
|-
| [[File:Roomba original.jpg|96px]]
| [[File:flowchart.png|96px]]
| [[File:Kernel_Layout.svg|96px]]
| [[File:Uarm_metal_wiki2.jpg|96px]]
|-
| [[Ubiquitous computing]]
| [[Systems architecture]]
| [[Operating system]]s
| [[Input/output]]
|-
| [[File:Physical_computing.svg|96px]]
| [[File:FIR_Filter_General.svg|96px]]
| [[File:Dep-1.svg|96px]]
| [[File:Linker.svg|96px]]
|-
| [[Embedded system]]
| [[Real-time computing]]
| [[Dependability]]
| [[Interpreter (computing)|Interpreter]]
|}

====Concurrent, parallel and distributed computing====
{{main|Concurrency (computer science)|Distributed computing}}
Concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other.&lt;ref&gt;Jiacun Wang, 2017. Real-Time Embedded Systems. Wiley. p. 12. {{ISBN|978-1-119-42070-5}}.&lt;/ref&gt; A number of mathematical models have been developed for general concurrent computation including [[Petri net]]s, [[Process calculus|process calculi]] and the [[Parallel random-access machine|Parallel Random Access Machine]] model.&lt;ref&gt;Gordana Dodig-Crnkovic; Raffaela Giovagnoli; 2013. Computing Nature: Turing Centenary Perspective. Springer Science &amp; Business Media. p. 247. {{ISBN|978-3-642-37225-4}}.&lt;/ref&gt; When multiple computers are connected in a network while using concurrency, this is known as a distributed system. Computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.&lt;ref&gt;Simon Elias Bibri; 2018. Smart Sustainable Cities of the Future: The Untapped Potential of Big Data Analytics and Context-Aware Computing for Advancing Sustainability. Springer. p. 74. {{ISBN|978-3-319-73981-6}}.&lt;/ref&gt;

====Computer networks====
{{main|Computer network}}
This branch of computer science aims to manage networks between computers worldwide.

====Computer security and cryptography====
{{main|Computer security|Cryptography}}
Computer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users. [[Cryptography]] is the practice and study of hiding (encryption) and therefore deciphering (decryption) information. Modern cryptography is largely related to computer science, for many encryption and decryption algorithms are based on their computational complexity.

====Databases and data mining====
{{main|Database|Data mining}}
A database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through [[database model]]s and [[query language]]s. Data mining is a process of discovering patterns in large data sets.

====Computer graphics and visualization====
{{main|Computer graphics (computer science)}}
Computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. The study is connected to many other fields in computer science, including [[computer vision]], [[image processing]], and [[computational geometry]], and is heavily applied in the fields of special effects and [[video game]]s.
{| style="border:1px solid #ccc; text-align:center; margin:auto;" cellspacing="15"
|-
| [[File:Simx2=transl_OK.svg|96px]]
| [[File:FWDvsINV_Kinematics_HighResTransp.png|96px]]
| [[File:5-cell.gif|96px]]
| [[File:Hud_on_the_cat.jpg|96px]]
| [[File:Visible_light_eye-tracking_algorithm.jpg|96px]]
| [[File:Csg_tree.png|96px]]
|-
| [[2D computer graphics]]
| [[Computer animation]]
| [[Rendering (computer graphics)|Rendering]]
| [[Mixed reality]]
| [[Virtual reality]]
| [[Solid modeling]]
|}

====Image and sound processing====
{{main|Information processing}}
[[Information]] can take the form of images, sound, video or other multimedia. [[Bit]]s of information can be streamed via [[signal]]s. Its [[information processing|processing]] is the central notion of [[informatics]], the European view on [[computing]], which studies information processing algorithms independently of the type of information carrier - whether it is electrical, mechanical or biological. This field plays important role in [[information theory]], [[telecommunications]], [[information engineering (field)|information engineering]] and has applications in [[medical image computing]] and [[speech synthesis]], among others. ''What is the lower bound on the complexity of [[fast Fourier transform]] algorithms?'' is one of [[List of unsolved problems in computer science|unsolved problems in theoretical computer science]].
{| style="border:1px solid #ccc; text-align:center; margin:auto;" cellspacing="15"
|-
| [[File:DIT-FFT-butterfly.png|96px]]
| [[File:Bayer_pattern_on_sensor.svg|96px]]
| [[File:Opus_quality_comparison_colorblind_compatible.svg|96px]]
| [[File:Quality_comparison_jpg_vs_saveforweb.jpg|96px]]
| [[File:MeningiomaMRISegmentation.png|96px]]
| [[File:Ætoms_-_Translation.svg|96px]]
|-
| [[Fast Fourier transform|FFT algorithms]]
| [[Image processing]]
| [[Speech recognition]]
| [[Data compression]]
| [[Medical image computing]]
| [[Speech synthesis]]
|}

===Applied computer science===
====Computational science, finance and engineering====
{{main|Computational science|Computational finance|Computational engineering}}

[[Scientific computing]] (or [[computational science]]) is the field of study concerned with constructing [[scientific modelling|mathematical models]] and [[numerical analysis|quantitative analysis]] techniques and using computers to analyze and solve [[Science|scientific]] problems. A major usage of scientific computing is [[simulation]] of various processes, including computational [[fluid dynamics]], physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. Modern computers enable optimization of such designs as complete aircraft. Notable in electrical and electronic circuit design are SPICE,&lt;ref&gt;Muhammad H. Rashid, 2016. SPICE for Power Electronics and Electric Power. CRC Press. p. 6. {{ISBN|978-1-4398-6047-2}}.&lt;/ref&gt; as well as software for physical realization of new (or modified) designs. The latter includes essential design software for [[integrated circuit]]s.{{Citation needed|date=October 2010}}

{| style="border:1px solid #ccc; text-align:center; margin:auto;" cellspacing="15"
|-
| [[File:Lorenz attractor yb.svg|96px]]
| [[File:Quark wiki.jpg|96px]]
| [[File:Naphthalene-3D-balls.png|96px]]
| [[File:1u04-argonaute.png|96px]]
| [[File:GalvesLocherbach_-_Low_resolution.gif|96px]]
| [[File:Plutchik-wheel.svg|96px]]
| [[File:X-ray_of_hand,_where_bone_age_is_automatically_found_by_BoneXpert_software.jpg|75px]]
| [[File:Elmer-pump-heatequation.png|94px]]
| [[File:Bachlut1.png|75px]]
|-
| [[Numerical analysis]]
| [[Computational physics]]
| [[Computational chemistry]]
| [[Bioinformatics]]
| [[Neuroinformatics]]
| [[Psychoinformatics]]
| [[Medical informatics]]
| [[Computational engineering]]
| [[Computational musicology]]
|}

====Social computing and human-computer interaction====
{{main|Social computing|Human-computer interaction}}
Social computing is an area that is concerned with the intersection of social behavior and computational systems. Human-computer interaction research develops theories, principles, and guidelines for user interface designers.

====Software engineering====
{{main|Software engineering}}
{{see also|Computer programming}}
Software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it doesn't just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. For example [[software testing]], [[systems engineering]], [[technical debt]] and [[Software development process|software development processes]]. 

==Discoveries==
The philosopher of computing [[William J. Rapaport|Bill Rapaport]] noted three ''Great Insights of Computer Science'':&lt;ref&gt;{{cite web|url=http://www.cse.buffalo.edu/~rapaport/computation.html|title=What Is Computation?|publisher=State University of New York at Buffalo|last = Rapaport|first = William J.|date = 20 September 2013}}&lt;/ref&gt;
* [[Gottfried Wilhelm Leibniz]]'s, [[George Boole]]'s, [[Alan Turing]]'s, [[Claude Shannon]]'s, and [[Samuel Morse]]'s insight: there are only ''two objects'' that a computer has to deal with in order to represent "anything".{{refn |group="note"|The word "anything" is written in quotation marks because there are things that computers cannot do. One example is: to answer the question if an arbitrary given computer program will eventually finish or run forever (the [[Halting problem]]).}}
:: All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as "on/off", "magnetized/de-magnetized", "high-voltage/low-voltage", etc.).
{{see also|Digital physics}}
* [[Alan Turing]]'s insight: there are only ''five actions'' that a computer has to perform in order to do "anything".
:: Every algorithm can be expressed in a language for a computer consisting of only five basic instructions:&lt;ref&gt;B. Jack Copeland, 2012. Alan Turing's Electronic Brain: The Struggle to Build the ACE, the World's Fastest Computer. OUP Oxford. p. 107. {{ISBN|978-0-19-960915-4}}.&lt;/ref&gt;
::* move left one location;
::* move right one location;
::* read symbol at current location;
::* print 0 at current location;
::* print 1 at current location.
{{see also|Turing machine}}
* [[Corrado Böhm]] and [[Giuseppe Jacopini]]'s insight: there are only ''three ways of combining'' these actions (into more complex ones) that are needed in order for a computer to do "anything".&lt;ref&gt;Charles W. Herbert, 2010. An Introduction to Programming Using Alice 2.2. Cengage Learning. p. 122. {{ISBN|0-538-47866-7}}.&lt;/ref&gt;

:: Only three rules are needed to combine any set of basic instructions into more complex ones:
::*''sequence'': first do this, then do that;
::* '' selection'': IF such-and-such is the case, THEN do this, ELSE do that;
::* ''repetition'': WHILE such-and-such is the case, DO this.
:: Note that the three rules of Boehm's and Jacopini's insight can be further simplified with the use of [[goto]] (which means it is more elementary than [[structured programming]]).
{{see also|Structured program theorem}}

==Programming paradigms==
{{main|Programming paradigm}}

Programming languages can be used to accomplish different tasks in different ways. Common programming paradigms include:

* [[Functional programming]], a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.&lt;ref&gt;Md. Rezaul Karim; Sridhar Alla; 2017. Scala and Spark for Big Data Analytics: Explore the concepts of functional programming, data streaming, and machine learning. Packt Publishing Ltd. p. 87. {{ISBN|978-1-78355-050-0}}.&lt;/ref&gt;
* [[Imperative programming]], a programming paradigm that uses statements that change a program's state.&lt;ref&gt;Lex Sheehan, 2017. Learning Functional Programming in Go: Change the way you approach your applications using functional programming in Go. Packt Publishing Ltd. p. 16. {{ISBN|978-1-78728-604-7}}.&lt;/ref&gt; In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.
* [[Object-oriented programming]], a programming paradigm based on the concept of "objects", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. A feature of objects is that an object's procedures can access and often modify the data fields of the object with which they are associated. Thus object-oriented computer programs are made out of objects that interact with one another.&lt;ref&gt;Evelio Padilla, 2015. Substation Automation Systems: Design and Implementation. Wiley. p. 245. {{ISBN|978-1-118-98730-8}}.&lt;/ref&gt;
*[[Service-oriented programming]], a programming paradigm that uses "services" as the unit of computer work, to design and implement integrated business applications and [[mission critical]] software programs

Many languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.&lt;ref&gt;{{cite web |title=Multi-Paradigm Programming Language |url=https://developer.mozilla.org/en-US/docs/multiparadigmlanguage.html |website=developer.mozilla.org |publisher=[[Mozilla Foundation]] |archive-url=https://web.archive.org/web/20130821052407/https://developer.mozilla.org/en-US/docs/multiparadigmlanguage.html |archive-date=21 August 2013}}&lt;/ref&gt;

==Academia==
{{further|List of computer science conferences|Category:Computer science journals}}
Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of [[proceedings|conference papers]] is greater than that of journal publications.&lt;ref&gt;{{cite journal|last1=Meyer|first1=Bertrand|title=Viewpoint: Research evaluation for computer science|journal=Communications of the ACM|date=April 2009|volume=25|issue=4|pages=31–34|doi=10.1145/1498765.1498780|s2cid=8625066}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Patterson|first1=David|title=Evaluating Computer Scientists and Engineers For Promotion and Tenure|url=http://cra.org/resources/bp-view/evaluating_computer_scientists_and_engineers_for_promotion_and_tenure/|publisher=Computing Research Association|date=August 1999}}&lt;/ref&gt; One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.&lt;ref&gt;{{cite journal|last1=Fortnow|first1=Lance|title=Viewpoint: Time for Computer Science to Grow Up|journal=Communications of the ACM|date=August 2009|volume=52|issue=8|pages=33–35|doi=10.1145/1536616.1536631|url=http://cacm.acm.org/magazines/2009/8/34492-viewpoint-time-for-computer-science-to-grow-up/fulltext|doi-access=free}}&lt;/ref&gt;

==Education==
{{Main|Computer science education}}
'''Computer Science''', known by its near synonyms, '''Computing''', '''Computer Studies''', has been taught in UK schools since the days of [[batch processing]], [[punched cards|mark sensitive card]]s and [[paper tape]] but usually to a select few students.&lt;ref&gt;{{cite news |last1=Burns |first1=Judith |title=Computer science A-level 1970s style |url=https://www.bbc.co.uk/news/education-35890450 |access-date=9 February 2019 |date=3 April 2016}}&lt;/ref&gt; In 1981, the BBC produced a [[BBC Model B|micro-computer]] and [[Econet|classroom network]] and Computer Studies became common for GCE [[O level]] students (11–16-year-old), and Computer Science to [[A level]] students. Its importance was recognised, and it became a compulsory part of the [[National Curriculum]], for Key Stage 3 &amp; 4. In September 2014 it became an entitlement for all pupils over the age of 4.&lt;ref name="Jones"&gt;{{cite web |last1=Jones |first1=Michael |title=Developing a Computer Science Curriculum in England: Exploring Approaches in the USA |url=https://www.wcmt.org.uk/sites/default/files/report-documents/Jones%20M%20Report%202015%20%20Final.pdf |publisher=Winston Churchill Memorial Trust |access-date=9 February 2019 |date=October 1915}}&lt;/ref&gt;

In the [[United States of America|US]], with 14,000 school districts deciding the curriculum, provision was fractured.&lt;ref&gt;{{cite news|title=Computer Science: Not Just an Elective Anymore|url=http://www.edweek.org/ew/articles/2014/02/26/22computer_ep.h33.html|work=Education Week|date=February 25, 2014}}&lt;/ref&gt; According to a 2010 report by the [[Association for Computing Machinery]] (ACM) and [[Computer Science Teachers Association]] (CSTA), only 14 out of 50 states have adopted significant education standards for high school computer science.&lt;ref&gt;{{cite web|title=Running on Empty: The Failure to Teach K–12 Computer Science in the Digital Age |url = http://runningonempty.acm.org/fullreport2.pdf | date= 2010|first1 =Cameron |last1=Wilson|publisher = ACM|first2=Leigh Ann|last2= Sudol|first3= Chris|last3 =Stephenson|first4 =Mark |last4=Stehlik}}&lt;/ref&gt;

Israel, New Zealand, and South Korea have included computer science in their national secondary education curricula,&lt;ref&gt;{{cite news|title=A is for algorithm|url=https://www.economist.com/news/international/21601250-global-push-more-computer-science-classrooms-starting-bear-fruit|work=The Economist|date=April 26, 2014}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Computing at School International comparisons|url=http://www.computingatschool.org.uk/data/uploads/internationalcomparisons-v5.pdf|access-date=July 20, 2015}}&lt;/ref&gt; and several others are following.&lt;ref&gt;{{cite news|title=Adding Coding to the Curriculum|url=https://www.nytimes.com/2014/03/24/world/europe/adding-coding-to-the-curriculum.html|work=The New York Times|date=March 23, 2014}}&lt;/ref&gt;

==See also==
{{main|Glossary of computer science|Outline of computer science}}
{{Div col}}
* [[Computer Science and Engineering]]
* [[Computer engineering]]
* [[Information technology]]
* [[List of computer scientists]]
* [[List of computer science awards]]
* [[List of important publications in computer science]]
* [[List of pioneers in computer science]]
* [[List of unsolved problems in computer science]]
* [[List of terms relating to algorithms and data structures]]
* [[Digital Revolution]]
* [[Software engineering]]
* [[Programming language]]
* [[Algorithmic trading]]
* [[Information and communications technology]]
{{Div col end}}

==Notes==
{{reflist|group=note}}

==References==
{{reflist|colwidth=30em}}

==Further reading==
{{refbegin}}
===Overview===
* {{cite book|first=Allen B.|last=Tucker|author-link=Allen B. Tucker|title=Computer Science Handbook|edition=2nd|publisher=Chapman and Hall/CRC|year=2004|isbn=978-1-58488-360-9}}
** "Within more than 70 chapters, every one new or significantly revised, one can find any kind of information and references about computer science one can imagine. […] all in all, there is absolute nothing about Computer Science that can not be found in the 2.5 kilogram-encyclopaedia with its 110 survey articles […]." (Christoph Meinel, ''[[Zentralblatt MATH]]'')
* {{cite book|first=Jan|last=van Leeuwen|author-link=Jan van Leeuwen|title=Handbook of Theoretical Computer Science|publisher=The MIT Press|year=1994|isbn=978-0-262-72020-5}}
** "[…] this set is the most unique and possibly the most useful to the [theoretical computer science] community, in support both of teaching and research […]. The books can be used by anyone wanting simply to gain an understanding of one of these areas, or by someone desiring to be in research in a topic, or by instructors wishing to find timely information on a subject they are teaching outside their major areas of expertise." (Rocky Ross, ''[[SIGACT News]]'')
* {{cite book|title=Encyclopedia of Computer Science|edition=4th|first1=Anthony|last1=Ralston|author-link=Anthony Ralston|first2=Edwin D.|last2=Reilly|author-link2=Edwin D. Reilly|first3=David|last3=Hemmendinger|author-link3=David Hemmendinger|publisher=Grove's Dictionaries|year=2000|isbn=978-1-56159-248-7|url=http://portal.acm.org/ralston.cfm}}
** "Since 1976, this has been the definitive reference work on computer, computing, and computer science. […] Alphabetically arranged and classified into broad subject areas, the entries cover hardware, computer systems, information and data, software, the mathematics of computing, theory of computation, methodologies, applications, and computing milieu. The editors have done a commendable job of blending historical perspective and practical reference information. The encyclopedia remains essential for most public and academic library reference collections." (Joe Accardin, Northeastern Illinois Univ., Chicago)
* {{cite book|url=https://archive.org/details/milestonesincomp0000reil|url-access=registration|title=Milestones in Computer Science and Information Technology|author=Edwin D. Reilly|publisher=Greenwood Publishing Group|year=2003|isbn=978-1-57356-521-9}}

===Selected literature===
* {{cite book|first=Donald E.|last=Knuth|author-link=Donald Knuth|title=Selected Papers on Computer Science|publisher=CSLI Publications, [[Cambridge University Press]]|year=1996}}
* {{cite book|ref=COLLIER|last=Collier|first=Bruce|title=The little engine that could've: The calculating machines of Charles Babbage|publisher=Garland Publishing Inc|isbn=978-0-8240-0043-1|url=http://robroy.dyndns.info/collier/index.html|year=1990}}
* {{cite book|ref=HAIKEN|first=Bernard|last=Cohen|title=Howard Aiken, Portrait of a computer pioneer|publisher=The MIT press|year=2000|isbn=978-0-262-53179-5}}
* {{cite book|first=Matti|last=Tedre|title=The Science of Computing: Shaping a Discipline|publisher=CRC Press, [[Taylor &amp; Francis]]|year=2014}}
* {{cite book|title=The origins of Digital computers, Selected Papers|last=Randell|first=Brian|author-link=Brian Randell |year=1973|publisher=Springer-Verlag|isbn=978-3-540-06169-4}}
** "Covering a period from 1966 to 1993, its interest lies not only in the content of each of these papers – still timely today – but also in their being put together so that ideas expressed at different times complement each other nicely." (N. Bernard, ''Zentralblatt MATH'')

===Articles===
* Peter J. Denning. ''[http://portal.acm.org/citation.cfm?id=1053309&amp;coll=&amp;dl=ACM&amp;CFID=15151515&amp;CFTOKEN=6184618 Is computer science science?]'', Communications of the ACM, April 2005.
* Peter J. Denning, ''[http://portal.acm.org/citation.cfm?id=971303&amp;dl=ACM&amp;coll=&amp;CFID=15151515&amp;CFTOKEN=6184618 Great principles in computing curricula]'', Technical Symposium on Computer Science Education, 2004.
* Research evaluation for computer science, Informatics Europe [http://www.eqanie.eu/media/Como%20Conference/Tanca-Research_Assessment_A_new_Initiative_by_Informatics_Europe.pdf report] {{Webarchive|url=https://web.archive.org/web/20171018181136/http://www.eqanie.eu/media/Como%20Conference/Tanca-Research_Assessment_A_new_Initiative_by_Informatics_Europe.pdf |date=October 18, 2017 }}. Shorter journal version: Bertrand Meyer, Christine Choppy, Jan van Leeuwen and Jorgen Staunstrup, ''Research evaluation for computer science'', in [[Communications of the ACM]], vol. 52, no. 4, pp.&amp;nbsp;31–34, April 2009.

===Curriculum and classification===
* [[Association for Computing Machinery]]. [https://web.archive.org/web/20080828002940/http://www.acm.org/class/1998/overview.html 1998 ACM Computing Classification System]. 1998.
* Joint Task Force of Association for Computing Machinery (ACM), [[Association for Information Systems]] (AIS) and [[IEEE Computer Society]] (IEEE CS). [https://web.archive.org/web/20141021153204/http://www.acm.org/education/curric_vols/CC2005-March06Final.pdf Computing Curricula 2005: The Overview Report]. September 30, 2005.
* [[Norman Gibbs]], Allen Tucker. "A model curriculum for a liberal arts degree in computer science". ''Communications of the ACM'', Volume 29 Issue 3, March 1986.
{{refend}}

==External links==
{{Wikibooks|Informatics Practices for Class XI (CBSE)}}
{{Sister project links| wikt=computer science|c=Category:Computer science | b=Computer science | q=Computer science|n=no|s=no| v=Computer science | voy=no | species=no | d=no}}

{{Library resources box}}
* {{curlie|Computers/Computer_Science/}}
* [http://www.lib.uwaterloo.ca/society/compsci_soc.html Scholarly Societies in Computer Science]
* [https://www.youtube.com/watch?v=fjMU-km-Cso What is Computer Science?]
* [http://jeffhuang.com/best_paper_awards.html Best Papers Awards in Computer Science since 1996]
* [http://se.ethz.ch/~meyer/gallery/ Photographs of computer scientists] by [[Bertrand Meyer]]
* [http://www.eecs.berkeley.edu/department/history.shtml EECS.berkeley.edu]

===Bibliography and academic search engines===
* [http://citeseerx.ist.psu.edu/ CiteSeer&lt;sup&gt;''x''&lt;/sup&gt;] ([[CiteSeerX|article]]): search engine, digital library and repository for scientific and academic papers with a focus on computer and information science.
* [http://dblp.uni-trier.de/ DBLP Computer Science Bibliography] ([[Digital Bibliography &amp; Library Project|article]]): computer science bibliography website hosted at Universität Trier, in Germany.
* [http://liinwww.ira.uka.de/bibliography/ The Collection of Computer Science Bibliographies] ([[Collection of Computer Science Bibliographies]])

===Professional organizations===
* [http://www.acm.org/ Association for Computing Machinery]
* [http://www.computer.org/ IEEE Computer Society]
* [http://www.informatics-europe.org/ Informatics Europe]
* [http://www.aaai.org/home.html AAAI]
* [https://web.archive.org/web/20160205000119/http://membercentral.aaas.org/categories/computer-science AAAS Computer Science]

===Misc===
* [https://cs.stackexchange.com/ Computer Science—Stack Exchange]: a community-run question-and-answer site for computer science
* [http://www.cs.bu.edu/AboutCS/WhatIsCS.pdf What is computer science]
* [https://web.archive.org/web/20170810205524/https://www.cs.mtu.edu/~john/jenning.pdf Is computer science science?]
* [https://www.researchgate.net/publication/306078165_Computer_Science_Software_Must_be_Considered_as_an_Independent_Discipline_Computer_Science_Software_must_not_be_Treated_as_a_Sub-Domain_or_Subset_of_Mathematics Computer Science (Software) Must be Considered as an Independent Discipline.]

{{Computer science}}
{{Glossaries of science and engineering}}
{{Software engineering}}

{{Authority control}}

[[Category:Computer science| ]]
[[Category:Formal sciences| ]]
[[Category:Computer engineering]]</text>
      <sha1>nf8e61ibmqjubj25jo50ftsgauh0lj3</sha1>
    </revision>
  </page>
  <page>
    <title>K-D heap</title>
    <ns>0</ns>
    <id>61017112</id>
    <revision>
      <id>946063989</id>
      <parentid>928389903</parentid>
      <timestamp>2020-03-17T20:57:10Z</timestamp>
      <contributor>
        <username>Atexit</username>
        <id>2730217</id>
      </contributor>
      <minor/>
      <comment>Spelling fix while tree -&gt; whole tree</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2625" xml:space="preserve">[[File:K-d heap 2 keys.png|thumb|A 2-d heap with 20 elements.]]
A K-D heap&lt;ref&gt;Ding Y., Weiss M.A. (1993) The ''K''-D heap: An efficient multi-dimensional priority queue. In: Dehne F., Sack JR., Santoro N., Whitesides S. (eds) Algorithms and Data Structures. WADS 1993. Lecture Notes in Computer Science, vol 709. Springer, Berlin, Heidelberg&lt;/ref&gt;  is a [[data structure]] in [[computer science]] which implements a multidimensional [[priority queue]] without requiring additional space. It is a generalization of the [[Heap (data structure)|Heap]].&lt;ref&gt;Advanced Data Structures, Peter Brass, {{ISBN|978-0-521-88037-4}}, page 270&lt;/ref&gt; It allows for efficient insertion, query of the minimum element, and deletion of the minimum element in any of the k dimensions, and therefore includes the [[Double-ended priority queue|double-ended heap]] as a special case.

==Structure==

Given a collection of ''n'' items, where each has &lt;math&gt;k&lt;/math&gt; keys (or priorities), the K-D heap organizes them in to a [[binary tree]] which satisfies two conditions:

* It is a ''complete binary tree'', which means it is full except for possibly the last layer, where it must be filled-up from the left.
* It satisfies ''k-d heap order.''

The property of ''k-d heap order'' is analogous to that of the [[heap property]] for regular heaps. A heap maintains k-d heap order if:

* The node at the root has the smallest 1st-property of the whole tree, and
* Every other node ''v'' that is not the root, is such that if its parent ''w'' has the smallest i-th property of the subtree rooted by the parent, then ''v'' has the smallest &lt;math&gt;(i \mod k) +1&lt;/math&gt;-th property of the whole subtree rooted by ''v.''

One consequence of this structure is that the smallest 1-st property-element will trivially be in the root, and moreover all the smallest ''i''-th property elements for every ''i'' will be in the first ''k'' levels.

==Operations==
Creating a K-D heap from ''n'' items takes ''O(n)'' time. The following operations are supported:

* Insert a new item in time ''O(log n)'' 
* Retrieve the item with a minimum key in any of the dimensions in constant time 
* Delete an item with a minimum key in any dimension in time ''O(log n)'' 
* Delete or modify an arbitrary item in the heap in time ''O(log n)'' assuming its position in the heap is known

Importantly, the hidden constant in these operations is exponentially large relative &lt;math&gt;k&lt;/math&gt;, the number of dimensions, so K-D heaps are not practical for applications with very many dimensions.

== References ==
{{Reflist}}

[[Category:Computer science]]
[[Category:Data structures]]</text>
      <sha1>44tiuk4hpjnvlnrcu2x6vycg2e78xxq</sha1>
    </revision>
  </page>
  <page>
    <title>Outline of computer science</title>
    <ns>0</ns>
    <id>169633</id>
    <revision>
      <id>1007070386</id>
      <parentid>1001445348</parentid>
      <timestamp>2021-02-16T09:12:52Z</timestamp>
      <contributor>
        <username>LifeLine Shop</username>
        <id>41233742</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10240" xml:space="preserve">{{Short description|1=Overview of and topical guide to computer science}}
'''[[Computer science]]''' (also called '''computing science''') is the study of the theoretical foundations of [[information]] and [[computation]] and their implementation and application in [[computer]] systems. One well known subject classification system for computer science is the [[ACM Computing Classification System]] devised by the [[Association for Computing Machinery]].

{{TOC limit|limit=2}}

== What is computer science? ==
Computer science can be described as all of the following:

* [[Academic discipline]]
* [[Science]]
** [[Applied science]]

== Subfields ==

=== Mathematical foundations ===

* [[Coding theory]] – Useful in networking, programming and other areas where computers communicate with each other.
* [[Game theory]] – Useful in artificial intelligence and [[cybernetics]].
*[[Discrete Mathematics]]
* [[Graph theory]] – Foundations for data structures and searching algorithms.
* [[Mathematical logic]] – [[Boolean logic]] and other ways of [[mathematical model|modeling]] logical queries; the uses and limitations of formal proof methods
* [[Number theory]] – Theory of the [[integer]]s.  Used in [[cryptography]] as well as a test domain in [[artificial intelligence]].

=== Algorithms and data structures ===

* [[Algorithms]] – Sequential and parallel computational procedures for solving a wide range of problems.
* [[Data structure]]s – The organization and manipulation of data.

=== Artificial intelligence ===

[[Outline of artificial intelligence]]
* [[Artificial intelligence]] – The implementation and study of systems that exhibit an autonomous intelligence or behavior of their own.
*  [[Automated reasoning]] – Solving engines, such as used in [[Prolog]], which produce steps to a result given a query on a fact and rule database, and [[Automated theorem proving|automated theorem provers]] that aim to prove [[mathematical theorem]]s with some assistance from a programmer.
*  [[Computer vision]] – Algorithms for identifying three-dimensional objects from a two-dimensional picture.
* [[Soft computing]], the use of inexact solutions for otherwise extremely difficult problems:
** [[Machine learning]] - Automated creation of a set of rules and axioms based on input.
** [[Evolutionary computing]] - Biologically inspired algorithms.
*  [[Natural language processing]] - Building systems and algorithms that analyze, understand, and generate natural (human) languages.
*  [[Robotics]] – Algorithms for controlling the behaviour of robots.

=== Communication and security===

*  [[Computer networking|Networking]] – Algorithms and protocols for reliably communicating data across different shared or dedicated media, often including [[error correction]].
*  [[Computer security]] – Practical aspects of securing computer systems and computer networks.
*  [[Cryptography]] – Applies results from complexity, probability, algebra and number theory to invent and [[cryptoanalysis|break codes]], and analyze the security of [[cryptographic protocols]].

=== Computer architecture ===

* [[Computer architecture]] – The design, organization, optimization and verification of a computer system, mostly about [[CPU]]s and [[Memory (computers)|Memory]] subsystem (and the bus connecting them).
*  [[Operating system]]s – Systems for managing computer programs and providing the basis of a usable system.

=== Computer graphics ===

*  [[Computer graphics]] – Algorithms both for generating visual images synthetically, and for integrating or altering visual and spatial information sampled from the real world.
*  [[Image processing]] – Determining information from an image through computation.
* [[Information visualization]] – Methods for representing and displaying abstract data to facilitate human interaction for exploration and understanding.

=== Concurrent, parallel, and distributed systems ===

* [[Parallel computing]] - The theory and practice of simultaneous computation; data safety in any multitasking or multithreaded environment.
* [[Concurrency (computer science)]] – Computing using multiple concurrent threads of execution, devising algorithms for solving problems on multiple processors to achieve maximal speed-up compared to sequential execution.
* [[Distributed computing]] – Computing using multiple computing devices over a network to accomplish a common objective or task and thereby reducing the latency involved in single processor contributions for any task.

=== Databases ===
[[Outline of databases]]
* [[Relational databases]] – the [[set theory|set theoretic]] and algorithmic foundation of databases.
* [[Structured Storage]] - non-relational databases such as [[NoSQL]] databases. 
* [[Data mining]] – Study of algorithms for searching and processing information in documents and databases; closely related to [[information retrieval]].

=== Programming languages and compilers ===

* [[Compiler theory]] – Theory of [[compiler]] design, based on [[Automata theory]].
* [[Programming language|Programming language pragmatics]] – Taxonomy of programming languages, their strength and weaknesses. Various [[programming paradigm]]s, such as [[object-oriented programming]].
* [[Programming language theory]]
* [[Formal semantics of programming languages|Formal semantics]] – rigorous mathematical study of the meaning of programs.
* [[Type theory]] – Formal analysis of the types of data, and the use of these types to understand properties of programs — especially program safety.

=== Scientific computing ===
* [[Computational science]] &amp;ndash; constructing [[scientific modeling|mathematical model]]s and [[numerical analysis|quantitative analysis]] techniques and using computers to analyze and solve [[scientific]] problems.
* [[Numerical analysis]] – Approximate numerical solution of mathematical problems such as [[Root-finding algorithm|root-finding]], [[Numerical integration|integration]], the [[Numerical ordinary differential equations|solution of ordinary differential equations]]; the approximation of [[special functions]].
* [[Symbolic computation]] – Manipulation and solution of expressions in symbolic form, also known as [[Computer algebra]].
* [[Computational physics]] – Numerical simulations of large non-analytic systems
* [[Computational chemistry]] – Computational modelling of theoretical chemistry in order to determine chemical structures and properties
* [[Bioinformatics]] and [[Computational biology]] – The use of computer science to maintain, analyse, store [[biological data]] and to assist in solving biological problems such as [[Protein folding]], function prediction and [[Phylogeny]].
* [[Computational neuroscience]] – Computational modelling of [[neurophysiology]].

=== Software engineering ===
[[Outline of software engineering]]
* [[Formal methods]] – Mathematical approaches for describing and reasoning about software design.
* [[Software engineering]] – The principles and practice of designing, developing, and testing programs, as well as proper engineering practices.
*  [[Algorithm design]] – Using ideas from algorithm theory to creatively design solutions to real tasks.
*  [[Computer programming]] – The practice of using a programming language to implement algorithms.
*  [[Human–computer interaction]] – The study and design of computer interfaces that people use.
* [[Reverse engineering]] – The application of the scientific method to the understanding of arbitrary existing software.

=== Theory of computation ===
{{main | Theory of computation}}
* [[Automata theory]] – Different logical structures for solving problems.
* [[Computability theory (computer science)|Computability theory]] – What is calculable with the current models of computers. Proofs developed by [[Alan Turing]] and others provide insight into the possibilities of what may be computed and what may not.
** [[List of unsolved problems in computer science]]
* [[Computational complexity theory]] – Fundamental bounds (especially time and storage space) on classes of computations.
* [[Quantum computing]] theory – Explores computational models involving [[quantum superposition]] of bits.

== History ==

* [[History of computer science]]
* [[List of pioneers in computer science]]

== Professions ==
* [[Programmer|Programmer(Software developer)]]
* [[Teacher]]/[[Professor]]
* [[Software engineer]]
* [[Software architect]]
* [[Software tester]]
* [[Hardware engineer]]
* [[Data analyst]]
* [[Interaction designer]]
* [[Network administrator]]

== Data and data structures==
* [[Data structure]]
* [[Datatype|Data type]]
* [[Associative array]] and [[Hash table]]
* [[Array data structure|Array]]
* [[List (computing)|List]]
* [[Tree (data structure)|Tree]]
* [[String (computer science)|String]]
* [[Matrix (computer science)]]
* [[Databases|Database]]

==Programming paradigms==

* [[Imperative programming]]/[[Procedural programming]]
* [[Functional programming]]
* [[Logic programming]]
* [[Object oriented programming]]
** [[Class (computer science)|Class]]
** [[Inheritance (computer science)|Inheritance]]
** [[Object (computer science)|Object]]

== See also ==

* [[Abstraction (computer science)|Abstraction]]
* [[Big O notation]]
* [[Closure (computer science)|Closure]]
* [[Compiler]]
* [[Cognitive science]]

== External links ==
{{sisterlinks|Computer science}}

* {{dmoz|Computers/Computer_Science/}}
* [http://www.acm.org//education/curricula/ComputerScience2008.pdf [[Association for Computing Machinery|ACM]] report on a recommended computer science curriculum (2008)]
* [https://web.archive.org/web/20080512152252/http://lecturefox.com/computerscience/ Directory of free university lectures in Computer Science]
* [http://liinwww.ira.uka.de/bibliography/ Collection of Computer Science Bibliographies]
* [http://se.ethz.ch/~meyer/gallery/ Photographs of computer scientists] ([[Bertrand Meyer]]'s gallery)

{{Computer science}}
{{Outline footer}}

[[Category:Outlines of sciences|Computer science]]
[[Category:Wikipedia outlines|Computer science]]
[[Category:Computer science|Outline]]
[[Category:Computing-related lists|Computer science topics]]</text>
      <sha1>s2rmw5ojhqi4e594nkhdonfcb654c2d</sha1>
    </revision>
  </page>
  <page>
    <title>List of Turing Award laureates by university affiliation</title>
    <ns>0</ns>
    <id>30791291</id>
    <revision>
      <id>1002826641</id>
      <parentid>978199084</parentid>
      <timestamp>2021-01-26T06:12:33Z</timestamp>
      <contributor>
        <username>IznoRepeat</username>
        <id>12897086</id>
      </contributor>
      <minor/>
      <comment>/* Notes */clean up reflist class in wild</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="70898" xml:space="preserve">{{short description|Wikipedia list article}}
This '''list of''' '''Turing Award laureates by university affiliation''' shows the [[university]] affiliations of [[Turing Award]] winners since 1966 (as of 2020, 72 winners in total).&lt;ref name=":18" /&gt; The Turing Award is awarded every year by the [[Association for Computing Machinery]] (ACM) to winners of the previous year, and this list considers Turing Award winners as equal individuals, regardless of the total number of laureates who received the award each time.&lt;ref name=":18"&gt;{{Cite web|url=https://amturing.acm.org/byyear.cfm|title=A.M. Turing Award Winners by Year|last=|first=|date=|website=amturing.acm.org|language=en|access-date=2019-03-27}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://amturing.acm.org/|title=A.M. Turing Award|website=amturing.acm.org|access-date=2019-07-12}}&lt;/ref&gt; In this list, universities are presented in descending order starting from those affiliated with most Turing Award winners.

The university affiliations in this list are all official academic affiliations such as degree programs and official academic employment. Non-academic affiliations such as advisory committee and administrative staff are generally excluded. The official academic affiliations fall into three categories: 1) Alumni (graduates and attendees), 2) Long-term academic staff, and 3) Short-term academic staff. Graduates are defined as those who hold [[Bachelor's degree|Bachelor's]], [[Master's degree|Master's]], [[Doctorate]], or equivalent degrees from a university, while attendees are those who formally enrolled in degree programs at a university but did not complete the programs; thus, honorary degrees, summer attendees, exchange students and auditing students are excluded. The category of "Long-term academic staff" consists of [[Academic tenure|tenure]]/tenure-track and equivalent academic positions, while that of "Short-term academic staff" consists of lecturers (without tenure), postdoctoral researchers, visiting professors/scholars (visitors), and equivalent academic positions. At any university, the specific academic title solely determines the type of affiliation, regardless of the actual time the position was held by a laureate.

Further explanations on "visitors" under "Short-term academic staff" are now presented. 1) All informal or personal visits are excluded from the list; 2) all employment-based visiting positions, which carry teaching/research duties, are included as affiliations in the list; 3) as for award-based visiting positions, to minimize controversy this list takes a conservative view and includes the positions as affiliations only if the awardees were required to assume employment-level duty (teaching/research) or the awardees specifically classified the visiting positions as "appointment" or similar in reliable sources such as their [[curriculum vitae]]. In particular, attending meetings and giving public lectures, talks or non-curricular seminars are employment-level duties. Finally, summer visitors are generally excluded from the list unless summer work yielded significant end products such as research publications and components of Turing-winning work, since summer terms are not part of formal academic years; the same rule applies to extension schools of universities.

The number following a person's name is the year he/she received the Turing Award; in particular, a number with asterisk (*) means the person received the award while he/she was working at the institution (including [[emeritus]] staff) containing that asterisk. A name underlined implies that this person has been listed for a same institution previously (i.e., multiple affiliations). If a person had multiple positions under one category, only the position with highest rank is considered.

This list, together with the [[List of Nobel laureates by university affiliation]] and [[List of Fields Medal winners by university affiliation]], presents the university affiliations of people who have won highest honors in fundamental academic disciplines.

== Summary of results ==

=== Top 15 universities worldwide since 1966 ===
According to Wikipedia policies on [[wikipedia:No original research|no original research]] and [[wikipedia:Neutral point of view|objectivity/neutrality]], it is impossible in Wikipedia to assign various weights to different types of affiliations. Hence, all types of affiliations count equally in the following table and throughout the whole page.
{| class="wikitable sortable"
!Rank
! colspan="2" |University
!Total
!Alumni
!Long-term academic staff
!Short-term academic staff
!Overlap&lt;ref group="Note" name="Overlap" /&gt;
|-
|1
|[[Stanford University]]
|{{flagicon|United States}}
|28
|9
|16
|12
| -9
|-
|2
|[[Massachusetts Institute of Technology]]
|{{flagicon|United States}}
|26
|6
|16
|11
| -7
|-
|3
|[[University of California, Berkeley]]
|{{flagicon|United States}}
|25
|11
|12
|11
| -9
|-
| rowspan="2" |4
|[[Harvard University]]
|{{flagicon|United States}}
|14
|9
|5
|4
| -4
|-
|[[Princeton University]]
|{{flagicon|United States}}
|14
|8
|5
|2
|  -1
|-
|6
|[[Carnegie Mellon University]]
|{{flagicon|United States}}
|13
|5
|9
|1
|  -2
|-
|7
|[[New York University]]
|{{flagicon|United States}}
|8
|3
|2
|3
|0
|-
|8
|[[University of Cambridge]]
|{{flagicon|United Kingdom}}
|7
|5
|2
|3
|  -3
|-
| rowspan="3" |9
|[[California Institute of Technology]]
|{{flagicon|United States}}
|6
|6
|2
|0
|  -2
|-
|[[University of Michigan]]
|{{flagicon|United States}}
|6
|4
|0
|2
|0
|-
|[[University of Oxford]]
|{{flagicon|United Kingdom}}
|6
|3
|3
|2
| -2
|-
| rowspan="2" |12
|[[University of California, Los Angeles]]
|{{flagicon|United States}}
|5
|2
|1
|1
|0
|-
|[[University of Toronto]]
|{{flagicon|Canada}}
|5
|1
|3
|2
| -1
|-
| rowspan="2" |14
|[[Cornell University]]
|{{flagicon|United States}}
|4
|1
|3
|0
|0
|-
|[[University of Chicago]]
|{{flagicon|United States}}
|4
|3
|0
|1
|0
|}

=== Top 10 universities worldwide since 2000 ===
According to Wikipedia policies on [[wikipedia:No original research|no original research]] and [[wikipedia:Neutral point of view|objectivity/neutrality]], it is impossible in Wikipedia to assign various weights to different types of affiliations. Hence, all types of affiliations count equally in the following table and throughout the whole page.
{| class="wikitable sortable"
!Rank
! colspan="2" |University
!Total
!Alumni
!Long-term academic staff
!Short-term academic staff
!Overlap
|-
|1
|[[Massachusetts Institute of Technology]]
|{{flagicon|United States}}
|15
|2
|11
|4
| -2
|-
|2
|[[Stanford University]]
|{{flagicon|United States}}
|11
|5
|6
|4
| -4
|-
|3
|[[University of California, Berkeley]]
|{{flagicon|United States}}
|9
|5
|4
|2
| -2
|-
|4
|[[Princeton University]]
|{{flagicon|United States}}
|5
|2
|2
|1
|0
|-
| rowspan="5" |5
|[[Carnegie Mellon University]]
|{{flagicon|United States}}
|4
|1
|2
|1
|0
|-
|[[Harvard University]]
|{{flagicon|United States}}
|4
|2
|2
|0
|0
|-
|[[New York University]]
|{{flagicon|United States}}
|4
|2
|1
|1
|0
|-
|[[University of California, Los Angeles]]
|{{flagicon|United States}}
|4
|2
|1
|1
|0
|-
|[[University of Cambridge]]
|{{flagicon|United Kingdom}}
|4
|2
|0
|2
|0
|-
|10
|[[University of Toronto]]
|{{flagicon|Canada}}
|3
|0
|1
|2
|0
|}

== Stanford University (1st) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Stanford University]], [[United States]] {{flagicon|United States}}
|-
| colspan="4" |'''Notes''': 1) Affiliates of [[Stanford Research Institute]] (SRI) before Jan 13th, 1970, are included in this list.&lt;ref name=":93"&gt;{{Cite web|url=https://www.sri.com/about/corporate-history|title=Corporate History {{!}} SRI International|website=www.sri.com|language=en|access-date=2018-03-17}}&lt;/ref&gt; On May 16, 1977, the institute was renamed [[SRI International]].&lt;ref name=":93" /&gt;
|-
|28
|
# [[Martin Hellman]]&lt;ref name=":94"&gt;{{Cite web|url=https://www-ee.stanford.edu/~hellman/|title=Martin E. Hellman Home Page|website=www-ee.stanford.edu|access-date=2016-04-24}}&lt;/ref&gt;&lt;ref name=":35"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/hellman_4055781.cfm|title=Martin Hellman – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (M.S, PhD){{snd}} 2015
# [[Whitfield Diffie]]&lt;ref name=":34"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/diffie_8371646.cfm|title=Whitfield Diffie – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Graduate Attendee){{snd}} 2015
# [[Barbara Liskov]]&lt;ref name=":87"&gt;{{Cite web|url=http://www.pmg.csail.mit.edu/~liskov/newcv-09.pdf|title=CV (Barbara Liskov)}}&lt;/ref&gt;&lt;ref name=":6"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/liskov_1108679.cfm|title=Barbara Liskov – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt; (M.S, PhD){{snd}} 2008
# [[Vinton Cerf]]&lt;ref name=":2"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/cerf_1083211.cfm|title=Vinton Cerf – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt; (B.S){{snd}} 2004
# [[Ronald Rivest]]&lt;ref name=":39"&gt;{{Cite web|url=http://people.csail.mit.edu/rivest/bio.html|title=Ronald L. Rivest : Biographical Information|website=people.csail.mit.edu|access-date=2018-03-17}}&lt;/ref&gt;&lt;ref name=":86"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/rivest_1403005.cfm|title=Ronald L Rivest – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt; (PhD){{snd}} 2002
# [[John Hopcroft]]&lt;ref name=":55"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/hopcroft_1053917.cfm|title=John E Hopcroft – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt;&lt;ref name=":74"&gt;{{Cite web|url=http://www.cs.cornell.edu/jeh/|title=John E. Hopcroft|website=Cornell University}}&lt;/ref&gt; (M.S, PhD){{snd}} 1986
# [[Robert Tarjan]]&lt;ref name=":1"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/tarjan_1092048.cfm|title=Robert E Tarjan – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt;&lt;ref name=":72"&gt;{{Cite web|url=https://www.cs.princeton.edu/~ret/Vita2012A1.pdf|title=CV (Robert Endre Tarjan)}}&lt;/ref&gt; (M.S, PhD){{snd}} 1986
# [[Allen Newell]]&lt;ref name=":29"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/newell_3167755.cfm|title=Allen Newell – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt; (B.S){{snd}} 1975
# [[Raj Reddy]]&lt;ref name=":50"&gt;{{Cite web|url=http://www.rr.cs.cmu.edu/|title=rrlong|website=www.rr.cs.cmu.edu|access-date=2018-03-16}}&lt;/ref&gt; (PhD){{snd}} 1994
|
#[[Pat Hanrahan]]&lt;ref name=":103"&gt;{{Cite web|url=https://amturing.acm.org/|title=PIONEERS OF MODERN COMPUTER GRAPHICS RECOGNIZED WITH ACM A.M. TURING AWARD|last=|first=|date=|website=amturing.acm.org|url-status=live|archive-url=|archive-date=|access-date=2020-03-18}}&lt;/ref&gt; (Professor) - 2019*
#[[John L. Hennessy]]&lt;ref name=":96"&gt;{{Cite web|url=https://web.stanford.edu/~hennessy/cv.html|title=CV (John L. Hennessy)}}&lt;/ref&gt;&lt;ref name=":97"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/hennessy_1426931.cfm|title=John L Hennessy – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-21}}&lt;/ref&gt; (Professor) – 2017*
# [[Martin Hellman|&lt;u&gt;Martin Hellman&lt;/u&gt;]]&lt;ref name=":94" /&gt;&lt;ref name=":35" /&gt; (Professor){{snd}} 2015*
# [[Whitfield Diffie|&lt;u&gt;Whitfield Diffie&lt;/u&gt;]]&lt;ref name=":34" /&gt; (Professor){{snd}} 2015*
# [[Vinton Cerf|&lt;u&gt;Vinton Cerf&lt;/u&gt;]]&lt;ref name=":2" /&gt; (Assistant Professor){{snd}} 2004
# [[Andrew Chi-Chih Yao]]&lt;ref name=":3"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/yao_1611524.cfm|title=Andrew C Yao – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt;&lt;ref name=":85"&gt;{{Cite web|url=http://iiis.tsinghua.edu.cn/yao/|title=Andrew Chi-Chih Yao|website=iiis.tsinghua.edu.cn|language=zh-CN|access-date=2018-03-17}}&lt;/ref&gt; (Professor){{snd}} 2000
# [[Douglas Engelbart]]&lt;ref name=":80"&gt;{{Cite web|url=https://www.dougengelbart.org/about/cv.html|title=Curriculum Vitae – Doug Engelbart Institute|last=Administrator|website=www.dougengelbart.org|language=en|access-date=2018-03-17}}&lt;/ref&gt;&lt;ref name=":7"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/engelbart_5078811.cfm|title=Douglas Engelbart – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (SRI Director){{snd}} 1997
# [[Edward Feigenbaum]]&lt;ref name=":26"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/feigenbaum_4167235.cfm|title=Edward A Feigenbaum – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt; (Professor){{snd}} 1994*
# [[Raj Reddy|&lt;u&gt;Raj Reddy&lt;/u&gt;]]&lt;ref name=":50" /&gt; (Assistant Professor){{snd}} 1994
# [[Robert Tarjan|&lt;u&gt;Robert Tarjan&lt;/u&gt;]]&lt;ref name=":1" /&gt;&lt;ref name=":72" /&gt; (Associate Professor){{snd}} 1986
# [[Niklaus Wirth]]&lt;ref name=":8"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/wirth_1025774.cfm|title=Niklaus E. Wirth – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Assistant Professor){{snd}} 1984
# [[Robert W. Floyd]]&lt;ref name=":30"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/floyd_3720707.cfm|title=Robert W. Floyd – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt; (Professor){{snd}} 1978*
# [[Dana Scott]]&lt;ref name=":4"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/scott_1193622.cfm|title=Dana S Scott – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt;&lt;ref name=":71"&gt;{{Cite web|url=https://www.cs.cmu.edu/~scott/career.html|title=Dana Scott's Career Highlights|website=www.cs.cmu.edu|access-date=2018-03-16}}&lt;/ref&gt; (Professor){{snd}} 1976
# [[Donald Knuth|Donald E. Knuth]]&lt;ref name=":32"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/knuth_1013846.cfm|title=Donald E. Knuth – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt;&lt;ref name=":70"&gt;{{Cite web|url=https://www-cs-faculty.stanford.edu/~knuth/vita.pdf|title=CV (Donald E. Knuth)}}&lt;/ref&gt; (Professor){{snd}} 1974*
# [[John McCarthy (computer scientist)|John McCarthy]]&lt;ref name=":10"&gt;{{Cite web|url=http://www.computerhistory.org/fellowawards/hall/john-mccarthy/|title=John McCarthy {{!}} Computer History Museum|website=www.computerhistory.org|language=en|access-date=2018-03-16}}&lt;/ref&gt;&lt;ref name=":69"&gt;{{Cite web|url=http://www.nasonline.org/publications/biographical-memoirs/memoir-pdfs/mccarthy-john.pdf|title=John McCarthy (1927–2011)|website=National Academy o Sciences}}&lt;/ref&gt; (Professor){{snd}} 1971*
# [[James H. Wilkinson]]&lt;ref name=":63"&gt;{{Cite web|url=http://rsbm.royalsocietypublishing.org/content/roybiogmem/33/669.full.pdf|title=James Hardy Wilkinson (27 September 1919 – 5 October 1986)|last=Fox|first=L.}}&lt;/ref&gt; (Professor) – 1970
|
# [[Whitfield Diffie|&lt;u&gt;Whitfield Diffie&lt;/u&gt;]]&lt;ref name=":34" /&gt; (Visiting Scholar){{snd}} 2015
# [[Alan Kay]]&lt;ref name=":40"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/kay_3972189.cfm|title=Alan Kay – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt; (Researcher){{snd}} 2003
# [[Kristen Nygaard]]&lt;ref name=":42"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/nygaard_5916220.cfm|title=Kristen Nygaard – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-15}}&lt;/ref&gt; (Visiting Professor) – 2001
# [[Ole-Johan Dahl]]&lt;ref&gt;{{Cite book|url=https://pdfs.semanticscholar.org/6acd/c67a3a69e2bafc4d11b0cabb2fff046b5e8d.pdf|title=A Biography of Ole-Johan Dahl|website=University of Oslo|series=Lecture Notes in Computer Science|year=2004|doi=10.1007/978-3-540-39993-3_1|s2cid=40996890|last1=Owe|first1=Olaf|last2=Krogdahl|first2=Stein|last3=Lyche|first3=Tom|volume=2635|pages=1–7|isbn=978-3-540-21366-6}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Knuth|first1=Donald E|last2=Ruskey|first2=Frank|year=2004|title=Efficient coroutine generation of constrained Gray sequences|journal=Lecture Notes in Computer Science|volume=2635|pages=183–204|arxiv=cs/0404058|doi=10.1007/978-3-540-39993-3_11|isbn=978-3-540-21366-6|s2cid=17787805}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://docplayer.me/amp/47186802-Ole-johan-dahls-kontorarkiv-donald-e-knuth-sortering-navn-ar-tittel.html|title=Ole-Johan Dahls kontorarkiv Donald E. Knuth Sortering: navn, år, tittel – PDF|website=docplayer.me|access-date=2018-03-17}}&lt;/ref&gt; (Visiting Professor) – 2001
# [[Jim Gray (computer scientist)|Jim Gray]]&lt;ref name=":5"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/gray_3649936.cfm|title=Jim Gray – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt;&lt;ref name=":82"&gt;{{Cite web|url=https://jimgray.azurewebsites.net/|title=Jim Gray, Microsoft Research Home Page|website=jimgray.azurewebsites.net|access-date=2018-03-17}}&lt;/ref&gt; (Visitor){{snd}} 1998
# [[Douglas Engelbart|&lt;u&gt;Douglas Engelbart&lt;/u&gt;]]&lt;ref name=":80" /&gt; (Visiting Scholar){{snd}} 1997
# [[Amir Pnueli]]&lt;ref name=":49"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/pnueli_4725172.cfm|title=Amir Pnueli – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt;&lt;ref name=":81"&gt;{{Cite web|url=https://cs.nyu.edu/faculty/pnueli/shrtbio.html|title=Short biography of Amir Pnueli Harel|website=cs.nyu.edu|access-date=2018-03-17}}&lt;/ref&gt; (Postdoctoral Researcher){{snd}} 1996
# [[Robin Milner]]&lt;ref name=":75"&gt;{{Cite web|url=http://www.cl.cam.ac.uk/archive/rm135/cv.pdf|title=CV (Robin Milner)}}&lt;/ref&gt;&lt;ref name=":51"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/milner_1569367.cfm|title=A J Milner – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Research Associate){{snd}}1991
# [[William Kahan]]&lt;ref name=":52"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/kahan_1023746.cfm|title=William Kahan – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://people.eecs.berkeley.edu/~wkahan/ieee754status/754story.html|title=An Interview with the Old Man of Floating-Point}}&lt;/ref&gt; (Visiting Professor) – 1989
# [[John Hopcroft|&lt;u&gt;John Hopcroft&lt;/u&gt;]]&lt;ref name=":74" /&gt; (Visiting Associate Professor){{snd}} 1986
# [[James H. Wilkinson|&lt;u&gt;James H. Wilkinson&lt;/u&gt;]]&lt;ref name=":63" /&gt; (Visiting Professor) – 1970
# [[Richard Hamming]]&lt;ref name=":64"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/hamming_1000652.cfm|title=Richard W. Hamming – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.cs.virginia.edu/~robins/YouAndYourResearch.pdf|title=Richard Hamming ''You and Your Research''|last=Kaiser|first=J.F.|website=University of Virginia}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://stacks.stanford.edu/file/druid:cp135qt4613/1960-1961.pdf|title=Stanford University Bulletin (1960–61)|website=Stanford University}}&lt;/ref&gt; (Visiting Professor) – 1969
|}

== Massachusetts Institute of Technology (2nd) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Massachusetts Institute of Technology]], [[United States]] {{flagicon|United States}}
|-
| colspan="4" |'''Notes''': 1) [[Dennis M. Ritchie]], while a graduate student at Harvard University, worked part-time in MIT [[Project MAC]] (Multics project), a joint venture of MIT, [[General Electric]] and [[Bell Labs]].&lt;ref&gt;{{Cite web|url=https://www.cs.princeton.edu/~bwk/dmr.html|title=Dennis M. Ritchie|website=www.cs.princeton.edu|access-date=2018-03-16}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.bell-labs.com/usr/dmr/www/bigbio1st.html|title=Dennis Ritchie Bio|website=www.bell-labs.com|access-date=2018-03-16}}&lt;/ref&gt; He is not included in this list since he did not form any academic affiliation with MIT.
|-
|26
|
# [[Whitfield Diffie]]&lt;ref name=":34" /&gt; (B.S){{snd}} 2015
# [[Leslie Lamport]]&lt;ref name=":95"&gt;{{Cite web|url=http://lamport.azurewebsites.net/pubs/pubs.html|title=The Writings of Leslie Lamport|website=lamport.azurewebsites.net|access-date=2018-03-17}}&lt;/ref&gt;&lt;ref name=":33"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/lamport_1205376.cfm|title=Leslie Lamport – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (B.S){{snd}} 2013
# [[Manuel Blum]]&lt;ref name=":14"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/blum_4659082.cfm|title=Manuel Blum – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt;&lt;ref name=":83"&gt;{{Cite web|url=https://www.cs.cmu.edu/~mblum/pdfs/manuel_blum_cv.pdf|title=CV (Manuel Blum)}}&lt;/ref&gt; (B.S, M.S, PhD){{snd}} 1995
# [[Fernando Corbato]]&lt;ref name=":17"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/corbato_1009471.cfm|title=Fernando J Corbato – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt;&lt;ref name=":76"&gt;{{Cite web|url=http://archive.computerhistory.org/resources/text/Oral_History/Corbato_Fernando/Corbato_Fernando_1.oral_history.2006.102658041.pdf|title=Oral History of Fernando Corbató|website=Computer History Museum}}&lt;/ref&gt; (PhD){{snd}} 1990
# [[Ivan Sutherland]]&lt;ref name=":28"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/sutherland_3467412.cfm|title=Ivan Sutherland – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24|archive-url=https://web.archive.org/web/20170919194156/http://amturing.acm.org/award_winners/sutherland_3467412.cfm|archive-date=2017-09-19|url-status=dead}}&lt;/ref&gt; (PhD){{snd}} 1988
# [[Alan Perlis]]&lt;ref name=":16"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/perlis_0132439.cfm|title=A. J. Perlis – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (M.S, PhD){{snd}} 1966
|
# [[Tim Berners-Lee]]&lt;ref name=":36"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/berners-lee_8087960.cfm|title=Sir Tim Berners-Lee – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt; (Professor) – 2016*
# [[Martin Hellman]]&lt;ref name=":94" /&gt;&lt;ref name=":35" /&gt; (Assistant Professor){{snd}} 2015
# [[Michael Stonebraker]]&lt;ref name=":15"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/stonebraker_1172121.cfm|title=Michael Stonebraker – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.csail.mit.edu/person/michael-stonebraker|title=Michael Stonebraker {{!}} MIT CSAIL|website=www.csail.mit.edu|language=en|access-date=2018-03-15}}&lt;/ref&gt; (Adjunct Professor){{snd}} 2014*
# [[Shafi Goldwasser]]&lt;ref name=":91"&gt;{{Cite web|url=http://people.csail.mit.edu/shafi/wordpress/wp-content/uploads/Shafi_Goldwasser_CV_2014.pdf|title=CV (Shafi Goldwasser)}}&lt;/ref&gt;&lt;ref name=":12"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/goldwasser_8627889.cfm|title=Shafi Goldwasser – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Professor){{snd}} 2012*
# [[Silvio Micali]]&lt;ref name=":92"&gt;{{Cite web|url=https://people.csail.mit.edu/silvio/CV.pdf|title=CV (Silvio Micali)}}&lt;/ref&gt;&lt;ref name=":13"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/micali_9954407.cfm|title=Silvio Micali – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Professor){{snd}} 2012*
# [[Barbara Liskov]]&lt;ref name=":87" /&gt;&lt;ref name=":6" /&gt; (Professor){{snd}} 2008*
# [[Bob Kahn]]&lt;ref name=":31"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/kahn_4598637.cfm|title=Robert E Kahn – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Assistant Professor){{snd}} 2004
# [[Adi Shamir]]&lt;ref name=":19"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/shamir_2327856.cfm|title=Adi Shamir – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Assistant Professor){{snd}} 2002
# [[Leonard Adleman]]&lt;ref name=":11"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/adleman_7308544.cfm|title=Leonard M. Adleman – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Associate Professor){{snd}} 2002
# [[Ronald Rivest]]&lt;ref name=":39" /&gt;&lt;ref name=":86" /&gt; (Professor){{snd}} 2002*
# [[Andrew Yao|Andrew Chi-Chih Yao]]&lt;ref name=":3" /&gt;&lt;ref name=":85" /&gt; (Assistant Professor){{snd}} 2000
# [[Manuel Blum|&lt;u&gt;Manuel Blum&lt;/u&gt;]]&lt;ref name=":14" /&gt;&lt;ref name=":83" /&gt; (Assistant Professor){{snd}} 1995*
# [[Butler Lampson]]&lt;ref name=":77"&gt;{{Cite web|url=http://bwlampson.site/WebCV.html|title=Curriculum Vitae|website=bwlampson.site|access-date=2018-03-16}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://news.mit.edu/2014/mit-professor-made-much-of-our-world-possible-0218|title=MIT professor 'made much of our world possible'|website=MIT News|access-date=2016-04-24}}&lt;/ref&gt; (Adjunct Professor){{snd}} 1992*
# [[Fernando Corbato|&lt;u&gt;Fernando Corbato&lt;/u&gt;]]&lt;ref name=":17" /&gt;&lt;ref name=":76" /&gt; (Professor){{snd}} 1990*
# [[John McCarthy (computer scientist)|John McCarthy]]&lt;ref name=":69" /&gt; (Assistant Professor){{snd}} 1971
# [[Marvin Minsky]]&lt;ref name=":23"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/minsky_7440781.cfm|title=Marvin Minsky – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Professor){{snd}} 1969*

|
#[[Yoshua Bengio]]&lt;ref name=":100"&gt;{{Cite web|url=https://mila.quebec/wp-content/uploads/2019/03/YB-CV_19Feb2019.pdf|title=CV (Yoshua Bengio)|website=University of Montreal}}&lt;/ref&gt; (Postdoc) - 2018
#[[Shafi Goldwasser|&lt;u&gt;Shafi Goldwasser&lt;/u&gt;]]&lt;ref name=":91" /&gt;&lt;ref name=":12" /&gt; (Postdoc){{snd}} 2012
# [[Alan Kay]]&lt;ref name=":40" /&gt;&lt;ref name=":41"&gt;{{Cite web|url=http://www.odbms.org/about/contributors/kay/|title=Prof. Alan Kay, UCLA, Kyoto University, and MIT – ODBMS.org|website=www.odbms.org|language=en-US|access-date=2018-03-15}}&lt;/ref&gt; (Adjunct Professor){{snd}} 2003
# [[Adi Shamir|&lt;u&gt;Adi Shamir&lt;/u&gt;]]&lt;ref name=":19" /&gt; (Instructor){{snd}} 2002
# [[Manuel Blum|&lt;u&gt;Manuel Blum&lt;/u&gt;]]&lt;ref name=":14" /&gt;&lt;ref name=":83" /&gt; (Research Associate){{snd}} 1995
# [[Ivan Sutherland|&lt;u&gt;Ivan Sutherland&lt;/u&gt;]]&lt;ref name=":28" /&gt; (Researcher){{snd}} 1988
# [[Robert Tarjan|Robert E. Tarjan]]&lt;ref name=":1" /&gt;&lt;ref name=":72" /&gt; (Visiting Scientist) – 1986
# [[Robert W. Floyd]]&lt;ref&gt;{{Cite web|url=https://stacks.stanford.edu/file/druid:ng648pc2208/ng648pc2208.pdf|title=Computer Science at Stanford (1978–1979)}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Floyd|first1=Robert W.|date=1 August 1979|title=The paradigms of programming|journal=Communications of the ACM|volume=22|issue=8|pages=455–460|doi=10.1145/359138.359140|doi-access=free}}&lt;/ref&gt; (Visiting Professor){{snd}} 1978
# [[Michael O. Rabin]]&lt;ref name=":68" /&gt;&lt;ref name=":24"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/rabin_9681074.cfm|title=Michael O. Rabin – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Visiting Professor){{snd}} 1976
# [[Maurice Wilkes]]&lt;ref name=":65"&gt;{{Cite web|url=https://www.cl.cam.ac.uk/archive/mvw1/cv-2.pdf|title=CV (Maurice V. Wilkes)}}&lt;/ref&gt; (Adjunct Professor) – 1967
# [[Alan Perlis|&lt;u&gt;Alan Perlis&lt;/u&gt;]]&lt;ref name=":16" /&gt; (Researcher){{snd}} 1966
|}

== University of California, Berkeley (3rd) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[University of California, Berkeley]], [[United States]] {{flagicon|United States}}
|-
| colspan="4" |'''Notes''': 1) The [[Mathematical Sciences Research Institute]] (MSRI) at Berkeley is an independent research institute from the University. [[Juris Hartmanis]]&lt;ref name=":79"&gt;{{Cite web|url=http://www.cs.cornell.edu/people/hartmanis/HARTMANIS%20CV_08-05.pdf|title=CV (Juris Hartmanis)}}&lt;/ref&gt;&lt;ref name=":54"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/hartmanis_1059260.cfm|title=Juris Hartmanis – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Fall 1985 Visitor) and [[Richard E. Stearns]] (Fall 1985 Visitor)&lt;ref name=":53"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/stearns_1081900.cfm|title=Richard E Stearns – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt;&lt;ref name=":78"&gt;{{Cite web|url=http://www.cs.albany.edu/~res/stearns_cv.pdf|title=CV (Richard E. Stearn)}}&lt;/ref&gt; are thus excluded from the list.
2) [[Whitfield Diffie]] was a summer school attendee at Berkeley in 1962.&lt;ref&gt;{{Cite web|url=http://www.itas.kit.edu/pub/m/2002/wedi02a.htm|title=Weber: Interview with Whitfield Diffie on the Development of Public Key Cryptography – 2002|last=Weber|first=Arnd|website=www.itas.kit.edu|access-date=2018-03-17}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://archive.nytimes.com/www.nytimes.com/books/first/l/levy-crypto.html|title=Crypto|website=archive.nytimes.com|access-date=2018-03-17}}&lt;/ref&gt; He is thus excluded from the list.
|-
|25
|
# [[Shafi Goldwasser]]&lt;ref name=":91" /&gt;&lt;ref name=":12" /&gt; (M.S, PhD){{snd}} 2012
# [[Silvio Micali]]&lt;ref name=":92" /&gt;&lt;ref name=":13" /&gt; (PhD){{snd}} 2012
# [[Charles P. Thacker]]&lt;ref name=":9"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/thacker_1336106.cfm|title=Charles P. Thacker – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (B.S){{snd}} 2009
# [[Barbara Liskov]]&lt;ref name=":87" /&gt;&lt;ref name=":6" /&gt; (B.S){{snd}} 2008
# [[Leonard Adleman]]&lt;ref name=":11" /&gt; (B.A, PhD){{snd}} 2002
# [[Jim Gray (computer scientist)|Jim Gray]]&lt;ref name=":5" /&gt;&lt;ref name=":82" /&gt; (B.S, PhD){{snd}} 1998
# [[Douglas Engelbart]]&lt;ref name=":80" /&gt;&lt;ref name=":7" /&gt; (M.S, PhD){{snd}} 1997
# [[Butler Lampson]]&lt;ref name=":77" /&gt;&lt;ref name=":20"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/lampson_1142421.cfm|title=Butler W Lampson – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (PhD){{snd}} 1992
# [[Niklaus Wirth]]&lt;ref name=":8" /&gt; (PhD){{snd}} 1984
# [[Ken Thompson]]&lt;ref name=":56"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/thompson_4588371.cfm|title=Kenneth Lane Thompson – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (B.S, M.S){{snd}} 1983
# [[Dana Scott]]&lt;ref name=":4" /&gt;&lt;ref name=":71" /&gt; (B.A){{snd}} 1976
|
# [[David Patterson (computer scientist)|David Patterson]]&lt;ref name=":98"&gt;{{Cite web|url=https://people.eecs.berkeley.edu/~pattrsn/bio.html|title=David A. Patterson Biography|website=people.eecs.berkeley.edu|access-date=2018-03-21}}&lt;/ref&gt;&lt;ref name=":99"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/patterson_2316693.cfm|title=David Patterson – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-21}}&lt;/ref&gt; (Professor) – 2017*
# [[Michael Stonebraker]]&lt;ref name=":15" /&gt; (Professor){{snd}} 2014*
# [[Shafi Goldwasser|&lt;u&gt;Shafi Goldwasser&lt;/u&gt;]]&lt;ref&gt;{{Cite web|url=https://www2.eecs.berkeley.edu/Faculty/Homepages/goldwasser.html|title=Shafi Goldwasser {{!}} EECS at UC Berkeley|website=www2.eecs.berkeley.edu|language=en|access-date=2018-03-15}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://simons.berkeley.edu/people/shafi-goldwasser|title=Shafi Goldwasser {{!}} Simons Institute for the Theory of Computing|website=simons.berkeley.edu|language=en|access-date=2018-03-15}}&lt;/ref&gt; (Professor){{snd}} 2012
# [[Andrew Yao|Andrew Chi-Chih Yao]]&lt;ref name=":3" /&gt;&lt;ref name=":85" /&gt; (Professor){{snd}} 2000
# [[Douglas Engelbart|&lt;u&gt;Douglas Engelbart&lt;/u&gt;]]&lt;ref name=":80" /&gt;&lt;ref name=":7" /&gt; (Assistant Professor){{snd}} 1997
# [[Manuel Blum]]&lt;ref name=":14" /&gt;&lt;ref name=":83" /&gt; (Professor){{snd}} 1995*
# [[Edward Feigenbaum]]&lt;ref name=":26" /&gt; (Associate Professor){{snd}} 1994
# [[Butler Lampson|&lt;u&gt;Butler Lampson&lt;/u&gt;]]&lt;ref name=":77" /&gt;&lt;ref name=":20" /&gt; (Associate Professor){{snd}} 1992
# [[William Kahan]]&lt;ref name=":52" /&gt; (Professor){{snd}} 1989*
# [[Richard Karp]]&lt;ref name=":21"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/karp_3256708.cfm|title=Richard Karp – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Professor){{snd}} 1985*
# [[Stephen Cook]]&lt;ref name=":22"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/cook_n991950.cfm|title=Stephen A Cook – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Assistant Professor){{snd}} 1982
# [[Dana Scott|&lt;u&gt;Dana Scott&lt;/u&gt;]]&lt;ref name=":4" /&gt;&lt;ref name=":71" /&gt; (Associate Professor){{snd}} 1976

|
# [[Leslie Valiant]]&lt;ref&gt;{{Cite web|url=https://simons.berkeley.edu/people/leslie-valiant|title=Leslie Valiant {{!}} Simons Institute for the Theory of Computing|website=simons.berkeley.edu|language=en|access-date=2018-03-17}}&lt;/ref&gt;&lt;ref name=":90"&gt;{{Cite web|url=http://people.seas.harvard.edu/~valiant/cv-9-3-14.pdf|title=CV (Leslie G. Valiant)}}&lt;/ref&gt; (Visiting Scientist) – 2010
# [[Charles P. Thacker|&lt;u&gt;Charles P. Thacker&lt;/u&gt;]]&lt;ref name=":9" /&gt; (Researcher){{snd}} 2009
# [[Jim Gray (computer scientist)|&lt;u&gt;Jim Gray&lt;/u&gt;]]&lt;ref name=":5" /&gt;&lt;ref name=":82" /&gt; (Postdoc &amp; McKay Fellow){{snd}} 1998
# [[Manuel Blum|&lt;u&gt;Manuel Blum&lt;/u&gt;]]&lt;ref name=":83" /&gt;&lt;ref&gt;{{Cite web|url=https://simons.berkeley.edu/people/manuel-blum|title=Manuel Blum {{!}} Simons Institute for the Theory of Computing|website=simons.berkeley.edu|language=en|access-date=2018-03-17}}&lt;/ref&gt; (Visiting Scientist){{snd}} 1995
# [[Edward Feigenbaum|&lt;u&gt;Edward Feigenbaum&lt;/u&gt;]]&lt;ref name=":26" /&gt; (Researcher){{snd}} 1994
# [[Ivan Sutherland]]&lt;ref name=":28" /&gt; (Visiting Scholar){{snd}} 1988
# [[Robert Tarjan]]&lt;ref name=":1" /&gt;&lt;ref name=":72" /&gt; (Miller Research Fellow){{snd}} 1986
# [[Ken Thompson|&lt;u&gt;Ken Thompson&lt;/u&gt;]]&lt;ref name=":56" /&gt;&lt;ref name=":73"&gt;{{Cite web|url=https://s3-us-west-2.amazonaws.com/belllabs-microsite-unixhistory/thompsonbio.html|title=The Creation of the UNIX Operating System: Ken Thompson Biography|website=s3-us-west-2.amazonaws.com|access-date=2018-03-16}}&lt;/ref&gt; (Visiting Professor){{snd}} 1983
# [[John Backus]]&lt;ref name=":58"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/backus_0703524.cfm|title=John Backus – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Visiting Professor){{snd}} 1977
# [[Michael O. Rabin]]&lt;ref name=":68"&gt;{{cite web|url=https://www.seas.harvard.edu/sites/default/files/MOR-CV-UPDATED-12-1-2015%20.pdf|title=CV (Michael O. Rabin)|accessdate=31 March 2017}}&lt;/ref&gt; (Visiting Associate Professor){{snd}} 1976
# [[Herbert A. Simon]]&lt;ref name=":60"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/simon_1031467.cfm|title=Herbert A. Simon – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt; (Research Director){{snd}} 1975
|}

== Harvard University (4th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Harvard University]], [[United States]] {{flagicon|United States}}
|-
| colspan="4" |'''Notes''': 1) [[Barbara Liskov]] worked as a computer programmer (non-academic position) at Harvard during 1962–63.&lt;ref name=":87" /&gt;&lt;ref name=":6" /&gt; She is not included in the list.
|-
|14
|
# [[E. Allen Emerson]]&lt;ref name=":43"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/emerson_1671460.cfm|title=E. Allen Emerson – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (PhD){{snd}} 2007
# [[Andrew Chi-Chih Yao]]&lt;ref name=":3" /&gt;&lt;ref name=":85" /&gt; (M.A, PhD){{snd}} 2000
# [[Frederick P. Brooks, Jr.|Frederick P. Brooks]]&lt;ref name=":48"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/brooks_1002187.cfm|title=Frederick Brooks – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt;&lt;ref name=":84"&gt;{{Cite web|url=https://www.cs.unc.edu/~brooks/FPB_BIO.CV.04.2007.pdf|title=CV (Frederick Brooks)}}&lt;/ref&gt; (M.S, PhD){{snd}} 1999
# [[Butler Lampson]]&lt;ref name=":77" /&gt;&lt;ref name=":20" /&gt; (B.A){{snd}} 1992
# [[Richard Karp]]&lt;ref name=":21" /&gt; (B.A, M.S, PhD){{snd}} 1985
# [[Dennis M. Ritchie]]&lt;ref&gt;{{Cite web|url=http://amturing.acm.org/award_winners/ritchie_1506389.cfm|title=Dennis M. Ritchie – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (B.S, PhD){{snd}} 1983
# [[Stephen A. Cook]]&lt;ref name=":22" /&gt; (M.S, PhD){{snd}} 1982
# [[Kenneth E. Iverson]]&lt;ref name=":25"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/iverson_9147499.cfm|title=Kenneth E. Iverson – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (M.A, PhD){{snd}} 1979
# [[Marvin Minsky]]&lt;ref name=":23" /&gt; (B.A){{snd}} 1969
|
# [[Leslie G. Valiant]]&lt;ref name=":90" /&gt;&lt;ref name=":37"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/valiant_2612174.cfm|title=Leslie G Valiant – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-15}}&lt;/ref&gt; (Professor){{snd}} 2010*
# [[Edmund M. Clarke]]&lt;ref&gt;{{Cite web|url=https://embedded.eecs.berkeley.edu/research/seminar/cad-seminar/fall98/biodata/clarke.html|title=Prof. Edmund M. Clarke|website=embedded.eecs.berkeley.edu|access-date=2018-04-02}}&lt;/ref&gt;&lt;ref name=":27"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/clarke_1167964.cfm|title=Edmund Clarke – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-24}}&lt;/ref&gt; (Assistant Professor){{snd}} 2007
# [[Ivan Sutherland]]&lt;ref name=":28" /&gt; (Associate Professor){{snd}} 1988
# [[Kenneth E. Iverson|&lt;u&gt;Kenneth E. Iverson&lt;/u&gt;]]&lt;ref name=":25" /&gt; (Assistant Professor){{snd}} 1979
# [[Michael O. Rabin]]&lt;ref name=":68" /&gt;&lt;ref name=":24" /&gt; (Professor){{snd}} 1976

|
# [[Amir Pnueli]]&lt;ref name=":49" /&gt; (Visiting Professor){{snd}} 1996
# [[Kenneth E. Iverson|&lt;u&gt;Kenneth E. Iverson&lt;/u&gt;]]&lt;ref name=":25" /&gt; (Instructor){{snd}} 1979
# [[Michael O. Rabin|&lt;u&gt;Michael O. Rabin&lt;/u&gt;]]&lt;ref name=":68" /&gt; (Visiting Professor){{snd}} 1976
# [[Marvin Minsky|&lt;u&gt;Marvin Minsky&lt;/u&gt;]]&lt;ref name=":23" /&gt;&lt;ref name=":67"&gt;{{Cite web|url=https://web.media.mit.edu/~minsky/minskybiog.html|title=Brief Academic Biography of Marvin Minsky|website=web.media.mit.edu|access-date=2018-03-16}}&lt;/ref&gt; (Junior Fellow){{snd}} 1969
|}

== Princeton University (4th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Princeton University]], [[United States]] {{flagicon|United States}}
|-
| colspan="4" |'''Note''': 1) [[Herbert A. Simon]] had an unclear visiting position and is not included for now.&lt;ref&gt;{{Cite web|url=https://humanities.princeton.edu/opportunities/visiting-fellowships/|title=Visiting Fellowships — Princeton University Humanities Council|website=humanities.princeton.edu|language=en|access-date=2018-11-29}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://philosophy.princeton.edu/about/faculty-1949|title=Chairs and Faculty since 1949 {{!}} Department of Philosophy|website=philosophy.princeton.edu|language=en|access-date=2018-11-29}}&lt;/ref&gt;
|-
|14
|
#[[Michael Stonebraker]]&lt;ref name=":15" /&gt; (B.Eng){{snd}} 2014
#[[Bob Kahn|Robert Kahn]]&lt;ref name=":31" /&gt; (M.A, PhD){{snd}} 2004
#[[Richard E. Stearns]]&lt;ref name=":53" /&gt;&lt;ref name=":78" /&gt; (PhD){{snd}} 1993
#[[Dana Scott]]&lt;ref name=":4" /&gt;&lt;ref name=":71" /&gt; (PhD){{snd}} 1976
#[[Michael O. Rabin]]&lt;ref name=":68" /&gt;&lt;ref name=":24" /&gt; (PhD){{snd}} 1976
#[[Allen Newell]]&lt;ref name=":29" /&gt; (Graduate Attendee){{snd}} 1975
#[[John McCarthy (computer scientist)|John McCarthy]]&lt;ref name=":10" /&gt;&lt;ref name=":69" /&gt; (PhD){{snd}} 1971
#[[Marvin Minsky]]&lt;ref name=":23" /&gt;&lt;ref name=":67" /&gt; (PhD){{snd}} 1969
|
#[[Pat Hanrahan]]&lt;ref name=":103" /&gt; (Professor) - 2019
#[[Andrew Chi-Chih Yao]]&lt;ref name=":3" /&gt;&lt;ref name=":85" /&gt; (Professor){{snd}} 2000*
#[[John Hopcroft]]&lt;ref name=":55" /&gt;&lt;ref name=":74" /&gt; (Assistant Professor){{snd}} 1986
#[[Robert Tarjan]]&lt;ref name=":1" /&gt;&lt;ref name=":72" /&gt; (Professor){{snd}} 1986*
#[[Dana Scott|&lt;u&gt;Dana Scott&lt;/u&gt;]]&lt;ref name=":4" /&gt;&lt;ref name=":71" /&gt; (Professor){{snd}} 1976

|
#[[Shafi Goldwasser]]&lt;ref name=":91" /&gt; (Visiting Professor) – 2012
#[[Richard Hamming]]&lt;ref name=":64" /&gt; (Adjunct Professor) – 1969
|}

== Carnegie Mellon University (6th) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Carnegie Mellon University]], [[United States]] {{flagicon|United States}}
|-
|13
|
#[[Shafi Goldwasser]]&lt;ref name=":91" /&gt;&lt;ref name=":12" /&gt; (B.S){{snd}} 2012
#[[Edward Feigenbaum]]&lt;ref name=":26" /&gt; (B.S, PhD){{snd}} 1994
#[[Ivan E. Sutherland]]&lt;ref name=":28" /&gt; (B.S){{snd}} 1988
#[[Allen Newell]]&lt;ref name=":29" /&gt; (PhD){{snd}} 1975
#[[Alan J. Perlis]]&lt;ref name=":16" /&gt; (B.S){{snd}} 1966
|
#[[Geoffrey Hinton]]&lt;ref name=":101"&gt;{{Cite web|url=http://www.cs.toronto.edu/~hinton/fullcv.pdf|title=CV (Geoffrey E. Hinton)|website=University of Toronto}}&lt;/ref&gt; (Associate Professor) – 2018 
#[[Edmund M. Clarke]]&lt;ref name=":27" /&gt;&lt;ref name=":88"&gt;{{Cite web|url=https://www.cs.cmu.edu/~emc/bio.html|title=Edmund M. Clarke|website=www.cs.cmu.edu|access-date=2018-03-17}}&lt;/ref&gt; (Professor){{snd}} 2007*
#[[Manuel Blum]]&lt;ref name=":14" /&gt;&lt;ref name=":83" /&gt; (Professor){{snd}} 1995
#[[Raj Reddy]]&lt;ref name=":0"&gt;{{Cite web|url=http://amturing.acm.org/award_winners/reddy_9634208.cfm|title=Raj Reddy – A.M. Turing Award Winner|website=amturing.acm.org|access-date=2016-04-23}}&lt;/ref&gt;&lt;ref name=":50" /&gt; (Professor){{snd}} 1994*
#[[Robert W. Floyd]]&lt;ref name=":30" /&gt; (Assistant Professor){{snd}} 1978
#[[Dana Scott]]&lt;ref name=":4" /&gt;&lt;ref name=":71" /&gt; (Professor){{snd}} 1976
#[[Allen Newell|&lt;u&gt;Allen Newell&lt;/u&gt;]]&lt;ref name=":29" /&gt; (Professor){{snd}} 1975*
#[[Herbert A. Simon]]&lt;ref name=":60" /&gt; (Professor){{snd}} 1975*
#[[Alan J. Perlis|&lt;u&gt;Alan J. Perlis&lt;/u&gt;]]&lt;ref name=":16" /&gt; (Professor){{snd}} 1966*

|
#[[Leslie Valiant]]&lt;ref name=":90" /&gt;&lt;ref name=":37" /&gt; (Visiting Assistant Professor) – 2010
|}

== New York University (7th) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[New York University]], [[United States]] {{flagicon|United States}}
|-
|8
|
# [[Martin Hellman]]&lt;ref name=":35" /&gt; (B.Eng) – 2015
# [[Judea Pearl]]&lt;ref name=":38"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/pearl_2658896.cfm|title=Judea Pearl – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-15}}&lt;/ref&gt; (PhD) – 2011
# [[Jim Gray (computer scientist)|Jim Gray]]&lt;ref name=":5" /&gt;&lt;ref name=":82" /&gt; (Graduate Attendee){{snd}} 1998

|
#[[Yann LeCun]]&lt;ref name=":102"&gt;{{Cite web|url=http://yann.lecun.com/ex/bio.html|title=Yann LeCun's Biography|website=yann.lecun.com|access-date=2019-03-27}}&lt;/ref&gt; (Professor) – 2018*
#[[Amir Pnueli]]&lt;ref name=":49" /&gt; (Professor) – 1996

|
# [[Frances E. Allen]]&lt;ref name=":45"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/allen_1012327.cfm|title=Frances Allen – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-15}}&lt;/ref&gt; (Visiting Professor) – 2006
# [[Robert Tarjan]]&lt;ref name=":1" /&gt;&lt;ref name=":72" /&gt; (Adjunct Professor) – 1986
# [[Michael O. Rabin]]&lt;ref name=":68" /&gt; (Visiting Professor){{snd}} 1976
|}

== University of Cambridge (8th) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[University of Cambridge]], [[United Kingdom]] {{flagicon|United Kingdom}}
|-
|7
|
#[[Geoffrey Hinton]]&lt;ref name=":101" /&gt; (B.A) – 2018
#[[Leslie Valiant]]&lt;ref name=":90" /&gt;&lt;ref name=":37" /&gt; (B.A) – 2010
#[[Robin Milner]]&lt;ref name=":75" /&gt;&lt;ref name=":51" /&gt; (B.A) – 1991
#[[James H. Wilkinson]]&lt;ref name=":63" /&gt;&lt;ref&gt;{{Cite web|url=https://amturing.acm.org/award_winners/wilkinson_0671216.cfm|title=J. H. Wilkinson – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt; (B.A, M.A) – 1970
#[[Maurice Wilkes]]&lt;ref name=":65" /&gt;&lt;ref name=":66"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/wilkes_1001395.cfm|title=Maurice V. Wilkes – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt; (B.A, M.A, PhD) – 1967

|
#[[Robin Milner|&lt;u&gt;Robin Milner&lt;/u&gt;]]&lt;ref name=":75" /&gt;&lt;ref name=":51" /&gt; (Professor) – 1991
#[[Maurice Wilkes|&lt;u&gt;Maurice Wilkes&lt;/u&gt;]]&lt;ref name=":65" /&gt;&lt;ref name=":66" /&gt; (Professor) – 1967*

|
#[[Leslie Valiant|&lt;u&gt;Leslie Valiant&lt;/u&gt;]]&lt;ref name=":90" /&gt; (Visiting Fellow) – 2010
#[[Peter Naur]]&lt;ref name=":44"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/naur_1024454.cfm|title=Peter Naur – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-15}}&lt;/ref&gt; (Research Student) – 2005
#[[William Kahan]]&lt;ref name=":52" /&gt; (Postdoctoral Researcher) – 1989
|}

== California Institute of Technology (9th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[California Institute of Technology]], [[United States]] {{flagicon|United States}}
|-
|6
|
# [[Juris Hartmanis]]&lt;ref name=":79" /&gt;&lt;ref name=":54" /&gt; (PhD){{snd}} 1993
# [[Fernando Corbato]]&lt;ref name=":17" /&gt;&lt;ref name=":76" /&gt; (B.S){{snd}}1990
# [[Ivan Sutherland]]&lt;ref name=":28" /&gt; (M.S){{snd}} 1988
# [[Robert Tarjan]]&lt;ref name=":1" /&gt;&lt;ref name=":72" /&gt; (B.S){{snd}} 1986
# [[Donald Knuth|Donald E. Knuth]]&lt;ref name=":32" /&gt;&lt;ref name=":70" /&gt; (PhD){{snd}}1974
# [[John McCarthy (computer scientist)|John McCarthy]]&lt;ref name=":10" /&gt;&lt;ref name=":69" /&gt; (B.S){{snd}} 1971
|
# [[Ivan Sutherland|&lt;u&gt;Ivan Sutherland&lt;/u&gt;]]&lt;ref name=":28" /&gt; (Professor){{snd}} 1988
# [[Donald Knuth|&lt;u&gt;Donald E. Knuth&lt;/u&gt;]]&lt;ref name=":32" /&gt;&lt;ref name=":70" /&gt; (Associate Professor){{snd}} 1974

|
#
|}

== University of Michigan (9th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[University of Michigan]], [[United States]] {{flagicon|United States}}
|-
|6
|
# [[Michael Stonebraker]]&lt;ref name=":15" /&gt; (M.S, PhD) – 2014
# [[Frances E. Allen]]&lt;ref name=":45" /&gt; (M.A) – 2006
# [[Stephen A. Cook]]&lt;ref name=":22" /&gt; (B.S) – 1982
# [[Edgar Codd|Edgar F. Codd]]&lt;ref name=":57"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/codd_1000892.cfm|title=Edgar F. Codd – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt; (M.S, PhD) – 1981

|
|
# [[Richard Karp]]&lt;ref name=":21" /&gt; (Visiting Associate Professor){{snd}} 1985
# [[James H. Wilkinson]]&lt;ref name=":63" /&gt; (Visiting Professor) – 1970
|}

== University of Oxford (9th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[University of Oxford]], [[United Kingdom]] {{flagicon|United Kingdom}}
|-
|6
|
# [[Tim Berners-Lee]]&lt;ref name=":36" /&gt; (B.A){{snd}} 2016
# [[Edgar F. Codd]]&lt;ref name=":57" /&gt; (B.A, M.A){{snd}} 1981
# [[Tony Hoare|C. Anthony R. Hoare]]&lt;ref name=":59"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/hoare_4622167.cfm|title=C. Antony R. Hoare – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt; (B.A){{snd}} 1980

|
# [[Tim Berners-Lee|&lt;u&gt;Tim Berners-Lee&lt;/u&gt;]]&lt;ref name=":36" /&gt; (Professor){{snd}} 2016
# [[Tony Hoare|&lt;u&gt;C. Anthony R. Hoare&lt;/u&gt;]]&lt;ref name=":59" /&gt; (Professor){{snd}} 1980*
# [[Dana Scott]]&lt;ref name=":4" /&gt;&lt;ref name=":71" /&gt; (Professor){{snd}} 1976

|
# [[Leslie Valiant]]&lt;ref name=":90" /&gt; (Visiting Research Fellow) – 2010
# [[Donald Knuth|Donald E. Knuth]]&lt;ref name=":70" /&gt;&lt;ref&gt;{{Cite web|url=http://www.magd.ox.ac.uk/member-of-staff/donald-knuth/|title=Professor Donald Knuth {{!}} Magdalen College Oxford|website=www.magd.ox.ac.uk|language=en|access-date=2017-12-03}}&lt;/ref&gt; (Visiting Professor){{snd}} 1974
|}

== University of California, Los Angeles (12th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[University of California, Los Angeles]], United States {{flagicon|USA}}
|-
|5
|
# [[David Patterson (computer scientist)|David Patterson]]&lt;ref name=":98" /&gt;&lt;ref name=":99" /&gt; (B.A, M.S, PhD) – 2017
# [[Vinton Cerf]]&lt;ref name=":2" /&gt;(M.S, PhD) – 2004
# [[Fernando Corbato]]&lt;ref name=":17" /&gt;&lt;ref name=":76" /&gt; (Undergrad Attendee){{snd}} 1990
|
# [[Judea Pearl]]&lt;ref name=":38" /&gt;&lt;ref&gt;{{Cite web|url=http://bayes.cs.ucla.edu/jp_home.html|title=Judea Pearl – Home|website=bayes.cs.ucla.edu|language=en|access-date=2018-03-15}}&lt;/ref&gt; (Professor) – 2011*
|
# [[Alan Kay]]&lt;ref name=":40" /&gt;&lt;ref&gt;{{Cite web|url=http://www.cs.ucla.edu/faculty/|title=Faculty {{!}} CS|website=www.cs.ucla.edu|language=en-US|access-date=2018-03-15}}&lt;/ref&gt;(Adjunct Professor) – 2003
|}

== University of Toronto (12th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[University of Toronto]], [[Canada]] {{flagicon|CAN}}
|-
|5
|
#[[William Kahan]]&lt;ref name=":52" /&gt; (B.S, M.S, PhD) – 1989
|
#[[Geoffrey Hinton]]&lt;ref name=":101" /&gt; (Professor) – 2018*
#[[William Kahan|&lt;u&gt;William Kahan&lt;/u&gt;]]&lt;ref name=":52" /&gt; (Associate Professor) – 1989
#[[Stephen A. Cook]]&lt;ref name=":22" /&gt; (Professor) – 1982*
|
#[[Yann LeCun]]&lt;ref name=":102" /&gt; (Postdoctoral Researcher) - 2018
#[[Silvio Micali]]&lt;ref name=":92" /&gt;&lt;ref name=":13" /&gt; (Postdoctoral Researcher){{snd}} 2012
|}

== Cornell University (14th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Cornell University]], [[United States]] {{flagicon|United States}}
|-
|4
|
# [[Edmund M. Clarke]]&lt;ref name=":27" /&gt;&lt;ref name=":88" /&gt; (PhD) – 2007

|
#
# [[Juris Hartmanis]]&lt;ref name=":79" /&gt;&lt;ref name=":54" /&gt; (Professor) – 1993*
# [[John Hopcroft]]&lt;ref name=":55" /&gt;&lt;ref name=":74" /&gt; (Professor) – 1986*
# [[Robert Tarjan]]&lt;ref name=":1" /&gt;&lt;ref name=":72" /&gt; (Assistant Professor) – 1986

|
|}

== University of Chicago (14th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[University of Chicago]], United States {{flagicon|United States}}
|-
|4
|
# [[Robert W. Floyd]]&lt;ref name=":30" /&gt; (B.A, B.S) – 1978
# [[Herbert A. Simon]]&lt;ref name=":60" /&gt; (B.S, PhD) – 1975
# [[Richard Hamming]]&lt;ref name=":64" /&gt; (B.S) – 1968

|
|
# [[Dana Scott]]&lt;ref name=":4" /&gt;&lt;ref name=":71" /&gt; (Instructor) – 1976
|}

== Columbia University (16th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Columbia University]], United States {{flagicon|USA}}
|-
| colspan="4" |'''Notes''': 1) [[Frances E. Allen]] was a summer school attendee.&lt;ref name=":45" /&gt; She is excluded from the list.
|-
|3
|
# [[John Backus]]&lt;ref name=":58" /&gt; (B.S, M.A) – 1977
|
|
# [[Fred Brooks|Frederick Brooks]]&lt;ref name=":84" /&gt; (Adjunct Assistant Professor) – 1999
# [[Michael O. Rabin]]&lt;ref name=":68" /&gt; (Visiting Professor){{snd}} 1976
|}

== Duke University (16th, Tie) ==
{| class="wikitable"
|-
! Affiliates !!Alumni
! Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Duke University]], United States {{flagicon|USA}}
|-
|3
|
# [[Edmund M. Clarke]]&lt;ref name=":27" /&gt;&lt;ref name=":88" /&gt; (M.A) – 2007
# [[Frederick Brooks]]&lt;ref name=":48" /&gt;&lt;ref name=":84" /&gt; (B.A) – 1999
# [[John Cocke]]&lt;ref&gt;{{Cite web|url=https://amturing.acm.org/award_winners/cocke_2083115.cfm|title=John Cocke – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt; (B.S, PhD) – 1987
|
#
|
# [[Edmund M. Clarke|&lt;u&gt;Edmund M. Clarke&lt;/u&gt;]]&lt;ref name=":27" /&gt;&lt;ref name=":88" /&gt; (Lecturer) – 2007
|}

== Hebrew University (16th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Hebrew University of Jerusalem]], Israel {{flagicon|ISR}}
|-
|3
|
#[[Michael O. Rabin]]&lt;ref name=":68" /&gt;&lt;ref name=":24" /&gt; (M.S) – 1976
|
#[[Michael O. Rabin|&lt;u&gt;Michael O. Rabin&lt;/u&gt;]]&lt;ref name=":68" /&gt;&lt;ref name=":24" /&gt; (Professor) – 1976
|
#[[Shafi Goldwasser]]&lt;ref name=":91" /&gt;&lt;ref name=":12" /&gt; (Visiting Professor) – 2012
#[[Richard E. Stearns]]&lt;ref name=":53" /&gt;&lt;ref name=":78" /&gt; (Visiting Professor) – 1993
|}

== University of Edinburgh (16th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[University of Edinburgh]], [[United Kingdom]] {{flagicon|United Kingdom}}
|-
|3
|
# [[Geoffrey Hinton]]&lt;ref name=":101" /&gt; (PhD) – 2018 
|
#[[Leslie Valiant]]&lt;ref name=":90" /&gt;&lt;ref name=":37" /&gt; (Reader) – 2010
#[[Robin Milner]]&lt;ref name=":51" /&gt;&lt;ref name=":75" /&gt; (Professor) – 1991*
|
|}

== University of Utah (16th, Tie) ==
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[University of Utah]], United States {{flagicon|USA}}
|-
|3
|
#[[Edwin Catmull]]&lt;ref name=":103" /&gt; (B.S, PhD) - 2019
#[[Alan Kay]]&lt;ref name=":40" /&gt; (M.S, PhD) – 2003
|
#[[Ivan Sutherland]]&lt;ref name=":28" /&gt; (Professor) – 1988
|
|}

== Weizmann Institute of Science (16th, Tie) ==
{| class="wikitable"
|-
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Weizmann Institute of Science]], [[Israel]] {{flagicon|ISR}}
|-
|3
|
# [[Adi Shamir]]&lt;ref name=":19" /&gt; (M.S, PhD) – 2002
# [[Amir Pnueli]]&lt;ref name=":49" /&gt;&lt;ref name=":81" /&gt; (PhD) – 1996
|
# [[Shafi Goldwasser]]&lt;ref name=":91" /&gt;&lt;ref name=":12" /&gt; (Professor) – 2012*
# [[Amir Pnueli|&lt;u&gt;Amir Pnueli&lt;/u&gt;]]&lt;ref name=":49" /&gt;&lt;ref name=":81" /&gt; (Professor) – 1996
|
# [[Shafi Goldwasser|&lt;u&gt;Shafi Goldwasser&lt;/u&gt;]]&lt;ref name=":91" /&gt;&lt;ref name=":12" /&gt; (Visiting Professor) – 2012
# [[Amir Pnueli|&lt;u&gt;Amir Pnueli&lt;/u&gt;]]&lt;ref name=":49" /&gt;&lt;ref name=":81" /&gt; (Senior Research Fellow) – 1996
|}

== Yale University (16th, Tie) ==
{| class="wikitable"
|-
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Yale University]], United States {{flagicon|USA}}
|-
|3
|
# [[Ron Rivest|Ronald Rivest]]&lt;ref name=":39" /&gt;&lt;ref name=":86" /&gt; (B.A) – 2002
|
# [[Alan Perlis]]&lt;ref name=":16" /&gt; (Professor) – 1966
|
# [[Michael O. Rabin]]&lt;ref name=":68" /&gt;&lt;ref name=":24" /&gt; (Visiting Professor of Mathematics){{snd}} 1976
|}

== Other universities (23nd–37th) ==

=== 23nd (2 Affiliates) ===
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[City College of New York]], United States
|-
|2
|
# [[Bob Kahn|Robert Kahn]]&lt;ref name=":31" /&gt; (B.E.E) – 2004
|
|
# [[Richard Hamming]]&lt;ref name=":64" /&gt; (Adjunct Professor) – 1969
|-
| colspan="4" | [[Technion – Israel Institute of Technology]], Israel
|-
|2
|
# [[Amir Pnueli]]&lt;ref name=":49" /&gt;&lt;ref name=":81" /&gt; (B.S) – 1996
# [[Judea Pearl]]&lt;ref name=":38" /&gt; (B.S) – 2011
|
#
|
|-
| colspan="4" |[[Tel Aviv University]], Israel
|-
|2
|
# [[Adi Shamir]]&lt;ref name=":19" /&gt; (B.S) – 2002
|
# [[Amir Pnueli]]&lt;ref name=":49" /&gt;&lt;ref name=":81" /&gt; (Associate Professor) – 1996
|
|-
| colspan="4" |[[Aarhus University|University of Aarhus]], [[Denmark]]
|-
|2
|
|
|
# [[Kristen Nygaard]]&lt;ref name=":42" /&gt; (Visiting Professor) – 2001
# [[Robin Milner]]&lt;ref name=":75" /&gt;&lt;ref name=":51" /&gt; (Visiting Professor){{snd}} 1991
|-
| colspan="4" |[[University at Albany, SUNY]], United States
|-
|2
|
# [[Frances E. Allen]]&lt;ref name=":45" /&gt; (B.A) – 2006
|
# [[Richard E. Stearns]]&lt;ref name=":53" /&gt;&lt;ref name=":78" /&gt; (Professor) – 1993*
|
|-
| colspan="4" |[[University of Amsterdam]], [[Netherlands]]
|-
|2
|
# [[Edsger W. Dijkstra]]&lt;ref name=":61" /&gt; (PhD) – 1972
|
|
# [[Dana Scott]]&lt;ref name=":4" /&gt;&lt;ref name=":71" /&gt; (Visiting Professor) – 1976
|-
| colspan="4" | [[University of Illinois at Urbana–Champaign]], United States
|-
|2
|
# [[Andrew Chi-Chih Yao]]&lt;ref name=":3" /&gt;&lt;ref name=":85" /&gt; (PhD) – 2000
# [[Richard Hamming]]&lt;ref name=":64" /&gt; (PhD) – 1969
|
#
|
# [[Richard Hamming|&lt;u&gt;Richard Hamming&lt;/u&gt;]]&lt;ref name=":64" /&gt; (Instructor) – 1969
|-
| colspan="4" |[[University of Oslo]], [[Norway]]
|-
|2
|
# [[Kristen Nygaard]]&lt;ref name=":42" /&gt; (M.S) – 2001
# [[Ole-Johan Dahl]]&lt;ref name=":46"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/dahl_6917600.cfm|title=Ole-Johan Dahl – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-15}}&lt;/ref&gt; (M.S) – 2001
|
# [[Kristen Nygaard|&lt;u&gt;Kristen Nygaard&lt;/u&gt;]]&lt;ref name=":42" /&gt; (Professor) – 2001
# [[Ole-Johan Dahl|&lt;u&gt;Ole-Johan Dahl&lt;/u&gt;]]&lt;ref name=":46" /&gt; (Professor) – 2001
|
|-
| colspan="4" |[[University of Paris]], France
|-
|2
|
# [[Yann LeCun]]&lt;ref name=":102" /&gt; (PhD) – 2018
|
|
#[[Michael O. Rabin]]&lt;ref name=":68" /&gt;&lt;ref name=":24" /&gt; (Visiting Lecturer) – 1976
|-
| colspan="4" |[[University of Pennsylvania]], United States
|-
|2
|
# [[Charles Bachman]]&lt;ref name=":62"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/bachman_9385610.cfm|title=Charles W Bachman – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt; (M.S) – 1973
|
#
|
# [[Amir Pnueli]]&lt;ref name=":49" /&gt;&lt;ref name=":81" /&gt; (Visiting Associate Professor) – 1996
|-
| colspan="4" | [[University of Texas at Austin]], United States
|-
|2
|
# [[E. Allen Emerson]]&lt;ref name=":43" /&gt; (B.S) – 2007
|
# [[E. Allen Emerson|&lt;u&gt;E. Allen Emerson&lt;/u&gt;]]&lt;ref name=":43" /&gt; (Professor) – 2007*
# [[Edsger W. Dijkstra]]&lt;ref name=":61"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/dijkstra_1053701.cfm|title=Edsger W. Dijkstra – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-16}}&lt;/ref&gt; (Professor) – 1972
|
|-
| colspan="4" |[[University of Virginia]], United States
|-
|2
|
# [[Edmund M. Clarke]]&lt;ref name=":27" /&gt;&lt;ref name=":88" /&gt; (B.A) – 2007
# [[John Backus]]&lt;ref name=":58" /&gt; (Undergrad Attendee) – 1977
|
|
|-
| colspan="4" |[[University of Warwick]], United Kingdom
|-
|2
|
# [[Leslie Valiant]]&lt;ref name=":90" /&gt;&lt;ref name=":37" /&gt; (PhD) – 2010
|
|
# [[Adi Shamir]]&lt;ref name=":19" /&gt; (Postdoctoral Researcher) – 2002
|}

=== 38th (1 Affiliate) ===
{| class="wikitable"
!Affiliates
!Alumni
!Long-term academic staff
!Short-term academic staff
|-
| colspan="4" |[[Brandeis University]], United States
|-
|1
|
# [[Leslie Lamport]]&lt;ref name=":95" /&gt;&lt;ref name=":33" /&gt; (M.A, PhD) – 2013
|
|
|-
| colspan="4" |[[Carleton College]], United States
|-
|1
|
# [[Richard E. Stearns]]&lt;ref name=":53" /&gt;&lt;ref name=":78" /&gt; (B.A) – 1993
|
|
|-
| colspan="4" |[[Case Western Reserve University]], United States
|-
|1
|
# [[Donald Knuth|Donald E. Knuth]]&lt;ref name=":32" /&gt;&lt;ref name=":70" /&gt; (B.S, M.S) – 1974
|
|
|-
| colspan="4" |[[Chinese University of Hong Kong]], [[China]]
|-
|1
|
|
# [[Andrew Chi-Chih Yao]]&lt;ref name=":3" /&gt;&lt;ref name=":85" /&gt; (Professor-at-large) – 2000
|
#
|-
| colspan="4" |[[City University of Hong Kong]], China
|-
|1
|
|
|
# [[Manuel Blum]]&lt;ref name=":14" /&gt;&lt;ref name=":83" /&gt; (Visiting Professor) – 1995
|-
| colspan="4" |[[City, University of London]], United Kingdom
|-
|1
|
|
|
# [[Robin Milner]]&lt;ref name=":75" /&gt;&lt;ref name=":51" /&gt; (Lecturer) – 1991
|-
| colspan="4" |[[Dartmouth College]], United States
|-
|1
|
|
# [[John McCarthy (computer scientist)|John McCarthy]]&lt;ref name=":69" /&gt;&lt;ref&gt;{{Cite web|url=https://cs.stanford.edu/memoriam/professor-john-mccarthy|title=Professor John McCarthy {{!}} Stanford Computer Science|website=cs.stanford.edu|language=en|access-date=2018-03-16}}&lt;/ref&gt; (Assistant Professor) – 1971
|
#
|-
| colspan="4" |[[École Normale Supérieure]], France
|-
|1
|
|
|
# [[Adi Shamir]]&lt;ref name=":19" /&gt; (Invited Professor) – 2002
|-
| colspan="4" |[[Eindhoven University of Technology]], Netherlands
|-
|1
|
|
# [[Edsger W. Dijkstra]]&lt;ref name=":61" /&gt; (Professor) – 1972*
|
|-
| colspan="4" |[[ESIEE Paris]], France
|-
|1
|
# [[Yann LeCun]]&lt;ref name=":102" /&gt; (M.S) – 2018
|
|
|-
| colspan="4" |[[Haverford College]], United States
|-
|1
|
# [[John Backus]]&lt;ref name=":58" /&gt; (Undergrad Attendee) – 1977
|
|
|-
| colspan="4" |[[Illinois Institute of Technology]], United States
|-
|1
|
|
# [[Herbert A. Simon]]&lt;ref name=":60" /&gt; (Professor) – 1975
|
|-
| colspan="4" |[[Imperial College London]], United Kingdom
|-
|1
|
# [[Leslie Valiant]]&lt;ref name=":90" /&gt;&lt;ref name=":37" /&gt; (M.S) – 2010
|
|
|-
| colspan="4" |[[King's College London|King's College, London]], United Kingdom
|-
|1
|
|
|
# [[Michael O. Rabin]]&lt;ref name=":68" /&gt; (Visiting Professor) – 1976
|-
| colspan="4" |[[Kyoto University]], Japan
|-
|1
|
|
|
# [[Alan Kay]]&lt;ref name=":40" /&gt;&lt;ref name=":41" /&gt; (Visiting Professor) – 2003
|-
| colspan="4" |[[Leiden University]], Netherlands
|-
|1
|
# [[Edsger W. Dijkstra]]&lt;ref name=":61" /&gt; (B.S) – 1972
|
|
|-
| colspan="4" |[[Marlboro College]], United States
|-
|1
|
|
# [[Leslie Lamport]]&lt;ref name=":95" /&gt;&lt;ref&gt;{{Cite web|url=https://www.marlboro.edu/news/story/3712/Former%20Math%20Faculty%20Gains%20Turing%20Award|title=Upcoming Events {{!}} Marlboro College|website=www.marlboro.edu|language=en|access-date=2018-03-17}}&lt;/ref&gt; (Professor) – 2013
|
|-
| colspan="4" |[[McGill University]], Canada
|-
|1
|
# [[Yoshua Bengio]]&lt;ref name=":100" /&gt; (BEng, M.S, PhD) - 2018
|
|
|-
| colspan="4" |[[Michigan State University]], United States
|-
|1
|
# [[Charles Bachman]]&lt;ref name=":62" /&gt; (B.S) – 1973
|
|
|-
| colspan="4" |[[Moscow State University]], Russia
|-
|1
|
# [[Tony Hoare]]&lt;ref name=":59" /&gt; (Graduate Attendee) – 1980
|
|
|-
| colspan="4" |[[National Taiwan University]], Taiwan
|-
|1
|
# [[Andrew Chi-Chih Yao]]&lt;ref name=":3" /&gt;&lt;ref name=":85" /&gt; (B.S) – 2000
|
|
|-
| colspan="4" |[[National Technical University of Athens]], Greece
|-
|1
|
# [[Joseph Sifakis]]&lt;ref name=":47"&gt;{{Cite web|url=https://amturing.acm.org/award_winners/sifakis_1701095.cfm|title=Joseph Sifakis – A.M. Turing Award Winner|website=amturing.acm.org|language=en|access-date=2018-03-15}}&lt;/ref&gt;&lt;ref name=":89"&gt;{{Cite web|url=http://www-verimag.imag.fr/~sifakis/CV-Short%20Sifakis-Feb2017.pdf|title=CV (Joseph Sifakis)}}&lt;/ref&gt; (BEng) – 2007
|
|
|-
| colspan="4" |[[New Jersey Institute of Technology]], United States
|-
|1
|
# [[Judea Pearl]]&lt;ref name=":38" /&gt; (M.S) – 2011
|
|
|-
| colspan="3" |[[New York Institute of Technology]], United States
|
|-
|1
|
|
# [[Edwin Catmull]]&lt;ref name=":103" /&gt; (Computer Graphics Lab) - 2019
|
|-
| colspan="4" |[[Ohio State University]], United States
|-
|1
|
|
# [[Juris Hartmanis]]&lt;ref name=":79" /&gt;&lt;ref name=":54" /&gt; (Assistant Professor) – 1993
|
|-
| colspan="4" |[[Oregon State University]], United States
|-
|1
|
# [[Douglas Engelbart]]&lt;ref name=":80" /&gt;&lt;ref name=":7" /&gt; (B.S) – 1997
|
|
|-
| colspan="4" |[[Portland State University]], United States
|-
|1
|
|
|
# [[Ivan Sutherland]]&lt;ref name=":28" /&gt;&lt;ref&gt;{{Cite web|url=https://www.pdx.edu/ece/sutherland|title=Portland State Maseeh College of Engineering &amp; Computer Science: Electrical &amp; Computer Engineering {{!}} Ivan Sutherland|website=www.pdx.edu|language=en|access-date=2018-03-16}}&lt;/ref&gt; (Visiting Scientist) – 1988
|-
| colspan="4" |[[Purdue University]], United States
|-
|1
|
|
|
# [[Alan J. Perlis]]&lt;ref name=":16" /&gt; (Researcher) – 1966
|-
| colspan="4" |[[Queen's University, Canada]]
|-
|1
|
# [[Kenneth E. Iverson]]&lt;ref name=":25" /&gt; (B.A) – 1979
|
|
|-
| colspan="4" |[[Queen's University of Belfast]], United Kingdom
|-
|1
|
|
# [[Tony Hoare]]&lt;ref name=":59" /&gt; (Professor) – 1980
|
|-
| colspan="4" |[[Rensselaer Polytechnic Institute]], United States
|-
|1
|
|
|
# [[Richard E. Stearns]]&lt;ref name=":53" /&gt;&lt;ref name=":78" /&gt; (Adjunct Professor) – 1993
|-
| colspan="4" |[[Rutgers University]], United States
|-
|1
|
# [[Judea Pearl]]&lt;ref name=":38" /&gt; (M.S) – 2011
|
|
|-
| colspan="4" |[[Sapienza University of Rome]], Italy
|-
|1
|
# [[Silvio Micali]]&lt;ref name=":92" /&gt;&lt;ref name=":13" /&gt; (B.S) – 2012
|
|
|-
| colspan="4" |[[Seattle University]], United States
|-
|1
|
# [[John Hopcroft]]&lt;ref name=":55" /&gt;&lt;ref name=":74" /&gt; (B.S) – 1986
|
|
|-
| colspan="4" |[[Stony Brook University]], United States
|-
|1
|
# [[John L. Hennessy]]&lt;ref name=":96" /&gt;&lt;ref name=":97" /&gt; (M.S, PhD) – 2017
|
|
|-
| colspan="4" |[[Swansea University]], United Kingdom
|-
|1
|
|
|
# [[Robin Milner]]&lt;ref name=":75" /&gt;&lt;ref name=":51" /&gt; (Senior Research Assistant) – 1991
|-
| colspan="4" |[[École Polytechnique Fédérale de Lausanne|Swiss Federal Institute of Technology in Lausanne]], Switzerland
|-
|1
|
|
# [[Joseph Sifakis]]&lt;ref name=":47" /&gt;&lt;ref name=":89" /&gt; (Professor) – 2007
|
|-
| colspan="4" |[[ETH Zurich|Swiss Federal Institute of Technology in Zürich]] (ETH Zurich), Switzerland
|-
|1
|
# [[Niklaus Wirth]]&lt;ref name=":8" /&gt; (B.S) – 1984
|
# [[Niklaus Wirth|&lt;u&gt;Niklaus Wirth&lt;/u&gt;]]&lt;ref name=":8" /&gt; (Professor) – 1984*
|
|-
| colspan="4" |[[Technical University of Denmark]], Denmark
|-
|1
|
|
|
# [[Peter Naur]]&lt;ref&gt;{{Cite web|url=http://www.naur.com/|title=Introduction to the works of Peter Naur}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.genealogy.ams.org/id.php?id=111839|title=Peter Naur – The Mathematics Genealogy Project|website=www.genealogy.ams.org|access-date=2018-03-17}}&lt;/ref&gt; (Lecturer) – 2005
|-
| colspan="4" |[[Tsinghua University]], China
|-
|1
|
|
# [[Andrew Chi-Chih Yao]]&lt;ref name=":3" /&gt;&lt;ref name=":85" /&gt; (Professor) – 2000
|
|-
| colspan="4" |[[Université Laval]], Canada
|-
|1
|
# [[Niklaus Wirth]]&lt;ref name=":8" /&gt; (M.S) – 1984
|
|
|-
| colspan="4" |[[University College London]], United Kingdom
|-
|1
|
|
# [[Geoffrey Hinton]]&lt;ref name=":101" /&gt; (Research Director) – 2018
|
|-
| colspan="4" |[[University of California, Irvine]], United States
|-
|1
|
|
|
# [[Richard Hamming]]&lt;ref name=":64" /&gt; (Adjunct Professor) – 1969
|-
| colspan="4" |[[University of California, San Diego]], United States
|-
|1
|
|
|
# [[Geoffrey Hinton]]&lt;ref name=":101" /&gt; (Visiting Assistant Professor) – 2018 
|-
| colspan="4" |[[University of California, Santa Cruz]], United States
|-
|1
|
|
|
# [[John Backus]]&lt;ref name=":58" /&gt; (Adjunct Professor) – 1977
|-
| colspan="4" |[[University of Colorado Boulder|University of Colorado at Boulder]], United States
|-
|1
|
# [[Alan Kay]]&lt;ref name=":40" /&gt; (B.S) – 2003
|
|
|-
| colspan="4" |[[University of Copenhagen]], Denmark
|-
|1
|
# [[Peter Naur]]&lt;ref name=":44" /&gt; (B.A, PhD) -2005
|
# [[Peter Naur|&lt;u&gt;Peter Naur&lt;/u&gt;]]&lt;ref name=":44" /&gt; (Professor) – 2005*
|
|-
| colspan="4" |[[University of Grenoble]], France
|-
|1
|
# [[Joseph Sifakis]]&lt;ref name=":47" /&gt;&lt;ref name=":89" /&gt; (M.S, PhD) – 2007
|
|
|-
| colspan="4" |[[University of Leeds]], United Kingdom
|-
|1
|
|
|
# [[Leslie Valiant]]&lt;ref name=":90" /&gt;&lt;ref name=":37" /&gt; (Lecturer) – 2010
|-
| colspan="4" |[[Johannes Kepler University Linz|University of Linz]], Austria
|-
|1
|
|
# [[Dana Scott]]&lt;ref name=":4" /&gt;&lt;ref name=":71" /&gt; (Professor) – 1976
|
|-
| colspan="4" |[[University of Louisville]], United States
|-
|1
|
|
# [[Richard Hamming]]&lt;ref name=":64" /&gt; (Assistant Professor) – 1968
|
|-
| colspan="4" |[[University of Madras]], India
|-
|1
|
# [[Raj Reddy]]&lt;ref name=":50" /&gt; (BEng) – 1994
|
|
|-
| colspan="4" |[[University of Marburg]], Germany
|-
|1
|
# [[Juris Hartmanis]]&lt;ref name=":79" /&gt;&lt;ref name=":54" /&gt; (Undergrad Attendee) – 1993
|
|
|-
| colspan="4" |[[University of Missouri-Kansas City]], United States
|-
|1
|
# [[Juris Hartmanis]]&lt;ref name=":79" /&gt;&lt;ref name=":54" /&gt; (M.A) – 1993
|
|
|-
| colspan="4" |[[Université de Montréal]], Canada
|-
|1
|
|
#[[Yoshua Bengio]]&lt;ref name=":100" /&gt; (Professor) - 2018*
|
|-
| colspan="4" |[[University of Nebraska–Lincoln]], United States
|-
|1
|
# [[Richard Hamming]]&lt;ref name=":64" /&gt; (M.A) – 1968
|
|
|-
| colspan="4" |[[University of New South Wales]], Australia
|-
|1
|
# [[Raj Reddy]]&lt;ref name=":50" /&gt; (MTech) – 1994
|
|
|-
| colspan="4" |[[University of North Carolina at Chapel Hill]], United States
|-
|1
|
|
# [[Fred Brooks|Frederick Brooks]]&lt;ref name=":48" /&gt;&lt;ref name=":84" /&gt; (Professor) – 1999*
|
|-
| colspan="4" |[[University of Oslo]], Norway
|-
|1
|
|
|
# [[Donald Knuth|Donald E. Knuth]]&lt;ref name=":70" /&gt; (Guest Professor) – 1974
|-
| colspan="4" |[[University of Pittsburgh]], United States
|-
|1
|
# [[John Backus]]&lt;ref name=":58" /&gt;&lt;ref&gt;{{Cite web|url=http://www-history.mcs.st-andrews.ac.uk/Biographies/Backus.html|title=Backus biography|website=www-history.mcs.st-andrews.ac.uk|access-date=2018-03-16}}&lt;/ref&gt; (Undergrad Attendee) – 1977
|
|
|-
| colspan="4" |[[University of Southampton]], United Kingdom
|-
|1
|
|
# [[Tim Berners-Lee]]&lt;ref name=":36" /&gt; (Professor) – 2016
|
|-
| colspan="4" |[[University of Southern California]], United States
|-
|1
|
|
# [[Leonard Adleman]]&lt;ref name=":11" /&gt; (Professor) – 2002
|
|-
| colspan="4" |[[University of Sussex]], United Kingdom
|-
|1
|
|
|
# [[Geoffrey Hinton]]&lt;ref name=":101" /&gt; (Research Fellow) – 2018 
|-
| colspan="4" |[[University of Sydney]], Australia
|-
|1
|
|
|
# [[Ken Thompson]]&lt;ref name=":73" /&gt;&lt;ref&gt;{{Cite web|url=https://www.princeton.edu/~hos/mike/transcripts/thompson.htm|title=Ken Thompson 9-6-89|website=www.princeton.edu|access-date=2018-03-16}}&lt;/ref&gt; (Visiting Professor) – 1983
|-
| colspan="4" |[[University of Tennessee]], United States
|-
|1
|
|
|
# [[Edgar Codd|Edgar F. Codd]]&lt;ref name=":57" /&gt; (Lecturer) – 1981
|-
| colspan="4" |[[University of Washington]], United States
|-
|1
|
|
# [[Richard Karp]]&lt;ref name=":21" /&gt;&lt;ref&gt;{{Cite web|url=https://www.washington.edu/alumni/columns/sept96/karp.html|title=Karp Wins Medal of Science|website=www.washington.edu|access-date=2018-03-16}}&lt;/ref&gt; (Professor) – 1985
|
|-
| colspan="3" |[[University of Wisconsin–Madison|University of Wisconsin—Madison]], United States
|
|-
|1
|
# [[Pat Hanrahan]]&lt;ref name=":103" /&gt;&lt;ref&gt;{{Cite web|url=https://www.engr.wisc.edu/2012-distinguished-achievement-award-patrick-hanrahan/|title=2012 Distinguished achievement award: Patrick Hanrahan|date=2012-05-23|website=College of Engineering - University of Wisconsin-Madison|language=en-US|access-date=2020-03-18}}&lt;/ref&gt; (B.S, PhD) - 2019
|
|
|-
| colspan="4" |[[University of Zurich]], Switzerland
|-
|1
|
|
# [[Niklaus Wirth]]&lt;ref name=":8" /&gt; (Assistant Professor) {{snd}}1984
|
|-
| colspan="4" |[[Vassar College]], United States
|-
|1
|
|
|
# [[Fred Brooks|Frederick Brooks]]&lt;ref name=":48" /&gt;&lt;ref name=":84" /&gt; (Visiting Instructor) – 1999
|-
| colspan="4" |[[Villanova University]], United States
|-
|1
|
# [[John L. Hennessy]]&lt;ref name=":96" /&gt;&lt;ref name=":97" /&gt; (BEng) – 2017
|
|
|}

== See also ==
* [[List of Nobel laureates by university affiliation]]
* [[List of Fields Medal winners by university affiliation]]
* [[List of American universities with Olympic medals]]

== Notes ==

&lt;references group="Note"&gt;
&lt;ref name="Overlap"&gt;Overlap of affiliates among the three columns.&lt;/ref&gt;
&lt;/references&gt;

== References ==
{{reflist}}

[[Category:Turing Award laureates| ]]
[[Category:Lists of people by university or college]]
[[Category:Computer science]]</text>
      <sha1>jgs5n2c1jf5an9hgouewldjwcelx5q7</sha1>
    </revision>
  </page>
  <page>
    <title>Agnostic (data)</title>
    <ns>0</ns>
    <id>61776737</id>
    <revision>
      <id>1010645114</id>
      <parentid>1005749546</parentid>
      <timestamp>2021-03-06T15:27:47Z</timestamp>
      <contributor>
        <username>Rodw</username>
        <id>125972</id>
      </contributor>
      <minor/>
      <comment>Disambiguating links to [[PNG]] (link changed to [[Portable Network Graphics]]) using [[User:Qwertyytrewqqwerty/DisamAssist|DisamAssist]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7958" xml:space="preserve">In computing, a device or software program is said to be '''agnostic''' or '''data agnostic''' if the method or [[file format|format]] of data transmission is irrelevant to the device or program’s function. This means that the device or program can receive data in multiple formats or from multiple sources, and still process that data effectively.

==What is Non-Data Agnostic?==

Many devices or programs need data to be presented in a specific format in order to process it. For example, [[Apple Inc|Apple]] devices generally require applications to be downloaded from their [[App Store]].&lt;ref&gt;{{cite web |last1=Costello |first1=Sam |title=How to Get Apps That Are Not In The App Store |url=https://www.lifewire.com/get-apps-not-in-app-store-1999916 |website=Lifewire |access-date=4 February 2021}}&lt;/ref&gt; This is a non-data agnostic method, as it uses a specified file type, downloaded from a specific location, and does not function unless those requirements are met.

Non-data agnostic devices and programs can present problems. For example, if your file contains the right type of data (such as text), but in the wrong format, you may have to create a new file and enter the text manually in the proper format in order to use that program. Various file conversion programs exist because people need to convert their files to a different format in order to use them effectively.&lt;ref&gt;{{cite web |title=Free Online File Converter |url=https://www.online-convert.com/ |access-date=4 February 2021}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Cloud Convert File Converter |url=https://cloudconvert.com/ |access-date=4 February 2021}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Convertio File Converter |url=https://convertio.co/ |access-date=4 February 2021}}&lt;/ref&gt;

==How to be Data Agnostic==

Data agnostic devices and programs work to solve these problems in a variety of ways. Devices can treat files in the same way whether they are downloaded over the internet or transferred over a [[USB]] or other cable.

Devices and programs&lt;ref&gt;{{cite web |title=What Are Data Agnostic Services (DAS)? |url=https://greatideaz.com/Daas/DataAsService |website=Great Ideaz |access-date=4 February 2021}}&lt;/ref&gt; can become more data-agnostic by using a generic storage format to create, read, update, and delete files. Programs like [[XML]] and [[JSON]] can store information in a data agnostic manner. For example, [[XML]] is data agnostic in that it can save any type of information. However, if you use Data Transform Definitions (DTD) or XML Schema Definitions (XSD) to define what data should be placed where, it becomes non-data agnostic; it produces an error if the wrong type of data is placed in a field.

Once you have your data saved in a generic storage format, this source can act as an entity synchronization layer. The generic storage format can interface with a variety of different programs, with the data extraction method formatting the data in a way that the specific program can understand. This allows two programs that require different data formats to access the same data. Multiple devices and programs can create, read, update, and delete ([[CRUD]]) the same information from the same storage location without formatting errors.

When multiple programs are accessing the same records, they may have different defined fields for the same type of concept. Where the fields are differently labelled but contain the same data, the program pulling the information can ensure the correct data is used. If one program contains fields and information that another does not, those fields can be saved to the record and pulled for that program, but ignored by other programs. As the entity synchronization layer is data agnostic, additional fields can be added without worrying about recoding the whole database, and concepts created in other programs (that do not contain that field) are fine.

Since the information formatting is imposed on the data by the program extracting it, the format can be customized to the device or program extracting and displaying that data. The information extracted from the entity synchronization layer can therefore be dynamically rendered to display on the user’s device, regardless of the device or program being used.

Having data agnostic devices and programs allows you to transfer data easily between them, without having to convert that data. Companies like Great Ideaz&lt;ref&gt;{{cite web |title=trellispark Breakthroughs |url=https://greatideaz.com/Breakthroughs |website=Great Ideaz |access-date=4 February 2021}}&lt;/ref&gt; provide data agnostic services by storing the data in an entity synchronization layer. This acts as a compatibility layer, as [[TSQL]] statements can retrieve, update, sort, and write data regardless of the format employed. It also allows you to synchronize data between multiple applications, as the applications can all pull data from the same location. This prevents compatibility problems between different programs that have to access the same data, as well as reducing data replication.

==Benefits of Data Agnostic==

Keeping your devices and programs as data agnostic as possible has some clear advantages.

Since the data is stored in an agnostic format, you do not need to hard-code ways to deal with all different kinds of data. A table with information about dogs and one with information about cats can be treated in the same way; you extract the field definitions and the field content from your data agnostic storage format and display it based on the field definitions. Since you are using the same code for the different concepts you want to [[CRUD]], the amount of code is significantly reduced, and what remains is extensively tested with each concept you extract from the entity synchronization layer.

The field definitions and formatting can be stored in the entity synchronization layer with the data they are acting on. This lets you change the fields and formatting quickly and easily, without having to hardcode and compile programs. The data and formatting are then generated dynamically by the code used to extract the data and the formatting information.

The data itself only needs to be distinguished when it is being acted on or displayed in a specific way. If the data is being transferred between devices or databases, it does not need to be interpreted as a specific object. Whenever the data can be treated as agnostic, the coding is simplified, as it only has to deal with one case (the data agnostic case) rather than multiple ([[Portable Network Graphics|png]], [[pdf]], etc). When the data must be displayed or acted on, then it is interpreted based on the field definitions and formatting information, and returned to a data agnostic format as soon as possible to reduce the number of individual cases that must be accounted for.

==Risks of Data Agnostic==

There are, however, a few problems introduced when attempting to make a device or program data agnostic.

Since only one piece of code is being used for [[CRUD]] operations (regardless of the type of concept), there is a [[single point of failure]]. If that code breaks down, the whole system is broken. This risk is mitigated because the code is tested so many times (as it is used every time a record is stored or retrieved).

Additionally, data agnostic storage mediums can increase your load speed, as the code has to search for the field definitions and display format as well as the specific data to be displayed. The load speed can be improved by pre-shredding the data. This uses a copy of the record with the data already extracted to index the fields, instead of having to extract the fields and formatting information at the same time as the data. While this improves the speed, it adds a non-data agnostic element to the process; however, it can be created easily through [[code generation (compiler)|code generation]].

==References==
{{Reflist}}

[[Category:Computer data]]
[[Category:Computer science]]</text>
      <sha1>ppzou3wnypf1plxj3mwpyaanifqc4om</sha1>
    </revision>
  </page>
  <page>
    <title>Bidirectional transformation</title>
    <ns>0</ns>
    <id>30780965</id>
    <revision>
      <id>1012253566</id>
      <parentid>956876090</parentid>
      <timestamp>2021-03-15T12:23:18Z</timestamp>
      <contributor>
        <ip>37.192.2.125</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3934" xml:space="preserve">In computer programming, '''bidirectional transformations (bx)''' are programs in which a single piece of code can be run in several ways, such that the same data are sometimes considered as input, and sometimes as output. For example, a bx run in the forward direction might transform input I into output O, while the same bx run backward would take as input versions of I and O and produce a new version of I as its output.

[[Model transformation#Unidirectional versus bidirectional|Bidirectional model transformations]] are an important special case in which a model is input to such a program.

Some bidirectional languages are [[Bijection|''bijective'']]. The bijectivity of a language is a severe restriction of its bidirectionality,&lt;ref name="nate-foster"&gt;{{Cite web |url=http://grace.gsdlab.org/images/e/e2/Nate-short.pdf |title=Archived copy |access-date=2011-02-07 |archive-url=https://web.archive.org/web/20110726133528/http://grace.gsdlab.org/images/e/e2/Nate-short.pdf |archive-date=2011-07-26 |url-status=dead }}&lt;/ref&gt; because a bijective language is merely relating two different ways to present the very same information.

More general is a lens language, in which there is a distinguished forward direction ("get") that takes a concrete input to an abstract output, discarding some information in the process: the concrete state includes all the information that is in the abstract state, and usually some more. The backward direction ("put") takes a concrete state and an abstract state and computes a new concrete state. Lenses are required to obey certain conditions to ensure sensible behaviour.

The most general case is that of symmetric bidirectional transformations. Here the two states that are related typically share some information, but each also includes some information that is not included in the other.

== Usage ==

Bidirectional transformations can be used to:

* Maintain the consistency of several sources of information&lt;ref name="grace-report"&gt;http://www.cs.cornell.edu/~jnfoster/papers/grace-report.pdf&lt;/ref&gt;
* Provide an 'abstract view' to easily manipulate data and write them back to their source

== Vocabulary ==

A bidirectional program which obeys certain round-trip laws&lt;ref name="lens-laws"&gt;https://arxiv.org/abs/1809.00738&lt;/ref&gt; is called a '''''lens'''''.

== Examples of implementations ==

* [[Boomerang (programming language)|Boomerang]] is a programming language which allows writing lenses to process text data formats bidirectionally
* [[Augeas (software)|Augeas]] is a configuration management library whose lens language is inspired by the Boomerang project
* ''biXid'' is a programming language for processing XML data bidirectionally&lt;ref name="bixid"&gt;{{Cite web |url=http://arbre.is.s.u-tokyo.ac.jp/~hahosoya/papers/bixid.pdf |title=Archived copy |access-date=2011-02-07 |archive-url=https://web.archive.org/web/20070702195028/http://arbre.is.s.u-tokyo.ac.jp/~hahosoya/papers/bixid.pdf |archive-date=2007-07-02 |url-status=dead }}&lt;/ref&gt;
* ''XSugar'' allows translation from XML to non-XML formats&lt;ref name="xsugar"&gt;http://www.brics.dk/xsugar/&lt;/ref&gt;

== See also ==
* [[Bidirectionalization]]
* [[Reverse computation]]
* [[Transformation language]]

== References ==

{{reflist}}

== External links ==
* {{Webarchive|url=https://web.archive.org/web/20141012223700/http://grace.gsdlab.org/index.php?title=Main_Page|date=12 October 2014|title=GRACE International Meeting on Bidirectional Transformations}}
* [http://bx-community.wikidot.com/ Bidirectional Transformations: The Bx Wiki]
* Pacheco, Hugo, and Alcino Cunha. "[https://repositorium.sdum.uminho.pt/bitstream/1822/24674/1/icmt12-1.pdf Multifocal: A strategic bidirectional transformation language for XML schemas]." International Conference on Theory and Practice of Model Transformations. Springer, Berlin, Heidelberg, 2012.

[[Category:Computer science]]
[[Category:Mathematical relations]]


{{compu-prog-stub}}</text>
      <sha1>gyap06oj1v5xu2ix9mb60sxcybzuguy</sha1>
    </revision>
  </page>
  <page>
    <title>Computational politics</title>
    <ns>0</ns>
    <id>61580753</id>
    <revision>
      <id>994177699</id>
      <parentid>994177569</parentid>
      <timestamp>2020-12-14T13:34:23Z</timestamp>
      <contributor>
        <ip>175.159.124.5</ip>
      </contributor>
      <comment>removed 'main'.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2227" xml:space="preserve">{{one source|date=October 2019}}

'''Computational Politics''' is the intersection between [[computer science]] and [[political science]]. The area involves the usage of computational method such as analysis tools, prediction methods to present the solutions to political sciences questions. Researchers in this area use large sets of data to study user behavior.&lt;ref&gt;{{cite document |last1=Winston |first1=Patrick H. |last2=Finlayson |first2=Mark A. |s2cid=7589841 |title=Computational Politics }}&lt;/ref&gt; Common examples of such works are building a [[Statistical classification|classifier]] to predict users' political bias in [[social media]] or finding political bias in the news. This discipline is closely related with [[Digital sociology|Digital Sociology]]. However, the main focus is on political related problems and analysis.

Computational politics is often discussed together with policy and [[Social engineering (political science)|public opinion engineering]]. Ashu M. G. Solo highlights the need of technocracy in democratic process where decision makers can make decision, e.g. where and how to spend the campaign money&lt;ref&gt;Solo, Ashu MG. "The new fields of public policy engineering, political engineering, computational public policy, and computational politics." Proceedings of the International Conference on e-Learning, e-Business, Enterprise Information Systems, and e-Government (EEE). The Steering Committee of The World Congress in Computer Science, Computer Engineering and Applied Computing (WorldComp), 2011.&lt;/ref&gt; Although the political canvas is wide, Haq et al. categorise the work in to five major categories &lt;ref&gt;E. U. Haq, T. Braud, Y. D. Kwon and P. Hui, "A Survey on Computational Politics," in ''IEEE Access'', vol. 8, pp. 197379-197406, 2020, doi: 10.1109/ACCESS.2020.3034983.&lt;/ref&gt;
# [[User modeling|Community and User Modelling]]
# [[Information flow|Information Flow]]
# [[Discourse analysis#Political discourse|Political Discourse]]
# [[Political campaign|Election Campaigns]]
# [[Systems design|System Design]]
 
== References ==
{{reflist}}

{{improve categories|date=November 2019}}

[[Category:Computer science]]
[[Category:Political science]]


{{computer-stub}}
{{politics-stub}}</text>
      <sha1>fkfpnttpp20fq2i02y0cpyj6qmo1r72</sha1>
    </revision>
  </page>
  <page>
    <title>Faculty of Computer and Information Science, Ljubljana</title>
    <ns>0</ns>
    <id>62277324</id>
    <revision>
      <id>1010696961</id>
      <parentid>969345326</parentid>
      <timestamp>2021-03-06T20:37:04Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <comment>+{{[[Template:Authority control|Authority control]]}} ([[d:Q12788734|1 ID]] from [[Wikidata]]), [[WP:GenFixes]] on</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2153" xml:space="preserve">{{Infobox university
| name=Faculty of Computer and Information Science, University of Ljubljana
| native_name=Fakulteta za računalništvo in informatiko, Univerza v Ljubljani
| image=
| established=1996
| type=[[Public university|Public]]
| dean= [[Mojca Ciglarič]]
| students=2,000
| address=Večna pot 113
| city=[[Ljubljana]]
| country=[[Slovenia]]
| affiliations = 
| website={{URL|www.fri.uni-lj.si/en}}|
}}

The '''Faculty of Computer and Information Science'''  ({{lang-sl|Fakulteta za računalništvo in informatiko}}, also known by the acronym '''FRI UL''') in [[Ljubljana]] is part of the [[University of Ljubljana]] and was founded in 1996.&lt;ref&gt;[https://issuu.com/ulfri/docs/zbornik_fri20_web_100 FRI 20 : 1996-2016 : 20 let Fakultete za računalništvo in informatiko Univerze v Ljubljani, 2016]  {{COBISS|ID=284639232}}&lt;/ref&gt;

The study of computer science at the University of Ljubljana began already in 1973, first as an elective study programme after the 2nd year of electrical engineering study, and since 1982 as 
an independent study programme. 
In 1996 the Faculty of Electrical Engineering and Computer Science split into two separate faculties and in 2014
the Faculty of Computer and Information Science finally moved to a new building at the western outskirts of Ljubljana.

The Faculty offers undergraduate, master's and doctoral programmes, including interdisciplinary programmes in cooperation with other faculties and universities.

Research at the Faculty of Computer and Information Science in Ljubljana is focused in the following areas:
*[[Machine learning]] and [[Artificial Intelligence]],
*[[Data science]],
*[[Theoretical computer science]] and [[Numerical analysis]],
*[[Software engineering]] and [[Informatics]],
*[[Computer architecture]] and [[Computer network]]ing, 
*[[Machine perception]] and [[Multimedia]].

==See also==
* [[List of University of Ljubljana people]]

== References ==
{{Reflist}}

{{Authority control}}

[[Category:Computer science]]
[[Category:Educational institutions in Ljubljana|Computer]]
[[Category:Faculties of the University of Ljubljana|Computer]]
[[Category:Information science]]</text>
      <sha1>di30rc2ke1u0auda3a5epoltn84h1rl</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer scientists</title>
    <ns>14</ns>
    <id>694790</id>
    <revision>
      <id>952540645</id>
      <parentid>952540433</parentid>
      <timestamp>2020-04-22T19:46:08Z</timestamp>
      <contributor>
        <ip>50.26.172.216</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="435" xml:space="preserve">This category of [[Computer scientist]]s consists of people who do research in the field of [[computer science]]: university professors, researchers employed by industry research laboratories, and independent researchers.
{{Commons category|Computer scientists}}
{{CatAutoTOC|numerals=no}}

[[Category:Computer science|.]]
[[Category:Computer specialists by field]]
[[Category:Scientists by field]]
[[Category:Mathematicians by field]]</text>
      <sha1>1g99bkyrae0d525nrr7ujk9dkb52cbq</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Subfields of computer science</title>
    <ns>14</ns>
    <id>33240744</id>
    <revision>
      <id>938069051</id>
      <parentid>938046403</parentid>
      <timestamp>2020-01-28T23:10:38Z</timestamp>
      <contributor>
        <username>Dimadick</username>
        <id>24198</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="151" xml:space="preserve">Subfields of [[computer science]].
{{Commons category}}

[[Category:Computer science|-]]
[[Category:Subfields by academic discipline|Computer science]]</text>
      <sha1>asqynx5zibrdjgpaehwn4115agmao2n</sha1>
    </revision>
  </page>
  <page>
    <title>Spatial computing</title>
    <ns>0</ns>
    <id>62638470</id>
    <revision>
      <id>1002698631</id>
      <parentid>1000477878</parentid>
      <timestamp>2021-01-25T17:53:05Z</timestamp>
      <contributor>
        <username>Spatialdb1</username>
        <id>38073054</id>
      </contributor>
      <comment>Added citation to article on digital twins.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3018" xml:space="preserve">{{Expert needed|1=Computer science|reason=Technical term which has various definitions|date=December 2019}}
'''Spatial computing''' was defined in 2003 by Simon Greenwold,&lt;ref&gt;{{cite web |last1=Greenwold |first1=Simon |title=Spatial Computing |url=https://acg.media.mit.edu/people/simong/thesis/SpatialComputing.pdf |publisher=MIT Graduate Thesis |accessdate=22 December 2019 |date=June 2003}}&lt;/ref&gt; as "human interaction with a machine in which the machine retains and manipulates referents to real objects and spaces".

It has also been coined in 2007 during the [https://drops.dagstuhl.de/opus/volltexte/2007/1025/ 0631 Dagstuhl workshop] by [https://www.seas.upenn.edu/~andre/ André DeHon], [https://www.ircam.fr/person/jean-louis-giavitto/ Jean-Louis Giavitto] and [https://www.lri.fr/~gruau/ Frédéric Gruau] for a field of research in computer science where space is not an abstract notion but a first-order effect that has to be optimized. The [http://www.spatial-computing.org/ Spatial Computing] web site gathers some work done on that subject. 

With the advent of consumer [[virtual reality]],&lt;ref&gt;{{cite web |last1=Rubin |first1=Peter |title=The WIRED Guide to Virtual Reality |url=https://www.wired.com/story/wired-guide-to-virtual-reality/ |website=WIRED |publisher=Condé Nast |accessdate=22 December 2019}}&lt;/ref&gt; [[augmented reality]],&lt;ref&gt;{{cite web |last1=Nichols |first1=Greg |title=Spatial computing is reinventing how mobile techs work |url=https://www.zdnet.com/article/spatial-computing-reinventing-mobile-techs-work/ |publisher=ZDNet |accessdate=22 December 2019}}&lt;/ref&gt; and [[mixed reality]], companies such as [[Microsoft]]&lt;ref&gt;{{cite web |title=A new era of spatial computing brings fresh challenges—and solutions—to VR |url=https://www.microsoft.com/en-us/research/blog/a-new-era-of-spatial-computing-brings-fresh-challenges-and-solutions-to-vr/ |publisher=Microsoft |accessdate=22 December 2019 |date=Oct 21, 2019}}&lt;/ref&gt; and [[Magic Leap]]&lt;ref&gt;{{cite web |author1=Abovitz, R |author2=Greco, P |author3=Pellet, Y |author4=Welch, H |author5=Sam Miller |title=Spatial Computing: An Overview for Our Techie Friends |url=https://www.magicleap.com/news/op-ed/spatial-computing-an-overview-for-our-techie-friends |publisher=Magic Leap |accessdate=22 December 2019}}&lt;/ref&gt;  use "spatial computing" in reference to the practice of using physical actions (head and body movements, gestures, speech) as [[Input (computer science)|inputs]] for interactive digital media systems, with perceived 3D physical space as the canvas for video, audio, and [[haptic technology|haptic]] [[Output (computing)|outputs]]. It is also tied to the concept of 'digital twins'.&lt;ref&gt;{{Cite web|last=Ling|first=Corinna E. Lathan,Geoffrey|title=Spatial Computing Could Be the Next Big Thing|url=https://www.scientificamerican.com/article/spatial-computing-could-be-the-next-big-thing/|access-date=2021-01-25|website=Scientific American|language=en}}&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Computer science]]</text>
      <sha1>tu3g4mzlfpiwu71ubgbzhwdl432d4jk</sha1>
    </revision>
  </page>
  <page>
    <title>Computer science education</title>
    <ns>0</ns>
    <id>21166866</id>
    <revision>
      <id>1001943453</id>
      <parentid>999319404</parentid>
      <timestamp>2021-01-22T02:38:46Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 17 templates: hyphenate params (8×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8002" xml:space="preserve">{{Educational research}}
'''Computer science education'''  or '''computing education''' is the science and art of [[teacher|teaching]] and [[learning]] of [[computer science]],&lt;ref&gt;{{Cite book|title=Computer Science Education Research|year=2004|publisher=Taylor &amp; Francis|last1=Fincher|first1=Sally|last2=Petre|first2=Marian|author-link2=Marian Petre|isbn=90-265-1969-9|location=London|oclc=54455019}}&lt;/ref&gt;&lt;ref name=sentance&gt;{{Cite book|title=Computer science education : perspectives on teaching and learning in school|last1=Sentance|first1=Sue|author-link1=Sue Sentance|last2=Barendsen|first2= Erik|last3=Schulte|first3=Carsten|isbn=978-1-350-05711-1|location=London|oclc=999588195|publisher=Bloomsbury|year=2018}}&lt;/ref&gt; [[computing]]&lt;ref name="BruckmanBiggers2009"&gt;{{cite journal|last1=Bruckman|first1=Amy|last2=Biggers|first2=Maureen|last3=Ericson|first3=Barbara|last4=McKlin|first4=Tom|last5=Dimond|first5=Jill|last6=DiSalvo|first6=Betsy|last7=Hewner|first7=Mike|last8=Ni|first8=Lijun|last9=Yardi|first9=Sarita|title=Georgia computes! Improving the computing education pipeline|journal=ACM SIGCSE Bulletin|volume=41|issue=1|year=2009|pages=86|issn=0097-8418|doi=10.1145/1539024.1508899}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://royalsociety.org/topics-policy/projects/computing-education/|author=Anon|year=2017|website=royalsociety.org|title=Computing education}}&lt;/ref&gt;&lt;ref name=cup&gt;{{cite book|last1=Fincher|first1=Sally A.|last2=Robins|first2=Anthony V.|year=2019|doi=10.1017/9781108654555|title=The Cambridge Handbook of Computing Education Research|oclc=1090781199|publisher=[[Cambridge University Press]]|isbn=9781108654555|url=https://kar.kent.ac.uk/73256/1/2019ToolsEnvironments.pdf}}&lt;/ref&gt;&lt;ref name=after&gt;{{cite book|url=https://royalsociety.org/-/media/policy/projects/computing-education/computing-education-report-summary.pdf|first=Steve|last=Furber|author-link=Steve Furber|title= After the reboot: computing education in UK schools|year=2017|isbn=9781782522973|publisher=[[Royal Society]]|location=London}}&lt;/ref&gt; and [[computational thinking]].&lt;ref name="Guzdial2008"&gt;{{cite journal|last1=Guzdial|first1=Mark|author-link=Mark Guzdial|title=Education: Paving the way for computational thinking|journal=Communications of the ACM|volume=51|issue=8|year=2008|pages=25–27|issn=0001-0782|doi=10.1145/1378704.1378713|s2cid=35737830}}&lt;/ref&gt;&lt;ref name="compthink"&gt;{{Cite journal | doi = 10.1145/1118178.1118215| title = Computational thinking| journal = [[Communications of the ACM]]| volume = 49| issue = 3| pages = 33–35| year = 2006| url = https://www.cs.cmu.edu/~15110-s13/Wing06-ct.pdf| last1 = Wing | first1 = Jeanette M. | s2cid = 1693513| author-link = Jeannette Wing}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | doi = 10.1098/rsta.2008.0118| pmid = 18672462| title = Computational thinking and thinking about computing| journal = Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences| volume = 366| issue = 1881| pages = 3717–3725| year = 2008| last1 = Wing | first1 = Jeanette M.|author-link=Jeannette Wing |bibcode = 2008RSPTA.366.3717W | pmc = 2696102}}&lt;/ref&gt; As a subdiscipline of [[pedagogy]] it also addresses the wider impact of computer science in society through its intersection with [[philosophy]], [[psychology]], [[linguistics]], [[natural science]]s, and [[mathematics]]. In comparison to  [[science education]] and [[mathematics education]], computer science education is a much younger field.&lt;ref name="history"&gt;{{Cite journal | doi = 10.1080/08993408.2018.1486624| title = Changing aims of computing education: a historical survey| journal = Computer Science Education| volume = 28| issue = 2| pages = 158–186| year = 2018| last1 = Tedre | first1 = Matti | last2 = Simon | last3 = Malmi | first3 = Lauri | bibcode = 2018CSEd...28..158T| s2cid = 52884221| url = https://aaltodoc.aalto.fi/handle/123456789/101473}}&lt;/ref&gt; In the [[history of computing]], digital computers were only built from around the [[1940s]] – although [[computation]] has been around for centuries since the invention of [[analog computer]]s.&lt;ref&gt;{{Cite book|last=Tedre|first= Matti|title=The science of computing : shaping a discipline|isbn=978-1-4822-1769-8|location=Boca Raton|oclc=870289913|year=2015}}&lt;/ref&gt;

Another differentiator of computer science education is that it has primarily only been taught at [[university]] level until recently, with some notable exceptions in [[Israel]], [[Poland]] and the [[United Kingdom]] with the [[BBC Micro]] in the [[1980s]] as part of [[Computer science education in the United Kingdom]].&lt;ref name=after/&gt;&lt;ref name="RogersShum2017"&gt;{{cite journal|last1=Rogers|first1=Yvonne|last2=Shum|first2=Venus|last3=Marquardt|first3=Nic|last4=Lechelt|first4=Susan|last5=Johnson|first5=Rose|last6=Baker|first6=Howard|last7=Davies|first7=Matt|title=From the BBC micro to micro:bit and beyond|journal=Interactions|volume=24|issue=2|year=2017|pages=74–77|issn=1072-5520|doi=10.1145/3029601|s2cid=24258819}}&lt;/ref&gt; Computer science has been a part of the school [[curricula]] from age 14 or age 16 in a few countries for a few decades, but has typically as an elective subject.

==Computing education research==
[[Educational research]] on computing and [[teaching methods]] in computer science is usually known as ''Computing Education Research''.&lt;ref name=cup/&gt;&lt;ref name="CooperGrover2014"&gt;{{cite journal|last1=Cooper|first1=Steve|last2=Grover|first2=Shuchi|last3=Guzdial|first3=Mark|last4=Simon|first4=Beth|title=A future for computing education research|journal=Communications of the ACM|volume=57|issue=11|year=2014|pages=34–36|issn=0001-0782|doi=10.1145/2668899|s2cid=34034556}}&lt;/ref&gt; The [[Association for Computing Machinery]] (ACM) runs a [[Special Interest Group]] (SIG) on Computer science education known as [[SIGCSE]] which celebrated its 50th anniversary in 2018, making it one of the oldest and longest running ACM Special Interest Groups.&lt;ref name="MorrisonSettle2018"&gt;{{cite journal|last1=Morrison|first1=Briana|last2=Settle|first2=Amber|author-link2=Amber Settle|title=Celebrating SIGCSE's 50th anniversary!|journal=ACM SIGCSE Bulletin|volume=50|issue=1|year=2018|pages=2–3|issn=0097-8418|doi=10.1145/3183559.3183560|s2cid=19169248}}&lt;/ref&gt;

==Women in computer science==
In many countries, there is a significant gender gap in computer science education. In 2015, 15.3% of computer science students graduating from non-doctoral granting institutions in the US were women while at doctoral granting institutions, the figure was 16.6%.&lt;ref&gt;{{Cite web|title=The Mixed News on Diversity and the Enrollment Surge|url=https://cra.org/data/generation-cs/diversity/|date=2017-02-10|website=CRA|language=en-US|access-date=2020-05-05}}&lt;/ref&gt; The number of female PhD recipients in the US was 19.3% in 2018.&lt;ref&gt;2018 Taulbee Survey, Computing Research Association. https://cra.org/wp-content/uploads/2019/05/2018_Taulbee_Survey.pdf&lt;/ref&gt; The gender gap also exists in other western countries.&lt;ref name="gender"&gt;{{cite web|title=IT gender gap: Where are the female programmers? |url =http://www.techrepublic.com/blog/software-engineer/it-gender-gap-where-are-the-female-programmers/|first = Justin |last = James |work = TechRepublic}}&lt;/ref&gt; The gap is smaller, or nonexistent, in some parts of the world. In 2011, women earned half of the computer science degrees in [[Malaysia]].&lt;ref&gt;{{cite web|title=what ''[sic!]'' gender is science|url=http://www.soc.ucsb.edu/faculty/mariacharles/documents/WhatGenderisScience.pdf|access-date=July 20, 2015|archive-url=https://web.archive.org/web/20150924103245/http://www.soc.ucsb.edu/faculty/mariacharles/documents/WhatGenderisScience.pdf|archive-date=September 24, 2015|url-status=dead}}&lt;/ref&gt; In 2001, 55 percent of computer science graduates in [[Guyana]] were women.&lt;ref name="gender"/&gt;

==References==
{{reflist}}

{{Education by subject}}

{{DEFAULTSORT:Computer Science Education}}
[[Category:Computer science education| ]]
[[Category:Computer science]]
[[Category:Education]]</text>
      <sha1>avwwuisw5shbe6lim8elcszyiqdpdlg</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Problems in computer science</title>
    <ns>14</ns>
    <id>63383257</id>
    <revision>
      <id>946303542</id>
      <parentid>945728076</parentid>
      <timestamp>2020-03-19T10:06:28Z</timestamp>
      <contributor>
        <username>Andrybak</username>
        <id>23735172</id>
      </contributor>
      <comment>prepare categorization of [[:Category:Unsolved problems in computer science]]: - 3 categories; + 3 categories using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="151" xml:space="preserve">Problems in computer science

[[Category:Computer science]]
[[Category:Theoretical computer science]]
[[Category:Scientific problems|Computer science]]</text>
      <sha1>o55u5taxshfdyv5oy4fpmj2xrnnhsug</sha1>
    </revision>
  </page>
  <page>
    <title>The MICCAI Society</title>
    <ns>0</ns>
    <id>63572622</id>
    <revision>
      <id>1007474375</id>
      <parentid>1004981734</parentid>
      <timestamp>2021-02-18T09:17:20Z</timestamp>
      <contributor>
        <username>WikiCleanerBot</username>
        <id>18872885</id>
      </contributor>
      <minor/>
      <comment>v2.04b - [[User:WikiCleanerBot#T20|Bot T20 CW#61]] - Fix errors for [[WP:WCW|CW project]] (Reference before punctuation)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="21150" xml:space="preserve">{{Infobox organization
| logo = Miccai official logo.png
| type = Professional association
| key_people = [[Leo Joskowicz]] (President)
| name = The MICCAI Society
| full_name = The Medical Image Computing and Computer Assisted Intervention Society
| founded_date = {{start date and age|2004|7|29}}
| founder = 
| tax_id = 
| status = [[501(c)(3) organization|501(c)(3)]] [[nonprofit organization]]
| location = 
| origins = 
| focus = [[Computer Vision]], [[Medical Imaging]], [[Medical Devices]]
| method = Industry standards, Conferences, Publications
| revenue = 
| endowment = 
| num_volunteers = 
| num_employees = 
| num_members = 
| Non-profit_slogan = 
| homepage = {{URL|http://www.miccai.org}}
}}
'''The MICCAI Society''' is a professional organization for scientists in the areas of [[Medical Image Computing]] and [[Computer Assisted Interventions]]. Due to the multidisciplinary nature of these fields, the society brings together researchers from several scientific disciplines.&lt;ref&gt;{{cite web |title=King's School of Biomedical Engineering &amp; Imaging Sciences has prominent representation at MICCAI 2019 |url=https://www.kcl.ac.uk/news/kings-school-of-biomedical-engineering-imaging-sciences-has-prominent-representation-at-miccai-2019 |website=www.kcl.ac.uk |accessdate=7 April 2020}}&lt;/ref&gt; including [[computer science]], [[robotics]], [[physics]], and [[medicine]]. The society is best known for its annual flagship event, [[#Annual MICCAI Conference|The MICCAI Conference]], which facilitates the publication and presentation of original research on MICCAI-related topics.&lt;ref&gt;{{cite web |title=MICCAI 2020 - 23. International Conference On Medical Image Computing &amp; Computer Assisted Intervention |url=https://miccai2020.org/en/ |website=miccai2020.org |accessdate=7 April 2020}}&lt;/ref&gt; However, the society provides endorsements and sponsorships for several scientific events each year.&lt;ref&gt;{{cite web |title=Events |url=http://www.miccai.org/events/ |website=www.miccai.org |accessdate=7 April 2020}}&lt;/ref&gt;

== History ==

In 1998, three international conferences: Visualization in Biomedical Computing (VBC), Computer Vision and Virtual Reality in Robotics and Medicine (CVRMed), and Medical Robotics and Computer Assisted Surgery (MRCAS) merged into a single conference entitled "The International Conference on Medical Image Computing and Computer Assisted Interventions" (abbreviated MICCAI) with its first edition in [[Boston]]. The MICCAI Society was founded in 2004 by several active members of this research community and former chairs of the MICCAI conference.&lt;ref&gt;{{cite web |title=History |url=http://www.miccai.org/about-miccai/history/ |website=www.miccai.org |accessdate=7 April 2020}}&lt;/ref&gt; In 2009, the society introduced the "MICCAI Fellow" award to recognize senior members who had made substantial contributions to the MICCAI community. 12 fellows were elected in 2009 and three additional fellows are elected each year. New MICCAI Fellows are announced each year at the [[#Annual MICCAI Conference|Annual MICCAI Conference]].&lt;ref&gt;{{cite web |title=Fellows |url=http://www.miccai.org/about-miccai/miccai-fellows/ |website=www.miccai.org |accessdate=7 April 2020}}&lt;/ref&gt; Since 2012, the society is involved in several events each year outside of the annual conference through endorsements and/or sponsorships. These include a number of smaller international conferences, MICCAI-focused workshop sessions at related conferences, and educational programs such as "summer schools".&lt;ref&gt;{{cite web |title=Events |url=http://www.miccai.org/events/ |website=www.miccai.org |accessdate=7 April 2020}}&lt;/ref&gt;

== Research focus ==

=== Medical Image Computing ===
{{Main|Medical Image Computing}}

Medical Image Computing (the "MIC" in MICCAI) is the field of study involving the application of [[image processing]] and [[computer vision]] to [[medical imaging]]. The goals of medical image computing tasks are diverse, but some common examples are [[computer-aided diagnosis]], [[image segmentation]] of anatomical structures and/or abnormalities, and the [[image registration|registration]] or "alignment" of medical images acquired through different means or at different points in time.{{citation needed|date=April 2020}}

=== Computer Assisted Interventions ===
{{Main|Computer Assisted Interventions}}

Computer Assisted Interventions (the "CAI" in MICCAI) is the field of study concerned with the use of computational tools in [[Medical procedure|medical interventions]]. Prominent examples of computer aided interventions currently in widespread use include image guided [[biopsy]] and [[robot-assisted surgery]]. Integral to this research area is effective [[human-computer interaction]] and [[user interface design]].{{citation needed|date=April 2020}}

== Subgroups ==

Within the MICCAI community, a number of organizations have emerged to represent and advocate for certain populations of MICCAI researchers. Among these are the [[#MICCAI Student Board|MICCAI Student Board]] and the [[#Women in MICCAI Committee|Women in MICCAI Committee]].

=== MICCAI Student Board ===

The MICCAI Student Board began in 2010 when MICCAI initiated its [[social media]] presence by creating a [[facebook]] group. This effort was championed by student researchers who used the group to organize events specifically for students at the 2011 and 2012 annual conferences. After the 2012 event, the MICCAI board of directors formally recognized the MICCAI student board as a part of the society and began providing support for the student board's annual events.&lt;ref&gt;{{cite web |title=Student Board |url=http://www.miccai.org/about-miccai/student-board/ |website=www.miccai.org |accessdate=7 April 2020}}&lt;/ref&gt;

=== Women in MICCAI Committee ===

The Women in MICCAI Committee began as a series of networking sessions for female researchers within the medical image analysis research community during the 2015 MICCAI conference and the 2016 [[Institute of Electrical and Electronics Engineers|IEEE]] International Symposium on Biomedical Imaging. In October 2016, the MICCAI board of directors approved a measure to create the "Women in MICCAI Committee" with the goal of strengthening the representation of female scientists in this research area.

Since its inception, the Women in MICCAI Committee has continued to organize networking sessions in conjunction with MICCAI events. It also developed and maintains several online platforms for discussion on [[social media]]. The committee is the primary interface between the MICCAI board of directors and the community of women researchers in MICCAI.&lt;ref&gt;{{cite web |title=Women in MICCAI |url=http://www.miccai.org/about-miccai/women-in-miccai/ |website=www.miccai.org |accessdate=7 April 2020}}&lt;/ref&gt;

== Annual MICCAI conference ==

=== Conference format ===

MICCAI conferences are typically scheduled for five days, of which the first and last days set aside for ''satellite events'' consisting of [[Tutorial#Conference tutorials|tutorials]], workshops, and [[Competitions and prizes in artificial intelligence|challenges]]. Those include  the Brain lesion workshop (BrainLes),&lt;ref&gt;{{cite web |title=Brainles |url=http://www.brainlesion-workshop.org// |website=www.brainlesion-workshop.org |accessdate=5 February 2021}}&lt;/ref&gt;  the Workshop on Interpretability of Machine Intelligence in Medical Image Computing (iMIMIC),&lt;ref&gt;{{cite web |title=iMIMIC |url=https://imimic-workshop.com/// |website=imimic-workshop.com/ |accessdate=5 February 2021}}&lt;/ref&gt; Domain Adaptation and Representation Transfer (DART),&lt;ref&gt;{{cite web |title=DART |url=https://sites.google.com/view/dart2020/ |website=https://sites.google.com/view/dart2020/ |accessdate=5 February 2021}}&lt;/ref&gt; and others.&lt;ref&gt;{{cite web |title=Grand Challenge |url=https://grand-challenge.org/Why_Challenges/ |website=grand-challenge.org |accessdate=7 April 2020 |language=en}}&lt;/ref&gt; The main conference includes invited presentations, panel discussions, and podium and poster presentations of original research papers which are published by [[Springer Nature]] as conference proceedings.&lt;ref&gt;{{cite web |title=MICCAI - International Society and Conference Series on Medical Image Computing and Computer-Assisted Intervention |url=https://www.springer.com/gp/computer-science/lncs/societies-and-lncs/miccai/734372 |website=Springer.com |publisher=Springer |accessdate=5 April 2020}}&lt;/ref&gt;

=== Past MICCAI conferences ===

{| class="wikitable sortable"
|-
! Year !! Dates !! Location !! General Chair(s)
|-
| 2020&lt;ref&gt;{{cite book |last1=Martel |first1=Anne L. |last2=Abolmaesumi |first2=Purang |last3=Stoyanov |first3=Danail |last4=Mateus |first4=Diana |last5=Zuluaga |first5=Maria A. |last6=Zhou |first6=Kevin S. |last7=Racoceanu |first7=Daniel |last8=Joskowicz |first8=Leo |title=Medical Image Computing and Computer Assisted Intervention-MICCAI 2020: 23rd International Conference, Lima, Peru, October 4-8, 2020, Proceedings |date=2020 |publisher=Springer Nature |access-date=5 January 2021}}&lt;/ref&gt; || October 4–8, 2020 || [[Lima]] || Daniel Racoceanu, [[Leo Joskowicz]]
|-
| 2019&lt;ref&gt;{{cite book |last1=Shen |first1=Dinggang |last2=Liu |first2=Tianming |last3=Peters |first3=Terry |last4=Staib |first4=Lawrence |last5=Essert |first5=Caroline |last6=Zhou |first6=Sean |last7=Yap |first7=Pew-Thian |last8=Khan |first8=Ali |title=Medical image computing and computer assisted intervention -- MICCAI 2019 : 22nd International Conference, Shenzhen, China, October 13-17, 2019, Proceedings. Part VI |publisher=Springer, Cham |isbn=978-3-030-32226-7}}&lt;/ref&gt; || October 13–17, 2019 || [[Shenzhen]] || Dinggang Shen
|-
| 2018&lt;ref&gt;{{cite book |last1=Frangi |first1=Alejandro |last2=Schnabel |first2=Julia |last3=Davatzikos |first3=Christos |last4=Alberola-López |first4=Carlos |last5=Fichtinger |first5=Gabor |title=Medical image computing and computer assisted intervention -- MICCAI 2018 : 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings. Part IV |publisher=Springer, Cham |isbn=978-3-030-00937-3}}&lt;/ref&gt; || September 16–20, 2018 || [[Granada]] || [[Alejandro Frangi Caregnato]]
|-
| 2017&lt;ref&gt;{{cite book |last1=Maier-Hein |first1=Lena |last2=Franz |first2=Alfred |last3=Jannin |first3=Pierre |last4=Collins |first4=D. Louis |last5=Duchesne |first5=Simon |title=Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2017 : 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings. Part II |publisher=Springer, Cham |isbn=978-3-319-66182-7}}&lt;/ref&gt; || September 10–14, 2017 || [[Quebec City]] || Simon Duchesne
|-
| 2016&lt;ref&gt;{{cite book |last1=Ourselin |first1=Sebastian |last2=Joskowicz |first2=Leo |last3=Sabuncu |first3=Mert |last4=Unal |first4=Gozde |last5=Wells |first5=William |title=Medical image computing and computer-assisted intervention -- MICCAI 2016 : 19th International Conference, Athens, Greece, October 17-21, 2016, Proceedings. Part I |publisher=Springer, Cham |isbn=978-3-319-46720-7}}&lt;/ref&gt; || October 17–21, 2016 || [[Athens]] || Sebastien Ourselin, [[Aytül Erçil]]
|-
| 2015&lt;ref&gt;{{cite book |last1=Navab |first1=Nassir |last2=Hornegger |first2=Joachim |last3=Wells |first3=William |last4=Frangi |first4=Alejandro |title=Medical image computing and computer-assisted intervention -- MICCAI 2015 : 18th International Conference Munich, Germany, October 5-9, 2015, Proceedings. Part I |publisher=Springer, Cham |isbn=978-3-319-24553-9}}&lt;/ref&gt; || October 5–9, 2015 || [[Munich]] || Nassir Navab
|-
| 2014&lt;ref&gt;{{cite book |last1=Golland |first1=Polina |last2=Hata |first2=Nobuhiko |last3=Barillot |first3=Christian |last4=Hornegger |first4=Joachim |last5=Howe |first5=Robert |title=Medical image computing and computer-assisted intervention - MICCAI 2014 : 17th International Conference, Boston, MA, USA, September 14-18, 2014 : proceedings. Part I |publisher=Springer, Cham |isbn=978-3-319-10404-1}}&lt;/ref&gt; || September 14–18, 2014 || [[Cambridge, Massachusetts|Cambridge]] || Polina Golland
|-
| 2013&lt;ref&gt;{{cite book |last1=Mori |first1=Kensaku |last2=Sakuma |first2=Ichiro |last3=Sato |first3=Yoshinobu |last4=Barillot |first4=Christian |last5=Navab |first5=Nassir |title=Medical image computing and computer-assisted intervention-- MICCAI 2013 : 16th International Conference, Nagoya, Japan, September 22-26, 2013, Proceedings. Part II |publisher=Springer-Verlag |isbn=978-3-642-40763-5}}&lt;/ref&gt; || September 22–26, 2013 || [[Nagoya]] || Kensaku Mori
|-
| 2012&lt;ref&gt;{{cite book |last1=Ayache |first1=Nicholas |last2=Delingette |first2=Hervé |last3=Golland |first3=Polina |last4=Mori |first4=Kensaku |title=Medical image computing and computer-assisted intervention--MICCAI 2012. Part III : 15th International Conference, Nice, France, October 1-5, 2012, Proceedings |publisher=Springer |isbn=978-3-642-33454-2}}&lt;/ref&gt; || October 1–5, 2012 || [[Nice, France|Nice]] || [[Nicholas Ayache]]
|-
| 2011&lt;ref&gt;{{cite book |last1=Fichtinger |first1=Gabor |last2=Martel |first2=Anne |last3=Peters |first3=Terry |title=Medical image computing and computer-assisted intervention-- MICCAI 2011 : 14th International Conference, Toronto, Canada, September 18-22, 2011, proceedings. Part II |publisher=Springer |isbn=978-3-642-23629-7}}&lt;/ref&gt; || September 18–22, 2011 || [[Toronto]] || [[Gabor Fichtinger]]
|-
| 2010&lt;ref&gt;{{cite book |last1=Jiang |first1=Tianzi |last2=Navab |first2=Nassir |last3=Pluim |first3=Josien |last4=Viergever |first4=Max |title=Medical image computing and computer-assisted intervention - MICCAI 2010 : 13th international conference, Beijing, China, September 20-24, 2010, proceedings. Part I |publisher=Springer |isbn=978-3-642-15705-9}}&lt;/ref&gt; || September 20–24, 2010 || [[Beijing]] || Tingting Jiang
|-
| 2009&lt;ref&gt;{{cite book |last1=Yang |first1=Guang-Zhong |last2=Hawkes |first2=David |last3=Rueckert |first3=Daniel |last4=Noble |first4=Allison |last5=Taylor |first5=Chris |title=Medical Image Computing and Computer-Assisted Intervention - MICCAI 2009 : 12th International Conference, London, UK, September 20-24, 2009, Proceedings. Part I |publisher=Springer-Verlag |isbn=978-3-642-04268-3}}&lt;/ref&gt; || September 20–24, 2009 || [[London]] || Guang-Zhong Yang
|-
| 2008&lt;ref&gt;{{cite book |last1=Metaxas |first1=Dimitris |last2=Axel |first2=Leon |last3=Fichtinger |first3=Gabor |last4=Székely |first4=Gábor |title=Medical image computing and computer-assisted intervention - MICCAI 2008 : 11th international conference, New York, NY, USA, September 6-10, 2008 ; proceedings : part I |publisher=Springer |isbn=978-3-540-85988-8}}&lt;/ref&gt; || September 6–10, 2008 || [[New York City]] || [[Dimitris Metaxas]]
|-
| 2007&lt;ref&gt;{{cite book |last1=Ayache |first1=Nicholas |last2=Ourselin |first2=Sébastien |last3=Maeder |first3=Anthony |title=Medical image computing and computer-assisted intervention : MICCAI 2007 : 10th international conference, Brisbane, Australia, October 29-November 2, 2007 : proceedings |publisher=Springer |isbn=978-3-540-75759-7}}&lt;/ref&gt; || October 29 - November 2, 2007 || [[Brisbane]] || Anthony Maeder
|-
| 2006&lt;ref&gt;{{cite book |last1=Larsen |first1=Rasmus |last2=Nielsen |first2=Mads |last3=Sporring |first3=Jon |title=Medical image computing and computer-assisted intervention : MICCAI 2006 : 9th international conference, Copenhagen, Denmark, October 1-6, 2006 : proceedings |publisher=Springer |isbn=978-3-540-44728-3}}&lt;/ref&gt; || October 1–6, 2006 || [[Copenhagen]] || Mads Nielsen
|-
| 2005&lt;ref&gt;{{cite book |last1=Duncan |first1=James |last2=Gerig |first2=Guido |title=Medical image computing and computer-assisted intervention : MICCAI 2005 : 8th international conference, Palm Springs, CA, USA, October 26-29, 2005 : proceedings |publisher=Springer |isbn=978-3-540-32095-1}}&lt;/ref&gt; || October 26–29, 2005 || [[Palm Springs]] || James Duncan
|-
| 2004&lt;ref&gt;{{cite book |last1=Barillot |first1=Christian |last2=Haynor |first2=David |last3=Hellier |first3=Pierre |title=Medical Image Computing and Computer-Assisted Intervention MICCAI 2004 00 : 7th International Conference, Saint-Malo, France, September 26-29, 2004. Proceedings, Part I |publisher=Springer-Verlag Berlin Heidelberg |isbn=978-3-540-30135-6}}&lt;/ref&gt; || September 26–29, 2004 || [[St. Malo]] || Christian Barillot
|-
| 2003&lt;ref&gt;{{cite book |last1=Ellis |first1=Randy |last2=Terry |first2=Peters |title=Medical Image Computing and Computer-Assisted Intervention - MICCAI 2003. |publisher=Springer Berlin / Heidelberg |isbn=978-3-540-39903-2}}&lt;/ref&gt; || November 15–18, 2003 || [[Montreal]] || Terry Peters
|-
| 2002&lt;ref&gt;{{cite book |last1=Dohi |first1=Takeyoshi |last2=Kikinis |first2=Ron |title=Medical Image Computing and Computer-Assisted Intervention " MICCAI 2002 : 5th International Conference Tokyo, Japan, September 25 28, 2002 Proceedings, Part I. |publisher=Springer-Verlag Berlin Heidelberg |isbn=978-3-540-45786-2}}&lt;/ref&gt; || September 25–28, 2002 || [[Tokyo]] || Takeyoshi Dohi
|-
| 2001&lt;ref&gt;{{cite book |last1=Niessen |first1=Wiro |last2=Viergever |first2=Max |title=Medical Image Computing and Computer-Assisted Intervention MICCAI 2001 : 4th International Conference Utrecht, The Netherlands, October 14 17, 2001 Proceedings. |publisher=Springer-Verlag Berlin Heidelberg |isbn=978-3-540-45468-7}}&lt;/ref&gt; || October 14–17, 2001 || [[Utrecht]] || Max Viergever
|-
| 2000&lt;ref&gt;{{cite book |last1=Delp |first1=Scott |last2=DiGoia |first2=Anthony |last3=Branislav |first3=Jamaraz |title=Medical Image Computing and Computer-Assisted Intervention MICCAI 2000 00 : Third International Conference, Pittsburgh, PA, USA, October 11-14, 2000. Proceedings |publisher=Springer-Verlag Berlin Heidelberg |isbn=978-3-540-40899-4}}&lt;/ref&gt; || October 11–14, 2000 || [[Pittsburgh]] || Anthony M. DiGoia
|-
| 1999&lt;ref&gt;{{cite book |last1=Taylor |first1=Chris |last2=Colchester |first2=Alain |title=Medical Image Computing and Computer-Assisted Intervention – MICCAI’99 |date=1999 |publisher=Springer}}&lt;/ref&gt; || September 19–22, 1999 || [[Cambridge]] || Alan Colchester
|-
| 1998&lt;ref&gt;{{cite book |last1=Wells |first1=William |last2=Colchester |first2=Alan |last3=Delp |first3=Scott |title=Medical Image Computing and Computer-Assisted Intervention — MICCAI’98 |date=1998 |publisher=Springer}}&lt;/ref&gt; || October 11–13, 1998 || [[Boston]] || [[Ron Kikinis]]
|}

=== Upcoming MICCAI conferences ===

{| class="wikitable sortable"
|-
! Year !! Dates !! Location !! General Chair(s)
|-
| 2021 || September 27 - October 1, 2021 || [[Strasbourg]] || Caroline Essert
|-
| 2022 || September 18–22, 2022 || [[Singapore]] || Shuo Li
|-
| 2023 || October 8–12, 2023 || [[Vancouver]] || Tanveer Syeda-Mahmood, James Duncan, and Russ Taylor
|-
| 2024 || October 6–10, 2024 || [[Marrakesh]] || Karim Lekadir and [[Julia Schnabel]]
|}

== Publications ==

The MICCAI [[conference proceeding]]s consist of full-length papers which undergo comprehensive [[peer review]]. Since even before the merger of the CVRMed, MRCAS, and VBC conferences (see [[#History|History]]), the proceedings of the annual conference have been published by [[Springer Nature]] as part of the [[Lecture Notes in Computer Science]] (LNCS) series.&lt;ref&gt;{{cite web |title=MICCAI |url=https://www.springer.com/gp/computer-science/lncs/societies-and-lncs/miccai/734372 |website=www.springer.com |accessdate=7 April 2020 |language=en}}&lt;/ref&gt;


In addition to the proceedings of the annual conference, MICCAI officially partners with two peer reviewed [[scientific journals]]: "Medical Image Analysis" published by [[Elsevier]]&lt;ref&gt;{{cite web |title=Medical Image Analysis |url=https://www.journals.elsevier.com/medical-image-analysis |website=Elsevier Journals |publisher=Elsevier |accessdate=7 April 2020}}&lt;/ref&gt; and "[[International Journal of Computer Assisted Radiology and Surgery|The International Journal of Computer Assisted Radiology and Surgery]]" (IJCARS) published by [[Springer Nature]].&lt;ref&gt;{{cite web |title=International Journal of Computer Assisted Radiology and Surgery |url=https://www.springer.com/journal/11548 |website=Springer |accessdate=7 April 2020 |language=en}}&lt;/ref&gt; These journals loosely correspond to the "MIC" and "CAI" focuses of the MICCAI Society respectively, but they have substantial overlap in subject matter.

The MICCAI Society also partners with Elsevier to develop a series of books on MICCAI-related research, written by scientists in the MICCAI research community. {{As of|2020|April}}, nine books have been published in this series&lt;ref&gt;{{cite web |title=MICCAI Book Series |url=http://www.miccai.org/publications/miccai-book-series/ |website=www.miccai.org |accessdate=7 April 2020}}&lt;/ref&gt;

== See also ==
* [[Robot-assisted surgery]]
* [[Computer vision]]
* [[Conference on Computer Vision and Pattern Recognition]]
* [[International Conference on Computer Vision]]
* [[European Conference on Computer Vision]]
* [[Institute of Electrical and Electronics Engineers]]
* [[International Society for Computer Aided Surgery]]

== References ==
{{reflist}}

== External links ==
* [http://www.miccai.org The MICCAI Society Website]

{{Authority control}}

[[Category:Computer science]]</text>
      <sha1>csmqivkxbr72l35s2k0c0i3vhwq1cnt</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer hardware</title>
    <ns>14</ns>
    <id>699548</id>
    <revision>
      <id>950593162</id>
      <parentid>905604515</parentid>
      <timestamp>2020-04-12T22:07:50Z</timestamp>
      <contributor>
        <ip>188.146.230.233</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="318" xml:space="preserve">{{Category diffuse}}
{{Cat main|Computer hardware}}
{{Infobox library classification |DDC= |LCC= |UDC=0 004.3}}
{{Commons category|Computer hardware}}

[[Category:Computer engineering]]
[[Category:Computer science]]
[[Category:Computer systems|Hardware]]
[[Category:Computers|Hardware]]
[[Category:Manufactured goods]]</text>
      <sha1>pf64ppw63m215kf33jw9bl4oefyqqie</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Embedded systems</title>
    <ns>14</ns>
    <id>852879</id>
    <revision>
      <id>969859022</id>
      <parentid>963466472</parentid>
      <timestamp>2020-07-27T20:12:28Z</timestamp>
      <contributor>
        <username>Fayenatic london</username>
        <id>1639942</id>
      </contributor>
      <minor/>
      <comment>reinstate template per consensus at [[Template_talk:CatAutoTOC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="478" xml:space="preserve">{{Commons category|Embedded systems}}
This category includes articles about all aspects of '''[[embedded system]]s''': various systems, constituent components, uses, development tools, etc. For classes of software/devices, the category, if existent, or the relevant general article, is preferably included instead of each actual item.

[[Category:Classes of computers]]
[[Category:Computer engineering]]
[[Category:Computer science]]
[[Category:Computer systems]]
{{CatAutoTOC}}</text>
      <sha1>buk31mvw7jphtxt8dvvlg88yceyoouo</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer systems</title>
    <ns>14</ns>
    <id>1940227</id>
    <revision>
      <id>975665049</id>
      <parentid>950602190</parentid>
      <timestamp>2020-08-29T19:19:47Z</timestamp>
      <contributor>
        <username>Mike Peel</username>
        <id>214232</id>
      </contributor>
      <comment>Change {{Commons}} to {{Commons category}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="302" xml:space="preserve">{{Commons category}}
{{Cat main|Computer}}

Computer system is defined as the combination of hardware, software, user and data.

[[Category:Computer engineering|Systems]]
[[Category:Computer science|Systems]]
[[Category:Computers|Systems]]
[[Category:Computing|Systems]]
[[Category:Technology systems]]</text>
      <sha1>j0luihm3q4qpkcesax942sae2ujez3j</sha1>
    </revision>
  </page>
  <page>
    <title>Digital signal processing</title>
    <ns>0</ns>
    <id>8525</id>
    <revision>
      <id>1011170129</id>
      <parentid>1007105508</parentid>
      <timestamp>2021-03-09T12:21:46Z</timestamp>
      <contributor>
        <ip>77.139.59.160</ip>
      </contributor>
      <comment>/* Techniques */ Duplicate?</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="22627" xml:space="preserve">{{Redirect|Digital transform|the impact of digital technology on society|Digital transformation}}
{{short description|Mathematical signal manipulation by computers}}

{{More citations needed|date=May 2008}}

'''Digital signal processing''' ('''DSP''') is the use of [[digital processing]], such as by computers or more specialized [[digital signal processor]]s, to perform a wide variety of [[signal processing]] operations.  The [[digital signals]] processed in this manner are a sequence of numbers that represent [[Sampling (signal processing)|samples]] of a [[continuous variable]] in a domain such as time, space, or frequency. In [[digital electronics]], a digital signal is represented as a [[pulse train]],&lt;ref&gt;{{cite book |author=B. SOMANATHAN NAIR |title=Digital electronics and logic design |date=2002 |isbn=9788120319561 |publisher=PHI Learning Pvt. Ltd. |quote=Digital signals are fixed-width pulses, which occupy only one of two levels of amplitude. |page=289}}&lt;/ref&gt;&lt;ref&gt;{{cite book |author=Joseph Migga Kizza |isbn=9780387204734 |date=2005 |publisher=Springer Science &amp; Business Media |title=Computer Network Security}}&lt;/ref&gt; which is typically generated by the switching of a [[transistor]].&lt;ref&gt;{{cite book |title=2000 Solved Problems in Digital Electronics |date=2005 |publisher=[[Tata McGraw-Hill Education]] |isbn=978-0-07-058831-8 |page=151 |url=https://books.google.com/books?id=N6FDii6_nSEC&amp;pg=PA151}}&lt;/ref&gt;

Digital signal processing and [[analog signal processing]] are subfields of signal processing. DSP applications include [[Audio signal processing|audio]] and [[speech processing]], [[sonar]], [[radar]] and other [[sensor array]] processing, [[spectral density estimation]], [[statistical signal processing]], [[digital image processing]], [[data compression]], [[video coding]], [[audio coding]], [[image compression]], signal processing for [[telecommunication]]s, [[control system]]s, [[biomedical engineering]], and [[seismology]], among others.

DSP can involve linear or nonlinear operations. Nonlinear signal processing is closely related to [[nonlinear system identification]]&lt;ref&gt;{{cite book |last=Billings |first=Stephen A. |title=Nonlinear System Identification: NARMAX Methods in the Time, Frequency, and Spatio-Temporal Domains |publisher=Wiley |isbn=978-1-119-94359-4 |date=Sep 2013 |location=UK}}&lt;/ref&gt;  and can be implemented in the [[Time domain|time]], [[Frequency domain|frequency]], and [[Film|spatio-temporal domains]].&lt;!--sort of a flip stab at a wikilink for this concept. Readers ''might'' get the idea.--&gt;

The application of digital computation to signal processing allows for many advantages over analog processing in many applications, such as [[error detection and correction]] in transmission as well as [[data compression]].&lt;ref&gt;{{cite book |title=Digital Signal Processing: Instant access |last1=Broesch |first1=James D. |last2=Stranneby |first2=Dag |last3=Walker |first3=William |date=2008-10-20 |publisher=Butterworth-Heinemann-Newnes |edition=1 |isbn=9780750689762 |page=3}}&lt;/ref&gt; Digital signal processing is also fundamental to [[digital electronics|digital technology]], such as [[digital telecommunication]] and [[wireless communications]].&lt;ref name="Srivastava"&gt;{{cite book |last1=Srivastava |first1=Viranjay M. |last2=Singh |first2=Ghanshyam |title=MOSFET Technologies for Double-Pole Four-Throw Radio-Frequency Switch |date=2013 |publisher=[[Springer Science &amp; Business Media]] |isbn=9783319011653 |page=1 |url=https://books.google.com/books?id=fkO9BAAAQBAJ&amp;pg=PA1}}&lt;/ref&gt; DSP is applicable to both [[streaming data]] and static (stored) data.

== Signal sampling ==
{{Main|Sampling (signal processing)}}

To digitally analyze and manipulate an analog signal, it must be digitized with an [[analog-to-digital converter]] (ADC).&lt;ref&gt;{{cite journal |last=Walden |first=R. H. |date=1999 |title=Analog-to-digital converter survey and analysis |journal=IEEE Journal on Selected Areas in Communications |volume=17 |issue=4 |pages=539–550 |doi=10.1109/49.761034}}&lt;/ref&gt; Sampling is usually carried out in two stages, [[discretization]] and [[Quantization (signal processing)|quantization]]. Discretization means that the signal is divided into equal intervals of time, and each interval is represented by a single measurement of amplitude.  Quantization means each amplitude measurement is approximated by a value from a finite set.  Rounding [[real numbers]] to integers is an example.

The [[Nyquist–Shannon sampling theorem]] states that a signal can be exactly reconstructed from its samples if the sampling frequency is greater than twice the highest frequency component in the signal. In practice, the sampling frequency is often significantly higher than twice the [[Nyquist frequency]].&lt;ref&gt;{{cite journal |last1=Candes |first1=E. J. |last2=Wakin |first2=M. B. |date=2008 |title=An Introduction To Compressive Sampling |journal=IEEE Signal Processing Magazine |volume=25 |issue=2 |pages=21–30 |doi=10.1109/MSP.2007.914731|s2cid=1704522 }}&lt;/ref&gt;

Theoretical DSP analyses and derivations are typically performed on [[discrete-time signal]] models with no amplitude inaccuracies ([[quantization error]]), "created" by the abstract process of [[Sampling (signal processing)|sampling]]. Numerical methods require a quantized signal, such as those produced by an ADC.  The processed result might be a frequency spectrum or a set of statistics.  But often it is another quantized signal that is converted back to analog form by a [[digital-to-analog converter]] (DAC).

== Domains ==
In DSP, engineers usually study digital signals in one of the following domains: [[time domain]] (one-dimensional signals), spatial domain (multidimensional signals), [[frequency domain]], and [[wavelet]] domains. They choose the domain in which to process a signal by making an informed assumption (or by trying different possibilities) as to which domain best represents the essential characteristics of the signal and the processing to be applied to it. A sequence of samples from a measuring device produces a temporal or spatial domain representation, whereas a [[discrete Fourier transform]] produces the frequency domain representation.

=== Time and space domains ===
[[Time domain]] refers to the analysis of signals with respect to time. Similarly, space domain refers to the analysis of signals with respect to position, e.g., pixel location for the case of image processing.

The most common processing approach in the time or space domain is enhancement of the input signal through a method called filtering. [[Digital filter]]ing generally consists of some linear transformation of a number of surrounding samples around the current sample of the input or output signal. The surrounding samples may be identified with respect to time or space. The output of a linear digital filter to any given input may be calculated by [[convolution|convolving]] the input signal with an [[impulse response]].

=== Frequency domain ===
{{Main|Frequency domain}}

Signals are converted from time or space domain to the frequency domain usually through use of the [[Fourier transform]]. The Fourier transform converts the time or space information to a magnitude and phase component of each frequency. With some applications, how the phase varies with frequency can be a significant consideration. Where phase is unimportant, often the Fourier transform is converted to the power spectrum, which is the magnitude of each frequency component squared.

The most common purpose for analysis of signals in the frequency domain is analysis of signal properties. The engineer can study the spectrum to determine which frequencies are present in the input signal and which are missing. Frequency domain analysis is also called ''spectrum-'' or ''spectral analysis''.

Filtering, particularly in non-realtime work can also be achieved in the frequency domain, applying the filter and then converting back to the time domain. This can be an efficient implementation and can give essentially any filter response including excellent approximations to [[brickwall filter]]s.

There are some commonly used frequency domain transformations. For example, the [[cepstrum]] converts a signal to the frequency domain through Fourier transform, takes the logarithm, then applies another Fourier transform. This emphasizes the harmonic structure of the original spectrum.

===Z-plane analysis===
Digital filters come in both IIR and FIR types. Whereas FIR filters are always stable, IIR filters have feedback loops that may become unstable and oscillate. The [[Z-transform]] provides a tool for analyzing stability issues of digital IIR filters. It is analogous to the [[Laplace transform]], which is used to design and analyze analog IIR filters.

===Autoregression analysis===
A signal is represented as linear combination of its previous samples. Coefficients of the combination are called autoregression coefficients. This method has higher frequency resolution and can process shorter signals compared to the Fourier transform.&lt;ref name = "Marple"&gt;{{Cite book| publisher = Prentice Hall| isbn = 978-0-13-214149-9| last = Marple| first = S. Lawrence| title = Digital Spectral Analysis: With Applications| location = Englewood Cliffs, N.J| date = 1987-01-01}} &lt;/ref&gt; [[Prony's method]] can be used to estimate phases, amplitudes, initial phases and decays of the components of signal.&lt;ref name = "Ribeiro"&gt;&lt;/ref&gt;&lt;ref name = "Marple"&gt;&lt;/ref&gt; Components are assumed to be complex decaying exponents.&lt;ref name = "Ribeiro"&gt; {{Cite journal| doi = 10.1006/mssp.2001.1399| issn = 08883270| volume = 17| issue = 3| pages = 533–549| last1 = Ribeiro| first1 = M.P.| last2 = Ewins| first2 = D.J.| last3 = Robb| first3 = D.A.| title = Non-stationary analysis and noise filtering using a technique extended from the original Prony method| journal = Mechanical Systems and Signal Processing| accessdate = 2019-02-17| date = 2003-05-01| url = http://linkinghub.elsevier.com/retrieve/pii/S0888327001913998}}&lt;/ref&gt;&lt;ref name = "Marple"&gt;&lt;/ref&gt;

===Time-frequency analysis===
A time-frequency representation of signal can capture both temporal evolution and frequency structure of analyzed signal. Temporal and frequency resolution are limited by the principle of uncertainty and the tradeoff is adjusted by the width of analysis window. Linear techniques such as [[Short-time Fourier transform]], [[wavelet transform]], [[filter bank]],&lt;ref&gt;{{Cite conference| last1 = So| first1 = Stephen| last2 = Paliwal| first2 = Kuldip K.| title = Improved noise-robustness in distributed speech recognition via perceptually-weighted vector quantisation of filterbank energies| booktitle = Ninth European Conference on Speech Communication and Technology| date = 2005}}&lt;/ref&gt; non-linear (e.g., [[Wigner — Ville transform]] &lt;ref name = "Ribeiro"&gt;&lt;/ref&gt;) and [[Autoregression|autoregressive]] methods (e.g. segmented Prony method)&lt;ref name = "Ribeiro"&gt;&lt;/ref&gt;&lt;ref&gt;{{Cite journal| doi = 10.1515/acgeo-2015-0012| issn = 1895-6572| volume = 63| issue = 3| pages = 652–678| last1 = Mitrofanov| first1 = Georgy| last2 = Priimenko| first2 = Viatcheslav| title = Prony Filtering of Seismic Data| journal = Acta Geophysica| date = 2015-06-01}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal| doi = 10.20403/2078-0575-2020-2-55-67| issn = 20780575| issue = 2| pages = 55–67| last1 = Mitrofanov| first1 = Georgy| last2 = Smolin| first2 = S. N.| last3 = Orlov| first3 = Yu. A.| last4 = Bespechnyy| first4 = V. N.| title = Prony decomposition and filtering| journal = Geology and mineral resources of Siberia| accessdate = 2020-09-08| date = 2020| url = http://www.jourgimss.ru/en/SitePages/catalog/2020/02/abstract/2020_2_55.aspx}}&lt;/ref&gt; are used for representation of signal on the time-frequency plane. Non-linear and segmented Prony methods can provide higher resolution, but may produce undesireable artefacts. Time-frequency analysis is usually used for analysis of non-stationary signals. For example, methods of [[fundamental frequency]] estimation, such as RAPT and PEFAC&lt;ref&gt;{{Cite journal| doi = 10.1109/TASLP.2013.2295918| issn = 2329-9290| volume = 22| issue = 2| pages = 518–530| last1 = Gonzalez| first1 = Sira| last2 = Brookes| first2 = Mike| title = PEFAC - A Pitch Estimation Algorithm Robust to High Levels of Noise| journal = IEEE/ACM Transactions on Audio, Speech, and Language Processing| accessdate = 2017-12-03| date = February 2014| url = http://ieeexplore.ieee.org/document/6701334/}}&lt;/ref&gt; are based on windowed spectral analysis.

===Wavelet===
[[File:Jpeg2000 2-level wavelet transform-lichtenstein.png|thumb|300px|An example of the 2D discrete wavelet transform that is used in [[JPEG2000]]. The original image is high-pass filtered, yielding the three large images, each describing local changes in brightness (details) in the original image. It is then low-pass filtered and downscaled, yielding an approximation image; this image is high-pass filtered to produce the three smaller detail images, and low-pass filtered to produce the final approximation image in the upper-left.]]
In [[numerical analysis]] and [[functional analysis]], a [[discrete wavelet transform]] is any [[wavelet transform]] for which the [[wavelet]]s are discretely sampled. As with other wavelet transforms, a key advantage it has over [[Fourier transform]]s is temporal resolution: it captures both frequency ''and'' location information. The accuracy of the joint time-frequency resolution is limited by the [[Uncertainty principle#Signal processing|uncertainty principle]] of time-frequency.

===Empirical mode decomposition===
Empirical mode decomposition is based on decomposition signal into intrinsic mode functions (IMF). IMFs are quasiharmonical oscillations that are extracted from the signal.&lt;ref&gt;{{Cite journal| doi = 10.1098/rspa.1998.0193| issn = 1364-5021| volume = 454| issue = 1971| pages = 903–995| last1 = Huang| first1 = N. E.| last2 = Shen| first2 = Z.| last3 = Long| first3 = S. R.| last4 = Wu| first4 = M. C.| last5 = Shih| first5 = H. H.| last6 = Zheng| first6 = Q.| last7 = Yen| first7 = N.-C.| last8 = Tung| first8 = C. C.| last9 = Liu| first9 = H. H.| title = The empirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis| journal = Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences| accessdate = 2018-06-05| date = 1998-03-08| url = http://rspa.royalsocietypublishing.org/cgi/doi/10.1098/rspa.1998.0193}}&lt;/ref&gt;

== Implementation ==
DSP [[algorithm]]s may be run on general-purpose computers and [[digital signal processor]]s. DSP algorithms are also implemented on purpose-built hardware such as [[application-specific integrated circuit]] (ASICs). Additional technologies for digital signal processing include more powerful general purpose [[microprocessor]]s, [[graphics processing unit]]s, [[field-programmable gate array]]s (FPGAs), [[digital signal controller]]s (mostly for industrial applications such as motor control), and [[stream processing|stream processors]].&lt;ref&gt;{{cite book |title=Digital Signal Processing and Applications |last1=Stranneby |first1=Dag |last2=Walker |first2=William |edition=2nd |publisher=Elsevier |year=2004 |isbn=0-7506-6344-8 |url=https://books.google.com/books?id=NKK1DdqcDVUC&amp;pg=PA241}}&lt;/ref&gt;

For systems that do not have a [[real-time computing]] requirement and the signal data (either input or output) exists in data files, processing may be done economically with a general-purpose computer.  This is essentially no different from any other [[data processing]], except DSP mathematical techniques (such as the [[Discrete cosine transform|DCT]] and [[Fast Fourier transform|FFT]]) are used, and the sampled data is usually assumed to be uniformly sampled in time or space.  An example of such an application is processing [[digital photograph]]s with software such as [[Photoshop]].

When the application requirement is real-time, DSP is often implemented using specialized or dedicated processors or microprocessors, sometimes using multiple processors or multiple processing cores. These may process data using fixed-point arithmetic or floating point. For more demanding applications [[FPGA]]s may be used.&lt;ref&gt;{{cite web |last=JPFix |title=FPGA-Based Image Processing Accelerator |url=http://www.jpfix.com/About_Us/Articles/FPGA-Based_Image_Processing_Ac/fpga-based_image_processing_ac.html |date=2006 |access-date=2008-05-10}}&lt;/ref&gt; For the most demanding applications or high-volume products, [[Application-specific integrated circuit|ASIC]]s might be designed specifically for the application.

== Applications ==
General application areas for DSP include
{{Div col|colwidth=20em}}
*[[Audio signal processing]]
*[[Audio data compression]] e.g. [[MP3]]
*[[Video data compression]]
*[[Computer graphics]]
*[[Digital image processing]]
*[[Photo manipulation]]
*[[Speech processing]]
*[[Speech recognition]]
*[[Data transmission]]
*[[Radar]]
*[[Sonar]]
*[[Financial signal processing]]
*[[Economic forecasting]]
*[[Seismology]]
*[[Biomedicine]]
*[[Weather forecasting]]
{{Div col end}}

Specific examples include [[speech coding]] and transmission in digital [[mobile phone]]s, [[digital room correction|room correction]] of sound in [[hi-fi]] and [[sound reinforcement]] applications, analysis and control of [[industrial process]]es, [[medical imaging]] such as [[Computed axial tomography|CAT]] scans and [[MRI]], [[audio crossover]]s and [[equalization (audio)|equalization]], [[digital synthesizer]]s, and audio [[effects unit]]s.&lt;ref&gt;{{cite book |last1=Rabiner |first1=Lawrence R. |author1-link=Lawrence Rabiner |last2=Gold |first2=Bernard |date=1975 |title=Theory and application of digital signal processing |location=Englewood Cliffs, NJ |publisher=Prentice-Hall, Inc. |isbn=978-0139141010 |url-access=registration |url=https://archive.org/details/theoryapplicatio00rabi }}&lt;/ref&gt;

== Techniques ==
{{Div col|colwidth=20em}}
* [[Bilinear transform]]
* [[Discrete Fourier transform]]
* [[Discrete-time Fourier transform]]
* [[Filter design]]
* [[Goertzel algorithm]]
* [[LTI system theory]]
* [[Minimum phase]]
* [[s-plane]]
* [[Transfer function]]
* [[Z-transform]]
{{Div col end}}

== Related fields ==
{{Div col|colwidth=20em}}
* [[Analog signal processing]]
* [[Automatic control]]
* [[Computer engineering]]
* [[Computer science]]
* [[Data compression]]
* [[Dataflow programming]]
* [[Discrete cosine transform]]
* [[Electrical engineering]]
* [[Fourier analysis]]
* [[Information theory]]
* [[Machine learning]]
* [[Real-time computing]]
* [[Stream processing]]
* [[Telecommunication]]
* [[Time series]]
* [[Wavelet]]
{{Div col end}}

== References==
{{Reflist}}

== Further reading ==
{{wikibooks|Digital Signal Processing}}
{{refbegin|30em}}
*[[N. Ahmed]] and K.R. Rao (1975).  Orthogonal Transforms for Digital Signal Processing.  Springer-Verlag (Berlin – Heidelberg – New York), {{ISBN|3-540-06556-3}}.
*Jonathan M. Blackledge, Martin Turner: ''Digital Signal Processing: Mathematical and Computational Methods, Software Development and Applications'', Horwood Publishing, {{ISBN|1-898563-48-9}}
*James D. Broesch: ''Digital Signal Processing Demystified'', Newnes, {{ISBN|1-878707-16-7}}
*Paul M. Embree, Damon Danieli: ''C++ Algorithms for Digital Signal Processing'', Prentice Hall, {{ISBN|0-13-179144-3}}
*Hari Krishna Garg: ''Digital Signal Processing Algorithms'', CRC Press, {{ISBN|0-8493-7178-3}}
*P. Gaydecki: ''Foundations Of Digital Signal Processing: Theory, Algorithms And Hardware Design'', Institution of Electrical Engineers, {{ISBN|0-85296-431-5}}
*Ashfaq Khan: ''Digital Signal Processing Fundamentals'', Charles River Media, {{ISBN|1-58450-281-9}}
*Sen M. Kuo, Woon-Seng Gan: ''Digital Signal Processors: Architectures, Implementations, and Applications'', Prentice Hall, {{ISBN|0-13-035214-4}}
*Paul A. Lynn, Wolfgang Fuerst: ''Introductory Digital Signal Processing with Computer Applications'', John Wiley &amp; Sons, {{ISBN|0-471-97984-8}}
*Richard G. Lyons: ''Understanding Digital Signal Processing'', Prentice Hall, {{ISBN|0-13-108989-7}}
*Vijay Madisetti, Douglas B. Williams: ''The Digital Signal Processing Handbook'', CRC Press, {{ISBN|0-8493-8572-5}}
*[[James H. McClellan]], [[Ronald W. Schafer]], Mark A. Yoder: ''Signal Processing First'', Prentice Hall, {{ISBN|0-13-090999-8}}
*Bernard Mulgrew, Peter Grant, John Thompson: ''Digital Signal Processing – Concepts and Applications'', Palgrave Macmillan, {{ISBN|0-333-96356-3}}
*Boaz Porat: ''A Course in Digital Signal Processing'', Wiley, {{ISBN|0-471-14961-6}}
*John G. Proakis, [[Dimitris Manolakis]]: ''Digital Signal Processing: Principles, Algorithms and Applications'', 4th ed, Pearson, April 2006, {{ISBN|978-0131873742}}
*John G. Proakis: ''A Self-Study Guide for Digital Signal Processing'', Prentice Hall, {{ISBN|0-13-143239-7}}
*Charles A. Schuler: ''Digital Signal Processing: A Hands-On Approach'', McGraw-Hill, {{ISBN|0-07-829744-3}}
*Doug Smith: ''Digital Signal Processing Technology: Essentials of the Communications Revolution'', American Radio Relay League, {{ISBN|0-87259-819-5}}
*{{cite book|url=http://www.dspguide.com|title=Digital Signal Processing: A Practical Guide for Engineers and Scientists|last=Smith|first=Steven W.|date=2002|publisher=Newnes|isbn=0-7506-7444-X}}
*{{cite book|title =Digital Signal Processing, a Computer Science Perspective|last =Stein|first =Jonathan Yaakov|date =2000-10-09|publisher =Wiley|isbn =0-471-29546-9}}
*{{cite book|title =Advanced Signal Processing Handbook: Theory and Implementation for Radar, Sonar, and Medical Imaging Real-Time Systems|last =Stergiopoulos|first =Stergios|date =2000|publisher =CRC Press|isbn =0-8493-3691-0}}
*{{cite book|title =Fundamentals of Digital Signal Processing|last =Van De Vegte|first =Joyce|date =2001|publisher =Prentice Hall|isbn =0-13-016077-6}}
*{{Cite book|title =Discrete-Time Signal Processing|last1=Oppenheim|first1=Alan V.|last2=Schafer|first2=Ronald W.|publisher=Pearson|year=2001|isbn=1-292-02572-7}}
*Hayes, Monson H. Statistical digital signal processing and modeling. John Wiley &amp; Sons, 2009. (with [https://www.mathworks.com/matlabcentral/fileexchange/2183-statistical-digital-signal-processing-and-modeling?s_tid=prof_contriblnk MATLAB scripts]){{refend}}

{{Digital systems}}
{{DSP}}

{{Authority control}}

{{DEFAULTSORT:Digital Signal Processing}}
[[Category:Digital signal processing| ]]
[[Category:Digital electronics]]
[[Category:Computer engineering]]
[[Category:Telecommunication theory]]
[[Category:Computer science]]
[[Category:Radar signal processing]]</text>
      <sha1>m684ex0a6dlrg33ylmaslx43x33cnea</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer engineering</title>
    <ns>14</ns>
    <id>3240726</id>
    <revision>
      <id>981561743</id>
      <parentid>981559520</parentid>
      <timestamp>2020-10-03T02:38:36Z</timestamp>
      <contributor>
        <username>Hmains</username>
        <id>508734</id>
      </contributor>
      <comment>Undid revision 981559520 by [[Special:Contributions/Hmains|Hmains]] ([[User talk:Hmains|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="154" xml:space="preserve">{{Commonscat}}
{{Cat main}}

[[Category:Computing]]
[[Category:Computer science]]
[[Category:Electrical engineering]]
[[Category:Engineering disciplines]]</text>
      <sha1>pdx16zgft44ydrah5svivjuutbexjrz</sha1>
    </revision>
  </page>
  <page>
    <title>Informatics engineering</title>
    <ns>0</ns>
    <id>11120381</id>
    <revision>
      <id>1004226403</id>
      <parentid>1002717500</parentid>
      <timestamp>2021-02-01T16:54:25Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Misc citation tidying. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Suggested by Wikiminds34 | [[Category:Computer engineering]] | via #UCB_Category 49/56</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1609" xml:space="preserve">{{refimprove|date=September 2016}}
{{dicdef}}

'''Informatics Engineering''' is the direct translation from many southern European languages of an engineering discipline most commonly known in English as [[Computer Science &amp; Engineering]].

In [[Portugal]], for example, universities may use the term ''[[:pt:Engenharia inform%C3%A1tica|Engenharia Informática]]'' to refer strictly to [[Computer Science]]&lt;ref name="MIEIC"&gt;{{cite web|title=FEUP - Master in Informatics and Computing Engineering|url=https://sigarra.up.pt/feup/en/cur_geral.cur_view?pv_ano_lectivo=2015&amp;pv_origem=CUR&amp;pv_tipo_cur_sigla=MI&amp;pv_curso_id=742|website=FEUP|publisher=[[FEUP|Faculty of Engineering of the University of Porto]]|access-date=14 May 2016}}&lt;/ref&gt; or a distinction may be made between [[Computer Engineering]]&lt;ref name="MIEI"&gt;{{cite web|title=University of Minho - Integrated Master's Degree in Informatics Engineering|url=https://www.uminho.pt/EN/education/educational-offer/_layouts/15/UMinho.PortalUM.UI/Pages/CatalogoCursoDetail.aspx?itemId=2135&amp;catId=7|website=Uminho|publisher=[[University of Minho]]|access-date=18 September 2016}}&lt;/ref&gt; and [[Computer Science]].&lt;ref name="LCC"&gt;{{cite web|title=University of Minho - Bachelor's Degree in Computer Science|url=https://www.uminho.pt/EN/education/educational-offer/_layouts/15/UMinho.PortalUM.UI/Pages/CatalogoCursoDetail.aspx?itemId=1877&amp;catId=7|website=Uminho|publisher=[[University of Minho]]|access-date=18 September 2016}}&lt;/ref&gt;

==References==
{{Reflist|3}}

{{Informatics}}

[[Category:Computing]]
[[Category:Computer engineering]]
[[Category:Computer science]]</text>
      <sha1>tbve6br6i39x0ncpbtgw6lxotrjgy4b</sha1>
    </revision>
  </page>
  <page>
    <title>Information theory</title>
    <ns>0</ns>
    <id>14773</id>
    <revision>
      <id>1013476861</id>
      <parentid>1013464837</parentid>
      <timestamp>2021-03-21T20:41:49Z</timestamp>
      <contributor>
        <username>Tayste</username>
        <id>6531599</id>
      </contributor>
      <minor/>
      <comment>Undid revision 1013464837 by [[Special:Contributions/Bigbang.io|Bigbang.io]] ([[User talk:Bigbang.io|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="45973" xml:space="preserve">{{short description|Theory dealing with information}}
{{distinguish|Information science}}
{{Example farm|date=May 2020}}
{{Information theory}}
'''Information theory''' is the scientific study of the [[quantification (science)|quantification]], [[computer data storage|storage]], and [[telecommunication|communication]] of [[information]]. The field was fundamentally established by the works of [[Harry Nyquist]] and [[Ralph Hartley]], in the 1920s, and [[Claude Shannon]] in the 1940s. The field is at the intersection of [[probability theory]], [[statistics]], computer science, [[statistical mechanics]], [[information engineering (field)|information engineering]], and [[electrical engineering]].

A key measure in information theory is [[information entropy|entropy]]. Entropy quantifies the amount of uncertainty involved in the value of a [[random variable]] or the outcome of a [[random process]]. For example, identifying the outcome of a fair [[coin flip]] (with two equally likely outcomes) provides less information (lower entropy) than specifying the outcome from a roll of a [[dice|die]] (with six equally likely outcomes). Some other important measures in information theory are [[mutual information]], channel capacity, [[error exponent]]s, and [[relative entropy]]. Important sub-fields of information theory include [[source coding]], [[algorithmic complexity theory]], [[algorithmic information theory]], and [[information-theoretic security]].

Applications of fundamental topics of information theory include [[lossless data compression]] (e.g. [[ZIP (file format)|ZIP files]]), [[lossy data compression]] (e.g. [[MP3]]s and [[JPEG]]s), and [[channel capacity|channel coding]] (e.g. for [[digital subscriber line|DSL]]). Its impact has been crucial to the success of the [[Voyager program|Voyager]] missions to deep space, the invention of the [[compact disc]], the feasibility of mobile phones and the development of the Internet. The theory has also found applications in other areas, including [[statistical inference]],&lt;ref&gt;Burnham, K. P. and Anderson D. R. (2002) ''Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach, Second Edition'' (Springer Science, New York) {{ISBN|978-0-387-95364-9}}.&lt;/ref&gt; [[cryptography]], [[neurobiology]],&lt;ref name="Spikes"&gt;{{cite book|title=Spikes: Exploring the Neural Code|author1=F. Rieke|author2=D. Warland|author3=R Ruyter van Steveninck|author4=W Bialek|publisher=The MIT press|year=1997|isbn=978-0262681087}}&lt;/ref&gt; [[perception]],&lt;ref&gt;{{Cite journal|last1=Delgado-Bonal|first1=Alfonso|last2=Martín-Torres|first2=Javier|date=2016-11-03|title=Human vision is determined based on information theory|journal=Scientific Reports|language=En|volume=6|issue=1|pages=36038|bibcode=2016NatSR...636038D|doi=10.1038/srep36038|issn=2045-2322|pmc=5093619|pmid=27808236}}&lt;/ref&gt; linguistics, the evolution&lt;ref&gt;{{cite journal|last1=cf|last2=Huelsenbeck|first2=J. P.|last3=Ronquist|first3=F.|last4=Nielsen|first4=R.|last5=Bollback|first5=J. P.|year=2001|title=Bayesian inference of phylogeny and its impact on evolutionary biology|journal=Science|volume=294|issue=5550|pages=2310–2314|bibcode=2001Sci...294.2310H|doi=10.1126/science.1065889|pmid=11743192|s2cid=2138288}}&lt;/ref&gt; and function&lt;ref&gt;{{cite journal|last1=Allikmets|first1=Rando|last2=Wasserman|first2=Wyeth W.|last3=Hutchinson|first3=Amy|last4=Smallwood|first4=Philip|last5=Nathans|first5=Jeremy|last6=Rogan|first6=Peter K.|year=1998|title=Thomas D. Schneider], Michael Dean (1998) Organization of the ABCR gene: analysis of promoter and splice junction sequences|url=http://alum.mit.edu/www/toms/|journal=Gene|volume=215|issue=1|pages=111–122|doi=10.1016/s0378-1119(98)00269-8|pmid=9666097}}&lt;/ref&gt; of molecular codes ([[bioinformatics]]), [[thermal physics]],&lt;ref&gt;{{cite journal|last1=Jaynes|first1=E. T.|year=1957|title=Information Theory and Statistical Mechanics|url=http://bayes.wustl.edu/|journal=Phys. Rev.|volume=106|issue=4|page=620|bibcode=1957PhRv..106..620J|doi=10.1103/physrev.106.620}}&lt;/ref&gt; [[quantum computing]], black holes, [[information retrieval]], [[Intelligence (Information Gathering)|intelligence gathering]], [[plagiarism detection]],&lt;ref&gt;{{cite journal|last1=Bennett|first1=Charles H.|last2=Li|first2=Ming|last3=Ma|first3=Bin|year=2003|title=Chain Letters and Evolutionary Histories|url=http://sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=08B64096-0772-4904-9D48227D5C9FAC75|journal=Scientific American|volume=288|issue=6|pages=76–81|bibcode=2003SciAm.288f..76B|doi=10.1038/scientificamerican0603-76|pmid=12764940|access-date=2008-03-11|archive-url=https://web.archive.org/web/20071007041539/http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=08B64096-0772-4904-9D48227D5C9FAC75|archive-date=2007-10-07|url-status=dead}}&lt;/ref&gt; [[pattern recognition]], [[anomaly detection]]&lt;ref&gt;{{Cite web|url=http://aicanderson2.home.comcast.net/~aicanderson2/home.pdf|title=Some background on why people in the empirical sciences may want to better understand the information-theoretic methods|author=David R. Anderson|date=November 1, 2003|archive-url=https://web.archive.org/web/20110723045720/http://aicanderson2.home.comcast.net/~aicanderson2/home.pdf|archive-date=July 23, 2011|url-status=dead|access-date=2010-06-23}}
&lt;/ref&gt; and even art creation.

==Overview==
Information theory studies the transmission, processing, extraction, and utilization of information. Abstractly, information can be thought of as the resolution of uncertainty. In the case of communication of information over a noisy channel, this abstract concept was formalized in 1948 by Claude Shannon in a paper entitled ''[[A Mathematical Theory of Communication]]'', in which information is thought of as a set of possible messages, and the goal is to send these messages over a noisy channel, and to have the receiver reconstruct the message with low probability of error, in spite of the channel noise. Shannon's main result, the [[noisy-channel coding theorem]] showed that, in the limit of many channel uses, the rate of information that is asymptotically achievable is equal to the channel capacity, a quantity dependent merely on the statistics of the channel over which the messages are sent.&lt;ref name="Spikes" /&gt;

Information theory is closely associated with a collection of pure and applied disciplines that have been investigated and reduced to engineering practice under a variety of [[Rubric (academic)|rubrics]] throughout the world over the past half-century or more: [[adaptive system]]s, [[anticipatory system]]s, [[artificial intelligence]], [[complex system]]s, [[complexity science]], [[cybernetics]], [[Informatics (academic field)|informatics]], [[machine learning]], along with [[systems science]]s of many descriptions. Information theory is a broad and deep mathematical theory, with equally broad and deep applications, amongst which is the vital field of [[coding theory]].

Coding theory is concerned with finding explicit methods, called ''codes'', for increasing the efficiency and reducing the error rate of data communication over noisy channels to near the channel capacity. These codes can be roughly subdivided into data compression (source coding) and [[error-correction]] (channel coding) techniques. In the latter case, it took many years to find the methods Shannon's work proved were possible.

A third class of information theory codes are cryptographic algorithms (both [[code (cryptography)|code]]s and [[cipher]]s). Concepts, methods and results from coding theory and information theory are widely used in cryptography and [[cryptanalysis]]. ''See the article [[ban (unit)]] for a historical application.''

==Historical background==
{{Main|History of information theory}}

The landmark event ''establishing'' the discipline of information theory and bringing it to immediate worldwide attention was the publication of Claude E. Shannon's classic paper "A Mathematical Theory of Communication" in the ''[[Bell System Technical Journal]]'' in July and October 1948.

Prior to this paper, limited information-theoretic ideas had been developed at [[Bell Labs]], all implicitly assuming events of equal probability.  [[Harry Nyquist]]'s 1924 paper, ''Certain Factors Affecting Telegraph Speed'', contains a theoretical section quantifying "intelligence" and the "line speed" at which it can be transmitted by a communication system, giving the relation {{math|1=''W'' = ''K'' log ''m''}} (recalling [[Boltzmann's constant]]), where ''W'' is the speed of transmission of intelligence, ''m'' is the number of different voltage levels to choose from at each time step, and ''K'' is a constant.  [[Ralph Hartley]]'s 1928 paper, ''Transmission of Information'', uses the word ''information'' as a measurable quantity, reflecting the receiver's ability to distinguish one [[sequence of symbols]] from any other, thus quantifying information as {{math|1=''H'' = log ''S''&lt;sup&gt;''n''&lt;/sup&gt; = ''n'' log ''S''}}, where ''S'' was the number of possible symbols, and ''n'' the number of symbols in a transmission. The unit of information was therefore the [[decimal digit]], which since has sometimes been called the [[Hartley (unit)|hartley]] in his honor as a unit or scale or measure of information. [[Alan Turing]] in 1940 used similar ideas as part of the statistical analysis of the breaking of the German second world war [[Cryptanalysis of the Enigma|Enigma]] ciphers.

Much of the mathematics behind information theory with events of different probabilities were developed for the field of [[thermodynamics]] by [[Ludwig Boltzmann]] and [[J. Willard Gibbs]].  Connections between information-theoretic entropy and thermodynamic entropy, including the important contributions by [[Rolf Landauer]] in the 1960s, are explored in ''[[Entropy in thermodynamics and information theory]]''.

In Shannon's revolutionary and groundbreaking paper, the work for which had been substantially completed at Bell Labs by the end of 1944, Shannon for the first time introduced the qualitative and quantitative model of communication as a statistical process underlying information theory, opening with the assertion: 
:"The fundamental problem of communication is that of reproducing at one point, either exactly or approximately, a message selected at another point."

With it came the ideas of
* the information entropy and [[redundancy (information theory)|redundancy]] of a source, and its relevance through the [[source coding theorem]];
* the mutual information, and the channel capacity of a noisy channel, including the promise of perfect loss-free communication given by the noisy-channel coding theorem;
* the practical result of the [[Shannon–Hartley law]] for the channel capacity of a [[Gaussian channel]]; as well as
* the [[bit]]—a new way of seeing the most fundamental unit of information.

==Quantities of information==
{{Main|Quantities of information}}

Information theory is based on [[probability theory]] and statistics.  Information theory often concerns itself with measures of information of the distributions associated with random variables. Important quantities of information are entropy, a measure of information in a single random variable, and mutual information, a measure of information in common between two random variables.  The former quantity is a property of the probability distribution of a random variable and gives a limit on the rate at which data generated by independent samples with the given distribution can be reliably compressed. The latter is a property of the joint distribution of two random variables, and is the maximum rate of reliable communication across a noisy [[Communication channel|channel]] in the limit of long block lengths, when the channel statistics are determined by the joint distribution.

The choice of logarithmic base in the following formulae determines the [[units of measurement|unit]] of information entropy that is used.  A common unit of information is the bit, based on the [[binary logarithm]]. Other units include the [[nat (unit)|nat]], which is based on the [[natural logarithm]], and the [[deciban|decimal digit]], which is based on the [[common logarithm]].

In what follows, an expression of the form {{math|''p'' log ''p''}} is considered by convention to be equal to zero whenever {{math|1=''p'' = 0}}.  This is justified because &lt;math&gt;\lim_{p \rightarrow 0+} p \log p = 0&lt;/math&gt; for any logarithmic base.

===Entropy of an information source===
Based on the [[probability mass function]] of each source symbol to be communicated, the Shannon [[Entropy (information theory)|entropy]] {{math|''H''}}, in units of bits (per symbol), is given by
:&lt;math&gt;H = - \sum_{i} p_i \log_2 (p_i)&lt;/math&gt;
where {{math|''p&lt;sub&gt;i&lt;/sub&gt;''}} is the probability of occurrence of the {{math|''i''}}-th possible value of the source symbol. This equation gives the entropy in the units of "bits" (per symbol) because it uses a logarithm of base 2, and this base-2 measure of entropy has sometimes been called the [[Shannon (unit)|shannon]] in his honor. Entropy is also commonly computed using the natural logarithm (base {{mvar|[[E (mathematical constant)|e]]}}, where {{mvar|e}} is Euler's number), which produces a measurement of entropy in nats per symbol and sometimes simplifies the analysis by avoiding the need to include extra constants in the formulas. Other bases are also possible, but less commonly used. For example, a logarithm of base {{nowrap|1=2&lt;sup&gt;8&lt;/sup&gt; = 256}} will produce a measurement in [[byte]]s per symbol, and a logarithm of base 10 will produce a measurement in decimal digits (or [[Hartley (unit)|hartleys]]) per symbol.

Intuitively, the entropy {{math|''H&lt;sub&gt;X&lt;/sub&gt;''}} of a discrete random variable {{math|''X''}} is a measure of the amount of ''uncertainty'' associated with the value of {{math|''X''}} when only its distribution is known.

The entropy of a source that emits a sequence of {{math|''N''}} symbols that are [[independent and identically distributed]] (iid) is {{math|''N'' ⋅ ''H''}} bits (per message of {{math|''N''}} symbols). If the source data symbols are identically distributed but not independent, the entropy of a message of length {{math|''N''}} will be less than {{math|''N'' ⋅ ''H''}}.

[[File:Binary entropy plot.svg|thumbnail|right|200px|The entropy of a [[Bernoulli trial]] as a function of success probability, often called the {{em|[[binary entropy function]]}}, {{math|''H''&lt;sub&gt;b&lt;/sub&gt;(''p'')}}.  The entropy is maximized at 1 bit per trial when the two possible outcomes are equally probable, as in an unbiased coin toss.]]

If one transmits 1000 bits (0s and 1s), and the value of each of these bits is known to the receiver (has a specific value with certainty) ahead of transmission, it is clear that no information is transmitted.  If, however, each bit is independently equally likely to be 0 or 1, 1000 shannons of information (more often called bits) have been transmitted.  Between these two extremes, information can be quantified as follows. If &lt;math&gt;\mathbb{X}&lt;/math&gt; is the set of all messages {{math|{{mset|''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;}}}} that {{math|''X''}} could be, and {{math|''p''(''x'')}} is the probability of some &lt;math&gt;x \in \mathbb X&lt;/math&gt;, then the entropy, {{math|''H''}}, of {{math|''X''}} is defined:&lt;ref name = Reza&gt;{{cite book | title = An Introduction to Information Theory | author = Fazlollah M. Reza | publisher = Dover Publications, Inc., New York | orig-year = 1961| year = 1994 | isbn = 0-486-68210-2 | url = https://books.google.com/books?id=RtzpRAiX6OgC&amp;q=intitle:%22An+Introduction+to+Information+Theory%22++%22entropy+of+a+simple+source%22&amp;pg=PA8}}&lt;/ref&gt;

:&lt;math&gt; H(X) = \mathbb{E}_{X} [I(x)] = -\sum_{x \in \mathbb{X}} p(x) \log p(x).&lt;/math&gt;

(Here, {{math|''I''(''x'')}} is the [[self-information]], which is the entropy contribution of an individual message, and &lt;math&gt;\mathbb{E}_X&lt;/math&gt; is the [[expected value]].) A property of entropy is that it is maximized when all the messages in the message space are equiprobable {{math|1=''p''(''x'') = 1/''n''}}; i.e., most unpredictable, in which case {{math|1=''H''(''X'') = log ''n''}}.

The special case of information entropy for a random variable with two outcomes is the binary entropy function, usually taken to the logarithmic base 2, thus having the shannon (Sh) as unit:

:&lt;math&gt;H_{\mathrm{b}}(p) = - p \log_2 p - (1-p)\log_2 (1-p).&lt;/math&gt;

===Joint entropy===
The {{em|[[joint entropy]]}} of two discrete random variables {{math|''X''}} and {{math|''Y''}} is merely the entropy of their pairing: {{math|(''X'', ''Y'')}}.  This implies that if {{math|''X''}} and {{math|''Y''}} are [[statistical independence|independent]], then their joint entropy is the sum of their individual entropies.

For example, if {{math|(''X'', ''Y'')}} represents the position of a chess piece—{{math|''X''}} the row and {{math|''Y''}} the column, then the joint entropy of the row of the piece and the column of the piece will be the entropy of the position of the piece.

:&lt;math&gt;H(X, Y) = \mathbb{E}_{X,Y} [-\log p(x,y)] = - \sum_{x, y} p(x, y) \log p(x, y) \,&lt;/math&gt;

Despite similar notation, joint entropy should not be confused with {{em|[[cross entropy]]}}.

===Conditional entropy (equivocation)===
The {{em|[[conditional entropy]]}} or ''conditional uncertainty'' of {{math|''X''}} given random variable {{math|''Y''}} (also called the ''equivocation'' of {{math|''X''}} about {{math|''Y''}}) is the average conditional entropy over {{math|''Y''}}:&lt;ref name=Ash&gt;{{cite book | title = Information Theory | author = Robert B. Ash | publisher = Dover Publications, Inc. | orig-year = 1965| year = 1990 | isbn = 0-486-66521-6 | url = https://books.google.com/books?id=ngZhvUfF0UIC&amp;q=intitle:information+intitle:theory+inauthor:ash+conditional+uncertainty&amp;pg=PA16}}&lt;/ref&gt;

:&lt;math&gt; H(X|Y) = \mathbb E_Y [H(X|y)] = -\sum_{y \in Y} p(y) \sum_{x \in X} p(x|y) \log p(x|y) = -\sum_{x,y} p(x,y) \log p(x|y).&lt;/math&gt;

Because entropy can be conditioned on a random variable or on that random variable being a certain value, care should be taken not to confuse these two definitions of conditional entropy, the former of which is in more common use.  A basic property of this form of conditional entropy is that:

: &lt;math&gt; H(X|Y) = H(X,Y) - H(Y) .\,&lt;/math&gt;

===Mutual information (transinformation)===
''[[Mutual information]]'' measures the amount of information that can be obtained about one random variable by observing another.  It is important in communication where it can be used to maximize the amount of information shared between sent and received signals.  The mutual information of {{math|''X''}} relative to {{math|''Y''}} is given by:

:&lt;math&gt;I(X;Y) = \mathbb{E}_{X,Y} [SI(x,y)] = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)\, p(y)}&lt;/math&gt;
where {{math|SI}} (''S''pecific mutual ''I''nformation) is the [[pointwise mutual information]].

A basic property of the mutual information is that
: &lt;math&gt;I(X;Y) = H(X) - H(X|Y).\,&lt;/math&gt;
That is, knowing ''Y'', we can save an average of {{math|''I''(''X''; ''Y'')}} bits in encoding ''X'' compared to not knowing ''Y''.

Mutual information is [[symmetric function|symmetric]]:
: &lt;math&gt;I(X;Y) = I(Y;X) = H(X) + H(Y) - H(X,Y).\,&lt;/math&gt;

Mutual information can be expressed as the average Kullback–Leibler divergence (information gain) between the [[posterior probability|posterior probability distribution]] of ''X'' given the value of ''Y'' and the [[prior probability|prior distribution]] on ''X'':
: &lt;math&gt;I(X;Y) = \mathbb E_{p(y)} [D_{\mathrm{KL}}( p(X|Y=y) \| p(X) )].&lt;/math&gt;
In other words, this is a measure of how much, on the average, the probability distribution on ''X'' will change if we are given the value of ''Y''.  This is often recalculated as the divergence from the product of the marginal distributions to the actual joint distribution:
: &lt;math&gt;I(X; Y) = D_{\mathrm{KL}}(p(X,Y) \| p(X)p(Y)).&lt;/math&gt;

Mutual information is closely related to the [[likelihood-ratio test|log-likelihood ratio test]] in the context of contingency tables and the [[multinomial distribution]] and to [[Pearson's chi-squared test|Pearson's χ&lt;sup&gt;2&lt;/sup&gt; test]]: mutual information can be considered a statistic for assessing independence between a pair of variables, and has a well-specified asymptotic distribution.

===Kullback–Leibler divergence (information gain)===
The ''[[Kullback–Leibler divergence]]'' (or ''information divergence'', ''information gain'', or ''relative entropy'') is a way of comparing two distributions: a "true" [[probability distribution]] {{tmath|p(X)}}, and an arbitrary probability distribution {{tmath|q(X)}}. If we compress data in a manner that assumes {{tmath|q(X)}} is the distribution underlying some data, when, in reality, {{tmath|p(X)}} is the correct distribution, the Kullback–Leibler divergence is the number of average additional bits per datum necessary for compression.  It is thus defined

:&lt;math&gt;D_{\mathrm{KL}}(p(X) \| q(X)) = \sum_{x \in X} -p(x) \log {q(x)} \, - \, \sum_{x \in X} -p(x) \log {p(x)} = \sum_{x \in X} p(x) \log \frac{p(x)}{q(x)}.&lt;/math&gt;

Although it is sometimes used as a 'distance metric', KL divergence is not a true [[Metric (mathematics)|metric]] since it is not symmetric and does not satisfy the [[triangle inequality]] (making it a semi-quasimetric).

Another interpretation of the KL divergence is the "unnecessary surprise" introduced by a prior from the truth: suppose a number ''X'' is about to be drawn randomly from a discrete set with probability distribution {{tmath|p(x)}}.  If Alice knows the true distribution {{tmath|p(x)}}, while Bob believes (has a [[prior probability|prior]]) that the distribution is {{tmath|q(x)}}, then Bob will be more [[Information content|surprised]] than Alice, on average, upon seeing the value of ''X''.  The KL divergence is the (objective) expected value of Bob's (subjective) surprisal minus Alice's surprisal, measured in bits if the ''log'' is in base 2.  In this way, the extent to which Bob's prior is "wrong" can be quantified in terms of how "unnecessarily surprised" it is expected to make him.

===Other quantities===
Other important information theoretic quantities include [[Rényi entropy]] (a generalization of entropy), [[differential entropy]] (a generalization of quantities of information to continuous distributions), and the [[conditional mutual information]].

==Coding theory==
{{Main|Coding theory}}

[[File:CDSCRATCHES.jpg|thumb|right|A picture showing scratches on the readable surface of a CD-R.  Music and data CDs are coded using error correcting codes and thus can still be read even if they have minor scratches using [[error detection and correction]].]]

Coding theory is one of the most important and direct applications of information theory. It can be subdivided into [[data compression|source coding]] theory and channel coding theory. Using a statistical description for data, information theory quantifies the number of bits needed to describe the data, which is the information entropy of the source.

* Data compression (source coding): There are two formulations for the compression problem:
** [[lossless data compression]]: the data must be reconstructed exactly;
** [[lossy data compression]]: allocates bits needed to reconstruct the data, within a specified fidelity level measured by a distortion function. This subset of information theory is called ''[[rate–distortion theory]]''.
* Error-correcting codes (channel coding): While data compression removes as much redundancy as possible, an error-correcting code adds just the right kind of redundancy (i.e., error correction) needed to transmit the data efficiently and faithfully across a noisy channel.

This division of coding theory into compression and transmission is justified by the information transmission theorems, or source–channel separation theorems that justify the use of bits as the universal currency for information in many contexts. However, these theorems only hold in the situation where one transmitting user wishes to communicate to one receiving user. In scenarios with more than one transmitter (the multiple-access channel), more than one receiver (the [[broadcast channel]]) or intermediary "helpers" (the [[relay channel]]), or more general [[computer network|networks]], compression followed by transmission may no longer be optimal. [[Network information theory]] refers to these multi-agent communication models.

===Source theory===
Any process that generates successive messages can be considered a {{em|[[Communication source|source]]}} of information.  A memoryless source is one in which each message is an [[Independent identically distributed random variables|independent identically distributed random variable]], whereas the properties of [[ergodic theory|ergodicity]] and [[stationary process|stationarity]] impose less restrictive constraints.  All such sources are [[stochastic process|stochastic]].  These terms are well studied in their own right outside information theory.

====Rate====&lt;!-- This section is linked from [[Channel capacity]] --&gt;
Information ''[[Entropy rate|rate]]'' is the average entropy per symbol.  For memoryless sources, this is merely the entropy of each symbol, while, in the case of a stationary stochastic process, it is

:&lt;math&gt;r = \lim_{n \to \infty} H(X_n|X_{n-1},X_{n-2},X_{n-3}, \ldots);&lt;/math&gt;

that is, the conditional entropy of a symbol given all the previous symbols generated.  For the more general case of a process that is not necessarily stationary, the ''average rate'' is

:&lt;math&gt;r = \lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, \dots X_n);&lt;/math&gt;

that is, the limit of the joint entropy per symbol.  For stationary sources, these two expressions give the same result.&lt;ref&gt;{{cite book | title = Digital Compression for Multimedia: Principles and Standards | author = Jerry D. Gibson | publisher = Morgan Kaufmann | year = 1998 | url = https://books.google.com/books?id=aqQ2Ry6spu0C&amp;q=entropy-rate+conditional&amp;pg=PA56 | isbn = 1-55860-369-7 }}&lt;/ref&gt;

Information rate is defined as 
:&lt;math&gt;r = \lim_{n \to \infty} \frac{1}{n} I(X_1, X_2, \dots X_n;Y_1,Y_2, \dots Y_n);&lt;/math&gt;

It is common in information theory to speak of the "rate" or "entropy" of a language.  This is appropriate, for example, when the source of information is English prose.  The rate of a source of information is related to its redundancy and how well it can be compressed, the subject of {{em|source coding}}.

===Channel capacity===
{{Main|Channel capacity}}

Communications over a channel—such as an [[ethernet]] cable—is the primary motivation of information theory.  However, such channels often fail to produce exact reconstruction of a signal; noise, periods of silence, and other forms of signal corruption often degrade quality.

Consider the communications process over a discrete channel. A simple model of the process is shown below:

:&lt;math title="Channel model"&gt;
\xrightarrow[\text{Message}]{W}
\begin{array}{ |c| }\hline \text{Encoder} \\ f_n \\ \hline\end{array} \xrightarrow[\mathrm{Encoded \atop sequence}]{X^n} \begin{array}{ |c| }\hline \text{Channel} \\ p(y|x) \\ \hline\end{array} \xrightarrow[\mathrm{Received \atop sequence}]{Y^n} \begin{array}{ |c| }\hline \text{Decoder} \\ g_n \\ \hline\end{array} \xrightarrow[\mathrm{Estimated \atop message}]{\hat W}&lt;/math&gt;

Here ''X'' represents the space of messages transmitted, and ''Y'' the space of messages received during a unit time over our channel. Let {{math|''p''(''y''{{pipe}}''x'')}} be the [[conditional probability]] distribution function of ''Y'' given ''X''. We will consider {{math|''p''(''y''{{pipe}}''x'')}} to be an inherent fixed property of our communications channel (representing the nature of the ''[[Signal noise|noise]]'' of our channel). Then the joint distribution of ''X'' and ''Y'' is completely determined by our channel and by our choice of {{math|''f''(''x'')}}, the marginal distribution of messages we choose to send over the channel. Under these constraints, we would like to maximize the rate of information, or the ''[[Signal (electrical engineering)|signal]]'', we can communicate over the channel. The appropriate measure for this is the mutual information, and this maximum mutual information is called the {{em|channel capacity}} and is given by:
:&lt;math&gt; C = \max_{f} I(X;Y).\! &lt;/math&gt;
This capacity has the following property related to communicating at information rate ''R'' (where ''R'' is usually bits per symbol).  For any information rate ''R'' &lt; ''C'' and coding error ''ε'' &gt; 0, for large enough ''N'', there exists a code of length ''N'' and rate ≥ R and a decoding algorithm, such that the maximal probability of block error is ≤ ''ε''; that is, it is always possible to transmit with arbitrarily small block error.  In addition, for any rate ''R'' &amp;gt; ''C'', it is impossible to transmit with arbitrarily small block error.

''[[Channel code|Channel coding]]'' is concerned with finding such nearly optimal codes that can be used to transmit data over a noisy channel with a small coding error at a rate near the channel capacity.

====Capacity of particular channel models====
* A continuous-time analog communications channel subject to [[Gaussian noise]]—see [[Shannon–Hartley theorem]].
* A [[binary symmetric channel]] (BSC) with crossover probability ''p'' is a binary input, binary output channel that flips the input bit with probability ''p''. The BSC has a capacity of {{math|1 &amp;minus; ''H''&lt;sub&gt;b&lt;/sub&gt;(''p'')}} bits per channel use, where {{math|''H''&lt;sub&gt;b&lt;/sub&gt;}} is the binary entropy function to the base-2 logarithm:

::[[File:Binary symmetric channel.svg]]

* A [[binary erasure channel]] (BEC) with erasure probability ''p'' is a binary input, ternary output channel. The possible channel outputs are 0, 1, and a third symbol 'e' called an erasure. The erasure represents complete loss of information about an input bit. The capacity of the BEC is {{nowrap|1 &amp;minus; ''p''}} bits per channel use.

::[[File:Binary erasure channel.svg]]

====Channels with memory and directed information====
In practice many channels have memory. Namely, at time &lt;math&gt; i &lt;/math&gt; the channel is given by the condiation probability  &lt;math&gt; P(y_i|x_i,x_{i-1},x_{1-2},...,x_1,y_{i-1},y_{1-2},...,y_1). &lt;/math&gt;.
It is often more coomfortble to use the notation &lt;math&gt; x^i=(x_i,x_{i-1},x_{1-2},...,x_1) &lt;/math&gt; and the channel become &lt;math&gt; P(y_i|x^i,y^{i-1}). &lt;/math&gt;.
In such a case the capacity is given by the [[mutual information]] rate when there is no feedback available and the [[Directed information]] rate in the case that either there is feedback or not  &lt;ref&gt;{{cite journal |last1=Massey |first1=James L. |title=Causality, Feedback And Directed Information |date=1990 |url=https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.5688}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Permuter |first1=Haim Henry |last2=Weissman |first2=Tsachy |last3=Goldsmith |first3=Andrea J. |title=Finite State Channels With Time-Invariant Deterministic Feedback |journal=IEEE Transactions on Information Theory |date=February 2009 |volume=55 |issue=2 |pages=644–662 |doi=10.1109/TIT.2008.2009849|arxiv=cs/0608070 }}&lt;/ref&gt; (if there is no feedback the dircted informationj equals the mutual information).

==Applications to other fields==

===Intelligence uses and secrecy applications===
Information theoretic concepts apply to cryptography and cryptanalysis. Turing's information unit, the [[Ban (unit)|ban]], was used in the [[Ultra]] project, breaking the German [[Enigma machine]] code and hastening the [[Victory in Europe Day|end of World War II in Europe]].  Shannon himself defined an important concept now called the [[unicity distance]]. Based on the redundancy of the [[plaintext]], it attempts to give a minimum amount of [[ciphertext]] necessary to ensure unique decipherability.

Information theory leads us to believe it is much more difficult to keep secrets than it might first appear.  A [[brute force attack]] can break systems based on [[public-key cryptography|asymmetric key algorithms]] or on most commonly used methods of [[symmetric-key algorithm|symmetric key algorithms]] (sometimes called secret key algorithms), such as [[block cipher]]s.  The security of all such methods currently comes from the assumption that no known attack can break them in a practical amount of time.

[[Information theoretic security]] refers to methods such as the [[one-time pad]] that are not vulnerable to such brute force attacks.  In such cases, the positive conditional mutual information between the plaintext and ciphertext (conditioned on the [[key (cryptography)|key]]) can ensure proper transmission, while the unconditional mutual information between the plaintext and ciphertext remains zero, resulting in absolutely secure communications.  In other words, an eavesdropper would not be able to improve his or her guess of the plaintext by gaining knowledge of the ciphertext but not of the key. However, as in any other cryptographic system, care must be used to correctly apply even information-theoretically secure methods; the [[Venona project]] was able to crack the one-time pads of the Soviet Union due to their improper reuse of key material.

===Pseudorandom number generation===
[[Pseudorandom number generator]]s are widely available in computer language libraries and application programs. They are, almost universally, unsuited to cryptographic use as they do not evade the deterministic nature of modern computer equipment and software. A class of improved random number generators is termed [[cryptographically secure pseudorandom number generator]]s, but even they require [[random seed]]s external to the software to work as intended. These can be obtained via [[Extractor (mathematics)|extractors]], if done carefully. The measure of  sufficient randomness in extractors is [[min-entropy]], a value related to Shannon entropy through [[Rényi entropy]]; Rényi entropy is also used in evaluating randomness in cryptographic systems.  Although related, the distinctions among these measures mean that a random variable with high Shannon entropy is not necessarily satisfactory for use in an extractor and so for cryptography uses.

===Seismic exploration===
One early commercial application of information theory was in the field of seismic oil exploration. Work in this field made it possible to strip off and separate the unwanted noise from the desired seismic signal. Information theory and [[digital signal processing]] offer a major improvement of resolution and image clarity over previous analog methods.&lt;ref&gt;{{cite journal|doi=10.1002/smj.4250020202 | volume=2 | issue=2 | title=The corporation and innovation | year=1981 | journal=Strategic Management Journal | pages=97–118 | last1 = Haggerty | first1 = Patrick E.}}&lt;/ref&gt;

===Semiotics===
[[Semiotics|Semioticians]] [[:nl:Doede Nauta|Doede Nauta]] and [[Winfried Nöth]] both considered [[Charles Sanders Peirce]] as having created a theory of information in his works on semiotics.&lt;ref name="Nauta 1972"&gt;{{cite book |last1=Nauta |first1=Doede |title=The Meaning of Information |date=1972 |publisher=Mouton |location=The Hague |isbn=9789027919960}}&lt;/ref&gt;{{rp|171}}&lt;ref name="Nöth 2012"&gt;{{cite journal |last1=Nöth |first1=Winfried |title=Charles S. Peirce's theory of information: a theory of the growth of symbols and of knowledge |journal=Cybernetics and Human Knowing |date=January 2012 |volume=19 |issue=1–2 |pages=137–161 |url=https://edisciplinas.usp.br/mod/resource/view.php?id=2311849}}&lt;/ref&gt;{{rp|137}} Nauta defined semiotic information theory as the study of "the internal processes of coding, filtering, and information processing."&lt;ref name="Nauta 1972"/&gt;{{rp|91}}

Concepts from information theory such as redundancy and code control have been used by semioticians such as [[Umberto Eco]] and [[:it:Ferruccio Rossi-Landi|Ferruccio Rossi-Landi]] to explain ideology as a form of message transmission whereby a dominant social class emits its message by using signs that exhibit a high degree of redundancy such that only one message is decoded among a selection of competing ones.&lt;ref&gt;Nöth, Winfried (1981). "[https://kobra.uni-kassel.de/bitstream/handle/123456789/2014122246977/semi_2004_002.pdf?sequence=1&amp;isAllowed=y Semiotics of ideology]". ''Semiotica'', Issue 148.&lt;/ref&gt;

===Miscellaneous applications===
Information theory also has applications in [[Gambling and information theory]], [[black hole information paradox|black holes]], and [[bioinformatics]].

==See also==
{{Portal|Mathematics}}
{{cols|colwidth=21em}}
* [[Algorithmic probability]]
* [[Bayesian inference]]
* [[Communication theory]]
* [[Constructor theory]] - a generalization of information theory that includes quantum information
* [[Inductive probability]]
* [[Info-metrics]]
* [[Minimum message length]]
* [[Minimum description length]]
* [[List of important publications in theoretical computer science#Information theory|List of important publications]]
* [[Philosophy of information]]
{{colend}}

===Applications===
{{cols}}
* [[Active networking]]
* [[Cryptanalysis]]
* [[Cryptography]]
* [[Cybernetics]]
* [[Entropy in thermodynamics and information theory]]
* [[Gambling]]
* [[Intelligence (information gathering)]]
* [[reflection seismology|Seismic exploration]]
{{colend}}

===History===
* [[Ralph Hartley|Hartley, R.V.L.]]
* [[History of information theory]]
* [[Claude Elwood Shannon|Shannon, C.E.]]
* [[Timeline of information theory]]
* [[Hubert Yockey|Yockey, H.P.]]

===Theory===
{{div col|colwidth=16em}}
* [[Coding theory]]
* [[Detection theory]]
* [[Estimation theory]]
* [[Fisher information]]
* [[Information algebra]]
* [[Information asymmetry]]
* [[Information field theory]]
* [[Information geometry]]
* [[Information theory and measure theory]]
* [[Kolmogorov complexity]]
* [[List of unsolved problems in information theory]]
* [[Logic of information]]
* [[Network coding]]
* [[Philosophy of information]]
* [[Quantum information science]]
* [[Source coding]]
{{div col end}}

===Concepts===
{{div col|colwidth=16em}}
* [[Ban (unit)]]
* [[Channel capacity]]
* [[Communication channel]]
* [[Communication source]]
* [[Conditional entropy]]
* [[Covert channel]]
* [[Data compression]]
* Decoder
* [[Differential entropy]]
* [[Fungible information]]
* [[Information fluctuation complexity]]
* [[Information entropy]]
* [[Joint entropy]]
* [[Kullback–Leibler divergence]]
* [[Mutual information]]
* [[Pointwise mutual information]] (PMI)
* [[Receiver (information theory)]]
* [[Redundancy (information theory)|Redundancy]]
* [[Rényi entropy]]
* [[Self-information]]
* [[Unicity distance]]
* [[Variety (cybernetics)|Variety]]
* [[Hamming distance]]
{{div col end}}

==References==
{{Reflist}}

===The classic work===
{{refbegin}}
* [[Claude Elwood Shannon|Shannon, C.E.]] (1948), "[[A Mathematical Theory of Communication]]", ''Bell System Technical Journal'', 27, pp.&amp;nbsp;379–423 &amp; 623–656, July &amp; October, 1948. [http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf PDF.] &lt;br /&gt;[http://cm.bell-labs.com/cm/ms/what/shannonday/paper.html Notes and other formats.]
* R.V.L. Hartley, [http://www.dotrose.com/etext/90_Miscellaneous/transmission_of_information_1928b.pdf "Transmission of Information"], ''Bell System Technical Journal'', July 1928
* [[Andrey Kolmogorov]] (1968), "[https://www.tandfonline.com/doi/pdf/10.1080/00207166808803030 Three approaches to the quantitative definition of information]" in International Journal of Computer Mathematics.
{{refend}}

===Other journal articles===
{{refbegin|}}
* J. L. Kelly, Jr., [http://www.princeton.edu/~wbialek/rome/refs/kelly_56.pdf Princeton], "A New Interpretation of Information Rate" ''Bell System Technical Journal'', Vol. 35, July 1956, pp.&amp;nbsp;917–26.
* R. Landauer, [http://ieeexplore.ieee.org/search/wrapper.jsp?arnumber=615478 IEEE.org], "Information is Physical" ''Proc. Workshop on Physics and Computation PhysComp'92'' (IEEE Comp. Sci.Press, Los Alamitos, 1993) pp.&amp;nbsp;1–4.
* {{cite journal|last1=Landauer|first1=R.|year=1961|title=Irreversibility and Heat Generation in the Computing Process|url=http://www.research.ibm.com/journal/rd/441/landauerii.pdf|journal=IBM J. Res. Dev.|volume=5|issue=3|pages=183–191|doi=10.1147/rd.53.0183}}
* {{cite arXiv|last1=Timme|first1=Nicholas|last2=Alford|first2=Wesley|last3=Flecker|first3=Benjamin|last4=Beggs|first4=John M.|date=2012|title=Multivariate information measures: an experimentalist's perspective|eprint=1111.6857|class=cs.IT}}
{{refend}}

===Textbooks on information theory===
{{refbegin}}
* Arndt, C.  ''Information Measures, Information and its Description in Science and Engineering'' (Springer Series: Signals and Communication Technology), 2004, {{isbn|978-3-540-40855-0}}
* Ash, RB. ''Information Theory''. New York: Interscience, 1965. {{isbn|0-470-03445-9}}. New York: Dover 1990. {{isbn|0-486-66521-6}}
* [[Gallager, R]]. ''Information Theory and Reliable Communication.'' New York: John Wiley and Sons, 1968. {{isbn|0-471-29048-3}}
* Goldman, S. ''Information Theory''. New York: Prentice Hall, 1953. New York: Dover 1968 {{isbn|0-486-62209-6}}, 2005 {{isbn|0-486-44271-3}}
* {{cite book |last1=Cover |first1=Thomas |author-link1=Thomas M. Cover |last2=Thomas |first2=Joy A. |title=Elements of information theory |edition=2nd |location=New York |publisher=[[Wiley-Interscience]] |date=2006 |isbn=0-471-24195-4}}
* [[Csiszar, I]], Korner, J. ''Information Theory: Coding Theorems for Discrete Memoryless Systems''  Akademiai Kiado: 2nd edition, 1997. {{isbn|963-05-7440-3}}
* [[David J. C. MacKay|MacKay, David J. C.]]. ''[http://www.inference.phy.cam.ac.uk/mackay/itila/book.html Information Theory, Inference, and Learning Algorithms]'' Cambridge: Cambridge University Press, 2003. {{isbn|0-521-64298-1}}
* Mansuripur, M. ''Introduction to Information Theory''. New York: Prentice Hall, 1987. {{isbn|0-13-484668-0}}
* [[Robert McEliece|McEliece, R]]. ''The Theory of Information and Coding". Cambridge, 2002.  {{isbn|978-0521831857}}
*Pierce, JR.  "An introduction to information theory: symbols, signals and noise".  Dover (2nd Edition). 1961 (reprinted by Dover 1980).
* [[Reza, F]]. ''An Introduction to Information Theory''. New York: McGraw-Hill 1961. New York: Dover 1994. {{isbn|0-486-68210-2}}
* {{cite book |last1=Shannon |first1=Claude |author-link1=Claude Shannon |last2=Weaver |first2=Warren |author-link2=Warren Weaver |date=1949 |title=The Mathematical Theory of Communication |url=http://monoskop.org/images/b/be/Shannon_Claude_E_Weaver_Warren_The_Mathematical_Theory_of_Communication_1963.pdf |location=[[Urbana, Illinois]] |publisher=[[University of Illinois Press]] |lccn=49-11922 |isbn=0-252-72548-4}}
* Stone, JV.  Chapter 1 of book [http://jim-stone.staff.shef.ac.uk/BookInfoTheory/InfoTheoryBookMain.html "Information Theory: A Tutorial Introduction"], University of Sheffield, England, 2014. {{isbn|978-0956372857}}.
* Yeung, RW.  ''[http://iest2.ie.cuhk.edu.hk/~whyeung/book/ A First Course in Information Theory]'' Kluwer Academic/Plenum Publishers, 2002.  {{isbn|0-306-46791-7}}.
* Yeung, RW.  ''[http://iest2.ie.cuhk.edu.hk/~whyeung/book2/ Information Theory and Network Coding]'' Springer 2008, 2002.  {{isbn|978-0-387-79233-0}}
{{refend}}

===Other books===
{{refbegin}}
* Leon Brillouin, ''Science and Information Theory'', Mineola, N.Y.: Dover, [1956, 1962] 2004. {{isbn|0-486-43918-6}}
* [[James Gleick]], ''[[The Information: A History, a Theory, a Flood]]'', New York: Pantheon, 2011. {{isbn|978-0-375-42372-7}}
* A. I. Khinchin, ''Mathematical Foundations of Information Theory'', New York: Dover, 1957. {{isbn|0-486-60434-9}}
* H. S. Leff and A. F. Rex, Editors, ''Maxwell's Demon: Entropy, Information, Computing'', Princeton University Press, Princeton, New Jersey (1990). {{isbn|0-691-08727-X}}
* [[Robert K. Logan]]. ''What is Information? - Propagating Organization in the Biosphere, the Symbolosphere, the Technosphere and the Econosphere'', Toronto: DEMO Publishing.
* Tom Siegfried, ''The Bit and the Pendulum'', Wiley, 2000. {{isbn|0-471-32174-5}}
* [[Charles Seife]], ''[[Decoding the Universe]]'', Viking, 2006. {{isbn|0-670-03441-X}}
* Jeremy Campbell, ''[[Grammatical Man]]'', Touchstone/Simon &amp; Schuster, 1982, {{isbn|0-671-44062-4}}
* Henri Theil, ''Economics and Information Theory'', Rand McNally &amp; Company - Chicago, 1967.
* Escolano, Suau, Bonev, ''[https://www.springer.com/computer/image+processing/book/978-1-84882-296-2 Information Theory in Computer Vision and Pattern Recognition]'', Springer, 2009. {{isbn|978-1-84882-296-2}}
* Vlatko Vedral, ''Decoding Reality: The Universe as Quantum Information'', Oxford University Press 2010. {{ISBN|0-19-923769-7}}
{{refend}}

===MOOC on information theory===
* Raymond W. Yeung, "[http://www.inc.cuhk.edu.hk/InformationTheory/index.html Information Theory]" ([[The Chinese University of Hong Kong]])

==External links==
{{Wikiquote}}
{{Library resources box}}
* {{SpringerEOM |title=Information |id=p/i051040}}
* Lambert F. L. (1999), "[http://jchemed.chem.wisc.edu/Journal/Issues/1999/Oct/abs1385.html Shuffled Cards, Messy Desks, and Disorderly Dorm Rooms - Examples of Entropy Increase? Nonsense!]", ''Journal of Chemical Education''
* [http://www.itsoc.org/ IEEE Information Theory Society] and [https://www.itsoc.org/resources/surveys ITSOC Monographs, Surveys, and Reviews]

{{Cybernetics}}
{{Informatics}}
{{Compression methods}}
{{Areas of mathematics}}
{{Computer science}}

{{Authority control}}

{{DEFAULTSORT:Information Theory}}
[[Category:Information theory| ]]
[[Category:Computer-related introductions in 1948]]
[[Category:Computer science]]
[[Category:Cybernetics]]
[[Category:Formal sciences]]
[[Category:Information Age]]
[[Category:Claude Shannon]]</text>
      <sha1>tqxrljnj5ad06dtru32dmkuywkjiibb</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer algebra</title>
    <ns>14</ns>
    <id>984658</id>
    <revision>
      <id>951259802</id>
      <parentid>951190978</parentid>
      <timestamp>2020-04-16T08:17:26Z</timestamp>
      <contributor>
        <username>RussBot</username>
        <id>279219</id>
      </contributor>
      <minor/>
      <comment>Bot: Change redirected category [[:Category:Computer Science|Computer Science]] to [[:Category:Computer science|Computer science]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="505" xml:space="preserve">{{Portal|Mathematics}}
This is a category of topic relating to '''computer algebra''', which cover general information about [[algorithm]]s and techniques useful for computer algebra. Specific [[computer algebra system]]s are covered in the subcategory [[:Category:Computer algebra systems]].
{{Commons category|Computer algebra}}

[[Category:Computer science]]
[[Category:Algebra]]
[[Category:Computational science|Algebra]]
[[Category:Algorithms|Algebra]]
[[Category:Computational mathematics|allgebra]]</text>
      <sha1>kczz7icjq741ar7f7z8mupzy38g96hf</sha1>
    </revision>
  </page>
  <page>
    <title>Computational science</title>
    <ns>0</ns>
    <id>1181008</id>
    <revision>
      <id>1007070528</id>
      <parentid>1002558730</parentid>
      <timestamp>2021-02-16T09:14:26Z</timestamp>
      <contributor>
        <username>Eudamonic</username>
        <id>36879710</id>
      </contributor>
      <comment>added [[Differentiable programming]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="31612" xml:space="preserve">{{short description|Field that uses computers and mathematical models to analyze and solve scientific problems}}
'''Computational science''', also known as '''scientific computing''' or '''scientific computation''' ('''SC'''), is a rapidly growing field that uses advanced [[computing]] capabilities to understand and solve complex problems. It is an area of science which spans many disciplines, but at its core, it involves the development of models and simulations to understand natural systems.
*  [[Algorithm]]s ([[Numerical analysis|numerical]] and non-numerical): [[mathematical model]]s, [[computational model]]s, and [[computer simulation]]s developed to solve [[science]] (e.g., [[Computational biology|biological]], [[Computational physics|physical]], and [[Computational sociology|social]]), [[engineering]], and [[humanities]] problems
* [[Computer hardware]] that develops and optimizes the advanced system [[Computer hardware|hardware]], [[firmware]], [[Computer network|networking]], and [[data management]] components needed to solve computationally demanding problems
* The computing infrastructure that supports both the science and engineering problem solving and the developmental computer and information science 
In practical use, it is typically the application of [[computer simulation]] and other forms of [[computation]] from [[numerical analysis]] and [[theoretical computer science]] to solve problems in various scientific disciplines. The field is different from theory and laboratory experiment which are the traditional forms of science and [[engineering]]. The scientific computing approach is to gain understanding, mainly through the analysis of mathematical models implemented on [[computer]]s. Scientists and engineers develop [[computer programs]], [[application software]], that model systems being studied and run these programs with various sets of input parameters. The essence of computational science is the application of numerical algorithms&lt;ref&gt;Nonweiler T. R., 1986. Computational Mathematics: An Introduction to Numerical Approximation, John Wiley and Sons&lt;/ref&gt; and/or [[computational mathematics]]. In some cases, these models require massive amounts of calculations (usually [[floating-point]]) and are often executed on [[supercomputer]]s or [[distributed computing]] platforms.

== The computational scientist ==
[[File:Ways to study a system.png|thumb|Ways to study a system]]
The term [[computational scientist]] is used to describe someone skilled in scientific computing. This person is usually a scientist, an engineer or an applied mathematician who applies [[high-performance computing]] in different ways to advance the state-of-the-art in their respective applied disciplines in physics, chemistry or engineering.

Computational science is now commonly considered a third mode of [[science]], complementing and adding to [[experimentation]]/[[observation]] and [[theory]] (see image on the right).&lt;ref&gt;[http://www.siam.org/students/resources/report.php Graduate Education for Computational Science and Engineering].Siam.org, [[Society for Industrial and Applied Mathematics]] (SIAM) website; accessed Feb 2013.&lt;/ref&gt; Here, we define a [[system]] as a potential source of data,&lt;ref&gt;{{Cite book|title=Theory of Modeling and Simulation|last=Siegler|first=Bernard|year=1976}}&lt;/ref&gt; an [[experiment]] as a process of extracting data from a system by exerting it through its inputs&lt;ref&gt;{{Cite book|title=Continuous System Modelling|last=Cellier|first=François|year=1990}}&lt;/ref&gt; and a [[Computer model|model]] (''M'') for a system (''S'') and an experiment (''E'') as anything to which E can be applied in order to answer questions about S.&lt;ref&gt;{{Cite book|title=Models,Minds, Machines|last=Minski|first=Marvin|year=1965}}&lt;/ref&gt;  A computational scientist should be capable of:
* recognizing '''complex problems'''
* adequately '''conceptualising''' the system containing these problems
* designing a framework of algorithms suitable for studying this system: the '''simulation'''
* choosing a suitable '''computing infrastructure''' ([[parallel computing]]/[[grid computing]]/[[supercomputer]]s)
* hereby, maximising the '''computational power''' of the simulation
* assessing to what level the output of the simulation resembles the systems: the model is '''validated'''
* adjusting the conceptualisation of the system accordingly
* repeating cycle until a suitable level of validation is obtained: the computational scientists trusts that the simulation generates adequately realistic results for the system, under the studied conditions
In fact, substantial effort in computational sciences has been devoted to the development of algorithms, the efficient implementation in programming languages, and validation of computational results. A collection of problems and solutions in computational science can be found in Steeb, Hardy, Hardy and Stoop (2004).&lt;ref&gt;Steeb W.-H., Hardy Y., Hardy A. and Stoop R., 2004. Problems and Solutions in Scientific Computing with C++ and Java Simulations, World Scientific Publishing. {{ISBN|981-256-112-9}}&lt;/ref&gt;

Philosophers of science addressed the question to what degree computational science qualifies as science, among them Humphreys&lt;ref&gt;Humphreys, Paul. ''Extending ourselves: Computational science, empiricism, and scientific method.'' Oxford University Press, 2004.&lt;/ref&gt; and Gelfert.&lt;ref&gt;Gelfert, Axel. 2016. ''How to do science with models: A philosophical primer.'' Cham: Springer.&lt;/ref&gt; They address the general question of epistemology: how do we gain insight from such computational science approaches. Tolk&lt;ref&gt;Tolk, Andreas. "[https://books.google.com/books?hl=en&amp;lr=&amp;id=t3H0BwAAQBAJ&amp;oi=fnd&amp;pg=PA87&amp;ots=Q3eyC8ytJO&amp;sig=md19qkjAZIYgSGUAMywX5nMojD0#v=onepage&amp;q&amp;f=false Learning Something Right from Models That Are Wrong: Epistemology of Simulation]." In ''Concepts and Methodologies for Modeling and Simulation,'' edited by L. Yilmaz, pp. 87-106, Cham: Springer International Publishing, 2015.&lt;/ref&gt; uses these insights to show the epistemological constraints of computer-based simulation research. As computational science uses mathematical models representing the underlying theory in executable form, in essence, they apply modeling (theory building) and simulation (implementation and execution). While simulation and computational science are our most sophisticated way to express our knowledge and understanding, they also come with all constraints and limits already known for computational solutions.

== Applications of computational science ==
Problem domains for computational science/scientific computing include:

=== Predictive computational science ===
Predictive computational science is a scientific discipline concerned with the formulation, calibration, numerical solution and validation of mathematical models designed to predict specific aspects of physical events, given initial and boundary conditions and a set of characterizing parameters and associated uncertainties.&lt;ref&gt;Oden, J.T., Babuška, I. and Faghihi, D., 2017. Predictive computational science: Computer predictions in the presence of uncertainty. Encyclopedia of Computational Mechanics. Second Edition, pp. 1-26.&lt;/ref&gt; In typical cases, the predictive statement is formulated in terms of probabilities.  For example, given a mechanical component and a periodic loading condition, “the probability is (say) 90% that the number of cycles at failure (Nf) will be in the interval N1&lt;Nf&lt;N2”.&lt;ref&gt;Szabó B, Actis R and Rusk D.  Validation of notch sensitivity factors. Journal of Verification, Validation and Uncertainty Quantification.  4 011004, 2019&lt;/ref&gt;

=== Urban complex systems ===
In 2015, over half the world's population live in cities. By the middle of the 21st century, it is estimated that 75% of the world's population will be [[Urban area|urban]]. This urban growth is focused in the urban populations of developing countries where city dwellers will more than double, increasing from 2.5 billion in 2009 to almost 5.2 billion in 2050. Cities are massive complex systems created by humans, made up of humans and governed by humans. Trying to predict, understand and somehow shape the development of cities in the future requires complex thinking, and requires computational models and simulations to help mitigate challenges and possible disasters. The focus of research in urban complex systems is, through modeling and simulation, to build a greater understanding of city dynamics and help prepare for the coming [[Urbanization|urbanisation]].

=== Computational finance ===
{{main|Computational finance}}
In today's [[financial market]]s huge volumes of interdependent assets are traded by a large number of interacting market participants in different locations and time zones. Their behavior is of unprecedented complexity and the characterization and measurement of the risk inherent to these highly diverse set of instruments is typically based on complicated [[Mathematical model|mathematical]] and [[computational model]]s. Solving these models exactly in closed form, even at a single instrument level, is typically not possible, and therefore we have to look for efficient [[numerical algorithm]]s. This has become even more urgent and complex recently, as the credit crisis has clearly demonstrated the role of cascading effects going from single instruments through portfolios of single institutions to even the interconnected trading network. Understanding this requires a multi-scale and holistic approach where interdependent risk factors such as market, credit and liquidity risk are modelled simultaneously and at different interconnected scales.

=== Computational biology ===
{{main|Computational biology}}
Exciting new developments in [[biotechnology]] are now revolutionizing biology and [[biomedical research]]. Examples of these techniques are [[DNA sequencing|high-throughput sequencing]], high-throughput [[Real-time polymerase chain reaction|quantitative PCR]], intra-cellular imaging, [[In situ hybridization|in-situ hybridization]] of gene expression, three-dimensional imaging techniques like [[Light sheet fluorescence microscopy|Light Sheet Fluorescence Microscopy]] and [[Optical projection tomography|Optical Projection]], (micro)-[[CT scan|Computer Tomography]]. Given the massive amounts of complicated data that is generated by these techniques, their meaningful interpretation, and even their storage, form major challenges calling for new approaches. Going beyond current bioinformatics approaches, computational biology needs to develop new methods to discover meaningful patterns in these large data sets. Model-based reconstruction of [[Gene regulatory network|gene networks]] can be used to organize the gene expression data in a systematic way and to guide future data collection. A major challenge here is to understand how gene regulation is controlling fundamental biological processes like [[Biomineralization|biomineralisation]] and [[embryogenesis]]. The sub-processes like [[gene regulation]], [[Organic compound|organic molecules]] interacting with the mineral deposition process, [[Cell (biology)|cellular processes]], [[physiology]] and other processes at the tissue and environmental levels are linked. Rather than being directed by a central control mechanism, biomineralisation and embryogenesis can be viewed as an emergent behavior resulting from a complex system in which several sub-processes on very different [[Temporal scales|temporal]] and [[spatial scale]]s (ranging from nanometer and nanoseconds to meters and years) are connected into a multi-scale system. One of the few available options to understand such systems is by developing a [[Multiscale modeling|multi-scale model]] of the system.

=== Complex systems theory ===
{{main|Complex systems}}
Using [[information theory]], [[Non-equilibrium thermodynamics|non-equilibrium dynamics]] and explicit simulations computational systems theory tries to uncover the true nature of [[complex adaptive system]]s.

=== Computational science in engineering ===
{{main|Computational engineering}}

Computational science and engineering (CSE) is a relatively new discipline that deals with the development and application of computational models and simulations, often coupled with [[high-performance computing]], to solve complex physical problems arising in engineering analysis and design (computational engineering) as well as natural phenomena (computational science). CSE has been described as the "third mode of discovery" (next to theory and experimentation).&lt;ref&gt;{{Cite web |url=http://www.cseprograms.gatech.edu/sites/default/files/CSEHandbook-Students-v11.pdf |title=Computational Science and Engineering Program: Graduate Student Handbook |website=cseprograms.gatech.edu |date=September 2009 |access-date=2017-08-26 |archive-url=https://web.archive.org/web/20141014001918/http://www.cseprograms.gatech.edu/sites/default/files/CSEHandbook-Students-v11.pdf |archive-date=2014-10-14 |url-status=dead }}&lt;/ref&gt; In many fields, computer simulation is integral and therefore essential to business and research. Computer simulation provides the capability to enter fields that are either inaccessible to traditional experimentation or where carrying out traditional empirical inquiries is prohibitively expensive. CSE should neither be confused with pure [[computer science]], nor with [[computer engineering]], although a wide domain in the former is used in CSE (e.g., certain algorithms, data structures, parallel programming, high performance computing) and some problems in the latter can be modeled and solved with CSE methods (as an application area).

==Methods and algorithms==
Algorithms and mathematical methods used in computational science are varied. Commonly applied methods include:

{{div col|colwidth=20em}}
* [[Computer algebra]],&lt;ref&gt;Von Zur Gathen, J., &amp; Gerhard, J. (2013). Modern computer algebra. Cambridge University Press.&lt;/ref&gt;&lt;ref&gt;Geddes, K. O., Czapor, S. R., &amp; Labahn, G. (1992). Algorithms for computer algebra. Springer Science &amp; Business Media.&lt;/ref&gt;&lt;ref&gt;Albrecht, R. (2012). Computer algebra: symbolic and algebraic computation (Vol. 4). Springer Science &amp; Business Media.&lt;/ref&gt;&lt;ref&gt;Mignotte, M. (2012). Mathematics for computer algebra. Springer Science &amp; Business Media.&lt;/ref&gt; including symbolic computation in fields such as statistics, equation solving, algebra, calculus, geometry, linear algebra, tensor analysis (multilinear algebra), optimization
* [[Numerical analysis]],&lt;ref name="stoer"&gt;Stoer, J., &amp; Bulirsch, R. (2013). Introduction to numerical analysis. Springer Science &amp; Business Media.&lt;/ref&gt;&lt;ref name="conte"&gt;Conte, S. D., &amp; De Boor, C. (2017). Elementary numerical analysis: an algorithmic approach. [[Society for Industrial and Applied Mathematics]].&lt;/ref&gt;&lt;ref name="green"&gt;Greenspan, D. (2018). Numerical Analysis. CRC Press.&lt;/ref&gt;&lt;ref name="linz"&gt;Linz, P. (2019). Theoretical numerical analysis. Courier Dover Publications.&lt;/ref&gt; including [[Computing]] derivatives by [[finite difference]]s
** Application of [[Taylor series]] as convergent and asymptotic series
** [[Computing]] derivatives by [[Automatic differentiation]] (AD)
** [[Finite element method]] for solving PDEs&lt;ref name="bs"&gt;Brenner, S., &amp; Scott, R. (2007). The mathematical theory of finite element methods (Vol. 15). Springer Science &amp; Business Media.&lt;/ref&gt;&lt;ref name="or"&gt;Oden, J. T., &amp; Reddy, J. N. (2012). An introduction to the mathematical theory of finite elements. Courier Corporation.&lt;/ref&gt;
** High order difference approximations via [[Taylor series]] and [[Richardson extrapolation]]
** [[Methods of integration]]&lt;ref&gt;Davis, P. J., &amp; Rabinowitz, P. (2007). Methods of numerical integration. Courier Corporation.&lt;/ref&gt; on a uniform [[Mesh (mathematics)|mesh]]: [[rectangle rule]] (also called ''midpoint rule''), [[trapezoid rule]], [[Simpson's rule]]
** [[Runge–Kutta methods]] for solving ordinary differential equations
** [[Newton's method]]&lt;ref&gt;Peter Deuflhard, Newton Methods for Nonlinear Problems. Affine Invariance and Adaptive Algorithms, Second printed edition. Series Computational Mathematics 35, Springer (2006)&lt;/ref&gt;
* [[Discrete Fourier transform]]
* [[Monte Carlo method]]s&lt;ref&gt;Hammersley, J. (2013). Monte carlo methods. Springer Science &amp; Business Media.&lt;/ref&gt;&lt;ref&gt;Kalos, M. H., &amp; Whitlock, P. A. (2009). Monte carlo methods. John Wiley &amp; Sons.&lt;/ref&gt;
* [[Numerical linear algebra]],&lt;ref&gt;Demmel, J. W. (1997). Applied numerical linear algebra. [[Society for Industrial and Applied Mathematics|SIAM]].&lt;/ref&gt;&lt;ref&gt;Ciarlet, P. G., Miara, B., &amp; Thomas, J. M. (1989). Introduction to numerical linear algebra and optimization. Cambridge University Press.&lt;/ref&gt;&lt;ref&gt;Trefethen, Lloyd; Bau III, David (1997). Numerical Linear Algebra (1st ed.). Philadelphia: [[Society for Industrial and Applied Mathematics|SIAM]].&lt;/ref&gt; including decompositions and [[eigenvalue algorithm]]s
* [[Linear programming]]&lt;ref&gt;Vanderbei, R. J. (2015). Linear programming. Heidelberg: Springer.&lt;/ref&gt;&lt;ref&gt;Gass, S. I. (2003). Linear programming: methods and applications. Courier Corporation.&lt;/ref&gt;
* [[Branch and cut]]
* [[Branch and bound]]
* [[Molecular dynamics]], [[Car–Parrinello molecular dynamics]]
* [[Space mapping]]
* [[Time stepping]] methods for dynamical systems
{{div col end}}

Both historically and today, [[Fortran]] remains popular for most applications of scientific computing.&lt;ref name="ars"&gt;{{cite web |url=https://arstechnica.com/science/2014/05/scientific-computings-future-can-any-coding-language-top-a-1950s-behemoth/ |title=Scientific computing's future: Can any coding language top a 1950s behemoth? |last=Phillips |first=Lee |work=[[Ars Technica]] |date=2014-05-07 |access-date=2016-03-08 }}&lt;/ref&gt;&lt;ref name="princeton"&gt;{{cite web |url=http://press.princeton.edu/landau_firstCourse/FortranCD/AllFort.pdf |title=A First Course in Scientific Computing |last=Landau |first=Rubin |publisher=Princeton University |date=2014-05-07 |access-date=2016-03-08 }}&lt;/ref&gt; Other [[programming language]]s and [[computer algebra systems]] commonly used for the more mathematical aspects of scientific computing applications include [[GNU Octave]], [[Haskell (programming language)|Haskell]],&lt;ref name="ars" /&gt; [[Julia (programming language)|Julia]],&lt;ref name="ars" /&gt; [[Maple (software)|Maple]],&lt;ref name="princeton" /&gt; [[Mathematica]],&lt;ref&gt;[http://www.scientific-computing.com/products/review_details.php?review_id=17 Mathematica 6] Scientific Computing World, May 2007&lt;/ref&gt;&lt;ref&gt;Maeder, R. E. (1991). Programming in mathematica. Addison-Wesley Longman Publishing Co., Inc..&lt;/ref&gt;&lt;ref&gt;Stephen Wolfram. (1999). The MATHEMATICA® book, version 4. [[Cambridge University Press]].&lt;/ref&gt;&lt;ref&gt;Shaw, W. T., &amp; Tigg, J. (1993). Applied Mathematica: getting started, getting it done. Addison-Wesley Longman Publishing Co., Inc..&lt;/ref&gt;&lt;ref&gt;Marasco, A., &amp; Romano, A. (2001). Scientific Computing with Mathematica: Mathematical Problems for Ordinary Differential Equations; with a CD-ROM. [[Springer Science &amp; Business Media]].&lt;/ref&gt; [[MATLAB]],&lt;ref&gt;Quarteroni, A., Saleri, F., &amp; Gervasio, P. (2006). Scientific computing with MATLAB and Octave. Berlin: Springer.&lt;/ref&gt;&lt;ref name="gh"&gt;Gander, W., &amp; Hrebicek, J. (Eds.). (2011). Solving problems in scientific computing using Maple and Matlab®. [[Springer Science &amp; Business Media]].&lt;/ref&gt;&lt;ref name="bf"&gt;Barnes, B., &amp; Fulford, G. R. (2011). Mathematical modelling with case studies: a differential equations approach using Maple and MATLAB. Chapman and Hall/CRC.&lt;/ref&gt; [[Python (programming language)|Python]] (with third-party [[SciPy]] library&lt;ref&gt;Jones, E., Oliphant, T., &amp; Peterson, P. (2001). SciPy: Open source scientific tools for Python.&lt;/ref&gt;&lt;ref&gt;Bressert, E. (2012). SciPy and NumPy: an overview for developers. " O'Reilly Media, Inc.".&lt;/ref&gt;&lt;ref&gt;Blanco-Silva, F. J. (2013). Learning SciPy for numerical and scientific computing. Packt Publishing Ltd.&lt;/ref&gt;), [[Perl]] (with third-party [[Perl Data Language|PDL]] library),{{Citation needed|date=December 2008}} [[R (programming language)|R]],&lt;ref&gt;Ihaka, R., &amp; Gentleman, R. (1996). R: a language for data analysis and graphics. Journal of computational and graphical statistics, 5(3), 299-314.&lt;/ref&gt; [[Scilab]],&lt;ref&gt;Bunks, C., Chancelier, J. P., Delebecque, F., Goursat, M., Nikoukhah, R., &amp; Steer, S. (2012). Engineering and scientific computing with Scilab. [[Springer Science &amp; Business Media]].&lt;/ref&gt;&lt;ref&gt;Thanki, R. M., &amp; Kothari, A. M. (2019). Digital image processing using SCILAB. Springer International Publishing.&lt;/ref&gt; and [[TK Solver]]. The more computationally intensive aspects of scientific computing will often use some variation of [[C (programming language)|C]] or [[Fortran]] and optimized algebra libraries such as [[BLAS]] or [[LAPACK]]. In addition, [[parallel computing]] is heavily used in scientific computing to achieve solutions of large problems in a reasonable amount of time. In this framework, the problem is either divided over many cores on a single CPU node (such as with [[OpenMP]]), divided over many CPU nodes networked together (such as with [[Message Passing Interface|MPI]]), or is run on one or more [[Graphics processing unit|GPUs]] (typically using either [[CUDA]] or [[OpenCL]]).

Computational science application programs often model real-world changing conditions, such as weather, airflow around a plane, automobile body distortions in a crash, the motion of stars in a galaxy, an explosive device, etc. Such programs might create a 'logical mesh' in computer memory where each item corresponds to an area in space and contains information about that space relevant to the model. For example, in [[Numerical weather prediction|weather models]], each item might be a square kilometer; with land elevation, current wind direction, humidity, temperature, pressure, etc. The program would calculate the likely next state based on the current state, in simulated time steps, solving differential equations that describe how the system operates; and then repeat the process to calculate the next state.

==Conferences and journals==

In the year 2001, the [http://www.iccs-meeting.org/ ''International Conference on Computational Science (ICCS)''] was first organised. Since then it has been organised yearly. ICCS is an '''A-rank''' conference in CORE classification.

The international [https://www.journals.elsevier.com/journal-of-computational-science ''Journal of Computational Science''] published its first issue in May 2010.&lt;ref&gt;{{Cite journal|last1=Sloot|first1=Peter|last2=Coveney|first2=Peter|last3=Dongarra|first3=Jack|title=Redirecting|journal=Journal of Computational Science|volume=1|issue=1|pages=3–4|doi=10.1016/j.jocs.2010.04.003|year=2010}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Seidel|first1=Edward|last2=Wing|first2=Jeannette M.|title=Redirecting|journal=Journal of Computational Science|volume=1|issue=1|pages=1–2|doi=10.1016/j.jocs.2010.04.004|year=2010}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Sloot|first=Peter M.A.|title=Computational science: A kaleidoscopic view into science|journal=Journal of Computational Science|volume=1|issue=4|pages=189|doi=10.1016/j.jocs.2010.11.001|year=2010}}&lt;/ref&gt; A new initiative was launched in 2012, the ''Journal of Open Research Software.''&lt;ref&gt;[http://openresearchsoftware.metajnl.com/ The Journal of Open Research Software] ; announced at software.ac.uk/blog/2012-03-23-announcing-journal-open-research-software-software-metajournal&lt;/ref&gt;
In 2015, [[ReScience C]]&lt;ref&gt;{{cite journal |last1=Rougier |first1=Nicolas P. |last2=Hinsen |first2=Konrad |last3=Alexandre |first3=Frédéric |last4=Arildsen |first4=Thomas |last5=Barba |first5=Lorena A. |last6=Benureau |first6=Fabien C.Y. |last7=Brown |first7=C. Titus |last8=Buyl |first8=Pierre de |last9=Caglayan |first9=Ozan |last10=Davison |first10=Andrew P. |last11=Delsuc |first11=Marc-André |last12=Detorakis |first12=Georgios |last13=Diem |first13=Alexandra K. |last14=Drix |first14=Damien |last15=Enel |first15=Pierre |last16=Girard |first16=Benoît |last17=Guest |first17=Olivia |last18=Hall |first18=Matt G. |last19=Henriques |first19=Rafael N. |last20=Hinaut |first20=Xavier |last21=Jaron |first21=Kamil S. |last22=Khamassi |first22=Mehdi |last23=Klein |first23=Almar |last24=Manninen |first24=Tiina |last25=Marchesi |first25=Pietro |last26=McGlinn |first26=Daniel |last27=Metzner |first27=Christoph |last28=Petchey |first28=Owen |last29=Plesser |first29=Hans Ekkehard |last30=Poisot |first30=Timothée |last31=Ram |first31=Karthik |last32=Ram |first32=Yoav |last33=Roesch |first33=Etienne |last34=Rossant |first34=Cyrille |last35=Rostami |first35=Vahid |last36=Shifman |first36=Aaron |last37=Stachelek |first37=Joseph |last38=Stimberg |first38=Marcel |last39=Stollmeier |first39=Frank |last40=Vaggi |first40=Federico |last41=Viejo |first41=Guillaume |last42=Vitay |first42=Julien |last43=Vostinar |first43=Anya E. |last44=Yurchak |first44=Roman |last45=Zito |first45=Tiziano |title=Sustainable computational science: the ReScience initiative |journal=PeerJ Comput Sci |date=December 2017 |volume=3 |at=e142 |doi=10.7717/peerj-cs.142 |arxiv=1707.04393 |bibcode=2017arXiv170704393R |s2cid=7392801 }}&lt;/ref&gt; dedicated to the replication of computational results has been started on [[GitHub]].

==Education==
At some institutions, a specialization in scientific computation can be earned as a "minor" within another program (which may be at varying levels). However, there are increasingly many [[Bachelor's degree|bachelor's]], [[Master's degree|master's]] and [[doctoral degree|doctoral]] programs in computational science. The joint degree programme [http://www.uva.nl/en/shared-content/subsites/graduate-school-of-sciences/en/masters/computational-science/computational-science.html?origin=5BOaRAofTjCccATraJp2XA master program computational science] at the [[University of Amsterdam]] and the [[Vrije Universiteit Amsterdam|Vrije Universiteit]] in computational science was first offered in 2004. In this programme, students:
* learn to build computational models from real-life observations;
* develop skills in turning these models into computational structures and in performing large-scale simulations;
* learn theory that will give a firm basis for the analysis of complex systems;
* learn to analyse the results of simulations in a virtual laboratory using advanced numerical algorithms.

[[George Mason University]] was one of the early pioneers first offering a multidisciplinary doctorate Ph.D program in Computational Sciences and Informatics in 1992 that focused on a number of specialty areas including [[bioinformatics]], [[computational chemistry]], earth systems and global changes, [[computational mathematics]], [[computational physics]], space sciences, and [[computational statistics]]

School of Computational and Integrative Sciences, [[Jawaharlal Nehru University]] (erstwhile School of Information Technology&lt;ref&gt;{{Cite web | url=https://www.jnu.ac.in/scis |title = SCIS &amp;#124; Welcome to Jawaharlal Nehru University}}&lt;/ref&gt;) also offers a vibrant master's science program for computational science with two specialities namely- [[Computational Biology]] and [[Complex Systems]].&lt;ref&gt;{{Cite web | url=https://www.jnu.ac.in/content/scis-program-study | title=SCIS: Program of Study &amp;#124; Welcome to Jawaharlal Nehru University}}&lt;/ref&gt;

==Related fields==
{{div col|colwidth=15em}}
* [[Bioinformatics]]
* [[Car–Parrinello molecular dynamics]]
* [[Cheminformatics]]
* [[Chemometrics]]
* [[Computational archaeology]]
* [[Computational astrophysics]]
* [[Computational biology]]
* [[Computational chemistry]]
* [[Computational materials science]]
* [[Computational economics]]
* [[Computational electromagnetics]]
* [[Computational engineering]]
* [[Computational finance]]
* [[Computational fluid dynamics]]
* [[Computational forensics]]
* [[Computational geophysics]]
* [[Computational history]]
* [[Computational informatics]]
* [[Computational intelligence]]
* [[Computational law]]
* [[Computational linguistics]]
* [[Computational mathematics]]
* [[Computational mechanics]]
* [[Computational neuroscience]]
* [[Computational particle physics]]
* [[Computational physics]]
* [[Computational sociology]]
* [[Computational statistics]]
* [[Computational sustainability]]
* [[Computer algebra]]
* [[Computer simulation]]
* [[Financial modeling]]
* [[Geographic information system]] (GIS)
* [[High-performance computing]]
* [[Machine learning]]
* [[Network theory|Network analysis]]
* [[Neuroinformatics]]
* [[Numerical linear algebra]]
* [[Numerical weather prediction]]
* [[Pattern recognition]]
* [[Scientific visualization]]
* [[Simulation]]

{{div col end}}

==See also==
{{portal|Science|Mathematics}}
* [https://plato.stanford.edu/entries/simulations-science/ Computer simulations in science]
* [[Computational science and engineering]]
* [[Comparison of computer algebra systems]]
* [[Differentiable programming]]
* [[List of software for molecular mechanics modeling|List of molecular modeling software]]
* [[List of numerical analysis software]]
* [[List of statistical packages]]
* [[Timeline of scientific computing]]
* [[Simulated reality]]
* [[Extensions for Scientific Computation]] (XSC)

==References==
{{reflist|20em}}

==Additional sources==
* E. Gallopoulos and A. Sameh, "CSE: Content and Product". IEEE Computational Science and Engineering Magazine, 4(2):39–43 (1997)
* G. Hager and G. Wellein, Introduction to High Performance Computing for Scientists and Engineers, [[Chapman and Hall]] (2010)
* A.K. Hartmann, [https://web.archive.org/web/20090211113048/http://worldscibooks.com/physics/6988.html Practical Guide to Computer Simulations], [[World Scientific]] (2009)
* Journal [https://web.archive.org/web/20120224073451/http://www.man.poznan.pl/cmst/ Computational Methods in Science and Technology] (open access), [[Polish Academy of Sciences]]
* Journal [http://iopscience.iop.org/1749-4699/ Computational Science and Discovery], [[Institute of Physics]]
* R.H. Landau, C.C. Bordeianu, and M. Jose Paez, [https://books.google.com/books?id=gtlaWucfu3YC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false A Survey of Computational Physics: Introductory Computational Science], [[Princeton University Press]] (2008)

==External links==
{{Wikiversity|Scientific computing}}
{{Commons category}}
*[https://web.archive.org/web/20120221163722/http://www2.fz-juelich.de/nic/ John von Neumann-Institut for Computing (NIC) at Juelich (Germany)]
*[http://www.nccs.gov The National Center for Computational Science at Oak Ridge National Laboratory]
*[http://cmasc.gmu.edu/ Center for Simulation and Modeling at George Mason University]
*[https://web.archive.org/web/20100528022316/http://www.capital.edu/21424/Computational-Studies/7111/ Educational Materials for Undergraduate Computational Studies]
*[http://www.deixismagazine.org/ Computational Science at the National Laboratories]
*[http://www.udem.edu.co/index.php/departamento-de-ciencias-basicas-programas-de-pregrado/computacion-cientifica Bachelor in Computational Science, University of Medellin, Colombia, South America]
*[http://www.sos.mcmaster.ca Simulation Optimization Systems (SOS) Research Laboratory, McMaster University, Hamilton, ON]
*[https://cos.gmu.edu/cds/phd-in-computational-sciences-and-informatics/ Computational Sciences and Informatics, Ph.D Program, George Mason University]

{{DEFAULTSORT:Computational Science}}

{{Differentiable computing}}

[[Category:Computational science| ]]
[[Category:Computer science]]
[[Category:Applied mathematics]]
[[Category:Computational fields of study]]</text>
      <sha1>rk5sk8wb31xi6ksulgi8ddbererah2r</sha1>
    </revision>
  </page>
  <page>
    <title>Neural network Gaussian process</title>
    <ns>0</ns>
    <id>63513679</id>
    <revision>
      <id>993898324</id>
      <parentid>991011365</parentid>
      <timestamp>2020-12-13T02:16:47Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: url. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Suggested by Abductive | [[Category:Artificial neural networks]] | via #UCB_Category 62/168</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="20432" xml:space="preserve">[[File:Infinitely wide neural network.webm|thumb|406x406px|'''Left''': a [[Bayesian network|Bayesian neural network]] with two hidden layers, transforming a 3-dimensional input (bottom) into a two-dimensional output &lt;math&gt;(y_1, y_2)&lt;/math&gt; (top). '''Right''': output [[probability density function]] &lt;math&gt;p(y_1, y_2)&lt;/math&gt; induced by the random weights of the network. '''Video''': as the width of the network increases, the output distribution simplifies, ultimately converging to a [[Multivariate normal distribution|multivariate normal]] in the infinite width limit.]]

[[Bayesian network]]s are a modeling tool for assigning probabilities to events, and thereby characterizing the uncertainty in a model's predictions. [[Deep learning]] and [[artificial neural network]]s are approaches used in [[machine learning]] to build computational models which learn from training examples. Bayesian neural networks merge these fields. They are a type of artificial neural network whose [[Statistical parameter|parameters]] and predictions are both probabilistic.&lt;ref&gt;{{Cite journal|last=MacKay|first=David J. C.|date=1992|title=A Practical Bayesian Framework for Backpropagation Networks|journal=Neural Computation|volume=4|issue=3|pages=448–472|doi=10.1162/neco.1992.4.3.448|s2cid=16543854|issn=0899-7667|url=https://resolver.caltech.edu/CaltechAUTHORS:MACnc92b}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last=Neal|first=Radford M.|title=Bayesian Learning for Neural Networks|publisher=Springer Science and Business Media|year=2012}}&lt;/ref&gt; While standard artificial neural networks often assign high confidence even to incorrect predictions,&lt;ref&gt;
{{cite journal|last1=Guo|first1=Chuan|last2=Pleiss|first2=Geoff|last3=Sun|first3=Yu|last4=Weinberger|first4=Kilian Q.|date=2017|title=On calibration of modern neural networks|journal=Proceedings of the 34th International Conference on Machine Learning-Volume 70|arxiv=1706.04599}}
&lt;/ref&gt; Bayesian neural networks can more accurately evaluate how likely their predictions are to be correct.

Neural Network Gaussian Processes (NNGPs) are equivalent to Bayesian neural networks in a particular limit,&lt;ref name=":2" /&gt;&lt;ref name=":11"&gt;
{{cite journal|last1=Williams|first1=Christopher K. I.|date=1997|title=Computing with infinite networks|journal=Neural Information Processing Systems}}
&lt;/ref&gt;&lt;ref name=":0"&gt;{{cite journal|last1=Lee|first1=Jaehoon|last2=Bahri|first2=Yasaman|last3=Novak|first3=Roman|last4=Schoenholz|first4=Samuel S.|last5=Pennington|first5=Jeffrey|last6=Sohl-Dickstein|first6=Jascha|date=2017|title=Deep Neural Networks as Gaussian Processes|journal=International Conference on Learning Representations|arxiv=1711.00165|bibcode=2017arXiv171100165L}}&lt;/ref&gt;&lt;ref name=":3" /&gt;&lt;ref name=":1" /&gt;&lt;ref name=":4" /&gt;&lt;ref name=":9" /&gt;&lt;ref&gt;
{{cite arxiv|eprint=2002.08517|class=cs.LG|first1=Russell|last1=Tsuchida|first2=Tim|last2=Pearce|title=Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks|date=2020|last3=van der Heide|first3=Christopher|last4=Roosta|first4=Fred|last5=Gallagher|first5=Marcus}}
&lt;/ref&gt;&lt;ref name=":5" /&gt; and provide a [[Closed-form expression|closed form]] way to evaluate Bayesian neural networks. They are a [[Gaussian process]] [[probability distribution]] which describes the distribution over predictions made by the corresponding Bayesian neural network. Computation in artificial neural networks is usually organized into sequential layers of [[artificial neuron]]s. The number of neurons in a layer is called the layer width. The equivalence between NNGPs and Bayesian neural networks occurs when the layers in a Bayesian neural network become infinitely wide (see figure). This 
[[Large width limits of neural networks|large width limit]] is of practical interest, since finite width neural networks typically perform strictly better as layer width is increased.&lt;ref name=":7"&gt;
{{Cite journal|last1=Novak|first1=Roman|last2=Bahri|first2=Yasaman|last3=Abolafia|first3=Daniel A.|last4=Pennington|first4=Jeffrey|last5=Sohl-Dickstein|first5=Jascha|date=2018-02-15|title=Sensitivity and Generalization in Neural Networks: an Empirical Study|url=https://openreview.net/forum?id=HJC2SzZCW|journal=International Conference on Learning Representations|arxiv=1802.08760|bibcode=2018arXiv180208760N}}&lt;/ref&gt;&lt;ref name=":8"&gt;
{{Cite journal|last1=Canziani|first1=Alfredo|last2=Paszke|first2=Adam|last3=Culurciello|first3=Eugenio|date=2016-11-04|title=An Analysis of Deep Neural Network Models for Practical Applications|url=https://openreview.net/forum?id=Bygq-H9eg|arxiv=1605.07678|bibcode=2016arXiv160507678C}}&lt;/ref&gt;&lt;ref name=":1" /&gt;&lt;ref name=":6"&gt;
{{Cite journal|last1=Neyshabur|first1=Behnam|last2=Li|first2=Zhiyuan|last3=Bhojanapalli|first3=Srinadh|last4=LeCun|first4=Yann|last5=Srebro|first5=Nathan|date=2019|title=Towards understanding the role of over-parametrization in generalization of neural networks|journal=International Conference on Learning Representations|arxiv=1805.12076|bibcode=2018arXiv180512076N}}
&lt;/ref&gt;

The NNGP also appears in several other contexts: it describes the distribution over predictions made by wide non-Bayesian artificial neural networks after random initialization of their parameters, but before training; it appears as a term in [[neural tangent kernel]] prediction equations; it is used in [[deep information propagation]] to characterize whether hyperparameters and architectures will be trainable.&lt;ref name=":10"&gt;
{{Cite journal|last1=Schoenholz|first1=Samuel S.|last2=Gilmer|first2=Justin|last3=Ganguli|first3=Surya|last4=Sohl-Dickstein|first4=Jascha|date=2016|title=Deep information propagation|journal=International Conference on Learning Representations|arxiv=1611.01232}}
&lt;/ref&gt; 
It is related to other [[large width limits of neural networks]].

== A cartoon illustration ==
[[File:Wide neural networks are described by a Gaussian process svg.svg|alt=|thumb|406x406px|When parameters &lt;math&gt;\theta&lt;/math&gt; of an infinite width network are sampled repeatedly from their prior &lt;math&gt;p(\theta)&lt;/math&gt;, the resulting distribution over network outputs is described by a Gaussian process.]]
Every setting of a neural network's parameters &lt;math&gt;\theta&lt;/math&gt; corresponds to a specific function computed by the neural network. A prior distribution &lt;math&gt;p(\theta)&lt;/math&gt; over neural network parameters therefore corresponds to a prior distribution over functions computed by the network. As neural networks are made infinitely wide, this distribution over functions converges to a Gaussian process for many architectures.

The figure to the right plots the one-dimensional outputs &lt;math&gt;z^L(\cdot;\theta)&lt;/math&gt; of a neural network for two inputs &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;x^*&lt;/math&gt; against each other. The black dots show the function computed by the neural network on these inputs for random draws of the parameters from &lt;math&gt;p(\theta)&lt;/math&gt;. The red lines are iso-probability contours for the joint distribution over network outputs &lt;math&gt;z^L(x;\theta)&lt;/math&gt; and &lt;math&gt;z^L(x^*;\theta)&lt;/math&gt; induced by &lt;math&gt;p(\theta)&lt;/math&gt;. This is the distribution in function space corresponding to the distribution &lt;math&gt;p(\theta)&lt;/math&gt; in parameter space, and the black dots are samples from this distribution. For infinitely wide neural networks, since the distribution over functions computed by the neural network is a Gaussian process, the joint distribution over network outputs is a multivariate Gaussian for any finite set of network inputs.

The notation used in this section is the same as the notation used below to derive the correspondence between NNGPs and fully connected networks, and more details can be found there.

== Architectures which correspond to an NNGP ==
The equivalence between infinitely wide Bayesian neural networks and NNGPs has been shown to hold for: single hidden layer&lt;ref name=":2"&gt;{{Citation|last=Neal|first=Radford M.|chapter=Priors for Infinite Networks|date=1996|title=Bayesian Learning for Neural Networks|series=Lecture Notes in Statistics|volume=118|pages=29–53|publisher=Springer New York|doi=10.1007/978-1-4612-0745-0_2|isbn=978-0-387-94724-2}}&lt;/ref&gt; and deep&lt;ref name=":0" /&gt;&lt;ref name=":3"&gt;
{{cite journal |last1=G. de G. Matthews |first1=Alexander |last2=Rowland |first2=Mark |last3=Hron |first3=Jiri |last4=Turner |first4=Richard E. |last5=Ghahramani | first5=Zoubin |date=2017 |title=Gaussian Process Behaviour in Wide Deep Neural Networks |journal=International Conference on Learning Representations |arxiv=1804.11271 |bibcode=2018arXiv180411271M }}
&lt;/ref&gt; [[fully connected network]]s as the number of units per layer is taken to infinity; [[convolutional neural network]]s as the number of channels is taken to infinity;&lt;ref name=":1"&gt;
{{cite journal |last1=Novak |first1=Roman |last2=Xiao |first2=Lechao |last3=Lee |first3=Jaehoon |last4=Bahri |first4=Yasaman |last5=Yang | first5=Greg |last6=Abolafia | first6=Dan | last7= Pennington |first7=Jeffrey |last8=Sohl-Dickstein |first8=Jascha |date=2018 |title=Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes |journal=International Conference on Learning Representations |arxiv=1810.05148 |bibcode=2018arXiv181005148N }}&lt;/ref&gt;&lt;ref name=":4"&gt;
{{cite journal |last1=Garriga-Alonso |first1= Adrià |last2= Aitchison |first2= Laurence |last3=Rasmussen |first3=Carl Edward |date=2018 |title=Deep Convolutional Networks as shallow Gaussian Processes |journal=International Conference on Learning Representations |arxiv= 1808.05587 |bibcode= 2018arXiv180805587G }}&lt;/ref&gt;&lt;ref name=":9"&gt;
{{cite arxiv |last1=Borovykh |first1=Anastasia |date=2018 |title=A Gaussian Process perspective on Convolutional Neural Networks |class=stat.ML |eprint=1810.10798 }}
&lt;/ref&gt; transformer networks as the number of attention heads is taken to infinity;&lt;ref&gt;{{Cite journal|last1=Hron|first1=Jiri|last2=Bahri|first2=Yasaman|last3=Sohl-Dickstein|first3=Jascha|last4=Novak|first4=Roman|date=2020-06-18|title=Infinite attention: NNGP and NTK for deep attention networks|journal=International Conference on Machine Learning|volume=2020|arxiv=2006.10540|bibcode=2020arXiv200610540H}}&lt;/ref&gt; [[Recurrent neural network|recurrent networks]] as the number of units is taken to infinity.&lt;ref name=":5" /&gt;
In fact, this NNGP correspondence holds for almost any architecture: Generally, if an architecture can be expressed solely via matrix multiplication and coordinatewise nonlinearities (i.e. a [[tensor program]]), then it has an infinite-width GP.&lt;ref name=":5"&gt;
{{cite journal |last1=Yang |first1=Greg |date=2019 |title=Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes |url=https://papers.nips.cc/paper/9186-wide-feedforward-or-recurrent-neural-networks-of-any-architecture-are-gaussian-processes.pdf |journal=Advances in Neural Information Processing Systems |arxiv=1910.12478 |bibcode=2019arXiv191012478Y }}
&lt;/ref&gt;
This in particular includes all feedforward or recurrent neural networks composed of multilayer perceptron, recurrent neural networks (e.g. [[LSTM]]s, [[Gated recurrent unit|GRUs]]), (nD or graph) [[Convolutional neural network|convolution]], pooling, skip connection, attention, [[batch normalization]], and/or layer normalization.

== Correspondence between an infinitely wide fully connected network and a Gaussian process ==

This section expands on the correspondence between infinitely wide neural networks and Gaussian processes for the specific case of a fully connected architecture. It provides a proof sketch outlining why the correspondence holds, and introduces the specific functional form of the NNGP for fully connected networks. The proof sketch closely follows the approach in ''Novak,'' ''et al., 2018''.&lt;ref name=":1" /&gt;

=== Network architecture specification ===

[[File:Fully connected architecture.pdf|thumb|An NNGP is derived which is equivalent to a Bayesian neural network with this fully connected architecture.]]

Consider a fully connected artificial neural network with inputs &lt;math&gt;x&lt;/math&gt;, parameters &lt;math&gt;\theta&lt;/math&gt; consisting of weights &lt;math&gt;W^l&lt;/math&gt; and biases &lt;math&gt;b^l&lt;/math&gt; for each layer &lt;math&gt;l&lt;/math&gt; in the network, pre-activations (pre-nonlinearity) &lt;math&gt;z^l&lt;/math&gt;, activations (post-nonlinearity) &lt;math&gt;y^l&lt;/math&gt;, pointwise nonlinearity &lt;math&gt;\phi(\cdot)&lt;/math&gt;, and layer widths &lt;math&gt;n^l&lt;/math&gt;. For simplicity, the width &lt;math&gt;n^{L+1}&lt;/math&gt; of the readout vector &lt;math&gt;z^L&lt;/math&gt; is taken to be 1. The parameters of this network have a prior distribution &lt;math&gt;p(\theta)&lt;/math&gt;, which consists of an isotropic Gaussian for each weight and bias, with the variance of the weights scaled inversely with layer width. This network is illustrated in the figure to the right, and described by the following set of equations:

:&lt;math block=""&gt;
\begin{align}
x &amp;\equiv \text{input} \\
y^l(x) &amp;= \left\{\begin{array}{lcl} 
x &amp; &amp; l = 0 \\
\phi\left(z^{l-1}(x)\right) &amp; &amp; l &gt; 0 
\end{array}\right. \\
z^l_i(x) &amp;= \sum_j W^l_{ij} y^l_j(x) + b^l_i \\
W^l_{ij} &amp;\sim \mathcal N\left( 0, \frac{\sigma^2_w}{n^l} \right) \\
b^l_i &amp;\sim \mathcal N\left( 0,\sigma^2_b \right) \\
\phi(\cdot) &amp;\equiv \text{nonlinearity} \\
y^l(x), z^{l-1}(x) &amp;\in \mathbb R^{n^l \times 1} \\
n^{L+1} &amp;= 1 \\
\theta &amp;= \left\{ W^0, b^0, \dots, W^L, b^L \right\} 
\end{align}
&lt;/math&gt;

=== &lt;math&gt;z^l | y^l&lt;/math&gt; is a Gaussian process ===

We first observe that the pre-activations &lt;math&gt;z^l&lt;/math&gt; are described by a Gaussian process conditioned on the preceding activations &lt;math&gt;y^l&lt;/math&gt;. This result holds even at finite width. 
Each pre-activation &lt;math&gt;z^l_i&lt;/math&gt; is a weighted sum of Gaussian random variables, corresponding to the weights &lt;math&gt;W^l_{ij}&lt;/math&gt; and biases &lt;math&gt;b^l_i&lt;/math&gt;, where the coefficients for each of those Gaussian variables are the preceding activations &lt;math&gt;y^l_j&lt;/math&gt;. 
Because they are a weighted sum of zero-mean Gaussians, the &lt;math&gt;z^l_i&lt;/math&gt; are themselves zero-mean Gaussians (conditioned on the coefficients &lt;math&gt;y^l_j&lt;/math&gt;).
Since the &lt;math&gt;z^l&lt;/math&gt; are jointly Gaussian for any set of &lt;math&gt;y^l&lt;/math&gt;, they are described by a Gaussian process conditioned on the preceding activations &lt;math&gt;y^l&lt;/math&gt;. 
The covariance or kernel of this Gaussian process depends on the weight and bias variances &lt;math&gt;\sigma_w^2&lt;/math&gt; and &lt;math&gt;\sigma_b^2&lt;/math&gt;, as well as the second moment matrix &lt;math&gt;K^l&lt;/math&gt; of the preceding activations &lt;math&gt;y^l&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
z^l_i \mid y^l &amp;\sim \mathcal{GP}\left( 0, \sigma^2_w K^l + \sigma^2_b \right) \\
K^l(x, x') &amp;= \frac{1}{n^l} \sum_i y_i^l(x) y_i^l(x')
\end{align}
&lt;/math&gt;

The effect of the weight scale &lt;math&gt;\sigma^2_w&lt;/math&gt; is to rescale the contribution to the covariance matrix from &lt;math&gt;K^l&lt;/math&gt;, while the bias is shared for all inputs, and so &lt;math&gt;\sigma_b^2&lt;/math&gt; makes the &lt;math&gt;z^l_i&lt;/math&gt; for different datapoints more similar and makes the covariance matrix more like a constant matrix.

=== &lt;math&gt;z^l | K^l&lt;/math&gt; is a Gaussian process ===

The pre-activations &lt;math&gt;z^l&lt;/math&gt; only depend on &lt;math&gt;y^l&lt;/math&gt; through its second moment matrix &lt;math&gt;K^l&lt;/math&gt;. Because of this, we can say that &lt;math&gt;z^l&lt;/math&gt; is a Gaussian process conditioned on &lt;math&gt;K^l&lt;/math&gt;, rather than conditioned on &lt;math&gt;y^l&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
z^l_i \mid K^l &amp;\sim \mathcal{GP}\left( 0, \sigma^2_w K^l + \sigma^2_b \right).
\end{align}
&lt;/math&gt;

=== As layer width &lt;math&gt;n^l \rightarrow \infty&lt;/math&gt;, &lt;math&gt;K^l \mid K^{l-1}&lt;/math&gt; becomes deterministic ===

As previously defined, &lt;math&gt;K^l&lt;/math&gt; is the second moment matrix of &lt;math&gt;y^l&lt;/math&gt;. Since &lt;math&gt;y^l&lt;/math&gt; is the activation vector after applying the nonlinearity &lt;math&gt;\phi&lt;/math&gt;, it can be replaced by &lt;math&gt;\phi\left(z^{l-1}\right)&lt;/math&gt;, resulting in a modified equation expressing &lt;math&gt;K^l&lt;/math&gt; for &lt;math&gt;l&gt;0&lt;/math&gt; in terms of &lt;math&gt;z^{l-1}&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
K^l(x, x') &amp;= 
\frac{1}{n^l} \sum_i \phi\left( z^{l-1}_i(x) \right) \phi\left( z^{l-1}_i(x') \right)
.
\end{align}
&lt;/math&gt;

We have already determined that &lt;math&gt;z^{l-1} | K^{l-1}&lt;/math&gt; is a Gaussian process. This means that the sum defining &lt;math&gt;K^l&lt;/math&gt; is an average over &lt;math&gt;n^l&lt;/math&gt; samples from a Gaussian process which is a function of &lt;math&gt;K^{l-1}&lt;/math&gt;,

&lt;math block=""&gt;
\begin{align}
\left\{ z^{l-1}_i(x), z^{l-1}_i(x') \right\} &amp;\sim \mathcal{GP}\left( 0, \sigma^2_w K^{l-1} + \sigma^2_b \right)
.
\end{align}
&lt;/math&gt;

As the layer width &lt;math&gt;n^l&lt;/math&gt; goes to infinity, this average over &lt;math&gt;n^l&lt;/math&gt; samples from the Gaussian process can be replaced with an integral over the Gaussian process:

:&lt;math block=""&gt;
\begin{align}
\lim_{n^l \rightarrow \infty} K^l(x, x') &amp;= \int dz dz' \phi( z ) \phi( z' ) \mathcal{N}\left( \left[\begin{array}{c} 
z \\
z' 
\end{array}\right]; 0, \sigma^2_w \left[ 
\begin{array}{cc} 
K^{l-1}(x, x) &amp; K^{l-1}(x, x') \\
K^{l-1}(x', x) &amp; K^{l-1}(x', x') 
\end{array}
\right] + \sigma^2_b \right) 
\end{align}
&lt;/math&gt;

So, in the infinite width limit the second moment matrix &lt;math&gt;K^l&lt;/math&gt; for each pair of inputs &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;x'&lt;/math&gt; can be expressed as an integral over a 2d Gaussian, of the product of &lt;math&gt;\phi(z)&lt;/math&gt; and &lt;math&gt;\phi(z')&lt;/math&gt;. 
There are a number of situations where this has been solved analytically, such as when &lt;math&gt;\phi(\cdot)&lt;/math&gt; is a [[Rectifier (neural networks)|ReLU]]&lt;ref&gt;
{{cite journal|last1=Cho|first1=Youngmin|last2=Saul|first2=Lawrence K.|date=2009|title=Kernel Methods for Deep Learning|url=http://papers.nips.cc/paper/3628-kernel-methods-for-deep-|journal=Neural Information Processing Systems|pages=342–350}}
&lt;/ref&gt; or [[error function]]&lt;ref name=":11" /&gt; nonlinearity.
Even when it can't be solved analytically, since it is a 2d integral it can generally be efficiently computed numerically.&lt;ref name=":0" /&gt;
This integral is deterministic, so &lt;math&gt;K^l | K^{l-1}&lt;/math&gt; is deterministic.

For shorthand, we define a functional &lt;math&gt;F&lt;/math&gt;, which corresponds to computing this 2d integral for all pairs of inputs, and which maps &lt;math&gt;K^{l-1}&lt;/math&gt; into &lt;math&gt;K^l&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
\lim_{n^l \rightarrow \infty} K^l
&amp;= F\left(
K^{l-1}
\right)
.
\end{align}
&lt;/math&gt;

=== &lt;math&gt;z^L \mid x&lt;/math&gt; is an NNGP ===

By recursively applying the observation that &lt;math&gt;K^l \mid K^{l-1}&lt;/math&gt; is deterministic as &lt;math&gt;n^l \rightarrow \infty&lt;/math&gt;, &lt;math&gt;K^L&lt;/math&gt; can be written as a deterministic function of &lt;math&gt;K^0&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
\lim_{\min\left( n^1, \dots, n^L\right) \rightarrow \infty} K^L
&amp;= F \circ F
\cdots
\left(
K^{0}
\right) = F^L\left(K^0\right)
,
\end{align}
&lt;/math&gt;

where &lt;math&gt;F^L&lt;/math&gt; indicates applying the functional &lt;math&gt;F&lt;/math&gt; sequentially &lt;math&gt;L&lt;/math&gt; times. 
By combining this expression with the further observations that the input layer second moment matrix &lt;math&gt;K^0(x,x')=\frac{1}{n^0} \sum_i x_i x'_i&lt;/math&gt; is a deterministic function of the input &lt;math&gt;x&lt;/math&gt;, and that &lt;math&gt;z^L | K^L&lt;/math&gt; is a Gaussian process, the output of the neural network can be expressed as a Gaussian process in terms of its input,

:&lt;math block=""&gt;
\begin{align}
z^L_i(x) &amp;\sim \mathcal{GP}\left( 0, \sigma^2_w F^L\left(K^0\right) + \sigma^2_b \right)
.
\end{align}
&lt;/math&gt;

== Software libraries ==
[https://github.com/google/neural-tangents Neural Tangents] is a [[free and open-source]] [[Python (programming language)|Python]] library used for computing and doing inference with the NNGP and [[neural tangent kernel]] corresponding to various common ANN architectures.&lt;ref&gt;{{Citation|last1=Novak|first1=Roman|title=Neural Tangents: Fast and Easy Infinite Neural Networks in Python|date=2019-12-05|work=International Conference on Learning Representations (ICLR)|volume=2020|arxiv=1912.02803|bibcode=2019arXiv191202803N|last2=Xiao|first2=Lechao|last3=Hron|first3=Jiri|last4=Lee|first4=Jaehoon|last5=Alemi|first5=Alexander A.|last6=Sohl-Dickstein|first6=Jascha|last7=Schoenholz|first7=Samuel S.}}&lt;/ref&gt;

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

[[Category:Computer science]]
[[Category:Bayesian networks]]
[[Category:Machine learning]]
[[Category:Deep learning]]
[[Category:Bayesian statistics]]
[[Category:Artificial neural networks]]
[[Category:Kernel methods for machine learning]]</text>
      <sha1>3yck2xeuevgydedzwrv99gvjr7j4c2t</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer networking</title>
    <ns>14</ns>
    <id>4677693</id>
    <revision>
      <id>981528880</id>
      <parentid>981528609</parentid>
      <timestamp>2020-10-02T21:23:45Z</timestamp>
      <contributor>
        <username>Andrybak</username>
        <id>23735172</id>
      </contributor>
      <comment>break categorization cycle: removed [[Category:Computer-mediated communication]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="286" xml:space="preserve">{{Commons category|Computer networking}}
{{Category diffuse}}
{{Cat main|Computer network}}

==See also==
* [[:Category:Distributed computing]]
{{CatAutoTOC}}

[[Category:Computer science]]
[[Category:Telecommunications]]
[[Category:Computer engineering]]
[[Category:Data transmission]]</text>
      <sha1>6mj2k558d1dnbudpkvf0vtcwjkxtzuo</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computer languages</title>
    <ns>14</ns>
    <id>935897</id>
    <revision>
      <id>1002240530</id>
      <parentid>1002187952</parentid>
      <timestamp>2021-01-23T14:03:56Z</timestamp>
      <contributor>
        <username>Mike Peel</username>
        <id>214232</id>
      </contributor>
      <comment>Removing Commons category link that does not match this category ([[:commons:Category:Programming languages]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="136" xml:space="preserve">{{Cat more|Computer language}}

[[Category:Computer science]]
[[Category:Computing]]
[[Category:Formal languages]]
[[Category:Notation]]</text>
      <sha1>ngtjskgqf3kq7ja0oidt2e6nkq4lkgv</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Control theory</title>
    <ns>14</ns>
    <id>1028771</id>
    <revision>
      <id>963341303</id>
      <parentid>963210103</parentid>
      <timestamp>2020-06-19T08:15:50Z</timestamp>
      <contributor>
        <username>RussBot</username>
        <id>279219</id>
      </contributor>
      <minor/>
      <comment>Bot: Change redirected category [[:Category:Computer Science|Computer Science]] to [[:Category:Computer science|Computer science]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="249" xml:space="preserve">{{Commons category|Control theory}}
{{Cat main|Control theory}}
{{CatAutoTOC}}

[[Category:Cybernetics]]
[[Category:Control engineering]]
[[Category:Computer science]]
[[Category:Mathematics]]
[[Category:Systems theory]]
[[Category:Formal sciences]]</text>
      <sha1>gm8zeukousxb9v5wtlh00i8bv3sf7zm</sha1>
    </revision>
  </page>
  <page>
    <title>Large width limits of neural networks</title>
    <ns>0</ns>
    <id>64415394</id>
    <revision>
      <id>995422720</id>
      <parentid>995016799</parentid>
      <timestamp>2020-12-20T23:28:43Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 16 templates: del empty params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8524" xml:space="preserve">[[File:Infinitely wide neural network.webm|thumb|406x406px|Behavior of a neural network simplifies as it becomes infinitely wide. '''Left''': a [[Bayesian network|Bayesian neural network]] with two hidden layers, transforming a 3-dimensional input (bottom) into a two-dimensional output &lt;math&gt;(y_1, y_2)&lt;/math&gt; (top). '''Right''': output [[probability density function]] &lt;math&gt;p(y_1, y_2)&lt;/math&gt; induced by the random weights of the network. '''Video''': as the width of the network increases, the output distribution simplifies, ultimately converging to a [[Neural network Gaussian process]] in the infinite width limit.]]

[[Artificial neural network]]s are a class of models used in [[machine learning]], and inspired by [[neural circuit|biological neural networks]]. They are the core component of modern [[deep learning]] algorithms. Computation in artificial neural networks is usually organized into sequential layers of [[artificial neuron]]s. The number of neurons in a layer is called the layer width. Theoretical analysis of artificial neural networks sometimes considers the limiting case that layer width becomes large or infinite. This limit enables simple analytic statements to be made about neural network predictions, training dynamics, generalization, and loss surfaces. This wide layer limit is also of practical interest, since finite width neural networks often perform strictly better as layer width is increased.&lt;ref name=":7"&gt;
{{Cite journal|last1=Novak|first1=Roman|last2=Bahri|first2=Yasaman|last3=Abolafia|first3=Daniel A.|last4=Pennington|first4=Jeffrey|last5=Sohl-Dickstein|first5=Jascha|date=2018-02-15|title=Sensitivity and Generalization in Neural Networks: an Empirical Study|url=https://openreview.net/forum?id=HJC2SzZCW|journal=International Conference on Learning Representations|arxiv=1802.08760|bibcode=2018arXiv180208760N}}&lt;/ref&gt;&lt;ref name=":8"&gt;
{{Cite journal|last1=Canziani|first1=Alfredo|last2=Paszke|first2=Adam|last3=Culurciello|first3=Eugenio|date=2016-11-04|title=An Analysis of Deep Neural Network Models for Practical Applications|url=https://openreview.net/forum?id=Bygq-H9eg|arxiv=1605.07678|bibcode=2016arXiv160507678C}}&lt;/ref&gt;&lt;ref name=":1"&gt;
{{cite journal |last1=Novak |first1=Roman |last2=Xiao |first2=Lechao |last3=Lee |first3=Jaehoon |last4=Bahri |first4=Yasaman |last5=Yang | first5=Greg |last6=Abolafia | first6=Dan | last7= Pennington |first7=Jeffrey |last8=Sohl-Dickstein |first8=Jascha |date=2018 |title=Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes |journal=International Conference on Learning Representations |arxiv=1810.05148 |bibcode=2018arXiv181005148N }}&lt;/ref&gt;&lt;ref name=":6"&gt;
{{Cite journal|last1=Neyshabur|first1=Behnam|last2=Li|first2=Zhiyuan|last3=Bhojanapalli|first3=Srinadh|last4=LeCun|first4=Yann|last5=Srebro|first5=Nathan|date=2019|title=Towards understanding the role of over-parametrization in generalization of neural networks|journal=International Conference on Learning Representations|arxiv=1805.12076|bibcode=2018arXiv180512076N}}
&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Lawrence|first1=Steve|last2=Giles|first2=C. Lee|last3=Tsoi|first3=Ah Chung|date=1996|title=What size neural network gives optimal generalization? convergence properties of backpropagation|citeseerx=10.1.1.125.6019|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.125.6019}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Bartlett|first=P.L.|date=1998|title=The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network|url=https://ieeexplore.ieee.org/document/661502|journal=IEEE Transactions on Information Theory|volume=44|issue=2|pages=525–536|doi=10.1109/18.661502|issn=1557-9654}}&lt;/ref&gt;
__TOC__
== Theoretical approaches based on a large width limit ==

* The [[Neural Network Gaussian Process]] (NNGP) corresponds to the infinite width limit of Bayesian neural networks, and to the distribution over functions realized by non-Bayesian neural networks after random initialization.&lt;ref&gt;
{{Citation|last=Neal|first=Radford M.|chapter=Priors for Infinite Networks|date=1996|title=Bayesian Learning for Neural Networks|series=Lecture Notes in Statistics|volume=118|pages=29–53|publisher=Springer New York|doi=10.1007/978-1-4612-0745-0_2|isbn=978-0-387-94724-2}}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal|last1=Lee|first1=Jaehoon|last2=Bahri|first2=Yasaman|last3=Novak|first3=Roman|last4=Schoenholz|first4=Samuel S.|last5=Pennington|first5=Jeffrey|last6=Sohl-Dickstein|first6=Jascha|date=2017|title=Deep Neural Networks as Gaussian Processes|journal=International Conference on Learning Representations|arxiv=1711.00165|bibcode=2017arXiv171100165L}}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal |last1=G. de G. Matthews |first1=Alexander |last2=Rowland |first2=Mark |last3=Hron |first3=Jiri |last4=Turner |first4=Richard E. |last5=Ghahramani | first5=Zoubin |date=2017 |title=Gaussian Process Behaviour in Wide Deep Neural Networks |journal=International Conference on Learning Representations |arxiv=1804.11271 |bibcode=2018arXiv180411271M }}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal |last1=Hron |first1=Jiri |last2=Bahri |first2=Yasaman |last3=Novak |first3=Roman |last4=Pennington |first4=Jeffrey |last5=Sohl-Dickstein | first5=Jascha |date=2020 |title=Exact posterior distributions of wide Bayesian neural networks |journal=ICML 2020 Workshop on Uncertainty &amp; Robustness in Deep Learning |arxiv=2006.10541}}
&lt;/ref&gt;
* The same underlying computations that are used to derive the NNGP kernel are also used in [[deep information propagation]] to characterize the propagation of information about gradients and inputs through a deep network.&lt;ref name=":10"&gt;
{{Cite journal|last1=Schoenholz|first1=Samuel S.|last2=Gilmer|first2=Justin|last3=Ganguli|first3=Surya|last4=Sohl-Dickstein|first4=Jascha|date=2016|title=Deep information propagation|journal=International Conference on Learning Representations|arxiv=1611.01232}}
&lt;/ref&gt;  This characterization is used to predict how model trainability depends on architecture and initializations hyper-parameters.
* The [[Neural tangent kernel|Neural Tangent Kernel]] describes the evolution of neural network predictions during gradient descent training. In the infinite width limit the NTK usually becomes constant, often allowing closed form expressions for the function computed by a wide neural network throughout gradient descent training.&lt;ref&gt;
{{Cite journal|last1=Jacot| first1=Arthur| last2=Gabriel| first2=Franck| last3=Hongler| first3=Clement|title=Neural tangent kernel: Convergence and generalization in neural networks|date=2018|journal=Advances in Neural Information Processing Systems|arxiv=1806.07572}}&lt;/ref&gt; The training dynamics essentially become linearized.&lt;ref name="Lee"&gt;{{Cite journal|last=Lee|first=Jaehoon|last2=Xiao|first2=Lechao|last3=Schoenholz|first3=Samuel S.|last4=Bahri|first4=Yasaman|last5=Novak|first5=Roman|last6=Sohl-Dickstein|first6=Jascha|last7=Pennington|first7=Jeffrey|date=2018-02-15|title=Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent|arxiv=1902.06720}}&lt;/ref&gt;
* The study of infinite width neural networks with a different initial weight scaling and suitably large learning rates leads to qualitatively different nonlinear training dynamics than those described by the fixed neural tangent kernel.&lt;ref&gt;{{Cite book|last=Mei, Song Montanari, Andrea Nguyen, Phan-Minh|title=A Mean Field View of the Landscape of Two-Layers Neural Networks|date=2018-04-18|oclc=1106295873}}&lt;/ref&gt;&lt;ref&gt;
{{Cite arxiv|last1=Nguyen| first1=Phan-Minh| last2=Pham| first2=Huy Tuan|title=A Rigorous Framework for the Mean Field Limit of Multilayer Neural Networks|date=2020| class=cs.LG|eprint=2001.11443}}
&lt;/ref&gt;
* Catapult dynamics describe neural network training dynamics in the case that logits diverge to infinity as the layer width is taken to infinity, and describe qualitative properties of early training dynamics.&lt;ref&gt;
{{cite arxiv|last1=Lewkowycz|first1=Aitor|last2=Bahri|first2=Yasaman|last3=Dyer|first3=Ethan|last4=Sohl-Dickstein|first4=Jascha|last5=Gur-Ari|first5=Guy|date=2020|title=The large learning rate phase of deep learning: the catapult mechanism|class=stat.ML|eprint=2003.02218}}
&lt;/ref&gt;

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

[[Category:Computer science]]
[[Category:Machine learning]]
[[Category:Deep learning]]
[[Category:Artificial neural networks]]</text>
      <sha1>918uzeztfi1icf8up44uqgupczae9ze</sha1>
    </revision>
  </page>
  <page>
    <title>Linux kernel</title>
    <ns>0</ns>
    <id>21347315</id>
    <revision>
      <id>1014972818</id>
      <parentid>1014886371</parentid>
      <timestamp>2021-03-30T00:54:05Z</timestamp>
      <contributor>
        <username>Quebec99</username>
        <id>8019410</id>
      </contributor>
      <minor/>
      <comment>Fix duplicate ref names – [[:Category:Pages with duplicate reference names|You can help!]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="179080" xml:space="preserve">{{Short description|Free and open-source Unix-like operating system kernel}}
{{Use dmy dates|date=June 2016}}
{{Infobox OS
| name = Linux &lt;!-- no templates use your name--&gt;
| title = Linux kernel
| logo = [[File:Tux.svg|120px|Tux]]
| logo caption = [[Tux (mascot)|Tux]] the penguin, mascot of Linux&lt;ref&gt;{{cite web|date=2008 |title=Linux Logos and Mascots |publisher=Linux Online |url=http://www.linux.org/info/logos.html |access-date=11 August 2009 |archive-url=https://web.archive.org/web/20100815085106/http://www.linux.org/info/logos.html |archive-date=15 August 2010 |url-status=dead }}&lt;/ref&gt;
| screenshot = Linux 3.0.0 boot.png
| caption = Linux kernel 3.0.0 booting
| developer = [[Linus Torvalds]] and thousands of collaborators&lt;!--see git-log--&gt;
| programmed in = [[C (programming language)|C]] (95.7%), and other languages including [[C++]] and [[Assembly language|assembly]]&lt;ref&gt;{{Cite web |url=https://www.openhub.net/p/linux/analyses/latest/languages_summary |title=The Linux Kernel Open Source Project on Open Hub: Languages Page |access-date=28 March 2019 |archive-date=15 November 2018 |archive-url=https://web.archive.org/web/20181115222418/https://www.openhub.net/p/linux/analyses/latest/languages_summary |url-status=live }}&lt;/ref&gt;
| family = [[Unix-like]]
| released = 0.02 &lt;small&gt;({{Start date and age|1991|10|5|df=yes}})&lt;/small&gt;&lt;!--note that 0.01 was not released to public--&gt;
| language = English
| kernel type = [[Monolithic kernel|Monolithic]]
| license = [[GNU General Public License|GNU GPLv2 (only)]] with some code under compatible GPL variants or under permissive licenses like BSD, MIT&lt;ref name="Linux_Licensing"&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/process/license-rules.html#kernel-licensing|title=Linux kernel licensing rules — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-06|archive-date=7 March 2020|archive-url=https://web.archive.org/web/20200307065451/https://www.kernel.org/doc/html/latest/process/license-rules.html#kernel-licensing|url-status=live}}&lt;/ref&gt;
| website = {{URL|https://www.kernel.org/}}
| author = [[Linus Torvalds]]
}}
The '''Linux kernel''' is a [[free and open-source]],&lt;ref&gt;{{Cite book|last1=Tanenbaum|first1=Andrew|title=Modern Operating Systems|last2=Bos|first2=Herbert|publisher=Pearson|year=2015|isbn=9781292061429|location=United States of America|pages=722|oclc=892574803}}&lt;/ref&gt;&lt;ref name="Love 2010 p.4 "&gt;{{cite book | last=Love | first=Robert | title=Linux kernel development | publisher=Addison-Wesley | year=2010 | isbn=978-0-672-32946-3 | oclc=268788260 | language=en | page=4}}&lt;/ref&gt; [[Monolithic kernel|monolithic]], [[Modular design|modular]],&lt;ref name="Love 2010 p.338 "&gt;{{cite book | last=Love | first=Robert | title=Linux kernel development | publisher=Addison-Wesley | year=2010 | isbn=978-0-672-32946-3 | oclc=268788260 | language=en | page=338}}&lt;/ref&gt; [[Computer multitasking|multitasking]], [[Unix-like]] [[operating system]] [[kernel (operating system)|kernel]].&lt;ref&gt;{{cite web|title=README|url=https://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=blob;f=README;h=90a07658ede14840346eee6610648bcf4ec79997;hb=f3b8436ad9a8ad36b3c9fa1fe030c7f38e5d3d0b|publisher=git.kernel.org|access-date=24 March 2021|archive-date=24 July 2012|archive-url=https://archive.today/20120724163945/http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=blob;f=README;h=90a07658ede14840346eee6610648bcf4ec79997;hb=f3b8436ad9a8ad36b3c9fa1fe030c7f38e5d3d0b|url-status=dead}}&lt;/ref&gt; It was conceived and created in 1991 by [[Linus Torvalds]]&lt;ref&gt;{{cite web |last=Richardson |first=Marjorie |date=1 November 1999 |title=Interview: Linus Torvalds |publisher=Linux Journal |url=http://www.linuxjournal.com/article/3655 |access-date=20 August 2009 |archive-date=14 May 2011 |archive-url=https://web.archive.org/web/20110514084627/http://www.linuxjournal.com/article/3655 |url-status=live }}&lt;/ref&gt; for his [[Intel 80386|i386]]-based PC, and it was soon adopted as the kernel for the [[GNU|GNU operating system]],&lt;ref&gt;{{cite book|last=Williams|first=Sam|title=Free as in Freedom: Richard Stallman's Crusade for Free Software|date=March 2002|publisher=[[O'Reilly Media|O'Reilly]]|isbn=0-596-00287-4|chapter=Chapter 9: The GNU General Public License|access-date=12 November 2010|chapter-url=https://archive.org/details/freeasinfreedomr00will}}&lt;/ref&gt; which was created as a [[Free software|free]] replacement for UNIX.&lt;ref name="832 F.Supp. 7902"&gt;{{cite court|litigants=Unix System Laboratories v. Berkeley Software|court=[[United States District Court for the District of New Jersey|D.N.J.]]|reporter=F. Supp.|vol=832|opinion=790|date=1993|url=https://www.leagle.com/decision/19931622832fsupp79011506}}&lt;/ref&gt; Since then, it has spawned a plethora of [[Linux distributions|operating system distributions]], commonly also called [[Linux]].

Linux is deployed on a wide variety of computing systems, such as [[embedded device]]s, [[mobile device]]s (including its use in the [[Android (operating system)|Android]] operating system), [[personal computer]]s, [[Server (computing)|servers]], [[Mainframe computers|mainframes]], and [[supercomputer]]s.&lt;ref name="top500stats" /&gt; It can be tailored for specific architectures and for several usage scenarios using a family of simple commands (that is, without the need of manually editing its source code before compilation);&lt;ref name=":10" /&gt;&lt;ref name=":11" /&gt;&lt;ref name=":12" /&gt; privileged users can also fine-tune kernel parameters at runtime.&lt;ref name=":13" /&gt;&lt;ref name=":14" /&gt;&lt;ref name=":15" /&gt; Most of the Linux kernel code is written using the [[GNU]] extensions of [[GNU Compiler Collection|GCC]]&lt;ref name="Love 2010 p.18"&gt;{{Cite book|last=Love|first=Robert|title=Linux Kernel Development|publisher=Addison Wesley|year=2010|isbn=978-0-672-32946-3 | oclc=268788260 | language=en|page=18}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=C Extensions (Using the GNU Compiler Collection (GCC))|url=https://gcc.gnu.org/onlinedocs/gcc-10.2.0/gcc/C-Extensions.html#C-Extensions|access-date=2020-11-13|website=gcc.gnu.org|archive-date=20 November 2020|archive-url=https://web.archive.org/web/20201120064908/https://gcc.gnu.org/onlinedocs/gcc-10.2.0/gcc/C-Extensions.html#C-Extensions|url-status=live}}&lt;/ref&gt; to the standard [[C (programming language)|C programming language]] and with the use of architecture specific instructions ([[Instruction set architecture|ISA]]). This produces a highly optimized executable ([[vmlinux]]) with respect to utilization of memory space and task execution times.&lt;ref name="Love 2010 pp.379-380"&gt;{{Cite book|last=Love|first=Robert|title=Linux Kernel Development|publisher=Addison Wesley|year=2010|isbn=9780672329463|location=USA|pages=379–380}}&lt;/ref&gt;

Day-to-day development discussions take place on the [[Linux kernel mailing list]] (LKML). Changes are tracked using the version control system [[git]], which was created by Torvalds as a bespoke replacement for [[BitKeeper]]. Linux as a whole is released under the [[GNU General Public License]] version 2 (GPLv2),&lt;ref name="COPYING_File"&gt;{{Cite web|url=https://elixir.bootlin.com/linux/latest/source/COPYING|title=Linux source code: COPYING (v5.4.8) - Bootlin|website=elixir.bootlin.com|access-date=2020-01-06|archive-date=1 June 2020|archive-url=https://web.archive.org/web/20200601173846/https://elixir.bootlin.com/linux/latest/source/COPYING|url-status=live}}&lt;/ref&gt; but it also contains several files under other compatible licenses,&lt;ref name="Linux_Licensing" /&gt; and an ad hoc exemption for the user space API [[Include directive|header files]] (UAPI).

== History ==
{{See also|History of Linux|Linux kernel version history}}
[[File:LinuxCon Europe Linus Torvalds 03 (cropped).jpg|thumb|[[Linus Torvalds]] at the LinuxCon Europe 2014 in [[Düsseldorf]]]]

In April 1991, [[Linus Torvalds]], at the time a 21-year-old [[computer science]] student at the [[University of Helsinki]], [[Finland]], started working on some simple ideas for an operating system. He started with a [[Context switch|task switcher]] in [[x86 assembly language|Intel 80386 assembly language]] and a [[Pseudo terminal|terminal driver]]. On 25 August 1991, Torvalds posted the following to ''comp.os.minix'', a [[Usenet newsgroup|newsgroup]] on [[Usenet]]:&lt;ref name="Torvlads25Aug91"&gt;{{cite newsgroup |last=Torvalds |first=Linus Benedict |author-link=Linus Torvalds |date=26 August 1991 |title=What would you like to see most in minix? |newsgroup=comp.os.minix |message-id=1991Aug25.205708.9541@klaava.Helsinki.FI |url=https://groups.google.com/group/comp.os.minix/msg/b813d52cbc5a044b |access-date=14 September 2016 |archive-date=9 May 2013 |archive-url=https://web.archive.org/web/20130509134305/http://groups.google.com/group/comp.os.minix/msg/b813d52cbc5a044b |url-status=live }}&lt;/ref&gt;

{{quote|I'm doing a (free) operating system (just a hobby, won't be big and professional like gnu) for 386(486) [[IBM Personal Computer/AT|AT]] clones. This has been brewing since April, and is starting to get ready. I'd like any feedback on things people like/dislike in minix, as my OS resembles it somewhat (same physical layout of the file-system (due to practical reasons) among other things).
I've currently ported [[bash (Unix shell)|bash]](1.08) and [[GNU Compiler Collection|gcc]](1.40), and things seem to work. This implies that I'll get something practical within a few months [...] Yes - it's free of any minix code, and it has a multi-threaded fs. It is NOT protable{{sic}} (uses 386 task switching etc), and it probably never will support anything other than AT-harddisks, as that's all I have :-(.}}

On 17 September 1991, Torvalds prepared version 0.01 of Linux and put on the "ftp.funet.fi" – FTP server of the Finnish University and Research Network ([[FUNET]]). It was not even executable since its code still needed Minix for compilation and play.&lt;ref name="Running Linux"&gt;{{Cite book|last1=Welsh|first1=Matt|title=Running Linux|last2=Dalheimer|first2=Matthias Kalle|last3=Kaufman|first3=Lar|publisher=O'Reilly Media, Inc.|year=1999|isbn=1-56592-976-4|edition=3rd|location=Sebastopol, CA|chapter=1|oclc=50638246}}&lt;/ref&gt;

On 5 October 1991, Torvalds announced the first "official" version of Linux, version 0.02.&lt;ref name="Free minix-like kernel sources for 386-AT"&gt;{{Cite web|url=https://groups.google.com/g/comp.os.minix/c/4995SivOl9o/m/GwqLJlPSlCEJ|title=Free minix-like kernel sources for 386-AT - Google Groups|date=1991-10-05|website=groups.google.com|access-date=2020-03-19|archive-date=1 March 2021|archive-url=https://web.archive.org/web/20210301162937/https://groups.google.com/g/comp.os.minix/c/4995SivOl9o/m/GwqLJlPSlCEJ|url-status=live}}&lt;/ref&gt; At this point, Linux was able to run Bash, GCC, and some other GNU utilities:&lt;ref name="Free minix-like kernel sources for 386-AT" /&gt;&lt;ref name="Running Linux" /&gt;

{{quote|[As] I mentioned a month ago, I'm working on a free version of a Minix-lookalike for AT-386 computers.  It has finally reached the stage where it's even usable (though may not be depending on what you want), and I am willing to put out the sources for wider distribution.  It is just version 0.02...but I've successfully run bash, gcc, gnu-make, gnu-sed, compress, etc. under it.}}

After that, many people contributed code to the project, including some developers from the [[MINIX]] community. At the time, the [[GNU Project]] had created many of the components required for a free operating system, but its own kernel, [[GNU Hurd]], was incomplete and unavailable. The [[Berkeley Software Distribution]] had not yet freed itself from [[History of the Berkeley Software Distribution#Net/2 and legal troubles|legal encumbrances]]. Despite the limited functionality of the early versions, Linux rapidly gained developers and users.

Torvalds assigned version 0 to the kernel to indicate that it was mainly for testing and not intended for productive use.&lt;ref name="Christine Bresnahan &amp; Richard Blum 2016 107"&gt;{{cite book |title=LPIC-2: Linux Professional Institute Certification Study Guide: Exam 201 and Exam 202 |author= Christine Bresnahan &amp; Richard Blum|year=2016 |publisher=John Wiley &amp; Sons |isbn=9781119150794 |page=107 }}&lt;/ref&gt; Version 0.11, released in December 1991, was the first [[self-hosting (compilers)|self-hosted]] Linux, for it could be compiled by a computer running the same kernel.

When Torvalds released version 0.12 in February 1992, he adopted the [[GNU General Public License]] version 2 (GPLv2) over his previous self-drafted license, which had not permitted commercial redistribution.&lt;ref name="Relnotes-0.12"&gt;{{cite web |last=Torvalds |first=Linus |author-link=Linus Torvalds |title=Release Notes for Linux v0.12 |publisher=The Linux Kernel Archives |url=https://www.kernel.org/pub/linux/kernel/Historic/old-versions/RELNOTES-0.12 |access-date=21 February 2007 |archive-date=19 August 2007 |archive-url=https://web.archive.org/web/20070819045030/http://www.kernel.org/pub/linux/kernel/Historic/old-versions/RELNOTES-0.12 |url-status=live }}&lt;/ref&gt; In contrast to [[Unix]], all [[source files]] of Linux are freely available, including [[device drivers]].&lt;ref&gt;{{cite book|author=Fred Hantelmann|title=LINUX Start-up Guide: A self-contained introduction|publisher=Springer Science &amp; Business Media|year=2016|isbn=9783642607493|page=1}}&lt;/ref&gt; The initial success of Linux was driven by programmers and testers across the world. With the support of the [[POSIX]] APIs, through the libC that, whether needed, acts as an entry point to the kernel address space, Linux could run software and applications that had been developed for Unix.&lt;ref name="Fred Hantelmann 2016 16"&gt;{{cite book|author=Fred Hantelmann|title=LINUX Start-up Guide: A self-contained introduction|publisher=Springer Science &amp; Business Media|year=2016|isbn=9783642607493|page=16}}&lt;/ref&gt;

[[File:Linux kernel ubiquity.svg|thumb|300px|The Linux kernel supports various hardware architectures, providing a common platform for software, including [[proprietary software]].]]
On 19 January 1992, the first post to the new newsgroup ''alt.os.linux'' was submitted.&lt;ref&gt;{{cite newsgroup |last=Summers |first=David W. |date=19 January 1992 |title=Troubles with Partitions |newsgroup=alt.os.linux |message-id=1992Jan19.085628.18752@cseg01.uark.edu |url=https://groups.google.com/group/alt.os.linux/msg/c638df159fa15159 |access-date=7 January 2007 |archive-date=2 June 2013 |archive-url=https://web.archive.org/web/20130602210415/http://groups.google.com/group/alt.os.linux/msg/c638df159fa15159 |url-status=live }}&lt;/ref&gt; On 31 March 1992, the newsgroup was renamed ''comp.os.linux''.&lt;ref&gt;{{cite newsgroup |last=Clegg |first=Alan B. |date=31 March 1992 |title=It's here! |newsgroup=comp.os.linux |message-id=1992Mar31.131811.19832@rock.concert.net |url=https://groups.google.com/group/comp.os.linux/msg/81fe3618c4803d1e |access-date=7 January 2007 |archive-date=2 June 2013 |archive-url=https://web.archive.org/web/20130602203914/http://groups.google.com/group/comp.os.linux/msg/81fe3618c4803d1e |url-status=live }}&lt;/ref&gt; The fact that Linux is a [[monolithic kernel]] rather than a [[microkernel]] was the topic of a debate between [[Andrew S. Tanenbaum]], the creator of MINIX, and Torvalds.&lt;ref&gt;{{cite book |date=1999 |title=Open Sources: Voices from the Open Source Revolution |chapter-url=https://archive.org/details/isbn_9781565925823 |publisher=[[O'Reilly Media|O'Reilly]] |chapter=Appendix A: The Tanenbaum-Torvalds Debate |isbn=1-56592-582-3 |access-date=22 November 2006 }}&lt;/ref&gt; The [[Tanenbaum–Torvalds debate]] started in 1992 on the [[Usenet]] group ''comp.os.minix'' as a general discussion about kernel architectures.&lt;ref&gt;{{cite newsgroup |title=LINUX is obsolete |last=Tanenbaum |first=Andy |author-link=Andrew S. Tanenbaum |date=29 January 1992 |newsgroup=comp.os.minix |message-id=12595@star.cs.vu.nl |url=https://groups.google.com/group/comp.os.minix/msg/f447530d082cd95d |access-date=10 May 2006 |archive-date=17 October 2011 |archive-url=https://web.archive.org/web/20111017163006/http://groups.google.com/group/comp.os.minix/msg/f447530d082cd95d |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Tanenbaum-Torvalds Debate: Part II |url=http://www.cs.vu.nl/~ast/reliable-os/ |last=Tanenbaum |first=Andy |author-link=Andrew S. Tanenbaum |date=12 May 2006 |publisher=[[VU University Amsterdam]] |access-date=6 January 2007 |archive-date=5 August 2015 |archive-url=https://web.archive.org/web/20150805132304/http://www.cs.vu.nl/~ast/reliable-os/ |url-status=live }}&lt;/ref&gt;

Linux version 0.95 was the first to be capable of running the [[X Window System]].&lt;ref&gt;{{Cite web|url=https://www.techradar.com/news/software/operating-systems/the-history-of-linux-how-time-has-shaped-the-penguin-1113914|title=The history of Linux: how time has shaped the penguin|last=November 2012|first=David Hayward22|website=TechRadar|language=en|access-date=2020-03-19|archive-date=19 March 2020|archive-url=https://web.archive.org/web/20200319065513/https://www.techradar.com/news/software/operating-systems/the-history-of-linux-how-time-has-shaped-the-penguin-1113914|url-status=live}}&lt;/ref&gt; In March 1994, Linux 1.0.0 was released with 176,250 lines of code.&lt;ref&gt;{{Cite web|url=https://www.techradar.com/news/software/operating-systems/the-history-of-linux-how-time-has-shaped-the-penguin-1113914/2|title=The history of Linux: how time has shaped the penguin|last=November 2012|first=David Hayward22|website=TechRadar|language=en|access-date=2020-03-26|archive-date=19 March 2020|archive-url=https://web.archive.org/web/20200319065522/https://www.techradar.com/news/software/operating-systems/the-history-of-linux-how-time-has-shaped-the-penguin-1113914/2|url-status=live}}&lt;/ref&gt; It was the first version suitable for use in [[Deployment environment|production environments]].&lt;ref name="Christine Bresnahan &amp; Richard Blum 2016 107"/&gt;

It started a versioning system for the kernel with three or four numbers separated by dots where the first represented the ''major'' release, the second was the ''minor release'', and the third was the ''revision.''&lt;ref&gt;{{Cite book|last=Love, Robert (Robert M.)|title=Linux kernel development|publisher=Addison-Wesley|year=2010|isbn=978-0-672-32946-3|edition=3rd|location=Upper Saddle River, NJ|pages=9|oclc=268788260}}&lt;/ref&gt; At that time odd-numbered ''minor'' releases were for development and tests, whilst even numbered ''minor'' releases were for production. The optional fourth digit indicated a set of patches to a ''revision.''&lt;ref name="Christine Bresnahan &amp; Richard Blum 2016 107" /&gt; Development releases were indicated with ''-rc'' ("release candidate") suffix.

The current version numbering is slightly different from the above. The even vs. odd numbering has been dropped and a specific ''major'' version is now indicated by the first two numbers, taken as a whole. While the time-frame is open for the development of the next ''major'', the -rcN suffix is used to identify the n'th ''release candidate'' for the next version.&lt;ref name=":2"&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/process/2.Process.html#the-big-picture|title=How the development process works — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-03-26|archive-date=9 December 2017|archive-url=https://web.archive.org/web/20171209130758/https://www.kernel.org/doc/html/latest/process/2.Process.html#the-big-picture|url-status=live}}&lt;/ref&gt; For example, the release of the version 4.16 was preceded by seven 4.16-rcN (from -rc1 to -rc7). Once a stable release is made, its maintenance is passed off to the “stable team". Occasional updates to stable releases are identified by a three numbering scheme (e.g., 4.13.1, 4.13.2, ..., 4.13.16).&lt;ref name=":2" /&gt;

After version 1.3 of the kernel, Torvalds decided that Linux had evolved enough to warrant a new ''major'' number, so he released version 2.0.0 in June 1996.&lt;ref name="Christine Bresnahan &amp; Richard Blum 2016 108"&gt;{{cite book |title=LPIC-2: Linux Professional Institute Certification Study Guide: Exam 201 and Exam 202 |author= Christine Bresnahan &amp; Richard Blum|year=2016 |publisher=John Wiley &amp; Sons |isbn=9781119150794 |page=108 }}&lt;/ref&gt;&lt;ref name="2.0.0 release"&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/9606.1/0056.html |title=Linux 2.0 really _is_ released.. |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=9 June 1996 |mailing-list=[[LKML]] |access-date=8 March 2015 |archive-date=2 April 2015 |archive-url=https://web.archive.org/web/20150402091044/http://lkml.iu.edu/hypermail/linux/kernel/9606.1/0056.html |url-status=live }}&lt;/ref&gt; The series included 41 releases. The major feature of 2.0 was support for [[symmetric multiprocessing]] (SMP) and support for more types of processors.

Starting with version 2.0, Linux is configurable for selecting specific hardware targets and for enabling architecture specific features and optimizations.&lt;ref name="Fred Hantelmann 2016 16"/&gt; The ''make *config'' family of commands of ''kbuild'' are used to enable and configure thousands of options for building ad hoc kernel executables ([[vmlinux]]) and loadable modules.&lt;ref name=":10"&gt;{{Cite web|title=Kernel Build System — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/kbuild/index.html|access-date=2020-07-17|website=www.kernel.org|archive-date=22 July 2020|archive-url=https://web.archive.org/web/20200722122129/https://www.kernel.org/doc/html/latest/kbuild/index.html|url-status=live}}&lt;/ref&gt;&lt;ref name=":11"&gt;{{Cite web|title=Kconfig make config — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/kbuild/kconfig.html|access-date=2020-09-13|website=www.kernel.org|archive-date=17 July 2020|archive-url=https://web.archive.org/web/20200717132644/https://www.kernel.org/doc/html/latest/kbuild/kconfig.html|url-status=live}}&lt;/ref&gt;

Version 2.2, released on 20 January 1999,&lt;ref name="2.2.0 release"&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/9901.2/1084.html |title=2.2.0-final |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=20 January 1999 |mailing-list=[[LKML]] |access-date=8 March 2015 |archive-date=2 April 2015 |archive-url=https://web.archive.org/web/20150402144000/http://lkml.iu.edu/hypermail/linux/kernel/9901.2/1084.html |url-status=live }}&lt;/ref&gt; improved locking granularity and SMP management, added [[m68k]], [[PowerPC]], [[SPARC|Sparc64]], [[DEC Alpha|Alpha]], and other 64-bit platforms support.&lt;ref name=":16" /&gt; Furthermore, it added new [[file systems]] including [[Microsoft]]'s [[NTFS]] read-only capability.&lt;ref name=":16"&gt;{{cite web |url=http://kniggit.net/wonderful-world-linux/wonderful-world-linux-2-2/ |title=The Wonderful World of Linux 2.2 |date=26 January 1999 |access-date=27 October 2008 |archive-date=6 November 2014 |archive-url=https://web.archive.org/web/20141106030845/http://kniggit.net/wonderful-world-linux/wonderful-world-linux-2-2/ |url-status=live }}&lt;/ref&gt; In 1999, IBM published its patches to the Linux 2.2.13 code for the support of the [[IBM System/390|S/390]] architecture.&lt;ref&gt;{{Cite web|url=http://linuxvm.org/penguinvm/notes.html|title=Linux/390 Observations and Notes|website=linuxvm.org|access-date=2020-03-29|archive-date=26 February 2019|archive-url=https://web.archive.org/web/20190226085302/http://linuxvm.org/penguinvm/notes.html|url-status=live}}&lt;/ref&gt;

Version 2.4.0, released on 4 January 2001,&lt;ref name="2.4.0 release"&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/0101.0/0776.html |title=And oh, btw.. |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=4 January 2001 |mailing-list=[[LKML]] |access-date=8 March 2015 |archive-date=26 January 2016 |archive-url=https://web.archive.org/web/20160126231619/http://lkml.iu.edu/hypermail/linux/kernel/0101.0/0776.html |url-status=live }}&lt;/ref&gt; contained support for [[Industry Standard Architecture|ISA]] [[Plug and Play]], [[Universal Serial Bus|USB]], and [[PC Card]]s. Linux 2.4 added support for the [[Pentium 4]] and [[Itanium]] (the latter introduced the [[IA-64|ia64]] ISA that was jointly developed by Intel and Hewlett-Packard to supersede the older [[PA-RISC]]), and for the newer [[MIPS architecture|64-bit MIPS]] processor.&lt;ref name="WWOL24"&gt;{{cite web|url=http://kniggit.net/wwol24.html|archive-url=https://web.archive.org/web/20050317071343/http://www.kniggit.net/wwol24.html|url-status=dead|archive-date=17 March 2005|title=The Wonderful World of Linux 2.4|access-date=27 October 2008}}&lt;/ref&gt; Development for 2.4.''x'' changed a bit in that more features were made available throughout the duration of the series, including support for [[Bluetooth]], [[Logical Volume Manager (Linux)|Logical Volume Manager]] (LVM) version 1, [[RAID]] support, [[InterMezzo (file system)|InterMezzo]] and [[ext3]] file systems.

Version 2.6.0 was released on 17 December 2003.&lt;ref name="2.6.0 release"&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/0312.2/0348.html |title=Linux 2.6.0 |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=17 December 2003 |mailing-list=[[LKML]] |access-date=28 February 2015 |archive-date=2 April 2015 |archive-url=https://web.archive.org/web/20150402162542/http://lkml.iu.edu/hypermail/linux/kernel/0312.2/0348.html |url-status=live }}&lt;/ref&gt; The development for 2.6.''x'' changed further towards including new features throughout the duration of the series. Among the changes that have been made in the 2.6 series are: integration of [[µClinux]] into the mainline kernel sources, [[Physical Address Extension|PAE]] support, support for several new lines of [[Central processing unit|CPUs]], integration of Advanced Linux Sound Architecture (ALSA) into the mainline kernel sources, support for up to 2&lt;sup&gt;32&lt;/sup&gt; users (up from 2&lt;sup&gt;16&lt;/sup&gt;), support for up to 2&lt;sup&gt;29&lt;/sup&gt; process IDs (64-bit only, 32-bit arches still limited to 2&lt;sup&gt;15&lt;/sup&gt;),&lt;ref&gt;{{cite web|url=http://man7.org/linux/man-pages/man5/proc.5.html|title=proc(5) - Linux manual page|type=see /proc/sys/kernel/pid_max|access-date=19 February 2014|archive-date=7 February 2014|archive-url=https://web.archive.org/web/20140207232837/http://man7.org/linux/man-pages/man5/proc.5.html|url-status=live}}&lt;/ref&gt; substantially increased the number of device types and the number of devices of each type, improved [[64-bit]] support, support for [[file system]]s which support file sizes of up to 16 [[terabyte]]s, in-kernel [[Preemption (computing)|preemption]], support for the [[Native POSIX Thread Library]] (NPTL), [[User-mode Linux]] integration into the mainline kernel sources, [[Security-Enhanced Linux|SELinux]] integration into the mainline kernel sources, [[InfiniBand]] support, and considerably more.

Also notable are the addition of a wide selection of file systems starting with the 2.6.''x'' releases: now the kernel supports a large number of file systems, some that have been designed for Linux, like [[ext3]], [[ext4]], [[Filesystem in Userspace|FUSE]], [[Btrfs]],&lt;ref&gt;{{Cite web|title=btrfs Wiki|url=https://btrfs.wiki.kernel.org/index.php/Main_Page|access-date=2020-07-17|website=btrfs.wiki.kernel.org|archive-date=25 April 2012|archive-url=https://web.archive.org/web/20120425151829/https://btrfs.wiki.kernel.org/|url-status=live}}&lt;/ref&gt; and others that are native of other operating systems like [[JFS (file system)|JFS]], [[XFS]], Minix, [[Xenix]], [[IRIX|Irix]], [[Solaris (operating system)|Solaris]], [[System V]], [[Microsoft Windows|Windows]], and [[MS-DOS]].&lt;ref name="Fred Hantelmann 2016 1–2"&gt;{{cite book|author=Fred Hantelmann|title=LINUX Start-up Guide: A self-contained introduction|publisher=Springer Science &amp; Business Media|year=2016|isbn=9783642607493|pages=1–2}}&lt;/ref&gt;

In 2005 the ''stable team'' was formed as a response to the lack of a kernel tree where people could work on [[software bug|bug fixes]], and it would keep updating ''stable'' versions.&lt;ref name="2.6.16-longterm"&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/0608.0/1111.html |title=Adrian Bunk is now taking over the 2.6.16-stable branch |last=Kroah-Hartman |first=Greg |author-link=Greg Kroah-Hartman |date=3 August 2006 |mailing-list=[[LKML]] |access-date=21 February 2015 |archive-date=26 January 2016 |archive-url=https://web.archive.org/web/20160126231617/http://lkml.iu.edu/hypermail/linux/kernel/0608.0/1111.html |url-status=live }}&lt;/ref&gt; In February 2008 the ''linux-next'' tree was created to serve as a place where patches aimed to be merged during the next development cycle gathered.&lt;ref&gt;{{cite mailing list |url=https://lkml.org/lkml/2008/2/11/512 |title=Announce: Linux-next (Or Andrew's dream :-)) |last=Rothwell |first=Stephen |date=12 February 2008 |mailing-list=[[LKML]] |access-date=30 October 2010 |archive-date=24 November 2010 |archive-url=https://web.archive.org/web/20101124235700/http://lkml.org/lkml/2008/2/11/512 |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://lwn.net/Articles/269120/ |title=linux-next and patch management process |last=Corbet |first=Jonathan |date=21 October 2010 |work=[[LWN.net]] |publisher=Eklektix, Inc |access-date=30 October 2010 |archive-date=21 June 2010 |archive-url=https://web.archive.org/web/20100621034215/http://lwn.net/Articles/269120/ |url-status=live }}&lt;/ref&gt; Several subsystem maintainers also adopted the suffix ''-next'' for trees containing code which they mean to submit for inclusion in the next release cycle. {{As of|2014|January}}, the in-development version of Linux is held in an unstable branch named ''linux-next''.&lt;ref&gt;{{cite web |url=http://www.kernel.org |title=The Linux Kernel Archives |publisher=Kernel.org |access-date=22 January 2014 |archive-date=30 January 1998 |archive-url=https://web.archive.org/web/19980130085039/http://www.kernel.org/ |url-status=live }}&lt;/ref&gt;

Linux used to be maintained without the help of an automated [[source code management]] system until, in 2002, development switched to [[BitKeeper]]. It was freely available for Linux developers but it was not [[free software]]. In 2005, because of efforts to [[reverse-engineer]] it, the company which owned the software revoked the support of the Linux community. In response, Torvalds and others wrote [[Git (software)|Git]]. The new system was written within weeks, and in two months the first official kernel made using it was released.&lt;ref&gt;{{cite mailing list |mailing-list=git-commits-head |author=Linux Kernel Mailing List |url=http://marc.info/?l=git-commits-head&amp;m=111904216911731 |title=Linux 2.6.12 |date=17 June 2005 |access-date=23 January 2008 |archive-date=26 January 2016 |archive-url=https://web.archive.org/web/20160126231629/http://marc.info/?l=git-commits-head&amp;m=111904216911731 |url-status=live }}&lt;/ref&gt;

Details on the history of the 2.6 kernel series can be found in the ChangeLog files on the 2.6 kernel series source code release area of [[kernel.org]].&lt;ref&gt;{{cite web |url=https://www.kernel.org/pub/linux/kernel/v2.6/ |title=Index of /pub/linux/kernel/v2.6 |publisher=Kernel.org |access-date=2 March 2014 |archive-date=10 February 2014 |archive-url=https://web.archive.org/web/20140210131743/https://www.kernel.org/pub/linux/kernel/v2.6/ |url-status=live }}&lt;/ref&gt;

The 20th anniversary of Linux was celebrated by Torvalds in July 2011 with the release of the 3.0.0 kernel version.&lt;ref name="Christine Bresnahan &amp; Richard Blum 2016 108"/&gt; As 2.6 has been the version number for 8 years, a new ''uname26'' personality that reports 3.x as 2.6.40+x had to be added to the kernel so that old programs would work.&lt;ref&gt;{{cite web |title=Add a personality to report 2.6.x version numbers [LWN.net] |url=https://lwn.net/Articles/451168/ |website=lwn.net |access-date=15 July 2020 |archive-date=16 July 2020 |archive-url=https://web.archive.org/web/20200716092939/https://lwn.net/Articles/451168/ |url-status=live }}&lt;/ref&gt;

Version 3.0 was released on 22 July 2011.&lt;ref name="3.0 release"&gt;{{cite web |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=21 July 2011 |title=Linux 3.0 release |publisher=[[Linux kernel mailing list]] |url=http://lkml.indiana.edu/hypermail/linux/kernel/1107.2/01843.html |access-date=16 May 2013 |archive-date=18 October 2019 |archive-url=https://web.archive.org/web/20191018044641/http://lkml.iu.edu/hypermail/linux/kernel/1107.2/01843.html |url-status=live }}&lt;/ref&gt; On 30 May 2011, Torvalds announced that the big change was "NOTHING. Absolutely nothing." and asked, "...let's make sure we really make the next release not just an all new shiny number, but a good kernel too."&lt;ref&gt;{{cite mailing list |url=http://permalink.gmane.org/gmane.linux.kernel/1147415 |title=Linux 3.0-rc1 |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=30 May 2011 |mailing-list=[[LKML]] |access-date=1 July 2013 |archive-url=https://web.archive.org/web/20110531232747/http://permalink.gmane.org/gmane.linux.kernel/1147415 |archive-date=31 May 2011 |url-status=dead |df=dmy-all }}&lt;/ref&gt; After the expected 6–7 weeks of the development process, it would be released near the 20th anniversary of Linux.

On 11 December 2012, Torvalds decided to reduce kernel complexity by removing support for [[i386]] processors, making the 3.7 kernel series the last one still supporting the original processor.&lt;ref&gt;{{cite web |url=http://www.zdnet.com/article/good-bye-386-linux-to-drop-support-for-i386-chips-with-next-major-release/ |title=Good-Bye 386: Linux to drop support for i386 chips with next major release |last=Vaughan-Nichols |first=Steven J. |date=13 December 2012 |work=[[ZDNet]] |publisher=[[CBS Interactive]] |access-date=6 February 2013 |archive-date=17 February 2015 |archive-url=https://web.archive.org/web/20150217232706/http://www.zdnet.com/article/good-bye-386-linux-to-drop-support-for-i386-chips-with-next-major-release/ |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://www.engadget.com/2012/12/15/linux-to-drop-i386-support-in-the-3-8-kernel/ |title=Linux to drop i386 support in the 3.8 kernel, make us upgrade our Doom rig |last=Fingas |first=Jon |date=15 December 2012 |work=[[Engadget]] |publisher=[[AOL]] |access-date=22 March 2015 |archive-date=2 April 2015 |archive-url=https://web.archive.org/web/20150402141004/http://www.engadget.com/2012/12/15/linux-to-drop-i386-support-in-the-3-8-kernel/ |url-status=live }}&lt;/ref&gt; The same series unified support for the [[ARM architecture|ARM]] processor.&lt;ref&gt;{{cite web |url=http://www.zdnet.com/linux-3-7-arrives-arm-developers-rejoice-7000008638/ |title=Linux 3.7 arrives, ARM developers rejoice |last=Vaughan-Nichols |first=Steven J. |date=11 December 2012 |work=[[ZDNet]] |publisher=[[CBS Interactive]] |access-date=6 February 2013 |archive-date=5 November 2014 |archive-url=https://web.archive.org/web/20141105164320/http://www.zdnet.com/linux-3-7-arrives-arm-developers-rejoice-7000008638/ |url-status=live }}&lt;/ref&gt;

Version 3.11, released on 2 September 2013,&lt;ref name="3.11.0 release"&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/1309.0/00650.html |title=Linux 3.11 |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=2 September 2013 |mailing-list=[[LKML]] |access-date=3 September 2013 |archive-date=26 February 2014 |archive-url=https://web.archive.org/web/20140226021932/http://lkml.iu.edu//hypermail/linux/kernel/1309.0/00650.html |url-status=live }}&lt;/ref&gt; adds many new features such as new {{Mono|O_TMPFILE}} flag for {{man|2|open|Linux||inline}} to reduce temporary file vulnerabilities, experimental AMD [[Radeon]] dynamic power management, low-latency network polling, and [[zswap]] (compressed swap cache).&lt;ref&gt;{{cite web |title=Linux 3.11 |url=http://kernelnewbies.org/Linux_3.11 |publisher=kernelnewbies.org |date=2 September 2013 |access-date=21 January 2014}}&lt;/ref&gt;

The numbering change from 2.6.39 to 3.0, and from 3.19 to 4.0, involved no meaningful technical differentiation. The major version number was increased to avoid large minor numbers.&lt;ref name="3.0 release" /&gt;&lt;ref name="4.0 release"&gt;{{cite mailing list |url=https://lkml.org/lkml/2015/4/12/178 |title=Linux 4.0 released |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=12 April 2015 |mailing-list=[[LKML]] |access-date=12 April 2015 |archive-date=13 April 2015 |archive-url=https://web.archive.org/web/20150413015619/https://lkml.org/lkml/2015/4/12/178 |url-status=live }}&lt;/ref&gt; Stable 3.x.y kernels were released until 3.19 in February 2015.

In April 2015, Torvalds released kernel version 4.0.&lt;ref name="Christine Bresnahan &amp; Richard Blum 2016 108"/&gt; By February 2015, Linux had received contributions from nearly 12,000 programmers from more than 1,200 companies, including some of the world's largest software and hardware vendors.&lt;ref&gt;{{cite web |date=18 February 2015 |title=The Linux Foundation Releases Linux Development Report |publisher=[[Linux Foundation]] |url=http://www.linuxfoundation.org/news-media/announcements/2015/02/linux-foundation-releases-linux-development-report |access-date=20 February 2015 |url-status=dead |archive-url=https://web.archive.org/web/20160719042639/https://www.linuxfoundation.org/news-media/announcements/2015/02/linux-foundation-releases-linux-development-report |archive-date=19 July 2016 |df=dmy-all }}&lt;/ref&gt; Version 4.1 of Linux, released in June 2015, contains over 19.5 million lines of code contributed by almost 14,000 programmers.&lt;ref&gt;{{cite web |author=Michael Larabel |date=23 June 2014 |title=Linux Kernel At 19.5 Million Lines Of Code, Continues Rising |publisher=[[Phoronix]] |url=https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-19.5M-Stats |access-date=23 June 2015 |archive-date=23 November 2020 |archive-url=https://web.archive.org/web/20201123170810/https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-19.5M-Stats |url-status=live }}&lt;/ref&gt;

A total of 1,991 developers, of whom 334 are first collaborators, added more than 553,000 lines of code to version 5.8, breaking the record previously held by version 4.9.&lt;ref&gt;{{Cite web|last=Corbet|first=Jonathan|date=2020-08-03|title=Some statistics from the 5.8 kernel cycle|url=https://lwn.net/Articles/827735/|access-date=2020-08-11|website=LWN - Linux Weekly News|archive-date=4 September 2020|archive-url=https://web.archive.org/web/20200904084101/https://lwn.net/Articles/827735/|url-status=live}}&lt;/ref&gt;

{{Main|Usage share of operating systems}}

According to the Stack Overflow’s annual Developer Survey of 2019, more than the 53% of all respondents have developed software for [[Linux|Linux OS]] and about 27% for [[Android (operating system)|Android]],&lt;ref&gt;{{Cite web|url=https://insights.stackoverflow.com/survey/2019/?utm_source=social-share&amp;utm_medium=social&amp;utm_campaign=dev-survey-2019|title=Stack Overflow Developer Survey 2019 - most popular technologies|website=Stack Overflow|access-date=2020-03-17|archive-date=8 October 2020|archive-url=https://web.archive.org/web/20201008033536/https://insights.stackoverflow.com/survey/2019/?utm_source=social-share&amp;utm_medium=social&amp;utm_campaign=dev-survey-2019|url-status=live}}&lt;/ref&gt; although only about 25% develop with Linux-based operating systems.&lt;ref&gt;{{Cite web|url=https://insights.stackoverflow.com/survey/2019#development-environments-and-tools|title=Stack Overflow Developer Survey 2019 - development environments and tools|website=Stack Overflow|access-date=2020-03-17|archive-date=7 March 2020|archive-url=https://web.archive.org/web/20200307082721/https://insights.stackoverflow.com/survey/2019#development-environments-and-tools|url-status=live}}&lt;/ref&gt;

Most websites run on [[Linux|Linux-based operating systems]],&lt;ref&gt;{{Cite web|title=Usage Statistics and Market Share of Operating Systems for Websites, March 2020|url=https://w3techs.com/technologies/overview/operating_system|access-date=2020-03-17|website=w3techs.com}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=Usage Statistics and Market Share of Unix for Websites, March 2020|url=https://w3techs.com/technologies/details/os-unix|access-date=2020-03-17|website=w3techs.com}}&lt;/ref&gt; and all of the [[TOP500|world's 500 most powerful supercomputers]] use some kind of OS based on Linux.&lt;ref name="top500stats2"&gt;{{cite web|title=TOP500 Supercomputer Sites: Operating system Family / Linux|url=https://www.top500.org/statistics/details/osfam/1|access-date=5 October 2019|publisher=Top500.org|archive-date=19 November 2012|archive-url=https://web.archive.org/web/20121119205719/https://www.top500.org/statistics/details/osfam/1|url-status=live}}&lt;/ref&gt;

[[Linux distributions]] bundle the kernel with [[system software]] (e.g., the [[GNU C Library]], [[systemd]], and others [[Unix]] [[Utility software|utilities]] and [[Daemon (computing)|daemons]]) and a wide selection of [[application software]], but their [[Usage share of operating systems#Desktop and laptop computers|usage share]] in desktops is low in comparison to other operating systems.

[[Android (operating system)|Android]], which accounts for the majority of the [[installed base]] of all operating systems for mobile devices,&lt;ref&gt;{{cite press release |title=Gartner Says Sales of Tablets Will Represent Less Than 10 Percent of All Devices in 2014 |url=http://www.gartner.com/newsroom/id/2875017 |location=[[Egham|Egham, UK]] |publisher=[[Gartner]] |date=15 October 2014 |access-date=19 October 2014 |archive-date=17 October 2014 |archive-url=https://web.archive.org/web/20141017151529/http://www.gartner.com/newsroom/id/2875017 |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://techcrunch.com/2014/10/15/tablet-sales-growth-plummets-in-2014-as-android-smartphones-continue-to-soar-gartner |title=Tablet Sales Growth Plummets In 2014 As Android Smartphones Continue To Soar: Gartner |last=Lunden |first=Ingrid |date=15 October 2014 |work=[[TechCrunch]] |publisher=[[AOL]] |access-date=23 October 2014 |archive-date=23 October 2014 |archive-url=https://web.archive.org/web/20141023114800/http://techcrunch.com/2014/10/15/tablet-sales-growth-plummets-in-2014-as-android-smartphones-continue-to-soar-gartner/ |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite press release |title=Global PC Shipments Exceed Forecast with Mild Improvement in Consumer Demand, While Apple Moves to #5 Spot, According to IDC |url=http://www.idc.com/getdoc.jsp?containerId=prUS25187214 |location=[[Framingham, Massachusetts|Framingham, MA]] |publisher=[[International Data Corporation|IDC]] |date=8 October 2014 |access-date=19 October 2014 |url-status=dead |archive-url=https://web.archive.org/web/20141011215307/http://www.idc.com/getdoc.jsp?containerId=prUS25187214 |archive-date=11 October 2014 |df=dmy-all }}&lt;/ref&gt; is responsible for the rising usage of the Linux kernel,&lt;ref name="Fred Hantelmann 2016 16" /&gt; together with its wide use in a large variety of [[Linux on embedded systems|embedded devices]].

== Architecture and features ==
{{See also|vmlinux}}
[[File:Linux kernel map.png|thumb|300px|right|Map of the Linux kernel]]

Linux is a [[monolithic kernel]] with a modular design (e.g., it can insert and remove [[loadable kernel modules]] at runtime), supporting most features once only available in closed source kernels of non-free operating systems. The rest of the article makes use of the UNIX and Unix-like operating systems convention on the official [[Man page|manual pages]]. The numbers that follow the name of commands, interfaces, and other features, have the purpose of specifying the section (i.e., the type of the OS' component or feature) they belong to (e.g., {{mono|execve(2)}} refers to a system call, while {{mono|exec(3)}} refers to a userspace library wrapper):

* [[concurrent computing]] and (with the availability of enough CPU cores for tasks that are ready to run) even [[Parallel computing|true parallel execution]] of many [[Process (computing)|processes]] at once (each of them having one or more [[Thread (computing)|threads of execution]]) on [[Symmetric multiprocessing|SMP]] and [[Non-uniform memory access|NUMA]] architectures;
* selection and configuration of hundreds of kernel features and drivers (using one of the {{Mono|make *config}} family of commands, before running compilation),&lt;ref name=":12"&gt;{{Cite web|title=KernelBuild - Linux Kernel Newbies|url=https://kernelnewbies.org/KernelBuild|access-date=2020-09-13|website=kernelnewbies.org|archive-date=19 October 2020|archive-url=https://web.archive.org/web/20201019124650/https://kernelnewbies.org/KernelBuild|url-status=live}}&lt;/ref&gt;&lt;ref name=":11" /&gt;&lt;ref name=":10" /&gt; modification of kernel parameters before [[Linux boot|booting]] (usually by inserting instructions into the lines of the [[Grub2|GRUB2]] menu), and fine tuning of kernel behavior at run-time (using the {{mono|sysctl(8)}} interface to {{Mono|/proc/sys/}});&lt;ref name=":13"&gt;{{Cite web|title=The Sysctl Interface|url=https://www.linux.it/~rubini/docs/sysctl/sysctl.html|access-date=2020-09-13|website=www.linux.it|archive-date=17 February 2020|archive-url=https://web.archive.org/web/20200217004812/http://www.linux.it/~rubini/docs/sysctl/sysctl.html|url-status=live}}&lt;/ref&gt;&lt;ref name=":14"&gt;{{Cite web|title=sysctl(8) - Linux manual page|url=https://man7.org/linux/man-pages/man8/sysctl.8.html|access-date=2020-09-13|website=man7.org|archive-date=30 September 2020|archive-url=https://web.archive.org/web/20200930200903/https://man7.org/linux/man-pages/man8/sysctl.8.html|url-status=live}}&lt;/ref&gt;&lt;ref name=":15"&gt;{{Cite web|title=procfs(5) - Linux manual page|url=https://man7.org/linux/man-pages/man5/procfs.5.html|access-date=2020-09-13|website=man7.org|archive-date=24 September 2020|archive-url=https://web.archive.org/web/20200924010905/https://man7.org/linux/man-pages/man5/procfs.5.html|url-status=live}}&lt;/ref&gt;
* configuration (again using the {{Mono|make *config}} commands) and run-time modifications of the policies&lt;ref&gt;{{Cite web|title=sched(7) - Linux manual page|url=https://man7.org/linux/man-pages/man7/sched.7.html|access-date=2020-07-27|website=man7.org|archive-date=17 July 2020|archive-url=https://web.archive.org/web/20200717155549/https://man7.org/linux/man-pages/man7/sched.7.html|url-status=live}}&lt;/ref&gt; (via {{Mono|nice(2)}}, {{Mono|setpriority(2)}}, and the family of {{Mono|sched_*(2)}} syscalls) of the [[Scheduling (computing)|task schedulers]] that allow [[preemptive multitasking]] (both in [[user mode]] and, since the 2.6 series, in [[kernel mode]]&lt;ref&gt;{{cite web
| url = http://kernelnewbies.org/FAQ/Preemption
| title = FAQ: Preemption
| date = 22 August 2009
| access-date = 7 May 2015
| website = kernelnewbies.org
| archive-date = 7 August 2020
| archive-url = https://web.archive.org/web/20200807081640/https://kernelnewbies.org/FAQ/Preemption
| url-status = live
}}&lt;/ref&gt;&lt;ref name="lwn-22912"&gt;{{cite web
| url = https://lwn.net/Articles/22912/
| title = Driver porting: the preemptible kernel
| date = 24 February 2003
| access-date = 7 May 2015
| author = Jonathan Corbet
| publisher = [[LWN.net]]
| archive-date = 10 August 2020
| archive-url = https://web.archive.org/web/20200810170137/https://lwn.net/Articles/22912/
| url-status = live
}}&lt;/ref&gt;); the [[Completely Fair Scheduler|Completely Fair Scheduler (CFS)]] is the default scheduler of Linux since 2007 and it uses a [[Red–black tree|red-black tree]] which can search, insert and delete process information ([[task struct]]) with [[Big O notation|O(log n)]] [[time complexity]], where ''n'' is the number of runnable tasks;&lt;ref name=":5" /&gt;&lt;ref&gt;{{Cite web|url=https://www.linuxjournal.com/node/10267|title=Completely Fair Scheduler {{!}} Linux Journal|website=www.linuxjournal.com|access-date=2020-03-30|archive-date=3 August 2020|archive-url=https://web.archive.org/web/20200803104512/https://www.linuxjournal.com/node/10267|url-status=live}}&lt;/ref&gt;
* advanced [[memory management]] with [[virtual memory|paged virtual memory]];
* [[inter-process communication]]s and [[Synchronization (computer science)|synchronization]] mechanism; 
* a [[Virtual file system|virtual filesystem]] on top of several concrete filesystems ([[ext4]], [[Btrfs]], [[XFS]], [[JFS (file system)|JFS]], [[File Allocation Table|FAT32]], and many more);
* configurable I/O schedulers, {{Mono|ioctl(2)}}&lt;ref&gt;{{Cite web|title=ioctl(2) - Linux manual page|url=https://man7.org/linux/man-pages/man2/ioctl.2.html|access-date=2020-08-11|website=man7.org|archive-date=20 July 2020|archive-url=https://web.archive.org/web/20200720073257/https://man7.org/linux/man-pages/man2/ioctl.2.html|url-status=live}}&lt;/ref&gt; syscall that manipulates the underlying device parameters of special files (it is a non standard system call, since arguments, returns, and semantics depends on the device driver in question), support for POSIX asynchronous I/O&lt;ref&gt;{{Cite web|title=aio(7) - Linux manual page|url=https://man7.org/linux/man-pages/man7/aio.7.html|access-date=2020-08-11|website=man7.org|archive-date=12 April 2020|archive-url=https://web.archive.org/web/20200412005208/http://man7.org/linux/man-pages/man7/aio.7.html|url-status=live}}&lt;/ref&gt; (however, because they scale poorly with multithreaded applications, a family of Linux specific I/O system calls ({{Mono|io_*(2)}}&lt;ref&gt;{{Cite web|title=io_setup(2) - Linux manual page|url=https://man7.org/linux/man-pages/man2/io_setup.2.html|access-date=2020-08-11|website=man7.org|archive-date=20 August 2020|archive-url=https://web.archive.org/web/20200820190947/https://man7.org/linux/man-pages/man2/io_setup.2.html|url-status=live}}&lt;/ref&gt;) had to be created for the management of asynchronous I/O contexts suitable for concurrently processing);
* [[OS-level virtualization]] (with [[Linux-VServer]]), [[paravirtualization]] and [[hardware-assisted virtualization]] (with [[Kernel-based Virtual Machine|KVM]] or [[Xen]], and using [[QEMU]] for hardware emulation);&lt;ref&gt;{{Cite web|url=https://www.linux-kvm.org/page/Main_Page|title=KVM|website=www.linux-kvm.org|access-date=2020-03-29|archive-date=28 March 2020|archive-url=https://web.archive.org/web/20200328192644/https://www.linux-kvm.org/page/Main_Page|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://virt.kernelnewbies.org/TechComparison|title=TechComparison - Linux Virtualization Wiki|website=virt.kernelnewbies.org|access-date=2020-03-29|archive-date=3 August 2020|archive-url=https://web.archive.org/web/20200803081859/https://virt.kernelnewbies.org/TechComparison|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://kernelnewbies.org/Linux_2_6_20#Virtualization_support_through_KVM|title=Virtualization_support_through_KVM in Linux_2_6_20 - Linux Kernel Newbies|website=kernelnewbies.org|access-date=2020-03-29|archive-date=29 November 2019|archive-url=https://web.archive.org/web/20191129072053/https://kernelnewbies.org/Linux_2_6_20#Virtualization_support_through_KVM|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://blogs.oracle.com/wim/linux-mainline-contains-all-the-xen-code-bits-for-dom0-and-domu-support|title=Linux mainline contains all the Xen code bits for Dom0 and DomU support|last=Coekaerts|first=Wim|website=blogs.oracle.com|access-date=2020-03-29|archive-date=3 August 2020|archive-url=https://web.archive.org/web/20200803103832/https://blogs.oracle.com/wim/linux-mainline-contains-all-the-xen-code-bits-for-dom0-and-domu-support|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://blog.xen.org/index.php/2011/06/02/xen-celebrates-full-dom0-and-domu-support-in-linux-3-0/|archive-url=https://web.archive.org/web/20110607003740/http://blog.xen.org/index.php/2011/06/02/xen-celebrates-full-dom0-and-domu-support-in-linux-3-0/|url-status=dead|archive-date=2011-06-07|title=Xen celebrates full Dom0 and DomU support in Linux 3.0 – blog.xen.org|date=2011-06-07|access-date=2020-03-29}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://xenproject.org/2014/01/31/linux-3-14-and-pvh/|title=Linux 3.14 and PVH|last=Wilk|first=Konrad Rzeszutek|date=2014-01-31|website=Xen Project|language=en-US|access-date=2020-03-29|archive-date=29 March 2020|archive-url=https://web.archive.org/web/20200329115320/https://xenproject.org/2014/01/31/linux-3-14-and-pvh/|url-status=live}}&lt;/ref&gt; On the Xen hypervisor, the Linux kernel provides support to build Linux distributions (such as openSuSE Leap and many others) that work as ''Dom0'', that are virtual machine host servers that provide the management environment for the user's virtual machines (''DomU'').&lt;ref&gt;{{Cite web|title=Introduction to Xen Virtualization {{!}} Virtualization Guide {{!}} openSUSE Leap 15.2|url=https://doc.opensuse.org/documentation/leap/virtualization/html/book.virt/cha-xen-basics.html|access-date=2020-09-29|website=doc.opensuse.org|archive-date=28 September 2020|archive-url=https://web.archive.org/web/20200928214033/https://doc.opensuse.org/documentation/leap/virtualization/html/book.virt/cha-xen-basics.html|url-status=live}}&lt;/ref&gt;
* security mechanisms for [[Discretionary access control|discretionary]] and [[mandatory access control]] (SELinux, AppArmor, POSIX [[Access-control list|ACLs]], and others);&lt;ref name=":3" /&gt;&lt;ref name=":4" /&gt; 
* several types of layered [[communication protocol]]s (including the [[Internet protocol suite]]).

[[Device driver]]s and kernel extensions run in [[kernel space]] ([[Ring (computer security)|ring 0]] in many [[CPU]] [[CPU architecture|architectures]]), with full access to the hardware, although some exceptions run in [[user space]], for example, filesystems based on [[Filesystem in Userspace|FUSE]]/CUSE, and parts of UIO.&lt;ref&gt;{{cite web
| url = https://lwn.net/Articles/308445/
| title = Character devices in user space
| date = 25 November 2008
| access-date = 7 May 2015
| author = Jake Edge
| publisher = [[LWN.net]]
| archive-date = 26 January 2021
| archive-url = https://web.archive.org/web/20210126131908/https://lwn.net/Articles/308445/
| url-status = live
}}&lt;/ref&gt;&lt;ref&gt;{{cite web
| url = https://lwn.net/Articles/232575/
| title = UIO: user-space drivers
| date = 2 May 2007
| access-date = 7 May 2015
| author = Jonathan Corbet
| publisher = [[LWN.net]]
| archive-date = 11 November 2020
| archive-url = https://web.archive.org/web/20201111193009/https://lwn.net/Articles/232575/
| url-status = live
}}&lt;/ref&gt; The [[X Window System|graphics system]] most people use with Linux does not run within the kernel. Unlike standard monolithic kernels, device drivers are easily configured as [[module (Linux)|modules]], and loaded or unloaded while the system is running and can also be pre-empted under certain conditions in order to handle [[hardware interrupt]]s correctly and to better support [[symmetric multiprocessing]].&lt;ref name="lwn-22912" /&gt; By choice, Linux has no stable device driver [[application binary interface]].&lt;ref name="stable-api-nonsense2"&gt;{{Cite web|title=stable-api-nonsense - Linux kernel source tree|url=https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/process/stable-api-nonsense.rst|access-date=2020-04-18|website=git.kernel.org|archive-date=5 March 2021|archive-url=https://web.archive.org/web/20210305010734/https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/process/stable-api-nonsense.rst|url-status=live}}&lt;/ref&gt;

Linux typically makes use of [[memory protection]] and [[virtual memory]] and can also handle [[non-uniform memory access]],&lt;ref&gt;{{cite book
|last=Gorman
|first=Mel
|date=2004-02-15
|title=Understanding the Linux Virtual Memory Manager
|url=https://pdos.csail.mit.edu/~sbw/links/gorman_book.pdf
|publisher=Prentice Hall
|page=26
|isbn=0-13-145348-3
|access-date=27 January 2020
|archive-date=3 May 2019
|archive-url=https://web.archive.org/web/20190503113248/https://pdos.csail.mit.edu/~sbw/links/gorman_book.pdf
|url-status=live
}}&lt;/ref&gt; however the project has absorbed [[μClinux]] which also makes it possible to run Linux on [[microcontroller]]s without virtual memory.&lt;ref&gt;{{cite web|url=http://www.ucdot.org/article.pl?sid=02/11/05/0324207|title=uClinux mainline Announcement|access-date=2008-01-15|author=Greg Ungerer|archive-url=https://web.archive.org/web/20071031135123/http://www.ucdot.org/article.pl?sid=02%2F11%2F05%2F0324207|archive-date=31 October 2007|url-status=dead}}&lt;/ref&gt;

The hardware is represented in the file hierarchy. User applications interact with device drivers via entries in the {{Mono|[[Devfs|/dev]]}} or {{Mono|[[/sys]]}} directories.&lt;ref name="tldp file"&gt;{{cite web |url=http://tldp.org/LDP/Linux-Filesystem-Hierarchy/html/index.html |title=Linux Filesystem Hierarchy: Chapter 1. Linux Filesystem Hierarchy |last=Nguyen |first=Binh |date=30 July 2004 |publisher=The Linux Documentation Project |access-date=28 November 2012 |archive-date=2 December 2020 |archive-url=https://web.archive.org/web/20201202064950/https://tldp.org/LDP/Linux-Filesystem-Hierarchy/html/index.html |url-status=live }}&lt;/ref&gt; Processes information as well are mapped to the file system through the {{Mono|[[procfs|/proc]]}} directory.&lt;ref name="tldp file" /&gt;

{{Linux layers}}

=== Interfaces ===
{{Main|Linux kernel interfaces|:Category:Interfaces of the Linux kernel|l2=Interfaces of the Linux kernel (Category)}}
{{See also|System call|POSIX|Single UNIX Specification}}

[[File:Linux kernel interfaces.svg|thumb|300px|Four interfaces are distinguished: two internal to the kernel, and two between the kernel and userspace.]]

Linux is a clone of UNIX, and aims towards [[POSIX]] and [[Single UNIX Specification]] compliance.&lt;ref&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/admin-guide/README.html|title=Linux kernel release 5.x — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-04|archive-date=7 March 2020|archive-url=https://web.archive.org/web/20200307065108/https://www.kernel.org/doc/html/latest/admin-guide/README.html|url-status=live}}&lt;/ref&gt; The kernel also provides system calls and other interfaces that are Linux-specific. In order to be included in the official kernel, the code must comply with a set of licensing rules.&lt;ref name="COPYING_File"/&gt;&lt;ref name="Linux_Licensing" /&gt;

The Linux [[Application binary interface]] (ABI) between the kernel and the user space has four degrees of stability (stable, testing, obsolete, removed);&lt;ref&gt;{{Cite web|url=https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/ABI/README|title=README\ABI\Documentation - kernel/git/torvalds/linux.git - Linux kernel source tree|website=git.kernel.org|access-date=2020-04-18|archive-date=1 October 2020|archive-url=https://web.archive.org/web/20201001172809/https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/ABI/README|url-status=live}}&lt;/ref&gt; however, the [[system call]]s are expected to never change in order to not break the [[userspace]] programs that rely on them.&lt;ref&gt;{{Cite web|url=https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/ABI/stable/syscalls|title=syscalls\stable\ABI\Documentation - kernel/git/torvalds/linux.git - Linux kernel source tree|website=git.kernel.org|access-date=2020-04-18|archive-date=2 October 2020|archive-url=https://web.archive.org/web/20201002061451/https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/ABI/stable/syscalls|url-status=live}}&lt;/ref&gt;

[[Loadable kernel module]]s (LKMs), by design, cannot rely on a stable ABI.&lt;ref name="stable-api-nonsense2"/&gt; Therefore they must always be recompiled whenever a new kernel executable is installed in a system, otherwise they will not be loaded. In-tree drivers that are configured to become an integral part of the kernel executable ([[vmlinux]]) are statically linked by the building process.

There is also no guarantee of stability of source-level in-kernel API&lt;ref name="stable-api-nonsense2"/&gt; and, because of this, [[device driver]]s code, as well as the code of any other kernel subsystem, must be kept updated with kernel evolution. Any developer who makes an API change is required to fix any code that breaks as the result of their change.&lt;ref name=":9"&gt;{{Cite web|title=1.Intro.rst - Documentation/process/1.Intro.rst - Linux source code (v5.8) - Bootlin|url=https://elixir.bootlin.com/linux/latest/source/Documentation/process/1.Intro.rst|access-date=2020-08-08|website=elixir.bootlin.com}}&lt;/ref&gt;

==== Kernel-to-userspace API ====
The set of the [[Linux kernel API]] that regards the interfaces exposed to user applications is fundamentally composed of UNIX and Linux-specific [[system call]]s.&lt;ref name=":1"&gt;{{Cite web|title=syscalls|url=http://man7.org/linux/man-pages/man2/syscalls.2.html|website=man7|access-date=28 January 2020|archive-date=15 January 2020|archive-url=https://web.archive.org/web/20200115033131/http://man7.org/linux/man-pages/man2/syscalls.2.html|url-status=live}}&lt;/ref&gt; A system call is an entry point into the Linux kernel.&lt;ref&gt;{{Cite web|title=intro(2) - Linux manual page|url=https://man7.org/linux/man-pages/man2/intro.2.html|access-date=2020-07-16|website=man7.org|archive-date=17 July 2020|archive-url=https://web.archive.org/web/20200717161934/https://man7.org/linux/man-pages/man2/intro.2.html|url-status=live}}&lt;/ref&gt; For example, among the Linux-specific ones there is the family of the {{Mono|[[clone (Linux system call)|clone(2)]]}} system calls.&lt;ref&gt;{{Cite web|url=http://man7.org/linux/man-pages/man2/clone.2.html|title=clone|website=man7.org|access-date=2020-01-28|archive-date=18 January 2020|archive-url=https://web.archive.org/web/20200118015900/http://man7.org/linux/man-pages/man2/clone.2.html|url-status=live}}&lt;/ref&gt; Most extensions must be enabled by defining the &lt;code&gt;_GNU_SOURCE&lt;/code&gt; [[Macro (computer science)|macro]] in a [[Header files|header file]] or when the user-land code is being compiled.&lt;ref&gt;{{Cite web|url=http://man7.org/linux/man-pages/man7/feature_test_macros.7.html|title=feature_test_macros|website=man7.org|access-date=2020-01-28|archive-date=19 January 2020|archive-url=https://web.archive.org/web/20200119174511/http://man7.org/linux/man-pages/man7/feature_test_macros.7.html|url-status=live}}&lt;/ref&gt;

System calls can only be invoked by using assembly instructions which enable the transition from unprivileged user space to privileged kernel space in [[ring 0]]. For this reason, the [[C standard library]] (libC) acts as a wrapper to most Linux system calls, by exposing C functions that, only whether it is needed,&lt;ref&gt;{{Cite web|url=http://man7.org/linux/man-pages/man7/vdso.7.html|title=vdso(7) - Linux manual page|website=man7.org|access-date=2020-02-02|archive-date=2 February 2020|archive-url=https://web.archive.org/web/20200202123949/http://man7.org/linux/man-pages/man7/vdso.7.html|url-status=live}}&lt;/ref&gt; can transparently enter into the kernel which will execute on behalf of the calling process.&lt;ref name=":1" /&gt; For those system calls not exposed by libC, e.g. the ''fast userspace mutex'' ([[futex]]),&lt;ref name=":0"&gt;{{Cite web|url=http://man7.org/linux/man-pages/man2/futex.2.html|title=futex(2) - Linux manual page|website=man7.org|access-date=2020-02-02|archive-date=31 January 2020|archive-url=https://web.archive.org/web/20200131144454/http://man7.org/linux/man-pages/man2/futex.2.html|url-status=live}}&lt;/ref&gt; the library provides a function called {{Mono|syscall(2)}} which can be used to explicitly invoke them.&lt;ref&gt;{{Cite web|url=http://man7.org/linux/man-pages/man2/syscall.2.html|title=syscall(2) - Linux manual page|website=man7.org|access-date=2020-02-02|archive-date=21 January 2020|archive-url=https://web.archive.org/web/20200121174524/http://man7.org/linux/man-pages/man2/syscall.2.html|url-status=live}}&lt;/ref&gt;

[[Synthetic file system|Pseudo filesystems]] (e.g., the [[sysfs]] and [[procfs]] filesystems) and [[special file]]s (e.g., &lt;code&gt;/dev/random&lt;/code&gt;, &lt;code&gt;/dev/sda&lt;/code&gt;, &lt;code&gt;/dev/tty&lt;/code&gt;, and many others) constitute another layer of interface to kernel data structures representing hardware or logical (software) devices.&lt;ref&gt;{{Cite web|url=http://man7.org/linux/man-pages/man5/sysfs.5.html|title=sysfs(5) - Linux manual page|website=man7.org|access-date=2020-01-06|archive-date=18 January 2020|archive-url=https://web.archive.org/web/20200118044323/http://man7.org/linux/man-pages/man5/sysfs.5.html|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/admin-guide/sysfs-rules.html|title=Rules on how to access information in sysfs — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-06|archive-date=7 March 2020|archive-url=https://web.archive.org/web/20200307065123/https://www.kernel.org/doc/html/latest/admin-guide/sysfs-rules.html|url-status=live}}&lt;/ref&gt;

==== Kernel-to-userspace ABI ====
{{Main|Linux Standard Base}}Because of the differences existing between the hundreds of various implementations of the Linux OS, executable objects, even though they are compiled, assembled, and linked for running on a specific hardware architecture (that is, they use the [[Instruction set architecture|ISA]] of the target hardware), often cannot run on different Linux Distributions. This issue is mainly due to distribution-specific configurations and a set of patches applied to the code of the Linux kernel, differences in system libraries, services (daemons), filesystem hierarchies, and environment variables.

The main standard concerning application and binary compatibility of Linux distributions is the [[Linux Standard Base]] (LSB).&lt;ref&gt;{{Cite web|url=https://refspecs.linuxbase.org/|title=Linux Foundation Referenced Specifications|website=refspecs.linuxbase.org|access-date=2020-02-03}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://refspecs.linuxbase.org/lsb.shtml|title=LSB Specifications|website=refspecs.linuxbase.org|access-date=2020-02-03}}&lt;/ref&gt; However, the LSB goes beyond what concerns the Linux kernel, because it also defines the desktop specifications, the X libraries and Qt that have little to do with it.&lt;ref&gt;{{Cite web|url=https://refspecs.linuxbase.org/LSB_5.0.0/LSB-Desktop-generic/LSB-Desktop-generic/book1.html|title=Linux Standard Base Desktop Specification, Generic Part|website=refspecs.linuxbase.org|access-date=2020-02-03}}&lt;/ref&gt; The LSB version 5 is built upon several standards and drafts (POSIX, SUS, X/Open, [[Filesystem Hierarchy Standard|File System Hierarchy]] (FHS), and others).&lt;ref&gt;{{Cite web|url=https://refspecs.linuxfoundation.org/LSB_5.0.0/LSB-Core-generic/LSB-Core-generic/normativerefs.html|title=Normative References|website=refspecs.linuxfoundation.org|access-date=2020-02-03|archive-date=12 August 2020|archive-url=https://web.archive.org/web/20200812044159/https://refspecs.linuxfoundation.org/LSB_5.0.0/LSB-Core-generic/LSB-Core-generic/normativerefs.html|url-status=live}}&lt;/ref&gt;

The parts of the LSB largely relevant to the kernel are the ''General ABI'' (gABI),&lt;ref&gt;{{Cite web|url=https://refspecs.linuxfoundation.org/LSB_5.0.0/LSB-Core-generic/LSB-Core-generic/book1.html|title=Linux Standard Base Core Specification, Generic Part|website=refspecs.linuxfoundation.org|access-date=2020-02-03|archive-date=29 November 2019|archive-url=https://web.archive.org/web/20191129194815/https://refspecs.linuxfoundation.org/LSB_5.0.0/LSB-Core-generic/LSB-Core-generic/book1.html|url-status=live}}&lt;/ref&gt; especially the [[System V Interface Definition|System V ABI]]&lt;ref&gt;{{Cite web|url=https://www.sco.com/developers/devspecs/gabi41.pdf|title=System V Application Binary Interface - Edition 4.1|website=www.sco.com|access-date=3 February 2020|archive-date=13 December 2019|archive-url=https://web.archive.org/web/20191213124815/http://www.sco.com/developers/devspecs/gabi41.pdf|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.sco.com/developers/gabi/2003-12-17/contents.html|title=Xinuos Inc. {{!}} Developers {{!}} Gabi {{!}} 2003-12-17 {{!}} System V Application Binary Interface - DRAFT|website=www.sco.com|access-date=2020-02-03|archive-date=3 February 2020|archive-url=https://web.archive.org/web/20200203124116/http://www.sco.com/developers/gabi/2003-12-17/contents.html|url-status=live}}&lt;/ref&gt; and the [[Executable and Linkable Format|Executable and Linking Format]] (ELF),&lt;ref&gt;{{Cite web|url=https://refspecs.linuxbase.org/LSB_5.0.0/LSB-Core-generic/LSB-Core-generic/elf-generic.html|title=Executable And Linking Format (ELF)|website=refspecs.linuxbase.org|access-date=2020-02-03}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=elf(5) - Linux manual page|url=https://man7.org/linux/man-pages/man5/elf.5.html|access-date=2020-11-18|website=man7.org|archive-date=30 November 2020|archive-url=https://web.archive.org/web/20201130114725/https://man7.org/linux/man-pages/man5/elf.5.html|url-status=live}}&lt;/ref&gt; and the ''Processor Specific ABI'' (psABI), for example the ''Core Specification for X86-64.''&lt;ref&gt;{{Cite web|url=https://refspecs.linuxbase.org/LSB_5.0.0/LSB-Core-AMD64/LSB-Core-AMD64/book1.html|title=Linux Standard Base Core Specification for X86-64|website=refspecs.linuxbase.org|access-date=2020-02-03}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://refspecs.linuxbase.org/elf/gabi4+/contents.html|title=System V Application Binary Interface - DRAFT|website=refspecs.linuxbase.org|access-date=2020-02-03}}&lt;/ref&gt;

The standard ABI for how x86_64 user programs invoke system calls is to load the syscall number into the ''rax'' register, and the other parameters into ''rdi'', ''rsi'', ''rdx'', ''r10'', ''r8'', and ''r9'', and finally to put the ''syscall'' assembly instruction in the code.&lt;ref&gt;{{Cite book|last=Seyfarth|first=Ray|title=Introduction to 64 Bit Intel Assembly Language Programming for Linux|year=2012|isbn=9781478119203|pages=170}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=Anatomy of a system call, part 1 [LWN.net]|url=https://lwn.net/Articles/604287/|access-date=2020-07-16|website=lwn.net|archive-date=18 August 2020|archive-url=https://web.archive.org/web/20200818051836/https://lwn.net/Articles/604287/|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=Anatomy of a system call, part 2 [LWN.net]|url=https://lwn.net/Articles/604515/|access-date=2020-07-16|website=lwn.net|archive-date=6 August 2020|archive-url=https://web.archive.org/web/20200806081538/https://lwn.net/Articles/604515/|url-status=live}}&lt;/ref&gt;

==== In-kernel API ====
[[File:Linux AMD graphics stack.svg|thumb|upright=1.2|At XDC2014, Alex Deucher from AMD announced the unified kernel-mode driver.&lt;ref&gt;{{cite web |url=http://wiki.x.org/wiki/Events/XDC2014/XDC2014DeucherAMD/ |title=AMD's New Unified Open Source Driver |last=Deucher |first=Alex |date=7 October 2014 |publisher=[[X.Org Foundation]] |access-date=21 January 2015 |archive-date=21 January 2015 |archive-url=https://web.archive.org/web/20150121163629/http://wiki.x.org/wiki/Events/XDC2014/XDC2014DeucherAMD/ |url-status=live }}&lt;/ref&gt; The proprietary Linux graphic driver, {{Mono|[[AMD Catalyst|libGL-fglrx-glx]]}}, will share the same [[Direct Rendering Manager|DRM]] infrastructure with [[Mesa 3D]]. As there is no stable in-kernel [[Application binary interface|ABI]], AMD had to constantly adapt the former [[binary blob]] used by Catalyst.]]
There are several kernel internal APIs utilized between the different subsystems. Some are available only within the kernel subsystems, while a somewhat limited set of in-kernel symbols (i.e., variables, data structures, and functions) is exposed also to dynamically loadable modules (e.g., device drivers loaded on demand) whether they're exported with the {{Mono|EXPORT_SYMBOL()}} and {{Mono|EXPORT_SYMBOL_GPL()}} macros&lt;ref name=":6"&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/kernel-hacking/hacking.html?highlight=export_symbol#symbols|title=Symbols - Unreliable Guide To Hacking The Linux Kernel — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-02-08|archive-date=3 August 2020|archive-url=https://web.archive.org/web/20200803074501/https://www.kernel.org/doc/html/latest/kernel-hacking/hacking.html?highlight=export_symbol#symbols|url-status=live}}&lt;/ref&gt;&lt;ref name=":7"&gt;{{Cite web|url=https://lwn.net/Articles/249246/|title=Exported symbols and the internal API [LWN.net]|website=lwn.net|access-date=2020-03-15|archive-date=31 March 2020|archive-url=https://web.archive.org/web/20200331211446/https://lwn.net/Articles/249246/|url-status=live}}&lt;/ref&gt; (the latter reserved to modules released under a GPL-compatible license).&lt;ref name=":8"&gt;{{Cite web|url=https://lwn.net/Articles/813350/|title=Unexporting kallsyms_lookup_name() [LWN.net]|website=lwn.net|access-date=2020-03-15|archive-date=1 April 2020|archive-url=https://web.archive.org/web/20200401062303/https://lwn.net/Articles/813350/|url-status=live}}&lt;/ref&gt;

Linux provides in-kernel APIs that manipulate data structures (e.g., [[linked list]]s, [[radix tree]]s,&lt;ref&gt;{{Cite web|title=Trees I: Radix trees [LWN.net]|url=https://lwn.net/Articles/175432/|access-date=2020-11-13|website=lwn.net|archive-date=8 November 2020|archive-url=https://web.archive.org/web/20201108131647/https://lwn.net/Articles/175432/|url-status=live}}&lt;/ref&gt; [[Red–black tree|red-black trees]],&lt;ref&gt;{{Cite web|title=Trees II: red-black trees [LWN.net]|url=https://lwn.net/Articles/184495/|access-date=2020-11-13|website=lwn.net|archive-date=13 November 2020|archive-url=https://web.archive.org/web/20201113130357/https://lwn.net/Articles/184495/|url-status=live}}&lt;/ref&gt; [[Queue (abstract data type)|queues]]) or perform common routines (e.g., copy data from and to user space, allocate memory, print lines to the system log, and so on) that have remained stable at least since Linux version 2.6.&lt;ref&gt;{{Cite web| url=https://www.kernel.org/doc/htmldocs/kernel-hacking/index.html| title=Unreliable Guide To Hacking The Linux Kernel| year=2005| website=www.kernel.org| access-date=2020-03-15| edition=1st| archive-date=16 February 2020| archive-url=https://web.archive.org/web/20200216191225/https://www.kernel.org/doc/htmldocs/kernel-hacking/index.html| url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web| url=https://www.kernel.org/doc/html/latest/kernel-hacking/hacking.html| title=Unreliable Guide To Hacking The Linux Kernel — The Linux Kernel documentation| website=www.kernel.org| access-date=2020-03-15| archive-date=7 March 2020| archive-url=https://web.archive.org/web/20200307065323/https://www.kernel.org/doc/html/latest/kernel-hacking/hacking.html| url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web| url=https://www.kernel.org/doc/html/latest/kernel-hacking/locking.html| title=Unreliable Guide To Locking — The Linux Kernel documentation| website=www.kernel.org| access-date=2020-03-15| archive-date=7 March 2020| archive-url=https://web.archive.org/web/20200307065319/https://www.kernel.org/doc/html/latest/kernel-hacking/locking.html| url-status=live}}&lt;/ref&gt;

In-kernel APIs include libraries of low-level common services used by device drivers:

* [[SCSI]] Interfaces and [[libATA]]{{snd}} respectively, a peer-to-peer packet based communication protocol for storage devices attached to USB, SATA, SAS, Fibre Channel, FireWire, ATAPI device,&lt;ref&gt;{{Cite web|title=SCSI Interfaces Guide — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/driver-api/scsi.html|access-date=2020-06-11|website=www.kernel.org|archive-date=2 June 2020|archive-url=https://web.archive.org/web/20200602154450/https://www.kernel.org/doc/html/latest/driver-api/scsi.html|url-status=live}}&lt;/ref&gt; and an in-kernel library to support [S]ATA host controllers and devices.&lt;ref&gt;{{Cite web|title=libATA Developer's Guide — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/driver-api/libata.html|access-date=2020-06-11|website=www.kernel.org|archive-date=30 May 2020|archive-url=https://web.archive.org/web/20200530101401/https://www.kernel.org/doc/html/latest/driver-api/libata.html|url-status=live}}&lt;/ref&gt;
* [[Direct Rendering Manager]] (DRM) and [[Kernel Mode Setting]] (KMS){{snd}} for interfacing with GPUs and supporting the needs of modern 3D-accelerated video hardware,&lt;ref&gt;{{Cite web|title=DRM Internals — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/gpu/drm-internals.html|access-date=2020-06-11|website=www.kernel.org|archive-date=1 June 2020|archive-url=https://web.archive.org/web/20200601202717/https://www.kernel.org/doc/html/latest/gpu/drm-internals.html|url-status=live}}&lt;/ref&gt; and for setting screen resolution, color depth and refresh rate&lt;ref&gt;{{Cite web|title=Kernel Mode Setting (KMS) — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/gpu/drm-kms.html#overview|access-date=2020-06-11|website=www.kernel.org|archive-date=11 June 2020|archive-url=https://web.archive.org/web/20200611233817/https://www.kernel.org/doc/html/latest/gpu/drm-kms.html#overview|url-status=live}}&lt;/ref&gt;
* [[Direct memory access|DMA]] buffers ([[DMA-BUF]]){{snd}} for sharing buffers for hardware direct memory access across multiple device drivers and subsystems&lt;ref&gt;{{Cite web|title=Introduce DMA buffer sharing mechanism [LWN.net]|url=https://lwn.net/Articles/473668/|access-date=2020-06-11|website=lwn.net|archive-date=11 June 2020|archive-url=https://web.archive.org/web/20200611235759/https://lwn.net/Articles/473668/|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|date=2016-05-12|title=Sharing CPU and GPU buffers on Linux*|url=https://01.org/blogs/2016/sharing-cpu-and-gpu-buffers-linux|access-date=2020-06-11|website=01.org|archive-date=11 June 2020|archive-url=https://web.archive.org/web/20200611231858/https://01.org/blogs/2016/sharing-cpu-and-gpu-buffers-linux|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=Buffer Sharing and Synchronization — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/driver-api/dma-buf.html|access-date=2020-06-11|website=www.kernel.org|archive-date=1 June 2020|archive-url=https://web.archive.org/web/20200601205610/https://www.kernel.org/doc/html/latest/driver-api/dma-buf.html|url-status=live}}&lt;/ref&gt;
* [[Video4Linux]]{{snd}} for video capture hardware
* [[Advanced Linux Sound Architecture]] (ALSA){{snd}} for sound cards
* [[New API]]{{snd}} for [[network interface controller]]s
* [[mac80211]]{{snd}} for wireless network interface controllers&lt;ref&gt;{{cite web |url=https://wireless.wiki.kernel.org/en/developers/Documentation/mac80211 |title=About mac80211 |publisher=Linux Kernel Organization, Inc. |access-date=8 June 2014 |archive-date=1 February 2021 |archive-url=https://web.archive.org/web/20210201114135/https://wireless.wiki.kernel.org/en/developers/documentation/mac80211 |url-status=live }}&lt;/ref&gt;

==== In-kernel ABI ====
The Linux developers choose not to maintain a stable in-kernel ABI.&lt;ref&gt;{{cite web|url=http://abi-laboratory.pro/tracker/timeline/linux/|title=Report on ABI changes in the Linux kernel|publisher=Andrey Ponomarenko's ABI laboratory|date=17 March 2016|access-date=16 March 2016|archive-date=12 March 2016|archive-url=https://web.archive.org/web/20160312025113/http://abi-laboratory.pro/tracker/timeline/linux/|url-status=live}}&lt;/ref&gt; Modules compiled for a specific version of the kernel cannot be loaded into another version without being re-compiled, assuming that the source level in-kernel API has remained the same, otherwise also the module code must be modified accordingly.&lt;ref name="stable-api-nonsense2"/&gt;

=== Processes and threads ===
{{See also|Process (computing)|Thread (computing)|Process management (computing)}}Linux creates processes by means of the {{Mono|clone(2)}} or by the newer {{Mono|clone3(2)}}&lt;ref&gt;{{Cite web|title=[PATCH v3 1/2] fork: add clone3 [LWN.net]|url=https://lwn.net/ml/linux-kernel/20190604160944.4058-1-christian@brauner.io/|access-date=2020-07-16|website=lwn.net|archive-date=16 July 2020|archive-url=https://web.archive.org/web/20200716232314/https://lwn.net/ml/linux-kernel/20190604160944.4058-1-christian@brauner.io/|url-status=live}}&lt;/ref&gt; system calls. Depending on the given parameters, the new entity can share most or none of the resources of the caller. These syscalls can create new entities ranging from new independent processes (each having a special identifier called ''TGID'' within the ''task_struct'' data structure in kernel space, although that same identifier is called ''PID'' in userspace), to new threads of execution within the calling process (by using the {{Mono|CLONE_THREAD}} parameter). In this latter case the new entity owns the same ''TGID'' of the calling process and consequently has also the same ''PID'' in userspace.&lt;ref&gt;{{Cite web|title=clone(2) - Linux manual page|url=https://man7.org/linux/man-pages/man2/clone.2.html|access-date=2020-07-15|website=man7.org|archive-date=15 July 2020|archive-url=https://web.archive.org/web/20200715175357/https://man7.org/linux/man-pages/man2/clone.2.html|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=clone3(), fchmodat4(), and fsinfo() [LWN.net]|url=https://lwn.net/Articles/792628/|access-date=2020-07-15|website=lwn.net|archive-date=15 June 2020|archive-url=https://web.archive.org/web/20200615080341/https://lwn.net/Articles/792628/|url-status=live}}&lt;/ref&gt;

If the executable is dynamically linked to shared libraries, a [[dynamic linker]] (for ELF objects, it is typically {{Mono|/lib/ld-linux.so.2}}) is used to find and load the needed objects, prepare the program to run and then run it.&lt;ref&gt;{{Cite web|title=ld-linux.so(8) - Linux manual page|url=https://man7.org/linux/man-pages/man8/ld-linux.so.8.html|access-date=2020-11-18|website=man7.org|archive-date=26 November 2020|archive-url=https://web.archive.org/web/20201126063027/https://man7.org/linux/man-pages/man8/ld-linux.so.8.html|url-status=live}}&lt;/ref&gt;
        
The [[Native POSIX Thread Library]], simply known as the NPTL,&lt;ref&gt;{{Cite web|title=nptl(7) - Linux manual page|url=https://man7.org/linux/man-pages/man7/nptl.7.html|access-date=2020-07-25|website=man7.org|archive-date=25 July 2020|archive-url=https://web.archive.org/web/20200725045335/https://man7.org/linux/man-pages/man7/nptl.7.html|url-status=live}}&lt;/ref&gt; provides the standard POSIX threads interface (''pthreads'') to userspace&lt;ref&gt;{{Cite web|title=pthreads(7) - Linux manual page|url=https://man7.org/linux/man-pages/man7/pthreads.7.html|access-date=2020-07-25|website=man7.org|archive-date=15 July 2020|archive-url=https://web.archive.org/web/20200715200134/https://man7.org/linux/man-pages/man7/pthreads.7.html|url-status=live}}&lt;/ref&gt; Whenever a new thread is created using the pthread_create(3) POSIX interface,&lt;ref&gt;{{Cite web|title=pthread_create(3) - Linux manual page|url=https://man7.org/linux/man-pages/man3/pthread_create.3.html|access-date=2020-07-25|website=man7.org|archive-date=25 July 2020|archive-url=https://web.archive.org/web/20200725052820/https://man7.org/linux/man-pages/man3/pthread_create.3.html|url-status=live}}&lt;/ref&gt; the {{Mono|clone(2)}} family of system calls must also be given the address of the function that the new thread must jump to. The Linux kernel provides the {{Mono|futex(7)}} (acronym for "Fast user-space mutexes") mechanisms for fast user-space locking and synchronization;&lt;ref&gt;{{Cite web|title=futex(7) - Linux manual page|url=https://man7.org/linux/man-pages/man7/futex.7.html|access-date=2020-07-25|website=man7.org|archive-date=15 July 2020|archive-url=https://web.archive.org/web/20200715175424/https://man7.org/linux/man-pages/man7/futex.7.html|url-status=live}}&lt;/ref&gt; the majority of the operations are performed in userspace but it may be necessary to communicate with the kernel using the {{Mono|futex(2)}} system call.&lt;ref name=":0" /&gt;

A very special category of threads is the so-called ''kernel threads''. They must not be confused with the above-mentioned threads of execution of the user's processes. Kernel threads exist only in kernel space and their only purpose is to concurrently run kernel tasks.&lt;ref&gt;{{Cite web|title=Kernel threads made easy [LWN.net]|url=https://lwn.net/Articles/65178/|access-date=2020-08-15|website=lwn.net|archive-date=31 March 2020|archive-url=https://web.archive.org/web/20200331215714/https://lwn.net/Articles/65178/|url-status=live}}&lt;/ref&gt;

Differently, whenever an independent process is created, the syscalls return exactly to the next instruction of the same program, concurrently in ''parent'' process and in ''child's'' one (i.e., one program, two processes). Different return values (one per process) enable the program to know in which of the two processes it is currently executing. Programs need this information because the child process, a few steps after process duplication, usually invokes the {{Mono|execve(2)}} system call (possibly via the family of {{Mono|exec(3)}} wrapper functions in glibC) and replace the program that is currently being run by the calling process with a new program, with newly initialized stack, heap, and&amp;nbsp;(initialized and uninitialized) data segments.&lt;ref&gt;{{Cite web|title=execve(2) - Linux manual page|url=https://www.man7.org/linux/man-pages/man2/execve.2.html|access-date=2020-07-17|website=www.man7.org|archive-date=15 July 2020|archive-url=https://web.archive.org/web/20200715183742/https://man7.org/linux/man-pages/man2/execve.2.html|url-status=live}}&lt;/ref&gt; When it is done, it results in two processes that run two different programs.

Depending on the [[User identifier|effective user id]] (''euid''), and on the [[Group identifier|effective group id]] (''egid''), a process running with user zero privileges (''root'', the system administrator, owns the identifier 0) can perform everything (e.g., kill all the other processes or recursively wipe out whole filesystems), instead non zero user processes cannot. {{Mono|capabilities(7)}} divides the privileges traditionally associated with superuser into distinct units, which can be independently enabled and disabled by the parent process or dropped by the child itself.&lt;ref&gt;{{Cite web|title=capabilities(7) - Linux manual page|url=https://man7.org/linux/man-pages/man7/capabilities.7.html|access-date=2020-08-02|website=man7.org|archive-date=15 July 2020|archive-url=https://web.archive.org/web/20200715201514/https://man7.org/linux/man-pages/man7/capabilities.7.html|url-status=live}}&lt;/ref&gt;

=== Scheduling and preemption ===
{{See also|Completely Fair Scheduler|Preemption (computing)|Kernel preemption|}}

Linux enables different scheduling classes and policies.&lt;ref name="moshe"&gt;{{cite web |url=http://www.linuxjournal.com/article/3910 |title=The Linux Scheduler |last=Bar |first=Moshe |date=1 April 2000 |work=[[Linux Journal]] |publisher=Belltown Media, Inc. |access-date=14 April 2012 |archive-date=2 February 2021 |archive-url=https://web.archive.org/web/20210202131440/https://www.linuxjournal.com/article/3910 |url-status=live }}&lt;/ref&gt; By default the kernel uses a scheduler mechanism called the [[Completely Fair Scheduler]] (CFS) introduced in the 2.6.23 version of the kernel.&lt;ref name=":5"&gt;{{cite mailing list|title=&amp;#91;patch&amp;#93; Modular Scheduler Core and Completely Fair Scheduler &amp;#91;CFS&amp;#93;|url=https://lwn.net/Articles/230501/|last=Molnár|first=Ingo|author-link=Ingo Molnár|date=13 April 2007|mailing-list=[[LKML]]|access-date=30 March 2020|archive-date=3 November 2020|archive-url=https://web.archive.org/web/20201103034312/https://lwn.net/Articles/230501/|url-status=live}}&lt;/ref&gt; Internally this default-scheduler class is defined in a macro of a C header as &lt;code&gt;SCHED_NORMAL&lt;/code&gt;. In other  POSIX  kernels, a similar policy known as &lt;code&gt;SCHED_OTHER&lt;/code&gt; allocates CPU timeslices (i.e, it assigns absolute slices of the processor time depending on either predetermined or dynamically computed priority of each process). The Linux CFS does away with absolute timeslices and assigns a fair proportion of CPU time, as a function of parameters like the total number of runnable processes and the time they have already run; this function also takes into account a kind of weight that depends on their relative priorities (nice values).&lt;ref name="Love 2010 pp.46-50"&gt;{{Cite book|last=Love|first=Robert|title=Linux Kernel Development|publisher=Addison Wesley|year=2010|isbn=9780672329463|edition=3rd|pages=46-50|chapter=4}}&lt;/ref&gt;        

The kernel also contains two POSIX-compliant&lt;ref name="posix1b"&gt;{{cite web|url=http://www.opengroup.org/onlinepubs/009695399|title=IEEE Standard for Information Technology – Portable Operating System Interface, POSIX.1b, Real-time extensions (IEEE Std 1003.1b-1993)|access-date=17 March 2016|archive-date=16 November 2010|archive-url=https://web.archive.org/web/20101116144926/http://www.opengroup.org/onlinepubs/009695399/|url-status=live}}&lt;/ref&gt; real-time scheduling classes named &lt;code&gt;SCHED_FIFO&lt;/code&gt; (realtime [[FIFO (computing and electronics)|first-in-first-out]]) and &lt;code&gt;SCHED_RR&lt;/code&gt; (realtime [[round-robin scheduling|round-robin]]), both of which take precedence over the default class.&lt;ref name="moshe" /&gt; An additional scheduling policy known as &lt;code&gt;[[SCHED_DEADLINE]]&lt;/code&gt;, implementing the [[earliest deadline first scheduling|earliest deadline first algorithm]] (EDF), was added in kernel version 3.14, released on 30 March 2014.&lt;ref&gt;{{cite web |url=https://www.phoronix.com/scan.php?page=news_item&amp;px=MTU4Mjg |title=The Linux 3.14 Kernel Already Has Many Exciting Features |last=Larabel |first=Michael |author-link=Michael Larabel |date=24 January 2014 |publisher=[[Phoronix]] |access-date=3 February 2014 |archive-date=13 August 2020 |archive-url=https://web.archive.org/web/20200813143115/https://www.phoronix.com/scan.php?page=news_item&amp;px=MTU4Mjg |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://kernelnewbies.org/Linux_3.14#head-651929cdcf19cc2e2cfc7feb16b78ef963d195fe |title=Linux kernel 3.14, Section 1.1. Deadline scheduling class for better real-time scheduling |date=30 March 2014 |website=kernelnewbies.org |access-date=2 April 2014 |archive-date=15 January 2021 |archive-url=https://web.archive.org/web/20210115101454/https://kernelnewbies.org/Linux_3.14#head-651929cdcf19cc2e2cfc7feb16b78ef963d195fe |url-status=live }}&lt;/ref&gt; &lt;code&gt;SCHED_DEADLINE&lt;/code&gt; takes precedence over all the other scheduling classes.

Linux provides both ''user preemption'' as well as full ''kernel preemption''.&lt;ref name="Love 2010 pp.62-63"&gt;{{Cite book|last=Love|first=Robert|title=Linux Kernel Development|publisher=Addison Wesley|year=2010|isbn=9780672329463|edition=3rd|pages=62–63|chapter=4}}&lt;/ref&gt; Preemption reduces [[latency (engineering)|latency]], increases responsiveness,&lt;ref&gt;{{Cite web|title=Lowering Latency in Linux: Introducing a Preemptible Kernel {{!}} Linux Journal|url=https://www.linuxjournal.com/article/5600|access-date=2020-08-17|website=www.linuxjournal.com|archive-date=9 August 2020|archive-url=https://web.archive.org/web/20200809182228/https://www.linuxjournal.com/article/5600|url-status=live}}&lt;/ref&gt; and makes Linux more suitable for desktop and [[real-time computing|real-time]] applications.

With user preemption, the kernel scheduler can replace the current process with the execution of a [[context switch]] to a different one that therefore acquires the computing resources for running (CPU, memory, and more). It makes it according to the [[Completely Fair Scheduler|CFS]] algorithm (in particular, it uses a variable called {{Mono|vruntime}} for sorting processes), to the active scheduler policy and to the processes relative priorities. With kernel preemption, the kernel can preempt itself when an interrupt handler returns, when kernel tasks block, and whenever a subsystem explicitly calls the schedule() function.

The Linux kernel patch &lt;code&gt;PREEMPT_RT&lt;/code&gt; enables full preemption of critical sections, interrupt handlers, and "interrupt disable" code sequences.&lt;ref&gt;{{cite web |url=https://lwn.net/Articles/146861/ |title=A realtime preemption overview |last=McKenney |first=Paul |date=10 August 2005 |publisher=[[LWN.net]] |access-date=5 February 2012 |archive-date=10 August 2020 |archive-url=https://web.archive.org/web/20200810165635/https://lwn.net/Articles/146861/ |url-status=live }}&lt;/ref&gt; Partial integration of the real-time Linux patches brought the above mentioned functionality to the kernel mainline.&lt;ref&gt;{{cite web |url=https://www.osadl.org/Realtime-Linux.projects-realtime-linux.0.html |title=OSADL Project: Realtime Linux |publisher=[[OSADL]] |access-date=5 February 2012 |archive-date=4 February 2021 |archive-url=https://web.archive.org/web/20210204170950/https://www.osadl.org/Realtime-Linux.projects-realtime-linux.0.html |url-status=live }}&lt;/ref&gt;

=== Concurrency and synchronization ===
The kernel has different causes of concurrency (e.g., interrupts, bottom halves, preemption of kernel and users tasks, symmetrical multiprocessing).&lt;ref name="Love 2010 p.167"&gt;{{Cite book|last=Love|first=Robert|title=Linux Kernel Development|publisher=Addison Wesley|year=2010|isbn=9780672329463|edition=3rd|page=167|chapter=9}}&lt;/ref&gt; For protecting critical regions (sections of code that must be executed atomically), shared memory locations (like [[global variable]]s and other data structures with global scope), and regions of memory that are  asynchronously modifiable by hardware (e.g., having the C [[Volatile (computer programming)|&lt;code&gt;volatile&lt;/code&gt;]] [[type qualifier]]), Linux provides a large set of tools. They consist of [[Linearizability|atomic types]] (which can only be manipulated by a set of specific operators), [[Spinlock|spinlocks]], [[Semaphore (programming)|semaphores]], [[Mutual exclusion|mutexes]],&lt;ref name="Love 2010 pp.176-198"&gt;{{Cite book|last=Love|first=Robert|title=Linux Kernel Development|publisher=Addison Wesley|year=2010|isbn=9780672329463|edition=3rd|pages=176-198|chapter=10}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=locking.rst - Documentation/kernel-hacking/locking.rst - Linux source code (v5.11.10) - Bootlin|url=https://elixir.bootlin.com/linux/v5.11.10/source/Documentation/kernel-hacking/locking.rst|access-date=2021-03-29|website=elixir.bootlin.com}}&lt;/ref&gt; and [[Non-blocking algorithm|lockless algorithms]] (e.g., [[Read-copy-update|RCUs]]).&lt;ref&gt;{{Cite web|title=What is RCU, Fundamentally? [LWN.net]|url=https://lwn.net/Articles/262464/|access-date=2021-03-29|website=lwn.net}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=What is RCU? Part 2: Usage [LWN.net]|url=https://lwn.net/Articles/263130/|access-date=2021-03-29|website=lwn.net}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=RCU part 3: the RCU API [LWN.net]|url=https://lwn.net/Articles/264090/|access-date=2021-03-29|website=lwn.net}}&lt;/ref&gt; Most lock-less algorithms are built on top of [[memory barrier]]s for the purpose of enforcing [[memory ordering]] and prevent undesired side effects due to [[Optimizing compiler|compiler's optimizations]].&lt;ref&gt;{{Cite web|title=Linux-Kernel Memory Model|url=http://open-std.org/JTC1/SC22/WG21/docs/papers/2020/p0124r7.html|access-date=2021-03-29|website=open-std.org}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=A formal kernel memory-ordering model (part 1) [LWN.net]|url=https://lwn.net/Articles/718628/|access-date=2021-03-29|website=lwn.net}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=A formal kernel memory-ordering model (part 2) [LWN.net]|url=https://lwn.net/Articles/720550/|access-date=2021-03-29|website=lwn.net}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last=Stern|first=Alan|title=Explanation of the Linux-Kernel Memory Consistency Model|url=https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/tools/memory-model/Documentation/explanation.txt|url-status=live}}&lt;/ref&gt;

=== Interrupts management ===
The management of the [[Interrupt|interrupts]], although it could be seen as a single job, is divided in two separate parts. This split  in two is due to the different time constraints and to the synchronization needs of the tasks whose the management is composed of. The first part is made up of an asyncronous [[Interrupt handler|interrupt service routine]] that in Linux is known as the ''top half'', while the second part is carried out by one of three types of the so-called ''bottom halves'' (''softirq'', ''tasklets,'' and ''work queues'').&lt;ref name="Love 2010 pp.133-137"&gt;{{Cite book|last=Love|first=Robert|title=Linux Kernel Development|publisher=Addison Wesley|year=2010|isbn=9780672329463|pages=133-137}}&lt;/ref&gt; Linux interrupts service routines can be nested (i.e., a new IRQ can trap into a high priority ISR that preempts any other lower priority ISRs).  

=== Memory management  ===
{{See also|Memory management}}

Memory management in Linux is a complex topic. First of all, the kernel is not pageable (i.e., it is always resident in physical memory and cannot be swapped to the disk). In the kernel there is no memory protection (no ''SIGSEGV'' signals, unlike in userspace), therefore memory violations lead to instability and system crashes.&lt;ref name="Love 2010 p.20"&gt;{{Cite book|last=Love|first=Robert|title=Linux Kernel Development|publisher=Addison Wesley|year=2010|isbn=9780672329463|pages=20}}&lt;/ref&gt;

[[File:The Linux Storage Stack Diagram.svg|thumb|alt=|339px|The Linux Storage Stack Diagram&lt;ref&gt;{{Cite web|url=https://www.thomas-krenn.com/de/wikiDE/images/7/72/Linux-storage-stack-diagram_v4.10.svg|title=The Linux Storage Stack Diagram|website=www.thomas-krenn.com|access-date=2020-03-19|archive-date=3 August 2020|archive-url=https://web.archive.org/web/20200803100605/https://www.thomas-krenn.com/de/wikiDE/images/7/72/Linux-storage-stack-diagram_v4.10.svg|url-status=live}}&lt;/ref&gt;]]

=== Supported architectures ===
{{See also|List of Linux-supported computer architectures|Linux-powered device}}
[[Image:Series 2 tivo front.jpg|thumb|right|upright=1.1|[[TiVo]] [[digital video recorder|DVR]], a consumer device running Linux]]
While not originally designed to be [[porting|portable]],&lt;ref name="Torvlads25Aug91" /&gt;&lt;ref name="opensources"&gt;{{cite book |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=January 1999 |title=Open Sources: Voices from the Open Source Revolution |chapter-url=https://archive.org/details/isbn_9781565925823 |publisher=[[O'Reilly Media|O'Reilly]] |chapter=The Linux Edge |isbn=1-56592-582-3 |access-date=13 October 2013 }}&lt;/ref&gt; Linux is now one of the most widely ported operating system kernels, running on a diverse range of systems from the [[ARM architecture]] to IBM [[z/Architecture]] [[mainframe computer]]s. The first port was performed on the [[Motorola 68000]] platform. The modifications to the kernel were so fundamental that Torvalds viewed the Motorola version as a [[Fork (software)|fork]] and a "Linux-like operating system".&lt;ref name="opensources"/&gt; However, that moved Torvalds to lead a major restructure of the code to facilitate porting to more computing architectures. The first Linux that, in a single source tree, had code for more than i386 alone, supported the [[Digital Equipment Corporation|DEC]] [[Alpha AXP]] 64-bit platform.&lt;ref&gt;{{cite web|url=https://www.linuxjournal.com/article/1178?page=0,1|title=Porting Linux to the DEC Alpha: The Kernel and Shell|access-date=5 October 2019|archive-date=5 September 2019|archive-url=https://web.archive.org/web/20190905215158/https://www.linuxjournal.com/article/1178?page=0,1|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Linux on Alpha: A Strategic Choice|url=https://www.linuxjournal.com/article/1150?page=0,0|access-date=5 October 2019|archive-date=4 September 2019|archive-url=https://web.archive.org/web/20190904234429/https://www.linuxjournal.com/article/1150?page=0,0|url-status=live}}&lt;/ref&gt;&lt;ref name="opensources" /&gt;

Linux runs as the main operating system on [[IBM]]'s [[Summit (supercomputer)|Summit]]; {{as of|2019|10|lc=y}}, all of the world's [[TOP500|500 fastest supercomputers]] run some operating system based on the Linux kernel,&lt;ref name=top500stats&gt;{{cite web |url=https://www.top500.org/statistics/details/osfam/1 |title=TOP500 Supercomputer Sites: Operating system Family / Linux |publisher=Top500.org |access-date=5 October 2019 |archive-date=19 November 2012 |archive-url=https://web.archive.org/web/20121119205719/https://www.top500.org/statistics/details/osfam/1 |url-status=live }}&lt;/ref&gt; a big change from 1998 when the first Linux supercomputer got added to the list.&lt;ref&gt;{{Cite web| url=https://www.top500.org/system/166763| title=Avalon Cluster {{!}} TOP500 Supercomputer Sites| website=www.top500.org| access-date=2019-10-05| archive-date=5 October 2019| archive-url=https://web.archive.org/web/20191005210605/https://www.top500.org/system/166763| url-status=live}}&lt;/ref&gt;

Linux has also been ported to various handheld devices such as [[Apple Inc.|Apple's]] [[iPhone]] 3G and [[iPod]].&lt;ref&gt;{{cite web |url=https://www.pcworld.com/article/195789/android_now_running_on_iphone_3g.html |title=Android Now Running On iPhone 3G |last=Wang |first=David |date=6 May 2010 |work=TechHive |publisher=[[International Data Group|IDG]] |access-date=11 July 2010 |archive-date=22 July 2010 |archive-url=https://web.archive.org/web/20100722023655/http://www.pcworld.com/article/195789/android_now_running_on_iphone_3g.html |url-status=live }}&lt;/ref&gt;

=== Supported devices ===
In 2007, the LKDDb project has been started to build a comprehensive database of hardware and protocols known by Linux kernels.&lt;ref name="lkddb"&gt;{{cite web | url = https://cateee.net/lkddb/ | title = LKDDb | access-date = 2021-01-26 | publisher = LKDDb Project | archive-date = 25 February 2021 | archive-url = https://web.archive.org/web/20210225020934/https://cateee.net/lkddb/ | url-status = live }}&lt;/ref&gt; The database is built automatically by static analysis of the kernel sources. Later in 2014 the Linux Hardware project was launched to automatically collect a database of all tested hardware configurations with the help of users of various Linux distributions.&lt;ref name="linuxhw"&gt;{{cite web | url = https://linux-hardware.org/ | title = Linux Hardware | access-date = 2021-01-26 | publisher = Linux Hardware Project | archive-date = 26 January 2021 | archive-url = https://web.archive.org/web/20210126054431/https://linux-hardware.org/ | url-status = live }}&lt;/ref&gt;

=== Live patching ===
Rebootless updates can even be applied to the kernel by using [[live patching]] technologies such as [[Ksplice]], [[kpatch]] and [[kGraft]]. Minimalistic foundations for live kernel patching were merged into the Linux kernel mainline in kernel version 4.0, which was released on 12 April 2015. Those foundations, known as ''livepatch'' and based primarily on the kernel's [[ftrace]] functionality, form a common core capable of supporting hot patching by both kGraft and kpatch, by providing an [[application programming interface]] (API) for kernel modules that contain hot patches and an [[application binary interface]] (ABI) for the userspace management utilities. However, the common core included into Linux kernel&amp;nbsp;4.0 supports only the [[x86]] architecture and does not provide any mechanisms for ensuring [[Function (programming)|function]]-level consistency while the hot patches are applied. {{As of|2015|04}}, there is ongoing work on porting kpatch and kGraft to the common live patching core provided by the Linux kernel mainline.&lt;ref&gt;{{cite web
| url = http://kernelnewbies.org/Linux_4.0#head-9aa7c8499b42911a48c02b24f367bf2bc6db8606
| title = Linux kernel 4.0, Section 1.2. Live patching
| date = 26 April 2015
| access-date = 27 April 2015
| website = kernelnewbies.org
| archive-date = 4 May 2015
| archive-url = https://web.archive.org/web/20150504015114/http://kernelnewbies.org/Linux_4.0#head-9aa7c8499b42911a48c02b24f367bf2bc6db8606
| url-status = live
}}&lt;/ref&gt;&lt;ref&gt;{{cite web
| url = https://lwn.net/Articles/634649/
| title = A rough patch for live patching
| date = 25 February 2015
| access-date = 27 April 2015
| author = Jonathan Corbet
| publisher = [[LWN.net]]
| archive-date = 27 April 2015
| archive-url = https://web.archive.org/web/20150427181127/https://lwn.net/Articles/634649/
| url-status = live
}}&lt;/ref&gt;&lt;ref&gt;{{cite web
| url = https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=1d9c5d79e6e4385aea6f69c23ba543717434ed70
| title = kernel/git/torvalds/linux.git: Pull live patching infrastructure from Jiri Kosina (Linux kernel source tree)
| date = 11 February 2015
| access-date = 27 April 2015
| website = [[kernel.org]]
| archive-date = 11 June 2015
| archive-url = https://web.archive.org/web/20150611040359/https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=1d9c5d79e6e4385aea6f69c23ba543717434ed70
| url-status = live
}}&lt;/ref&gt;

=== Security ===
Kernel bugs present potential security issues. For example, they may allow for [[privilege escalation]] or create [[denial-of-service attack]] vectors. Over the years, numerous bugs affecting system security were found and fixed.&lt;ref&gt;{{cite book |last1=Mookhey |first1=K. K. |last2=Burghate |first2=Nilesh |date=1 July 2005 |title=Linux: Security, Audit and Control Features |url=https://books.google.com/books?id=-kD0sxQ0EkIC&amp;pg=PA14 |location=USA |publisher=[[ISACA]] |page=14 |isbn=1-893209-78-4 |access-date=31 December 2010 |archive-date=2 June 2013 |archive-url=https://web.archive.org/web/20130602223234/http://books.google.com/books?id=-kD0sxQ0EkIC&amp;pg=PA14 |url-status=live }}&lt;/ref&gt; New features are frequently implemented to improve the kernel's security.&lt;ref&gt;{{cite book |last=Hatch |first=Brian |date=15 July 2008 |title=Hacking Exposed Linux: Linux Security Secrets and Solutions |url=https://books.google.com/books?id=f5Vz08spzw8C&amp;pg=PA524 |publisher=[[McGraw-Hill Osborne Media]] |page=524 |isbn=978-0-07-226257-5 |access-date=31 December 2010 |archive-date=2 June 2013 |archive-url=https://web.archive.org/web/20130602212901/http://books.google.com/books?id=f5Vz08spzw8C&amp;pg=PA524 |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Jaeger |first=Trent |date=7 October 2008 |title=Operating System Security |url=https://books.google.com/books?id=P4PYPSv8nBMC&amp;pg=PA122 |publisher=Morgan and Claypool Publishers |page=122 |isbn=978-1-59829-212-1 |access-date=31 December 2010 |archive-date=2 June 2013 |archive-url=https://web.archive.org/web/20130602203613/http://books.google.com/books?id=P4PYPSv8nBMC&amp;pg=PA122 |url-status=live }}&lt;/ref&gt;

Capabilities(7) have already been introduced in the section about the processes and threads. Android makes use of them and [[systemd]] gives administrators detailed control over the capabilities of processes.&lt;ref&gt;{{Cite web|title=CAP_PERFMON — and new capabilities in general [LWN.net]|url=https://lwn.net/Articles/812719/|access-date=2020-08-02|website=lwn.net|archive-date=4 August 2020|archive-url=https://web.archive.org/web/20200804030704/https://lwn.net/Articles/812719/|url-status=live}}&lt;/ref&gt;

Linux offers a wealth of mechanisms to reduce kernel attack surface and improve security which are collectively known as the [[Linux Security Modules]] (LSM).&lt;ref&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/admin-guide/LSM/index.html|title=Linux Security Module Usage — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-10|archive-date=2 May 2020|archive-url=https://web.archive.org/web/20200502142406/https://www.kernel.org/doc/html/latest/admin-guide/LSM/index.html|url-status=live}}&lt;/ref&gt; They comprise the [[Security-Enhanced Linux]] (SELinux) module, whose code has been originally developed and then released to the public by the [[National Security Agency|NSA]],&lt;ref&gt;{{Cite web|url=https://www.nsa.gov/What-We-Do/Research/SELinux/FAQs/|title=National Security Agency {{!}} Central Security Service &gt; What We Do &gt; Research &gt; SE Linux &gt; SE Linux FAQs|website=www.nsa.gov|access-date=2020-01-10|archive-date=18 September 2019|archive-url=https://web.archive.org/web/20190918022139/https://www.nsa.gov/What-We-Do/Research/SELinux/FAQs/|url-status=live}}&lt;/ref&gt; and [[AppArmor]]&lt;ref name=":4"&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/admin-guide/LSM/apparmor.html|title=AppArmor — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-10|archive-date=8 May 2020|archive-url=https://web.archive.org/web/20200508080035/https://www.kernel.org/doc/html/latest/admin-guide/LSM/apparmor.html|url-status=live}}&lt;/ref&gt; among others. SELinux is now actively developed and maintained on [[GitHub]].&lt;ref name=":3"&gt;{{Cite web|url=https://github.com/SELinuxProject|title=SELinux Project|website=GitHub|language=en|access-date=2020-01-10|archive-date=12 December 2019|archive-url=https://web.archive.org/web/20191212214729/https://github.com/SELinuxProject|url-status=live}}&lt;/ref&gt; SELinux and AppArmor provide support to access control security policies, including [[mandatory access control]] (MAC), though they profoundly differ in complexity and scope.

Another security feature is the Seccomp BPF (SECure COMPuting with Berkeley Packet Filters) which works by filtering parameters and reducing the set of system calls available to user-land applications.&lt;ref&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/userspace-api/seccomp_filter.html|title=Seccomp BPF (SECure COMPuting with filters) — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-10|archive-date=7 March 2020|archive-url=https://web.archive.org/web/20200307065527/https://www.kernel.org/doc/html/latest/userspace-api/seccomp_filter.html|url-status=live}}&lt;/ref&gt;

Critics have accused kernel developers of covering up security flaws or at least not announcing them; in 2008, Linus Torvalds responded to this with the following:&lt;ref&gt;{{cite web|url=http://kerneltrap.org/Linux/Security_Bugs_and_Full_Disclosure |title=Security Bugs and Full Disclosure |last=Andrews |first=Jeremy |date=16 July 2008 |publisher=[[KernelTrap]] |access-date=31 December 2010 |archive-url=https://web.archive.org/web/20080719130436/http://kerneltrap.org/Linux/Security_Bugs_and_Full_Disclosure |archive-date=19 July 2008 |url-status=dead }}&lt;/ref&gt;&lt;ref&gt;{{cite mailing list |url=http://seclists.org/fulldisclosure/2008/Jul/276 |title=Linux's unofficial security-through-coverup policy |last=Spengler |first=Brad |date=16 July 2008 |mailing-list=Full Disclosure |access-date=31 December 2010 |archive-date=7 August 2020 |archive-url=https://web.archive.org/web/20200807161645/https://seclists.org/fulldisclosure/2008/Jul/276 |url-status=live }}&lt;/ref&gt;

{{quote|I personally consider security bugs to be just "normal bugs". I don't cover them up, but I also don't have any reason what-so-ever to think it's a good idea to track them and announce them as something special...one reason I refuse to bother with the whole security circus is that I think it glorifies—and thus encourages—the wrong behavior. It makes "heroes" out of security people, as if the people who don't just fix normal bugs aren't as important. In fact, all the boring normal bugs are ''way'' more important, just because there's[sic] a lot more of them. I don't think some spectacular security hole should be glorified or cared about as being any more "special" than a random spectacular crash due to bad locking.}}

Linux distributions typically release security updates to fix vulnerabilities in the Linux kernel. Many offer [[long-term support]] releases that receive security updates for a certain Linux kernel version for an extended period of time.


== Development ==
&lt;div class="tright"&gt;
{{Graph:Chart
| width = 600
| height = 300
| type = rect
| xAxisTitle = Kernel Version
| yAxisTitle = Million Lines of Code
| x = 1.0.0, 2.0.0, 2.1.0, 2.2.0, 2.3.0, 2.4.0, 2.5.0, 2.6.0,   3.0,    4.0,   5.0,  5.11
| y =  0.17,  0.71,  0.73,  1.67,  1.76,  3.15,  3.83,  8.10, 14.64,  19.31, 26.20, 30.34
}}
&lt;!-- Lines are counted with "find . -type f -not -regex '\./\.git/.*' | xargs cat | wc -l" --&gt;
&lt;/div&gt;

=== Developer community ===
The community of Linux kernel developers comprises about 5000-6000 members. According to the "2017 State of Linux Kernel Development", a study issued by the Linux Foundation, covering the commits for the releases 4.8 to 4.13, about 1500 developers were contributing from about 200-250 companies on average. The top 30 developers contributed a little more than 16% of the code. As of companies, the top contributors are Intel (13.1%) and Red Hat (7.2%), Linaro (5.6%), IBM (4.1%), the second and fifth places are held by the 'none' (8.2%) and 'unknown' (4.1%) categories.&lt;ref&gt;{{Cite web|title=2017 State of Linux Kernel Development|url=https://www.linuxfoundation.org/publications/2017/10/2017-state-of-linux-kernel-development/|last=Foundation|first=The Linux|date=2017-10-25|website=The Linux Foundation|language=en-US|access-date=2020-05-27|archive-date=27 May 2020|archive-url=https://web.archive.org/web/20200527074644/https://www.linuxfoundation.org/publications/2017/10/2017-state-of-linux-kernel-development/|url-status=live}}&lt;/ref&gt;

{{Quote|text=Instead of a roadmap, there are technical guidelines. Instead of a central resource allocation, there are persons and companies who all have a stake in the further development of the Linux kernel, quite independently from one another:

People like Linus Torvalds and I don’t plan the kernel evolution. We don’t sit there and think up the roadmap for the next two years, then assign resources to the various new features. That's because we don’t have any resources. The resources are all owned by the various corporations who use and contribute to Linux, as well as by the various independent contributors out there. It's those people who own the resources who decide...|sign=[[Andrew Morton (computer programmer)|Andrew Morton]], 2005}}

=== Source code management ===
The Linux development community uses [[Git]] to manage the [[source code]]. Git users clone the latest version of Torvalds' tree with {{Mono|git-clone(1)}}&lt;ref&gt;{{Cite web|title=git-clone(1) - Linux manual page|url=https://man7.org/linux/man-pages/man1/git-clone.1.html|access-date=2020-08-16|website=man7.org|archive-date=14 October 2020|archive-url=https://web.archive.org/web/20201014211233/https://man7.org/linux/man-pages/man1/git-clone.1.html|url-status=live}}&lt;/ref&gt; and keep it up to date using {{Mono|git-pull(1)}}.&lt;ref&gt;{{Cite web|title=git-pull(1) - Linux manual page|url=https://man7.org/linux/man-pages/man1/git-pull.1.html|access-date=2020-08-16|website=man7.org|archive-date=12 November 2020|archive-url=https://web.archive.org/web/20201112020325/https://man7.org/linux/man-pages/man1/git-pull.1.html|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Linux Kernel Development: Linux Kernel Development |author= Robert Love|year=2010 |publisher=Pearson Education |isbn=9780768696790 |page=11 }}&lt;/ref&gt; Contributions are submitted as patches, in the form of text messages on the LKML (and often also on other mailing lists dedicated to particular subsystems). The patches must conform to a set of rules and to a formal language that, among other things, describes which lines of code are to be deleted and what others are to be added to the specified files. These patches can be automatically processed so that system administrators can apply them in order to make just some changes to the code or to incrementally upgrade to the next version.&lt;ref&gt;{{cite book |title=Linux Kernel Development: Linux Kernel Development |author= Robert Love|year=2010 |publisher=Pearson Education |isbn=9780768696790 |page=12 }}&lt;/ref&gt; Linux is distributed also in [[GNU zip]] (gzip) and [[bzip2]] formats.

=== Submitting code to the kernel ===
A developer who wants to change the Linux kernel starts with developing and testing that change. Depending on how significant the change is and how many subsystems it modifies, the change will either be submitted as a single patch or in multiple patches of [[source code]]. In case of a single subsystem that is maintained by a single maintainer, these patches are sent as e-mails to the maintainer of the subsystem with the appropriate mailing list in Cc. The maintainer and the readers of the mailing list will review the patches and provide feedback. Once the review process has finished the subsystem maintainer accepts the patches in the relevant [[Git]] kernel tree. If the changes to the Linux kernel are bug fixes that are considered important enough, a pull request for the patches will be sent to Torvalds within a few days. Otherwise, a pull request will be sent to Torvalds during the next merge window. The merge window usually lasts two weeks and starts immediately after the release of the previous kernel version.&lt;ref&gt;{{cite web |title=How the development process works |url=https://www.kernel.org/doc/html/latest/process/2.Process.html |access-date=4 February 2018 |archive-date=9 December 2017 |archive-url=https://web.archive.org/web/20171209130758/https://www.kernel.org/doc/html/latest/process/2.Process.html |url-status=live }}&lt;/ref&gt; The Git kernel source tree names all developers who have contributed to the Linux kernel in the ''Credits'' directory and all subsystem maintainers are listed in ''Maintainers''.&lt;ref&gt;{{cite book |title=Linux Kernel Development: Linux Kernel Development |author= Robert Love|year=2010 |publisher=Pearson Education |isbn=9780768696790 |page=13 }}&lt;/ref&gt;

=== Programming language and coding style ===
Linux is written in a special [[C (programming language)|C programming language]] supported by [[GNU Compiler Collection|GCC]], a compiler that extends in many ways the C standard, for example using [[inline assembler|inline sections of code]] written in the [[assembly language]] (in GCC's "AT&amp;T-style" syntax) of the target architecture. Since 2002 all the code must adhere to the 21 rules comprising the ''Linux Kernel Coding Style.''&lt;ref&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/process/howto.html#documentation|title=HOWTO do Linux kernel development — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-04|archive-date=7 March 2020|archive-url=https://web.archive.org/web/20200307065439/https://www.kernel.org/doc/html/latest/process/howto.html#documentation|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/process/coding-style.html|title=Linux kernel coding style — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-04|archive-date=5 January 2020|archive-url=https://web.archive.org/web/20200105083545/https://www.kernel.org/doc/html/latest/process/coding-style.html|url-status=live}}&lt;/ref&gt;

=== GNU toolchain ===
The [[GNU Compiler Collection]] (GCC or GNU cc) is the default [[compiler]] for the mainline Linux sources and it is invoked by a utility called [[Make (Unix)|make]]. Then, the [[GNU Assembler]] (more often called GAS or GNU as) outputs the [[object file]]s from the GCC generated [[Assembly language|assembly]] code. Finally, the [[GNU linker|GNU Linker]] (GNU ld) is used to produce a statically linked executable kernel file called {{Mono|[[vmlinux]]}}. Both {{Mono|as}} and {{Mono|ld}} are part of [[GNU Binary Utilities]] (binutils). The above-mentioned tools are collectively known as the [[GNU toolchain]].

=== Compiler compatibility ===
GCC was for a long time the only compiler capable of correctly building Linux. In 2004, [[Intel]] claimed to have modified the kernel so that [[Intel C++ Compiler|its C compiler]] was also capable of compiling it.&lt;ref&gt;{{cite web|url=http://www.pyrillion.org/index.html?showframe=linuxkernelpatch.html |title=Linux kernel patch for Intel Compiler |last=Kubbilun |first=Ingo A. |date=2 June 2004 |publisher=Pyrillion.org |access-date=12 November 2010 |archive-url=https://web.archive.org/web/20110722090031/http://www.pyrillion.org/index.html?showframe=linuxkernelpatch.html |archive-date=22 July 2011 |language=de |url-status=dead }}&lt;/ref&gt; There was another such reported success in 2009, with a modified 2.6.22 version.&lt;ref&gt;{{cite web |url=http://linux.slashdot.org/article.pl?sid=09/02/26/2216241 |title=High Performance Linux Kernel Project &amp;mdash; LinuxDNA |author=timothy |date=26 February 2009 |work=[[Slashdot|Slashdot Linux]] |publisher=[[Dice Holdings]] |access-date=30 October 2010 |archive-date=18 October 2019 |archive-url=https://web.archive.org/web/20191018044639/https://linux.slashdot.org/story/09/02/26/2216241/high-performance-linux-kernel-project-linuxdna |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.linuxjournal.com/content/linuxdna-supercharges-linux-intel-cc-compiler |title=LinuxDNA Supercharges Linux with the Intel C/C++ Compiler |last=Ryan |first=Justin |date=25 February 2009 |work=[[Linux Journal]] |publisher=Belltown Media, Inc. |access-date=30 October 2010 |archive-date=9 November 2020 |archive-url=https://web.archive.org/web/20201109011614/https://www.linuxjournal.com/content/linuxdna-supercharges-linux-intel-cc-compiler |url-status=live }}&lt;/ref&gt;

Since 2010, effort has been underway to build Linux with [[Clang]], an alternative compiler for the C language;&lt;ref&gt;{{cite mailing list| url=http://lists.cs.uiuc.edu/pipermail/cfe-dev/2010-October/011711.html |title=Clang builds a working Linux Kernel (Boots to RL5 with SMP, networking and X, self hosts) |last=Lelbach |first=Bryce |mailing-list=cfe-dev |date=25 October 2010 |archive-url=https://web.archive.org/web/20150907044958/http://lists.cs.uiuc.edu/pipermail/cfe-dev/2010-October/011711.html |archive-date=7 September 2015}}&lt;/ref&gt; as of 12 April 2014, the official kernel could almost be compiled by Clang.&lt;ref&gt;{{cite web |url=https://www.phoronix.com/scan.php?page=news_item&amp;px=MTY2MjY |title=Linux 3.15 Can Almost Be Compiled Under LLVM's Clang |last=Larabel |first=Michael |author-link=Michael Larabel |date=12 April 2014 |publisher=[[Phoronix]] |access-date=10 June 2014 |archive-date=13 August 2020 |archive-url=https://web.archive.org/web/20200813143201/https://www.phoronix.com/scan.php?page=news_item&amp;px=MTY2MjY |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://www.phoronix.com/scan.php?page=news_item&amp;px=MTY2MjY |title=Patch By Patch, LLVM Clang Gets Better At Building The Linux Kernel |last=Larabel |first=Michael |author-link=Michael Larabel |publisher=[[Phoronix]] |access-date=20 November 2014 |archive-date=13 August 2020 |archive-url=https://web.archive.org/web/20200813143201/https://www.phoronix.com/scan.php?page=news_item&amp;px=MTY2MjY |url-status=live }}&lt;/ref&gt; The project dedicated to this effort is named ''LLVMLinux'' after the [[LLVM]] compiler infrastructure upon which Clang is built.&lt;ref&gt;{{cite web |url=https://lwn.net/Articles/549203/ |title=LFCS: The LLVMLinux project |last=Edge |first=Jake |date=7 May 2013 |publisher=[[LWN.net]] |access-date=3 March 2015 |archive-date=10 August 2020 |archive-url=https://web.archive.org/web/20200810165632/https://lwn.net/Articles/549203/ |url-status=live }}&lt;/ref&gt; LLVMLinux does not aim to fork either Linux or the LLVM, therefore it is a meta-project composed of patches that are eventually submitted to the upstream projects. By enabling Linux to be compiled by Clang, developers may benefit from shorter compilation times.&lt;ref&gt;{{cite web |url=http://llvm.org/devmtg/2014-02/slides/moller-llvmlinux.pdf |title=LLVMLinux: The Linux Kernel with Dragon Wings |last=Möller |first=Jan-Simon |date=2 February 2014 |publisher=[[LLVM|LLVM Project]] |access-date=3 March 2015 |archive-date=3 August 2020 |archive-url=https://web.archive.org/web/20200803053328/http://llvm.org/devmtg/2014-02/slides/moller-llvmlinux.pdf |url-status=live }}&lt;/ref&gt;

In 2017, developers completed upstreaming patches to support building the Linux kernel with [[Clang]] in the 4.15 release, having [[Backporting|backported]] support for [[X86-64]] and [[AArch64]] to the 4.4, 4.9, and 4.14 branches of the stable kernel tree. Google's [[Pixel 2]] shipped with the first [[Clang]] built [[Linux]] kernel,&lt;ref&gt;{{cite web |url=https://www.youtube.com/watch?v=6l4DtR5exwo&amp;t=2130 |title=2017 LLVM Developers' Meeting: Compiling Android userspace and Linux kernel with LLVM |date=18 October 2017 |publisher=[[YouTube]] |last1=Desaulniers |first1=Nick |last2=Hackmann |first2=Greg |last3=Hines |first3=Stephen |access-date=7 December 2020 |archive-date=31 December 2020 |archive-url=https://web.archive.org/web/20201231030548/https://www.youtube.com/watch?v=6l4DtR5exwo&amp;t=2130 |url-status=live }}&lt;/ref&gt; though patches for [[Pixel (1st generation)]] did exist.&lt;ref&gt;{{cite web |url=https://android-review.googlesource.com/q/topic:marlin-nougat-mr1-clang+(status:open+OR+status:closed) |access-date=6 December 2020 |last=Hackmann |first=Greg |title=marlin-nougat-mr1-clang Patch Series |date=2 February 2017 |archive-date=10 December 2020 |archive-url=https://web.archive.org/web/20201210125624/https://android-review.googlesource.com/q/topic:marlin-nougat-mr1-clang+(status:open+OR+status:closed) |url-status=live }}&lt;/ref&gt; 2018 saw [[ChromeOS]] move to building kernels with [[Clang]] by default,&lt;ref&gt;{{cite web |url=https://chromium-review.googlesource.com/c/chromiumos/overlays/chromiumos-overlay/+/1294370 |access-date=6 December 2020 |date=22 October 2018 |last=Kaehlcke |first=Matthias |title=cros-kernel2: Make clang the default compiler for kernel builds |archive-date=10 December 2020 |archive-url=https://web.archive.org/web/20201210015343/https://chromium-review.googlesource.com/c/chromiumos/overlays/chromiumos-overlay/+/1294370 |url-status=live }}&lt;/ref&gt; while [[Android (operating system)]] made [[Clang]]&lt;ref&gt;{{cite web |url=https://www.phoronix.com/scan.php?page=news_item&amp;px=Google-2019-Clang-Kernel |access-date=6 December 2020 |last=Larabel |first=Michael |author-link=Michael Larabel |publisher=[[Phoronix]] |title=Using LLVM Clang To Compile The Linux Kernel Is Heating Up Again Thanks To Google |date=4 February 2019 |archive-date=25 November 2020 |archive-url=https://web.archive.org/web/20201125201932/https://www.phoronix.com/scan.php?page=news_item&amp;px=Google-2019-Clang-Kernel |url-status=live }}&lt;/ref&gt; and [[LLVM]]'s linker LLD&lt;ref&gt;{{cite web |url=https://android-review.googlesource.com/c/platform/test/vts-testcase/kernel/+/1185200 |access-date=6 December 2020 |title=vts: kernel: enforce vts_kernel_toolchain for all TARGET_ARCH for R |last=Desaulniers |first=Nick |date=10 December 2019 |archive-date=10 December 2020 |archive-url=https://web.archive.org/web/20201210125711/https://android-review.googlesource.com/c/platform/test/vts-testcase/kernel/+/1185200 |url-status=live }}&lt;/ref&gt; required for kernel builds in 2019. [[Google]] moved its production kernel used throughout its datacenters to being built with [[Clang]] in 2020.&lt;ref&gt;{{cite web |url=https://lore.kernel.org/lkml/CAKwvOdmKjsJGbR7hHACk3qUgguy-HWvJQerwTnArE0AwhPgfcQ@mail.gmail.com/ |access-date=6 December 2020 |last=Desaulniers |first=Nick |title=Re: violating function pointer signature |date=19 November 2020 |publisher=[[LKML]]}}&lt;/ref&gt; Today, the ''[https://clangbuiltlinux.github.io/ ClangBuiltLinux]'' group coordinates fixes to both [[Linux]] and [[LLVM]] to ensure compatibility, both composed of members from ''LLVMLinux'' and having upstreamed patches from ''LLVMLinux''.

=== Kernel debugging ===
[[File:Kernel-panic.jpg|thumb|upright=0.9|An example of Linux kernel panic]]
{{Main|KGDB|Kernel panic|Linux kernel oops}}

Bugs in involving the Linux Kernel can be difficult to troubleshoot, this is because of the kernel's interaction with userspace and hardware; and also because they might be caused from a wider range of reasons compared to those of user programs. A few examples of the underlying causes are semantic errors in code, misuse of synchronization primitives, and an incorrect hardware management.&lt;ref name="Love 2010 p.364"&gt;{{cite book | last=Love | first=Robert | title=Linux kernel development | edition=3rd | publisher=Addison-Wesley | year=2010 | isbn=978-0-672-32946-3 | oclc=268788260 | language=en | page=364}}&lt;/ref&gt;

A report of a non-fatal bug in the kernel is called an "[[Linux kernel oops|oops]]"; such deviations from correct behavior of the Linux kernel may allow continued operation with compromised reliability.&lt;ref&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/0303.1/0009.html |title=Re: what's an OOPS |last=Bradford |first=John |date=8 March 2003 |mailing-list=[[LKML]] |access-date=30 October 2010 |archive-date=31 October 2014 |archive-url=https://web.archive.org/web/20141031032356/http://lkml.iu.edu/hypermail/linux/kernel/0303.1/0009.html |url-status=live }}&lt;/ref&gt;

A critical and fatal error is reported via the {{Mono|[[Kernel panic|panic()]]}} function. It prints a message and then halts the kernel.&lt;ref name="Love 2010 p.371"&gt;{{Cite book|last=Love| first=Robert| title=Linux kernel development|publisher=Addison Wesley|year=2010| isbn=9780672329463 |oclc=268788260|pages=371}}&lt;/ref&gt;

One of the most common techniques used to find out bugs in code is ''debugging by printing''. For this purpose Linux provides an in-kernel API called {{Mono|[[printk|printk()]]}} which stores messages in a circular buffer. The {{Mono|syslog(2)}} system call is used for reading and/or clearing the kernel message ring buffer and for setting the maximum ''log level'' of the messages to be sent to the console (i.e., one of the eight {{Mono|KERN_*}} parameters of {{Mono|printk()}}, which tell the severity of the condition reported); usually it is invoked via the glibC wrapper {{Mono|klogctl(3)}}.&lt;ref&gt;{{Cite web|title=syslog(2) - Linux manual page|url=https://man7.org/linux/man-pages/man2/syslog.2.html|access-date=2020-08-15|website=man7.org|archive-date=13 October 2020|archive-url=https://web.archive.org/web/20201013152012/https://man7.org/linux/man-pages/man2/syslog.2.html|url-status=live}}&lt;/ref&gt; Kernel messages are also exported to userland through the ''/dev/kmsg'' interface&lt;ref&gt;{{Cite web|title=kmsg: export printk records to the /dev/kmsg interface [LWN.net]|url=https://lwn.net/Articles/493182/|access-date=2020-08-16|website=lwn.net|archive-date=2 October 2015|archive-url=https://web.archive.org/web/20151002050933/http://lwn.net/Articles/493182/|url-status=live}}&lt;/ref&gt; (e.g., [[Systemd|systemd-journald]]&lt;ref&gt;{{Cite web| title=systemd| url=https://www.freedesktop.org/wiki/Software/systemd/| access-date=2020-08-16| website=www.freedesktop.org| archive-date=18 August 2020| archive-url=https://web.archive.org/web/20200818000645/https://www.freedesktop.org/wiki/Software/systemd/| url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=systemd-journald(8) - Linux manual page|url=https://man7.org/linux/man-pages/man8/systemd-journald.8.html|access-date=2020-08-15|website=man7.org|archive-date=12 August 2020|archive-url=https://web.archive.org/web/20200812003040/https://www.man7.org/linux/man-pages/man8/systemd-journald.8.html|url-status=live}}&lt;/ref&gt; reads that interface and by default append the messages to {{Mono|/var/log/journal}}).

Another fundamental technique for debugging a running kernel is tracing. The ''[[ftrace]]'' mechanism is a Linux internal tracer; it is used for monitoring and debugging Linux at runtime and it can also analyze user space latencies due to kernel misbehavior.&lt;ref&gt;{{Cite web|title=Debugging the kernel using Ftrace - part 1 [LWN.net]|url=https://lwn.net/Articles/365835/|access-date=2020-09-15|website=lwn.net|archive-date=9 November 2020|archive-url=https://web.archive.org/web/20201109001219/https://lwn.net/Articles/365835/|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=Debugging the kernel using Ftrace - part 2 [LWN.net]|url=https://lwn.net/Articles/366796/|access-date=2020-09-15|website=lwn.net|archive-date=31 March 2020|archive-url=https://web.archive.org/web/20200331222229/https://lwn.net/Articles/366796/|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=ftrace - Function Tracer — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/trace/ftrace.html|access-date=2020-09-15|website=www.kernel.org|archive-date=19 September 2020|archive-url=https://web.archive.org/web/20200919095357/https://www.kernel.org/doc/html/latest/trace/ftrace.html|url-status=live}}&lt;/ref&gt; Furthermore, ''ftrace'' allows users to trace Linux at boot-time.&lt;ref&gt;{{Cite web|title=Boot-time tracing — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/trace/boottime-trace.html|access-date=2020-09-19|website=www.kernel.org|archive-date=31 October 2020|archive-url=https://web.archive.org/web/20201031200922/https://www.kernel.org/doc/html/latest/trace/boottime-trace.html|url-status=live}}&lt;/ref&gt;

''kprobes'' and ''kretprobes'' can break (like debuggers in userspace) into Linux and non-disruptively collect information.&lt;ref&gt;{{Cite web|title=Kernel Probes (Kprobes) — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/trace/kprobes.html|access-date=2020-10-06|website=www.kernel.org|archive-date=11 October 2020|archive-url=https://web.archive.org/web/20201011030448/https://www.kernel.org/doc/html/latest/trace/kprobes.html|url-status=live}}&lt;/ref&gt; ''kprobes'' can be inserted into code at (almost) any address, while kretprobes work at function return. ''uprobes'' have similar purposes but they also have some differences in usage and implementation.&lt;ref&gt;{{Cite web|title=Uprobe-tracer: Uprobe-based Event Tracing — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/latest/trace/uprobetracer.html|access-date=2020-10-06|website=www.kernel.org|archive-date=4 December 2020|archive-url=https://web.archive.org/web/20201204204113/https://www.kernel.org/doc/html/latest/trace/uprobetracer.html|url-status=live}}&lt;/ref&gt;

With [[KGDB]] Linux can be debugged in much the same way as userspace programs. KGDB requires an additional machine that runs [[GNU Debugger#Remote debugging|GDB]] and that is connected to the target to be debugged using a [[serial cable]] or [[Ethernet]].&lt;ref&gt;{{Cite web|title=Using kgdb, kdb and the kernel debugger internals|url=https://mirrors.edge.kernel.org/pub/linux/kernel/people/jwessel/kdb/index.html|access-date=2020-11-03|website=mirrors.edge.kernel.org|archive-date=26 January 2021|archive-url=https://web.archive.org/web/20210126003430/https://mirrors.edge.kernel.org/pub/linux/kernel/people/jwessel/kdb/index.html|url-status=live}}&lt;/ref&gt;

=== Development model ===
The Linux kernel project integrates new code on a rolling basis. Software checked into the project must work and [[compiling|compile]] without error. For each kernel subsystem there is a maintainer who is responsible for reviewing patches against the kernel code standards and keeps a queue of patches that can be submitted to Linus Torvalds within a merge window of several weeks. Patches are merged by Torvalds into the source code of the prior stable Linux kernel release, creating the ''-rc'' release candidate for the next stable kernel. Once the merge window is closed only fixes to the new code in the development release are accepted. The ''-rc'' development release of the kernel goes through [[regression tests]] and once it is judged to be stable by Torvalds and the kernel subsystem maintainers a new Linux kernel is released and the development process starts all over again.&lt;ref&gt;{{cite book |title=Pro Linux Embedded Systems |author= Gene Sally|year=2010 |publisher=Apress |isbn=9781430272267 |page=252 }}&lt;/ref&gt;

Developers who feel treated unfairly can report this to the [[Linux Foundation]]'s Technical Advisory Board.&lt;ref&gt;{{cite web |title=Code of Conflict |url=https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/process/code-of-conflict.rst |access-date=4 February 2018 }}{{Dead link|date=February 2020 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; In July 2013, the maintainer of the USB 3.0 driver [[Sarah Sharp]] asked Torvalds to address the abusive commentary in the kernel development community. In 2014, Sharp backed out of Linux kernel development, saying that "The focus on technical excellence, in combination with overloaded maintainers, and people with different cultural and social norms, means that Linux kernel maintainers are often blunt, rude, or brutal to get their job done".&lt;ref&gt;{{cite web |first=Simon |last=Sharwood |title=Linux kernel dev who asked Linus Torvalds to stop verbal abuse quits over verbal abuse |url=https://www.theregister.co.uk/2015/10/06/linix_kernel_dev_who_asked_linus_torvalds_to_stop_swearing_quits_over_swearing/ |website=The Register |date=6 October 2015 |access-date=4 February 2018 |archive-date=29 March 2020 |archive-url=https://web.archive.org/web/20200329075939/https://www.theregister.co.uk/2015/10/06/linix_kernel_dev_who_asked_linus_torvalds_to_stop_swearing_quits_over_swearing/ |url-status=live }}&lt;/ref&gt; At the linux.conf.au (LCA) conference in 2018, developers expressed the view that the culture of the community has gotten much better in the past few years. Daniel Vetter, the maintainer of the Intel drm/i915 graphics kernel driver, commented that the "rather violent language and discussion" in the kernel community has decreased or disappeared.&lt;ref&gt;{{cite web |first=Jake |last=Edge |title=Too many lords, not enough stewards |url=https://lwn.net/Articles/745817/ |website=LWN.net |date=31 January 2018 |access-date=4 February 2018 |archive-date=9 November 2020 |archive-url=https://web.archive.org/web/20201109004145/https://lwn.net/Articles/745817/ |url-status=live }}&lt;/ref&gt;

Laurent Pinchart asked developers for feedback on their experience with the kernel community at the 2017 Embedded Linux Conference Europe. The issues brought up were discussed a few days later at the Maintainers Summit. Concerns over the lack of consistency in how maintainers responded to patches submitted by developers were echoed by [[Shuah Khan]], the maintainer of the kernel self-test framework. Torvalds contended that there would never be consistency in the handling of patches because different kernel subsystems have, over time, adopted different development processes. Therefore, it was agreed upon that each kernel subsystem maintainer would document the rules for patch acceptance.&lt;ref&gt;{{cite web |first=Jonathan |last=Corbet |title=Bash the kernel maintainers |url=https://lwn.net/Articles/738222/ |website=LWN.net |date=6 November 2017 |access-date=4 February 2018 |archive-date=26 January 2021 |archive-url=https://web.archive.org/web/20210126003428/https://lwn.net/Articles/738222/ |url-status=live }}&lt;/ref&gt;

=== Linux forks ===
[[File:Ipod linux booting kernel.jpg|thumb|200px|An [[iPod]] booting [[iPodLinux]] ]]{{See also|Mainline Linux}}
There are certain communities that develop kernels based on the official Linux. Some interesting bits of code from these ''forks'' (i.e., a slang term meaning "derived projects") that include [[Linux-libre]], [[Compute Node Linux]], [[INK (operating system)|INK]], [[L4Linux]], [[RTLinux]], and [[user-mode Linux|User-Mode Linux]] (UML) have been merged into the mainline.&lt;ref&gt;{{cite web| url = https://linuxplumbersconf.org/ocw/proposals/49| title = The state of preempt-rt| access-date = 14 June 2016| website = linuxplumbersconf.org| archive-url = https://web.archive.org/web/20161015044835/https://linuxplumbersconf.org/ocw/proposals/49| archive-date = 15 October 2016| url-status = dead| df = dmy-all}}&lt;/ref&gt; Some operating systems developed for mobile phones initially used heavily modified versions of Linux, including Google [[Android (operating system)|Android]], [[Firefox OS]], HP [[webOS]], Nokia [[Maemo]] and Jolla [[Sailfish OS]]. In 2010, the Linux community criticised Google for effectively starting its own kernel tree:&lt;ref&gt;{{cite web |url=https://www.zdnet.com/article/linux-developer-explains-android-kernel-code-removal/ |title=Linux developer explains Android kernel code removal |last=Meyer |first=David |date=3 February 2010 |work=[[ZDNet]] |publisher=[[CBS Interactive]] |access-date=3 February 2010 |archive-date=15 October 2016 |archive-url=https://web.archive.org/web/20161015045139/http://www.zdnet.com/article/linux-developer-explains-android-kernel-code-removal/ |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite book|date=2008 |title=maemo Technology Overview |chapter-url=http://maemo.org/maemo_training_material/maemo4.x/html/maemo_Technology_Overview/Chapter_03_maemo_Platform_Overview.html |publisher=[[Nokia]] |chapter=Chapter 03: maemo Platform Overview |access-date=9 April 2010 |archive-url=https://web.archive.org/web/20080616191310/http://maemo.org/maemo_training_material/maemo4.x/html/maemo_Technology_Overview/Chapter_03_maemo_Platform_Overview.html |archive-date=16 June 2008 |url-status=dead }}&lt;/ref&gt;

{{Quote|text=This means that any drivers written for Android hardware platforms, can not get merged into the main kernel tree because they have dependencies on code that only lives in Google's kernel tree, causing it to fail to build in the kernel.org tree. Because of this, Google has now prevented a large chunk of hardware drivers and platform code from ever getting merged into the main kernel tree. Effectively creating a kernel branch that a number of different vendors are now relying on.&lt;ref&gt;{{cite web |url=http://www.kroah.com/log/linux/android-kernel-problems.html |title=Android and the Linux kernel community |last=Kroah-Hartman |first=Greg |date=2 February 2010 |access-date=3 February 2010 |archive-date=27 April 2019 |archive-url=https://web.archive.org/web/20190427144039/http://www.kroah.com/log/linux/android-kernel-problems.html |url-status=live }}&lt;/ref&gt; |sign=[[Greg Kroah-Hartman]], 2010}}

Today Android uses a slightly customized Linux&lt;ref name="Roger Ye 2017 14"&gt;{{cite book |title=Android System Programming |author=Roger Ye|year=2017 |publisher=Packt Publishing |isbn=9781787120389 |page=14}}&lt;/ref&gt; where changes are implemented in device drivers so that little or no change to the core kernel code is required. Android developers also submit patches to the official Linux that finally can boot the Android operating system. For example, a [[Nexus 7]] can boot and run the mainline Linux.&lt;ref name="Roger Ye 2017 14"/&gt;

At a 2001 presentation at the [[Computer History Museum]], [[Linus Torvalds]] had this to say in response to a question about distributions of Linux using precisely the same kernel sources or not:

{{Quote |text=''They're not...well they are, and they're not. There is no single kernel. Every single distribution has their own changes. That's been going on since pretty much day one. I don't know if you may remember Yggdrasil was known for having quite extreme changes to the kernel and even today all of the major vendors have their own tweaks because they have some portion of the market they're interested in and quite frankly that's how it should be. Because if everybody expects one person, me, to be able to track everything that's not the point of GPL. That's not the point of having an open system. So actually the fact that a distribution decides that something is so important to them that they will add patches for even when it's not in the standard kernel, that's a really good sign for me. So that's for example how something like ReiserFS got added. And the reason why ReiserFS is the first journaling filesystem that was integrated in the standard kernel was not because I love Hans Reiser.  It was because SUSE actually started shipping with ReiserFS as their standard kernel, which told me "ok." This is actually in production use. Normal People are doing this. They must know something I don't know. So in a very real sense what a lot of distribution houses do, they are part of this "let's make our own branch" and "let's make our changes to this." And because of the GPL, I can take the best portions of them.''&lt;ref&gt;{{cite web |url=https://www.youtube.com/watch?v=WVTWCPoUt8w&amp;t=3435 |publisher=[[YouTube]] |date=19 September 2001 |last=Torvalds |first=Linus |access-date=6 December 2020 |title=The Origins of Linux—Linus Torvalds}}&lt;/ref&gt; |sign=[[Linus Torvalds]], 2001}}

=== Development community conflicts ===
There have been several notable conflicts among Linux kernel developers. Examples of such conflicts are:
* In July 2007, [[Con Kolivas]] announced that he would cease developing for the Linux kernel.&lt;ref name="ConKolivas"&gt;{{cite web |title=Why I quit: kernel developer Con Kolivas |url=http://apcmag.com/node/6735/ |access-date=15 August 2011 |date=24 July 2007 |work=APC Magazine |publisher=ACP Magazines |archive-url=https://web.archive.org/web/20110707151924/http://apcmag.com/why_i_quit_kernel_developer_con_kolivas.htm |archive-date = 2011-07-07}}&lt;/ref&gt;&lt;ref&gt;{{cite web |first=Jonathan |last=Corbet |title=Re: -mm merge plans for 2.6.23 |publisher=LWN.net |date=25 July 2007 |url=https://lwn.net/Articles/242768/ |access-date=10 February 2018 |archive-date=11 February 2018 |archive-url=https://web.archive.org/web/20180211131406/https://lwn.net/Articles/242768/ |url-status=live }}&lt;/ref&gt;
* In July 2009, [[Alan Cox]] quit his role as the [[Tty (Unix)|TTY]] layer maintainer after disagreement with [[Linus Torvalds]].&lt;ref&gt;{{cite web |first=Alan |last=Cox |title=Re: [PATCH] kdesu broken |url=https://lkml.org/lkml/2009/7/28/375 |date=28 July 2009 |access-date=10 February 2018 |archive-date=11 February 2018 |archive-url=https://web.archive.org/web/20180211190040/https://lkml.org/lkml/2009/7/28/375 |url-status=live }}&lt;/ref&gt;
* In December 2010, there was a discussion between Linux SCSI maintainer James Bottomley and SCST maintainer Vladislav Bolkhovitin about which SCSI target stack should be included in the Linux kernel.&lt;ref&gt;{{cite web |first=Goldwyn |last=Rodrigues |title=A tale of two SCSI targets |url=https://lwn.net/Articles/424004/ |date=22 January 2011 |access-date=14 February 2018 |archive-date=15 February 2018 |archive-url=https://web.archive.org/web/20180215204201/https://lwn.net/Articles/424004/ |url-status=live }}&lt;/ref&gt; This made some Linux users upset.&lt;ref&gt;{{cite web |first=Andreas |last=Steinmetz |title=LIO - the broken iSCSI target implementation |url=https://lkml.org/lkml/2013/1/16/803 |date=17 January 2013 |access-date=14 February 2018 |archive-date=15 February 2018 |archive-url=https://web.archive.org/web/20180215204140/https://lkml.org/lkml/2013/1/16/803 |url-status=live }}&lt;/ref&gt;
* In June 2012, Torvalds made it very clear that he did not agree with NVIDIA releasing its drivers as closed.&lt;ref&gt;{{cite web |first=Ryan |last=Paul |title=Linus Torvalds says "f–k you" to NVIDIA |url=https://arstechnica.com/information-technology/2012/06/linus-torvalds-says-f-k-you-to-nvidia/ |date=19 June 2012 |access-date=14 February 2018 |archive-date=15 February 2018 |archive-url=https://web.archive.org/web/20180215023959/https://arstechnica.com/information-technology/2012/06/linus-torvalds-says-f-k-you-to-nvidia/ |url-status=live }}&lt;/ref&gt;
* In April 2014, Torvalds banned [[Kay Sievers]] from submitting patches to the Linux kernel for failing to deal with [[Software bug|bugs]] that caused [[systemd]] to negatively interact with the kernel.&lt;ref&gt;{{cite web |author=John Gold |title=Linus Torvalds suspends key Linux developer: Kernel panic as Systemd dev pokes the bear |url=https://www.networkworld.com/article/2175826/linus-torvalds-suspends-key-linux-developer.html |date=3 April 2014 |access-date=24 March 2019 |archive-date=24 March 2019 |archive-url=https://web.archive.org/web/20190324195212/https://www.networkworld.com/article/2175826/linus-torvalds-suspends-key-linux-developer.html |url-status=live }}&lt;/ref&gt;
* In October 2014, [[Lennart Poettering]] accused Torvalds of tolerating the rough discussion style on Linux kernel related mailing lists and of being a bad role model.&lt;ref&gt;{{cite web |first=Lennart |last=Poettering |title=On the sickness of the Linux Kernel Community |url=https://plus.google.com/+LennartPoetteringTheOneAndOnly/posts/J2TZrTvu7vd |website=Google+ |date=6 October 2014 |access-date=10 February 2018 |archive-url=https://web.archive.org/web/20180527195108/https://plus.google.com/+LennartPoetteringTheOneAndOnly/posts/J2TZrTvu7vd |archive-date=27 May 2018 |url-status=dead }}&lt;/ref&gt;
* In March 2015, Christoph Hellwig filed a lawsuit against VMware for infringement of the copyright on the Linux kernel.&lt;ref&gt;{{cite web |first=Jon |last=Brodkin |title=VMware alleged to have violated Linux's open source license for years |url=https://arstechnica.com/tech-policy/2015/03/vmware-alleged-to-have-violated-linuxs-open-source-license-for-years/ |website=Ars Technica |date=6 March 2015 |access-date=14 February 2018 |archive-date=15 February 2018 |archive-url=https://web.archive.org/web/20180215023512/https://arstechnica.com/tech-policy/2015/03/vmware-alleged-to-have-violated-linuxs-open-source-license-for-years/ |url-status=live }}&lt;/ref&gt; Linus Torvalds made it clear that he did not agree with this and similar initiatives by calling lawyers a festering disease.&lt;ref&gt;{{cite web |first=Kieren |last=McCarthy |title=Having offended everyone else in the world, Linus Torvalds calls own lawyers a 'nasty festering disease' |url=https://www.theregister.co.uk/2016/08/26/linus_torvalds_calls_own_lawyers_nasty_festering_disease/ |website=The Register |date=26 August 2016 |access-date=14 February 2018 |archive-date=15 February 2018 |archive-url=https://web.archive.org/web/20180215023540/https://www.theregister.co.uk/2016/08/26/linus_torvalds_calls_own_lawyers_nasty_festering_disease/ |url-status=live }}&lt;/ref&gt;

Prominent Linux kernel developers have been aware of the importance of avoiding conflicts between developers.&lt;ref&gt;{{cite web |first=Jonathan |last=Corbet |title=KS2007: Developer relations and development process |url=https://lwn.net/Articles/249104/ |website=LWN.net |date=10 September 2007 |access-date=11 February 2018 |archive-date=12 February 2018 |archive-url=https://web.archive.org/web/20180212142109/https://lwn.net/Articles/249104/ |url-status=live }}&lt;/ref&gt; For a long time there was no code of conduct for kernel developers due to opposition by [[Linus Torvalds]].&lt;ref&gt;{{cite web |first=Jon |last=Brodkin |title=Linus Torvalds defends his right to shame Linux kernel developers |url=https://arstechnica.com/information-technology/2013/07/linus-torvalds-defends-his-right-to-shame-linux-kernel-developers/ |website=ARS Technica |date=16 July 2013 |access-date=11 February 2018 |archive-date=17 February 2018 |archive-url=https://web.archive.org/web/20180217143017/https://arstechnica.com/information-technology/2013/07/linus-torvalds-defends-his-right-to-shame-linux-kernel-developers/ |url-status=live }}&lt;/ref&gt; However, a Linux Kernel ''Code of Conflict'' was introduced on 8 March 2015.&lt;ref&gt;{{cite web |first=Jonathan |last=Corbet |title=The kernel's code of conflict |url=https://lwn.net/Articles/635999/ |website=LWN.net |date=9 March 2015 |access-date=11 February 2018 |archive-date=12 February 2018 |archive-url=https://web.archive.org/web/20180212142143/https://lwn.net/Articles/635999/ |url-status=live }}&lt;/ref&gt; It was replaced on 16 September 2018 by a new ''Code of Conduct'' based on the [[Contributor Covenant]]. This coincided with a public apology by Torvalds and a brief break from kernel development.&lt;ref&gt;{{cite web|url=https://lwn.net/SubscriberLink/765108/f1a80a6d6a6ff0f4/|title=Code, conflict, and conduct|first=Jonathan|last=Corbet|publisher=[[LWN.net]]|date=2018-09-18|access-date=19 September 2018|archive-date=19 September 2018|archive-url=https://web.archive.org/web/20180919175320/https://lwn.net/SubscriberLink/765108/f1a80a6d6a6ff0f4/|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.newyorker.com/science/elements/after-years-of-abusive-e-mails-the-creator-of-linux-steps-aside|title=After Years of Abusive E-mails, the Creator of Linux Steps Aside|first=Noam|last=Cohen|publisher=[[The New Yorker]]|date=2018-09-19|access-date=24 September 2018|archive-date=20 February 2020|archive-url=https://web.archive.org/web/20200220085413/https://www.newyorker.com/science/elements/after-years-of-abusive-e-mails-the-creator-of-linux-steps-aside|url-status=live}}&lt;/ref&gt; On 30 November 2018, complying with the ''Code of Conduct'', Jarkko Sakkinen of Intel sent out patches replacing instances of "fuck" appearing in source code comments with suitable versions focused on the word 'hug'.&lt;ref&gt;{{cite web |last1=Larabel |first1=Michael |title=Dropping Profanity In Kernel Code Comments: Linux Gets "Hugs" |url=https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kernel-Hugs |website=Phoronix |access-date=15 June 2019 |archive-date=21 April 2019 |archive-url=https://web.archive.org/web/20190421094724/https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kernel-Hugs |url-status=live }}&lt;/ref&gt;

=== Codebase ===
{{As of|2021}}, the 5.11 release of the Linux kernel had around 30.34 million lines of code, roughly 14% of the code is part of the "core" (arch, kernel and mm directories) while 60% is drivers.
&lt;!-- Line counting is done with "find . -type f -not -regex '\./\.git/.*' | xargs cat | wc -l", computation of percentages with "du -s arch/kernel/mm and so on" --&gt;

{{Quote|text=Linux is evolution, not intelligent design!|sign=[[Linus Torvalds]], 2005&lt;ref&gt;{{cite web |url=http://www.sprg.uniroma2.it/kernelhacking2008/lectures/lkhc08-01b.pdf |title=Linux Evolution |date=26 March 2008 |access-date=6 November 2013 |archive-date=14 December 2013 |archive-url=https://web.archive.org/web/20131214074153/http://www.sprg.uniroma2.it/kernelhacking2008/lectures/lkhc08-01b.pdf |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.cs.huji.ac.il/~feit/papers/LinuxDev12JSS.pdf |title=Perpetual Development: A Model of the Linux Kernel Life Cycle |date=25 October 2011 |access-date=6 November 2013 |archive-date=17 October 2013 |archive-url=https://web.archive.org/web/20131017210855/http://www.cs.huji.ac.il/~feit/papers/LinuxDev12JSS.pdf |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/0802.1/2159.html |title=Re: Announce: Linux-next (Or Andrew's dream :-)) |date=12 February 2008 |access-date=30 January 2017 |mailing-list=Linux Kernel Mailing List |last=Kroah-Hartman |first=Greg |archive-date=2 February 2017 |archive-url=https://web.archive.org/web/20170202070946/http://lkml.iu.edu/hypermail/linux/kernel/0802.1/2159.html |url-status=live }}&lt;/ref&gt;|source=}}

=== Estimated cost to redevelop ===
[[File:Redevelopment costs of Linux kernel.png|thumb|300px|Redevelopment costs of Linux kernel]]
The cost to redevelop the Linux kernel version 2.6.0 in a traditional proprietary development setting has been estimated to be US$612 million (€467M, £394M) in 2004 prices using the [[COCOMO]] person-month estimation model.&lt;ref&gt;{{cite web
|url = http://www.dwheeler.com/essays/linux-kernel-cost.html
|title = Linux Kernel 2.6: It's Worth More!
|last = Wheeler
|first = David A.
|access-date = 18 January 2007
|archive-date = 21 August 2011
|archive-url = https://www.webcitation.org/616XYjg7d?url=http://www.dwheeler.com/essays/linux-kernel-cost.html
|url-status = live
}}&lt;/ref&gt; In 2006, a study funded by the European Union put the redevelopment cost of kernel version 2.6.8 higher, at €882M ($1.14bn, £744M).&lt;ref&gt;{{cite web|url=http://ec.europa.eu/enterprise/sectors/ict/files/2006-11-20-flossimpact_en.pdf|title=Economic impact of FLOSS on innovation and competitiveness of the EU ICT sector|type=Table 3 on page 50|access-date=8 January 2011|archive-date=15 February 2010|archive-url=https://web.archive.org/web/20100215190539/http://ec.europa.eu/enterprise/sectors/ict/files/2006-11-20-flossimpact_en.pdf|url-status=live}}&lt;/ref&gt;

This topic was revisited in October 2008 by Amanda McPherson, Brian Proffitt, and Ron Hale-Evans. Using David A. Wheeler's methodology, they estimated redevelopment of the 2.6.25 kernel now costs $1.3bn (part of a total $10.8bn to redevelop Fedora 9).&lt;ref&gt;{{cite web|url=http://www.linuxfoundation.org/publications/estimatinglinux.pdf|title=Estimating Total Development Cost Of a Linux Distribution|type=Table on page 6|url-status=dead|archive-url=https://web.archive.org/web/20100711025812/http://www.linuxfoundation.org/publications/estimatinglinux.pdf|archive-date=11 July 2010|df=dmy-all}}&lt;/ref&gt; Again, Garcia-Garcia and Alonso de Magdaleno from University of Oviedo (Spain) estimate that the value annually added to kernel was about €100M between 2005 and 2007 and €225M in 2008, it would cost also more than €1bn (about $1.4bn as of February 2010) to develop in the European Union.&lt;ref&gt;{{cite web |url=http://linux.slashdot.org/story/10/02/24/155214/The-Billion-Dollar-Kernel |title=The Billion Dollar Kernel |publisher=Linux.slashdot.org |date=24 February 2010 |access-date=12 November 2010 |archive-date=15 May 2011 |archive-url=https://web.archive.org/web/20110515003125/http://linux.slashdot.org/story/10/02/24/155214/The-Billion-Dollar-Kernel |url-status=live }}&lt;/ref&gt;

{{As of|2011|3|7}}, using then-current [[Source lines of code|LOC]] (lines of code) of a 2.6.x Linux kernel and wage numbers with David A. Wheeler's calculations it would cost approximately $3bn (about €2.2bn) to redevelop the Linux kernel as it keeps getting bigger. An updated calculation {{as of|2018|9|26|lc=y}}, using then-current 20,088,609 LOC (lines of code) for the 4.14.14 Linux kernel and the current US National average programmer salary of $75,506 show it would cost approximately $14,725,449,000 dollars (£11,191,341,000) to rewrite the existing code.&lt;ref&gt;{{cite web|last=Wheeler|first=David|title=The Linux Kernel: It's Worth More!|url=https://dwheeler.com/essays/linux-kernel-cost.html|access-date=17 September 2012|archive-url=https://web.archive.org/web/20210224011056/https://dwheeler.com/essays/linux-kernel-cost.html |archive-date=2021-02-23 |url-status=live}}&lt;/ref&gt;

=== Maintenance and long-term support===
[[File:Linux-x86-under-qemu.png|thumb|right|300px|Boot messages of a Linux kernel 2.6.25.17]]
The latest kernel version and older kernel versions are maintained separately. Most latest kernel releases were supervised by Linus Torvalds.&lt;ref name="MAINTAINERS"&gt;{{cite web |url=https://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=blob;f=MAINTAINERS |archive-url=https://archive.today/20130112231112/http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=blob;f=MAINTAINERS |url-status=dead |archive-date=2013-01-12 |title=Linux MAINTAINERS file }}&lt;/ref&gt; Current versions are released by [[Greg Kroah-Hartman]].&lt;ref&gt;{{cite web |first=Linus |last=Torvalds |title=Linux 4.19-rc4 released, an apology, and a maintainership note |website=LKML |date=16 September 2018 |access-date=23 September 2018 |url=https://lkml.org/lkml/2018/9/16/167 |archive-date=23 September 2018 |archive-url=https://web.archive.org/web/20180923085327/https://lkml.org/lkml/2018/9/16/167 |url-status=live }}&lt;/ref&gt;

The Linux kernel developer community maintains a stable kernel by applying fixes for [[software bug]]s that have been discovered during the development of the subsequent stable kernel. Therefore, www.kernel.org will always list two stable kernels. The next stable Linux kernel is now released only 8 to 12 weeks later. Therefore, the Linux kernel maintainers have designated some stable kernel releases as ''longterm'', these [[long-term support]] Linux kernels are updated with bug fixes for two or more years.&lt;ref&gt;{{cite book |title=Linux: Embedded Development |author= Alexandru Vaduva, Alex Gonzalez &amp; Chris Simmonds|year=2016 |publisher=Packt Publishing|isbn=9781787124455 |page=663 }}&lt;/ref&gt; In November 2019 there were five longterm Linux kernels: 4.19.84, 4.14.154, 4.9.201, 4.4.201 and 3.16.76.&lt;ref&gt;{{cite web |url=https://www.kernel.org/ |title=The Linux Kernel Archives |access-date=13 November 2019 |archive-date=21 February 2011 |archive-url=https://web.archive.org/web/20110221140221/http://www.kernel.org/ |url-status=live }}&lt;/ref&gt; The full list of releases is at [[Linux kernel version history]].

=== Relation with Linux distributions ===
Most Linux users run a kernel supplied by their [[Linux distribution]]. Some distributions ship the "vanilla" or "stable" kernels. However, several Linux distribution vendors (such as [[Red Hat]] and [[Debian]]) maintain another set of Linux kernel branches which are integrated into their products. These are usually updated at a slower pace compared to the "vanilla" branch, and they usually include all fixes from the relevant "stable" branch, but at the same time they can also add support for drivers or features which had not been released in the "vanilla" version the distribution vendor started basing their branch from.

== Legal aspects ==

=== GPLv2 licensing terms ===
Initially, Torvalds released Linux under a license which forbade any commercial use.&lt;ref name="hiroo"&gt;{{cite web|url=http://hotwired.goo.ne.jp/matrix/9709/5_linus.html |title=The Pragmatist of Free Software |last=Yamagata |first=Hiroo |date=3 August 1997 |publisher=[[HotWired]] |access-date=21 February 2007 |archive-url=https://web.archive.org/web/20070210224351/http://hotwired.goo.ne.jp/matrix/9709/5_linus.html |archive-date=10 February 2007 |url-status=dead }}&lt;/ref&gt; This was changed in version 0.12 by a switch to the [[GNU General Public License]] version 2 (GPLv2).&lt;ref name="Relnotes-0.12" /&gt; This license allows distribution and sale of possibly modified and unmodified versions of Linux but requires that all those copies be released under the same license and be accompanied by the complete corresponding source code.&lt;ref&gt;{{Cite web|url=https://www.gnu.org/licenses/old-licenses/gpl-2.0.html|title=GPL-v2|website=gnu.org|access-date=28 January 2020|archive-date=25 December 2019|archive-url=https://web.archive.org/web/20191225033729/https://www.gnu.org/licenses/old-licenses/gpl-2.0.html|url-status=live}}&lt;/ref&gt; Torvalds has described licensing Linux under the GPLv2 as the "best thing I ever did".&lt;ref name="hiroo" /&gt;

The Linux kernel is licensed explicitly only under version 2 of the GPL,&lt;ref name="COPYING_File" /&gt; without offering the licensee the option to choose "any later version", which is a common GPL extension. The official git branch of Torvalds contains documentation that explains the kernel development process to people who want to work with the community and contribute code; it clearly states that "[Any] contributions which are not covered by a [GPLv2] compatible license will not be accepted into the kernel.".&lt;ref name=":9"/&gt;

There was considerable debate about how easily the license could be changed to use later GPL versions (including version 3), and whether this change is even desirable.&lt;ref&gt;{{cite web |url=https://lwn.net/Articles/169797/ |title=GPLv3 and the kernel |last=Corbet |first=Jonathan |date=31 January 2006 |publisher=[[LWN.net]] |access-date=21 February 2007 |archive-date=10 August 2020 |archive-url=https://web.archive.org/web/20200810165701/https://lwn.net/Articles/169797/ |url-status=live }}&lt;/ref&gt; Torvalds himself specifically indicated upon the release of version 2.4.0 that his own code is released only under version 2.&lt;ref&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/0009.1/0096.html |title=Linux-2.4.0-test8 |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=8 September 2000 |mailing-list=[[LKML]] |access-date=21 February 2007 |archive-date=15 May 2020 |archive-url=https://web.archive.org/web/20200515235654/http://lkml.iu.edu/hypermail/linux/kernel/0009.1/0096.html |url-status=live }}&lt;/ref&gt; However, the terms of the GPL state that if no version is specified, then any version may be used,&lt;ref&gt;{{Cite web|url=https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html#section9|title=gnu.org|website=www.gnu.org|language=en|access-date=2017-10-18|archive-date=2 February 2021|archive-url=https://web.archive.org/web/20210202151435/https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html#section9|url-status=live}}&lt;/ref&gt; and [[Alan Cox]] pointed out that very few other Linux contributors had specified a particular version of the GPL.&lt;ref&gt;{{cite mailing list |url=https://lwn.net/Articles/169831/ |title=Re: GPL V3 and Linux |last=Cox |first=Alan |author-link=Alan Cox |date=20 January 2006 |mailing-list=[[LKML]] |access-date=21 February 2007 |archive-date=26 January 2021 |archive-url=https://web.archive.org/web/20210126131909/https://lwn.net/Articles/169831/ |url-status=live }}&lt;/ref&gt;

In September 2006, a survey of 29 key kernel programmers indicated that 28 preferred GPLv2 to the then-current GPLv3 draft. Torvalds commented, "I think a number of outsiders... believed that I personally was just the odd man out because I've been so publicly not a huge fan of the GPLv3."&lt;ref&gt;{{cite web |url=http://news.com/Top+Linux+programmers+pan+GPL+3/2100-7344_3-6119372.html |title=Top Linux programmers pan GPL 3 |date=25 September 2006 |last=Shankland |first=Stephen |work=[[News.com]] |publisher=[[CNET]] |access-date=21 February 2007}}&lt;/ref&gt; This group of high-profile kernel developers, including Torvalds, [[Greg Kroah-Hartman]] and [[Andrew Morton (computer programmer)|Andrew Morton]], commented on mass media about their objections to the GPLv3.&lt;ref name="kerneldevelopers2006"/&gt; They referred to clauses regarding [[Digital rights management|DRM]]/[[tivoization]], patents, "additional restrictions" and warned a [[Balkanization|Balkanisation]] of the "Open Source Universe" by the GPLv3.&lt;ref name="kerneldevelopers2006"&gt;{{cite web |url=https://lwn.net/Articles/200422/ |title=Kernel developers' position on GPLv3: The Dangers and Problems with GPLv3 |authors=James E.J. Bottomley, Mauro Carvalho Chehab, Thomas Gleixner, Christoph Hellwig, Dave Jones, Greg Kroah-Hartman, Tony Luck, Andrew Morton, Trond Myklebust, David Woodhouse |date=15 September 2006 |publisher=[[LWN.net]] |access-date=11 March 2015 |archive-date=18 January 2021 |archive-url=https://web.archive.org/web/20210118015213/https://lwn.net/Articles/200422/ |url-status=live }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.linuxjournal.com/node/1000100 |title=A fight against evil or a fight for attention? |date=27 September 2006 |first=Nicholas |last=Petreley |publisher=linuxjournal.com |access-date=11 March 2015 |archive-date=2 March 2018 |archive-url=https://web.archive.org/web/20180302144635/http://www.linuxjournal.com/node/1000100 |url-status=live }}&lt;/ref&gt; Linus Torvalds, who decided not to adopt the GPLv3 for the Linux kernel, reiterated his criticism even years later.&lt;ref&gt;{{cite web |url=https://www.youtube.com/watch?v=PaKIZ7gJlRU |title=Linus Torvalds says GPL v3 violates everything that GPLv2 stood for |date=2014 |publisher=[[Debconf]] 2014 |access-date=21 March 2018 |archive-date=8 May 2018 |archive-url=https://web.archive.org/web/20180508034417/https://www.youtube.com/watch?v=PaKIZ7gJlRU |url-status=live }}&lt;/ref&gt;

=== Loadable kernel modules ===
It is debated whether some [[loadable kernel module]]s (LKMs) are to be considered [[derivative work]]s under copyright law, and thereby whether or not they fall under the terms of the GPL.

In accordance with the license rules, LKMs using only a public subset of the kernel interfaces&lt;ref name=":6" /&gt;&lt;ref name=":7" /&gt; are non-derived works, thus Linux gives system administrators the mechanisms to load out-of-tree binary objects into the kernel address space.&lt;ref name="Linux_Licensing" /&gt;

There are some out-of-tree loadable modules that make legitimate use of the ''dma_buf'' kernel feature.&lt;ref&gt;{{cite web |url=http://elinux.org/images/a/a8/DMA_Buffer_Sharing-_An_Introduction.pdf |title=DMA Buffer Sharing Framework: An Introduction |last1=Clark |first1=Rob |last2=Semwal |first2=Sumit |date=1 November 2012 |publisher=Embedded Linux Conference |access-date=2 August 2014 |archive-date=8 August 2014 |archive-url=https://web.archive.org/web/20140808051804/http://elinux.org/images/a/a8/DMA_Buffer_Sharing-_An_Introduction.pdf |url-status=live }}&lt;/ref&gt; GPL compliant code can certainly use it. However, a different possible use case would be [[Nvidia Optimus]] that pairs a fast GPU with an Intel integrated GPU, where the Nvidia GPU writes into the [[Intel]] framebuffer when it is active. But, Nvidia cannot use this infrastructure because it necessitates bypassing a rule that can only be used by LKMs that are also GPL.&lt;ref name=":8" /&gt; [[Alan Cox]] replied on [[Linux kernel mailing list|LKML]], rejecting a request from one of their engineers to remove this technical enforcement from the API.&lt;ref&gt;{{cite mailing list |url=http://lists.freedesktop.org/archives/dri-devel/2012-October/028846.html |title=[PATCH] dma-buf: Use EXPORT_SYMBOL |last=Cox |first=Alan |author-link=Alan Cox |date=10 October 2012 |mailing-list=[[Direct Rendering Infrastructure]] |access-date=3 September 2013 |archive-date=22 January 2013 |archive-url=https://web.archive.org/web/20130122222858/http://lists.freedesktop.org/archives/dri-devel/2012-October/028846.html |url-status=live }}&lt;/ref&gt; Torvalds clearly stated on the LKML that "[I] claim that binary-only kernel modules ARE derivative "by default"'".&lt;ref&gt;{{cite mailing list |url=https://lkml.org/lkml/2003/12/10/123 |title=RE: Linux GPL and binary module exception clause? |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=10 December 2003 |mailing-list=[[LKML]] |access-date=31 December 2010 |archive-date=15 June 2011 |archive-url=https://web.archive.org/web/20110615102501/http://lkml.org/lkml/2003/12/10/123 |url-status=live }}&lt;/ref&gt;

On the other hand, Torvalds has also said that "[one] gray area in particular is something like a driver that was originally written for another operating system (i.e., clearly not a derived work of Linux in origin). THAT is a gray area, and _that_ is the area where I personally believe that some modules may be considered to not be derived works simply because they weren't designed for Linux and don't depend on any special Linux behaviour".&lt;ref&gt;{{cite mailing list |url=http://lkml.iu.edu/hypermail/linux/kernel/0312.0/0670.html |title=Re: Linux GPL and binary module exception clause? |last=Torvalds |first=Linus |author-link=Linus Torvalds |date=3 December 2003 |mailing-list=[[LKML]] |access-date=12 November 2010 |archive-date=28 April 2020 |archive-url=https://web.archive.org/web/20200428052533/http://lkml.iu.edu/hypermail/linux/kernel/0312.0/0670.html |url-status=live }}&lt;/ref&gt; [[proprietary software|Proprietary]] graphics drivers, in particular, are heavily discussed.

=== Firmware binary blobs ===
The official kernel, that is the Linus git branch at the kernel.org repository, does not contain any kind of proprietary code;&lt;ref name="COPYING_File" /&gt;&lt;ref name="Linux_Licensing" /&gt; however Linux can search the filesystems to locate proprietary firmware, drivers, and other executable modules (collectively known as "[[binary blobs]]"), then it can load and link them into the kernel space.&lt;ref&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/driver-api/firmware/index.html|title=Linux Firmware API — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-13|archive-date=13 January 2020|archive-url=https://web.archive.org/web/20200113174720/https://www.kernel.org/doc/html/latest/driver-api/firmware/index.html|url-status=live}}&lt;/ref&gt; Whenever proprietary modules are loaded into Linux, the kernel marks itself as being "tainted",&lt;ref&gt;{{Cite web|url=https://www.kernel.org/doc/html/latest/admin-guide/tainted-kernels.html|title=Tainted kernels — The Linux Kernel documentation|website=www.kernel.org|access-date=2020-01-13|archive-date=7 March 2020|archive-url=https://web.archive.org/web/20200307065211/https://www.kernel.org/doc/html/latest/admin-guide/tainted-kernels.html|url-status=live}}&lt;/ref&gt; and therefore bug reports from tainted kernels will often be ignored by developers.

When it is needed (e.g., for accessing boot devices or for speed) firmware can be built-in to the kernel, this means building the firmware into [[vmlinux]]; however this is not always a viable option for technical or legal issues (e.g., it is not permitted to firmware that is non-GPL compatible).&lt;ref&gt;{{Cite web|title=Built-in firmware — The Linux Kernel documentation|url=https://www.kernel.org/doc/html/v4.16/driver-api/firmware/built-in-fw.html|access-date=2020-06-10|website=www.kernel.org|archive-date=10 June 2020|archive-url=https://web.archive.org/web/20200610041327/https://www.kernel.org/doc/html/v4.16/driver-api/firmware/built-in-fw.html|url-status=live}}&lt;/ref&gt;

=== Trademark ===
{{See also|Linux#Copyright, trademark, and naming|l1=Linux: Copyright, trademark, and naming}}
Linux is a registered [[trademark]] of [[Linus Torvalds]] in the United States, the European Union, and some other countries.&lt;ref&gt;{{Cite web|url=http://tmsearch.uspto.gov/bin/showfield?f=doc&amp;state=4808:r0ouik.2.17|title=Linux TM registration in the US|website=uspto.gov|access-date=6 September 2019|archive-date=24 February 2021|archive-url=https://web.archive.org/web/20210224164104/http://tmsearch.uspto.gov/bin/showfield?f=doc&amp;state=4808:r0ouik.2.17|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://euipo.europa.eu/eSearch/#details/trademarks/000851246|title=Linux TM registration in the EU|website=euipo.europa.eu|access-date=28 November 2020|archive-date=9 June 2016|archive-url=https://wayback.archive-it.org/all/20160609153529/https://euipo.europa.eu/eSearch/#details/trademarks/000851246|url-status=live}}&lt;/ref&gt; A legal battle over the trademark began in 1996, when William Della Croce, a lawyer who was never involved in the development of Linux, started requesting licensing fees for the use of the word ''Linux''. After it was proven that the word was in common use long before Della Croce's claimed first use, the trademark was awarded to Torvalds.&lt;ref&gt;{{cite web|url=http://www.linuxjournal.com/article/2425/|title=Linux Trademark Dispute|last=Hughes|first=Phil|date=1 August 1997|work=[[Linux Journal]]|publisher=Belltown Media, Inc.|access-date=8 December 2010|archive-date=30 April 2010|archive-url=https://web.archive.org/web/20100430060209/http://www.linuxjournal.com/article/2425|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.linuxjournal.com/article/2098|title=Action Taken on Linux Trademark|last=Hughes|first=Phil|date=1 March 1997|work=[[Linux Journal]]|publisher=Belltown Media, Inc.|access-date=8 December 2010|archive-date=3 March 2010|archive-url=https://web.archive.org/web/20100303180921/http://www.linuxjournal.com/article/2098|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.gisselberglawfirm.com/downloads/linux.pdf|title=The Trademark History of Linux, the Operating System|last=Gisselberg|first=Tonya|date=2010|publisher=Gisselberg Law Firm, Inc.|access-date=8 December 2010|archive-url=https://web.archive.org/web/20110711095344/http://www.gisselberglawfirm.com/downloads/linux.pdf |archive-date=11 July 2011 |url-status=dead }}&lt;/ref&gt;

== See also ==
{{Portal|Linux|Free and open-source software}}
*[[Operating system]]
*[[Kernel (operating system)|Kernel]] 
*[[Monolithic kernel|Monolithic Kernel]]
*[[Microkernel]]
*[[Linux kernel version history]]
*[[Comparison of operating systems]]
*[[Comparison of operating system kernels]]
*[[Linux]]
*[[Minix 3]]
*[[macOS]]
*[[Microsoft Windows]]

== References ==
{{reflist}}

== Further reading ==
{{Refbegin|40em}}
&lt;!-- The following are to be merged into the article. Please use &lt;ref&gt; tags as appropriate and then remove from this list. If the link doesn't contain anything referenced from the article, just remove it. --&gt;
* {{cite book|last1=Torvalds|first1=Linus|last2=Diamond|first2=David|year=2001|title=Just for Fun: The Story of an Accidental Revolutionary|publisher=[[HarperBusiness]]|isbn=978-0066620732|title-link=Just for Fun (book)}}
* {{cite book|last=Bezroukov|first=Nikolai|chapter-url=http://www.softpanorama.org/People/Torvalds/index.shtml|title=Portraits of Open Source Pioneers|chapter=Ch 4: A benevolent dictator|publisher=Softpanorama|type=e-book|access-date=3 October 2005|archive-date=13 October 2005|archive-url=https://web.archive.org/web/20051013082354/http://www.softpanorama.org/People/Torvalds/index.shtml|url-status=live}}
* {{cite web|url=https://lwn.net/Articles/53780/|title=LinkSys and binary modules|publisher=LWN.net Weekly Edition|date=16 October 2003|access-date=21 July 2016|archive-date=1 August 2016|archive-url=https://web.archive.org/web/20160801080742/http://lwn.net/Articles/53780/|url-status=live}}
* {{cite web|url=http://www.nd.edu/~ljordan/linux/tuxhistory.html|title=Everyone's Favorite Linux Mascot|access-date=16 June 2005|archive-date=16 August 2005|archive-url=https://web.archive.org/web/20050816235544/http://www.nd.edu/~ljordan/linux/tuxhistory.html|url-status=live}}
* {{cite web|url=http://kniggit.net/wwol26.html|archive-url=https://web.archive.org/web/20030716054145/http://www.kniggit.net/wwol26.html|url-status=dead|archive-date=2003-07-16|title=The Wonderful World of Linux 2.6|last=Pranevich|first=Joseph|date=December 2003}}
* {{cite web|url=http://wiki.kernelnewbies.org/LinuxChanges|title=LinuxChanges|access-date=31 October 2005|archive-date=31 October 2005|archive-url=https://web.archive.org/web/20051031211753/http://wiki.kernelnewbies.org/LinuxChanges|url-status=live}}
* {{cite web|url=http://engineeringproject.net/seminars/linux.htm|title=Seminar Paper on Linux Kernel 2.6|url-status=dead|archive-url=https://web.archive.org/web/20070202002917/http://www.engineeringproject.net/seminars/linux.htm|archive-date=2 February 2007|df=dmy-all}}
* {{cite web|url=https://lwn.net/Kernel/LDD3/|title=Linux Device Drivers|edition=3rd|access-date=21 July 2016|archive-date=27 July 2016|archive-url=https://web.archive.org/web/20160727085953/http://lwn.net/Kernel/LDD3/|url-status=live}}
* {{cite web|url=http://www.oreilly.com/catalog/understandlk/|title=Understanding the Linux Kernel|edition=3rd|type=Book|access-date=22 December 2005|archive-date=17 December 2005|archive-url=https://web.archive.org/web/20051217094234/http://www.oreilly.com/catalog/understandlk/|url-status=live}}
* {{cite web|url=http://www.apress.com/9781430261964|title=Linux Kernel Networking, by Rami Rosen, 2014|type=Book|access-date=14 June 2015|archive-date=12 May 2015|archive-url=https://web.archive.org/web/20150512052750/http://www.apress.com/9781430261964|url-status=live}}
* {{cite web |url=http://kerneltrap.org/node/1735 |title=Linux: The GPL And Binary Modules |url-status=dead |archive-url=https://web.archive.org/web/20050723031159/http://kerneltrap.org/node/1735 |archive-date=23 July 2005 }}
* {{cite web|url=http://www.ibm.com/developerworks/linux/library/l-linux-kernel/|title=Anatomy of the Linux kernel|access-date=9 June 2007|archive-date=27 June 2007|archive-url=https://web.archive.org/web/20070627093507/http://www.ibm.com/developerworks/linux/library/l-linux-kernel/|url-status=live}}
{{Refend}}

== External links ==
{{Commons}}
{{Wikibooks}}
* {{Official website|https://kernel.org}}
** [//kernel.org/doc/ Linux kernel documentation index]
** [//kernel.org/doc/man-pages/ Linux kernel man pages]
** [https://bugzilla.kernel.org/ Kernel bugzilla], and [https://bugzilla.kernel.org/show_bug.cgi?id=15790 regressions] for each recent kernel version
* [http://kernelnewbies.org/ Kernel Newbies], a source of various kernel-related information
* [https://lwn.net/Kernel/ Kernel coverage at LWN.net], an authoritative source of kernel-related information 
* [https://elixir.bootlin.com/linux/latest/source Bootlin's Elixir Cross Referencer], a Linux kernel source code cross-reference
* {{YouTube|L2SED6sewRw|Greg Kroah Hartman on the Linux kernel}}

{{Linux kernel}}
{{Linux}}
{{Mobile operating systems}}
{{Routing software}}
{{Linux people}}

{{DEFAULTSORT:Linux Kernel}}
[[Category:Linux kernel| ]]
[[Category:Finnish inventions]]
[[Category:Free software programmed in C]]
[[Category:Free system software]]
[[Category:Software using the GPL license]]
[[Category:Linus Torvalds]]
[[Category:Monolithic kernels]]
[[Category:Unix variants]]
[[Category:Computer science]]
[[Category:Operating systems]]
[[Category:Free and open-source software]]</text>
      <sha1>43fzfe0pvzo97lllhct2c2gks00ycrz</sha1>
    </revision>
  </page>
  <page>
    <title>Human City Interaction</title>
    <ns>0</ns>
    <id>64642723</id>
    <revision>
      <id>989083778</id>
      <parentid>984846009</parentid>
      <timestamp>2020-11-16T23:28:06Z</timestamp>
      <contributor>
        <username>WikiCleanerBot</username>
        <id>18872885</id>
      </contributor>
      <minor/>
      <comment>v2.04b - [[User:WikiCleanerBot#T20|Bot T20 CW#61]] - [[WP:WCW]] project (Reference before punctuation)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2776" xml:space="preserve">'''Human-City Interaction''' is the intersection between [[human-computer interaction]] and [[urban computing]]. The area involves data-driven methods such as analysis tools, prediction methods to present the solutions to urban design problems. Practitioners, Designers, software engineers in this area employ large sets of user-centric data to design urban environments with high levels of interactivity. &lt;ref&gt;Fischer, Patrick &amp; Hornecker, Eva. (2012). Urban HCI: Spatial aspects in the design of shared encounters for media Façades. Conference on Human Factors in Computing Systems - Proceedings. 307–316. 10.1145/2207676.2207719. &lt;/ref&gt; This discipline mainly focuses on the user perspective and devises various interaction design between the citizen (user) and various urban entities. Common examples in the discipline include the interactivity between human and buildings,&lt;ref&gt;Hamed S. Alavi, Elizabeth F. Churchill, Mikael Wiberg, Denis Lalanne, Peter Dalsgaard, Ava Fatah gen Schieck, and Yvonne Rogers. 2019. Introduction to Human-Building Interaction (HBI): Interfacing HCI with Architecture and Urban Design. ACM Trans. Comput.-Hum. Interact. 26, 2, Article 6 (April 2019), 10 pages. DOI:https://doi.org/10.1145/3309714&lt;/ref&gt; Interaction between Human and IoT devices,&lt;ref&gt;Turunen, Markku &amp; Sonntag, Daniel &amp; Engelbrecht, Klaus-Peter &amp; Olsson, Thomas &amp; Schnelle-Walka, Dirk &amp; Lucero, Andrés. (2015). Interaction and Humans in Internet of Things. 9299. 10.1007/978-3-319-22723-8_80. &lt;/ref&gt; participatory and collective urban design,&lt;ref&gt;Hofmann, Mathias &amp; Münster, Sander &amp; Noennig, Jörg. (2018). Building blocks for a massive digital participation system in urban planning.&lt;/ref&gt; and so on. The discipline attracts growing interests from people of various background such as designers, urban planners, computer scientists, and even architecture. Although the design canvas between human and city is board, Lee et al. proposed a framework considering the multi-disciplinary interests (Urban, Computers and Human) together, &lt;ref&gt;{{cite arXiv |last1=Lee |first1=Lik-Hang |last2=Braud |first2=Tristan |last3=Hosio |first3=Simo |last4=Hui |first4=Pan |title=Towards Augmented Reality-driven Human-City Interaction: Current Research and Future Challenges|year=2020 |class=cs.SI | eprint=2007.09207 }}&lt;/ref&gt; in which the emerging technologies such as extended reality (XR) can serve as a platform for such co-design purposes. &lt;ref&gt; Ronald T. Azuma. 1997. A survey of augmented reality. Presence: Teleoper. Virtual Environ. 6, 4 (August 1997), 355–385. DOI:https://doi.org/10.1162/pres.1997.6.4.355&lt;/ref&gt;

== References ==
{{reflist}}

{{improve categories|date=July 2020}}

[[Category:Computer science]]
[[Category:Urban design]]


{{computer-stub}}
{{design-stub}}</text>
      <sha1>ejfkao1d91323npmrvpon1s50rgitx9</sha1>
    </revision>
  </page>
  <page>
    <title>Operating system</title>
    <ns>0</ns>
    <id>22194</id>
    <revision>
      <id>1013808804</id>
      <parentid>1012863292</parentid>
      <timestamp>2021-03-23T15:36:14Z</timestamp>
      <contributor>
        <username>Dhtwiki</username>
        <id>9475572</id>
      </contributor>
      <minor/>
      <comment>slight copy editing (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="81752" xml:space="preserve">{{short description|Software that manages computer hardware resources}}
{{pp-vandalism|small=yes}}
{{pp-move-indef}}
{{Use dmy dates|date=July 2015}}
{{OS}}
An '''operating system''' ('''OS''') is [[system software]] that manages [[computer hardware]], [[computer software|software]] resources, and provides common [[daemon (computing)|services]] for [[computer program]]s.

[[Time-sharing]] operating systems [[scheduler (computing)|schedule tasks]] for efficient use of the system and may also include accounting software for cost allocation of [[Scheduling (computing)|processor time]], [[mass storage]], printing, and other resources.

For hardware functions such as [[input and output]] and [[memory allocation]], the operating system acts as an intermediary between programs and the computer hardware,&lt;ref&gt;{{cite book | last = Stallings | title = Operating Systems, Internals and Design Principles | publisher = Prentice Hall | year = 2005 | location = Pearson |page=6}}&lt;/ref&gt;&lt;ref&gt;{{cite book | last = Dhotre| first = I.A.| title = Operating Systems. | publisher = Technical Publications | year = 2009 |page=1}}&lt;/ref&gt; although the application code is usually executed directly by the hardware and frequently makes [[system call]]s to an OS function or is [[Interrupt|interrupted]] by it. Operating systems are found on many devices that contain a computer{{snd}} from cellular phones and video game consoles to [[web server]]s and [[supercomputer]]s.

The dominant general-purpose&lt;ref name="auto"&gt;{{Cite web|url=https://www.oreilly.com/library/view/operating-system-concepts/9780471694663/pt07.html|title=VII. Special-Purpose Systems - Operating System Concepts, Seventh Edition [Book]|website=www.oreilly.com}}&lt;/ref&gt; desktop operating system is [[Microsoft Windows]] with a market share of around 76.45%. [[macOS]] by [[Apple Inc.]] is in second place (17.72%), and the varieties of [[Linux]] are collectively in third place (1.73%).&lt;ref&gt;{{Cite web|title=Desktop Operating System Market Share Worldwide|url=https://gs.statcounter.com/os-market-share/desktop/worldwide/|access-date=2020-10-31|website=StatCounter Global Stats|language=en}}&lt;/ref&gt; In the [[Mobile operating system|mobile]] sector (including smartphones and [[Tablet computer|tablets]]), [[Android (operating system)|Android's]] share is up to 72% in the year 2020.&lt;ref&gt;{{Cite web|title=Mobile &amp; Tablet Operating System Market Share Worldwide|url=https://gs.statcounter.com/os-market-share/mobile-tablet/worldwide/|access-date=2020-10-31|website=StatCounter Global Stats|language=en}}&lt;/ref&gt; According to third quarter 2016 data, Android's share on smartphones is dominant with 87.5 percent with also a growth rate of 10.3 percent per year, followed by Apple's [[iOS]] with 12.1 percent with per year decrease in market share of 5.2 percent, while other operating systems amount to just 0.3 percent.&lt;ref&gt;{{cite web |url=http://www.businesswire.com/news/home/20161102006440/en/Strategy-Analytics-Android-Captures-Record-88-Percent |title=Strategy Analytics: Android Captures Record 88 Percent Share of Global Smartphone Shipments in Q3 2016 |date=November 2, 2016 |url-status=live |archive-url=https://web.archive.org/web/20161105223332/http://www.businesswire.com/news/home/20161102006440/en/Strategy-Analytics-Android-Captures-Record-88-Percent |archive-date=5 November 2016 |df=dmy-all }}&lt;/ref&gt; [[Linux distribution]]s are dominant in the server and supercomputing sectors. Other specialized classes of operating systems (special-purpose operating systems)&lt;ref name="auto"/&gt;&lt;ref&gt;{{Cite web|url=https://www.acs.eonerc.rwth-aachen.de/cms/E-ON-ERC-ACS/Studium/Lehrveranstaltungen/~lrhs/Spezial-Betriebssysteme/?lidx=1|title=Special-Purpose Operating Systems - RWTH AACHEN UNIVERSITY Institute for Automation of Complex Power Systems - English|website=www.acs.eonerc.rwth-aachen.de}}&lt;/ref&gt;), such as [[Embedded system|embedded]] and real-time systems, exist for many applications. [[Security-focused operating system]]s also exist. Some operating systems have low system requirements (i.e. [[light-weight Linux distribution]]). Others may have higher system requirements.

Some operating systems require installation or may come pre-installed with purchased computers ([[OEM]]-installation), whereas others may run directly from media (i.e. [[live cd]]) or flash memory (i.e. USB stick).

==Types of operating systems==

===Single-tasking and multi-tasking===
A single-tasking system can only run one program at a time, while a [[Computer multitasking|multi-tasking]] operating system allows more than one program to be running in [[Concurrent computing|concurrency]]. This is achieved by [[time-sharing]], where the available processor time is divided between multiple processes. These processes are each interrupted repeatedly in [[time slice]]s by a task-scheduling subsystem of the operating system. Multi-tasking may be characterized in preemptive and co-operative types. In [[Preemption (computing)|preemptive]] multitasking, the operating system slices the [[Central processing unit|CPU]] time and dedicates a slot to each of the programs. [[Unix-like]] operating systems, such as [[Solaris (operating system)|Solaris]] and [[Linux]]—as well as non-Unix-like, such as [[AmigaOS]]—support preemptive multitasking. Cooperative multitasking is achieved by relying on each process to provide time to the other processes in a defined manner. [[16-bit]] versions of Microsoft Windows used cooperative multi-tasking; [[32-bit]] versions of both Windows NT and Win9x used preemptive multi-tasking.

===Single- and multi-user===
Single-user operating systems have no facilities to distinguish users, but may allow multiple programs to run in tandem.&lt;ref&gt;Lorch, Jacob R., and Alan Jay Smith. "Reducing processor power consumption by improving processor time management in a single-user operating system." Proceedings of the 2nd annual international conference on Mobile computing and networking. ACM, 1996.&lt;/ref&gt; A [[multi-user]] operating system extends the basic concept of multi-tasking with facilities that identify processes and resources, such as disk space, belonging to multiple users, and the system permits multiple users to interact with the system at the same time. Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources to multiple users.

===Distributed===
A [[distributed operating system]] manages a group of distinct, [[Computer network|networked]] computers and makes them appear to be a single computer, as all computations are [[Distributed computing|distributed]] (divided amongst the constituent computers).&lt;ref&gt;{{cite book |last1=Mishra |first1=B. |last2=Singh |first2=N. |last3=Singh |first3=R. |chapter=Master-slave group based model for co-ordinator selection, an improvement of bully algorithm |title=International Conference on Parallel, Distributed and Grid Computing (PDGC) |year=2014 |pages=457–460 |doi=10.1109/PDGC.2014.7030789 |isbn=978-1-4799-7682-9 |s2cid=13887160 }}&lt;/ref&gt;

===Templated===
In the distributed and [[cloud computing]] context of an OS, ''templating'' refers to creating a single [[Disk image|virtual machine image]] as a guest operating system, then saving it as a tool for multiple running [[Virtual machine|virtual machines.]] The technique is used both in [[virtualization]] and cloud computing management, and is common in large server warehouses.&lt;ref name="Operating Systems Concepts"&gt;{{cite book |isbn=978-1118063330|title=Operating Systems Concepts |author=Gagne, Silberschatz Galvin |page=716|location=New York|publisher=Wiley|year=2012}}&lt;/ref&gt;

===Embedded===
[[Embedded operating system]]s are designed to be used in [[Embedded system|embedded computer systems]]. They are designed to operate on small machines with less autonomy (e.g. PDAs). They are very compact and extremely efficient by design, and are able to operate with a limited amount of resources. [[Windows CE]] and [[Minix 3]] are some examples of embedded operating systems.

===Real-time===
A [[real-time operating system]] is an operating system that guarantees to process [[Event (computing)|events]] or data by a specific moment in time. A real-time operating system may be single- or multi-tasking, but when multitasking, it uses specialized scheduling algorithms so that a [[Deterministic system|deterministic]] nature of behavior is achieved. Such an event-driven system switches between tasks based on their priorities or external events, whereas time-sharing operating systems switch tasks based on clock [[Interrupt|interrupts]].

===Library===
A library operating system is one in which the services that a typical operating system provides, such as networking, are provided in the form of [[Library (computing)|libraries]] and composed with the application and configuration code to construct a [[unikernel]]: a specialized, [[Single address space operating system|single address space]], machine image that can be deployed to cloud or embedded environments.

==History==
{{Main|History of operating systems}}
{{See also|Resident monitor}}

Early computers were built to perform a series of single tasks, like a calculator. Basic operating system features were developed in the 1950s, such as [[resident monitor]] functions that could automatically run different programs in succession to speed up processing. Operating systems did not exist in their modern and more complex forms until the early 1960s.&lt;ref name="google4"&gt;{{Cite book |title= Classic Operating Systems|editor1-first= Per Brinch|editor1-last= Hansen|year= 2001|publisher= Springer|isbn= 0-387-95113-X|pages=4–7|url= https://books.google.com/books?id=-PDPBvIPYBkC&amp;pg=PP1}}&lt;/ref&gt;   Hardware features were added, that enabled use of [[Runtime library|runtime libraries]], [[Programmable Interrupt Controller|interrupts]], and [[Parallel computing|parallel processing]]. When [[personal computer]]s became popular in the 1980s, operating systems were made for them similar in concept to those used on larger computers.

In the 1940s, the earliest electronic digital systems had no operating systems.  Electronic systems of this time were programmed on rows of mechanical switches or by jumper wires on [[plugboard]]s.  These were special-purpose systems that, for example, generated ballistics tables for the military or controlled the printing of payroll checks from data on punched paper cards.  After programmable general-purpose computers were invented, [[Machine code|machine languages ]](consisting of strings of the binary digits 0 and 1 on punched paper tape) were introduced that sped up the programming process (Stern, 1981).{{Full citation needed|date=August 2014}}
[[File:IBM360-65-1.corestore.jpg|thumb|[[OS/360]] was used on most IBM mainframe computers beginning in 1966, including computers used by the [[Apollo program]].]]

In the early 1950s, a computer could execute only one program at a time.  Each user had sole use of the computer for a limited period and would arrive at a scheduled time with their program and data on punched paper cards or [[punched tape]]. The program would be loaded into the machine, and the machine would be set to work until the program completed or [[Crash (computing)|crashed]]. Programs could generally be debugged via a front panel using toggle switches and panel lights. It is said that [[Alan Turing]] was a master of this on the early [[Manchester Mark 1]] machine, and he was already deriving the primitive conception of an operating system from the principles of the [[universal Turing machine]].&lt;ref name="google4"/&gt;

Later machines came with libraries of programs, which would be linked to a user's program to assist in operations such as input and output and [[Compiler|compiling]] (generating machine code from human-readable [[Assembly language|symbolic code]]). This was the genesis of the modern-day operating system. However, machines still ran a single job at a time. At Cambridge University in England, the job queue was at one time a washing line (clothesline) from which tapes were hung with different colored clothes-pegs to indicate job priority.{{citation needed|date=September 2010}}

An improvement was the [[Atlas Supervisor]]. Introduced with the Manchester [[Atlas (computer)|Atlas]] in 1962, it is considered by many to be the first recognisable modern operating system.&lt;ref&gt;{{cite book |last=Lavington |first=Simon |title=A History of Manchester Computers |year=1998 |edition=2nd |publisher=The British Computer Society |location=Swindon |isbn=978-1-902505-01-5|pages=50–52}}&lt;/ref&gt; [[Per Brinch Hansen|Brinch Hansen]] described it as "the most significant breakthrough in the history of operating systems."&lt;ref&gt;{{cite book |last=Brinch Hansen |first=Per |title=Classic Operating Systems: From Batch Processing to Distributed Systems |year=2000 |publisher=Springer-Verlag}}&lt;/ref&gt;

===Mainframes===
{{Main|History of IBM mainframe operating systems}}

Through the 1950s, many major features were pioneered in the field of operating systems on [[mainframe computer]]s, including [[batch processing]], input/output [[interrupt]]ing, [[Data buffer|buffering]], [[Computer multitasking|multitasking]], [[spooling]], [[runtime library|runtime libraries]], [[Linker (computing)|link-loading]], and programs for [[Sorting algorithm|sorting]] records in files. These features were included or not included in application software at the option of application programmers, rather than in a separate operating system used by all applications.  In 1959, the [[SHARE Operating System]] was released as an integrated utility for the [[IBM 704]], and later in the [[IBM 709|709]] and [[IBM 7090|7090]] mainframes, although it was quickly supplanted by [[IBM 7090/94 IBSYS|IBSYS]]/IBJOB on the 709, 7090 and 7094.

During the 1960s, IBM's [[OS/360]] introduced the concept of a single OS spanning an entire product line, which was crucial for the success of the System/360 machines. IBM's current mainframe operating systems are [[History of IBM mainframe operating systems|distant descendants]] of this original system and modern machines are [[Backward compatibility|backwards-compatible]] with applications written for OS/360.{{Citation needed|date=June 2010}}

OS/360 also pioneered the concept that the operating system keeps track of all of the system resources that are used, including program and data space allocation in main memory and file space in secondary storage, and [[file locking]] during updates. When a process is terminated for any reason, all of these resources are re-claimed by the operating system.

The alternative [[CP-67]] system for the [[IBM System/360 Model 67|S/360-67]] started a whole line of IBM operating systems focused on the concept of [[virtual machine]]s. Other operating systems used on IBM S/360 series mainframes included systems developed by IBM: COS/360 (Compatibility Operating System), [[DOS/360]] (Disk Operating System), [[TSS/360]] (Time Sharing System), [[TOS/360]] (Tape Operating System), [[BOS/360]] (Basic Operating System), and [[IBM Airline Control Program|ACP]] (Airline Control Program), as well as a few non-IBM systems: [[Michigan Terminal System|MTS]] (Michigan Terminal System), [[MUSIC/SP|MUSIC]] (Multi-User System for Interactive Computing), and [[ORVYL]] (Stanford Timesharing System).

[[Control Data Corporation]] developed the [[SCOPE (software)|SCOPE]] operating system in the 1960s, for [[batch processing]]. In cooperation with the University of Minnesota, the [[CDC Kronos|Kronos]] and later the [[NOS (software)|NOS]] operating systems were developed during the 1970s, which supported simultaneous batch and timesharing use. Like many commercial timesharing systems, its interface was an extension of the Dartmouth [[BASIC]] operating systems, one of the pioneering efforts in timesharing and programming languages. In the late 1970s, Control Data and the University of Illinois developed the [[PLATO (computer system)|PLATO]] operating system, which used plasma panel displays and long-distance time sharing networks. Plato was remarkably innovative for its time, featuring real-time chat, and multi-user graphical games.

In 1961, [[Burroughs Corporation]] introduced the [[B5000]] with the [[Burroughs MCP|MCP]] (Master Control Program) operating system. The B5000 was a [[stack machine]] designed to exclusively support high-level languages with no machine language or assembler; indeed, the MCP was the first OS to be written exclusively in a high-level language ([[Executive Systems Problem Oriented Language|ESPOL]], a dialect of [[ALGOL]]). MCP also introduced many other ground-breaking innovations, such as being the first commercial implementation of [[virtual memory]]. During development of the [[AS/400]], IBM made an approach to Burroughs to license MCP to run on the AS/400 hardware. This proposal was declined by Burroughs management to protect its existing hardware production. MCP is still in use today in the [[Unisys]] company's [[ClearPath/MCP]] line of computers.

[[UNIVAC]], the first commercial computer manufacturer, produced a series of EXEC operating systems{{citation needed|date=February 2015}}. Like all early main-frame systems, this batch-oriented system managed magnetic drums, disks, card readers and line printers. In the 1970s, UNIVAC produced the Real-Time Basic (RTB) system to support large-scale time sharing, also patterned after the Dartmouth BC system.

[[General Electric]] and [[MIT]] developed General Electric Comprehensive Operating Supervisor (GECOS), which introduced the concept of ringed security privilege levels. After acquisition by [[Honeywell]] it was renamed [[General Comprehensive Operating System]] (GCOS).

Digital Equipment Corporation developed many operating systems for its various computer lines, including [[TOPS-10]] and [[TOPS-20]] time sharing systems for the 36-bit PDP-10 class systems. Before the widespread use of UNIX, TOPS-10 was a particularly popular system in universities, and in the early [[ARPANET]] community. [[RT-11]] was a single-user real-time OS for the [[PDP-11]] class minicomputer, and [[RSX-11]] was the corresponding multi-user OS.

From the late 1960s through the late 1970s, several hardware capabilities evolved that allowed similar or ported software to run on more than one system. Early systems had utilized [[Microcode|microprogramming]] to implement features on their systems in order to permit different underlying [[computer architecture]]s to appear to be the same as others in a series. In fact, most 360s after the 360/40 (except the 360/165 and 360/168) were microprogrammed implementations.

The enormous investment in software for these systems made since the 1960s caused most of the original computer manufacturers to continue to develop compatible operating systems along with the hardware. Notable supported mainframe operating systems include:

* [[MCP (Burroughs Large Systems)|Burroughs MCP]]{{snd}} [[Burroughs large systems|B5000]], 1961 to [[Unisys]] Clearpath/MCP, present
* IBM [[OS/360]]{{snd}} [[IBM System/360]], 1966 to IBM [[z/OS]], present
* IBM [[CP-67]]{{snd}} [[IBM System/360]], 1967 to IBM [[z/VM]]
* UNIVAC [[EXEC 8]]{{snd}} [[UNIVAC 1108]], 1967, to [[OS 2200]] [[Unisys]] Clearpath Dorado, present

===Microcomputers===
[[File:PC DOS 1.10 screenshot.png|thumb|256px|PC DOS was an early personal computer OS that featured a command line interface.]]
[[File:Apple Macintosh Desktop.png|thumb|256px|Mac OS by [[Apple Computer]] became the first widespread OS to feature a [[graphical user interface]]. Many of its features such as windows and icons would later become commonplace in GUIs.]]

The first [[microcomputer]]s did not have the capacity or need for the elaborate operating systems that had been developed for mainframes and minis; minimalistic operating systems were developed, often loaded from [[Read-only memory|ROM]] and known as ''[[resident monitor|monitors]]''. One notable early [[disk operating system]] was [[CP/M]], which was supported on many early microcomputers and was closely imitated by [[Microsoft]]'s [[MS-DOS]], which became widely popular as the operating system chosen for the [[IBM PC]] (IBM's version of it was called IBM DOS or [[PC DOS]]). In the 1980s, Apple Computer Inc. (now [[Apple Inc.]]) abandoned its popular [[Apple II]] series of microcomputers to introduce the [[Apple Macintosh]] computer with an innovative [[graphical user interface]] (GUI) to the [[Classic Mac OS|Mac OS]].

The introduction of the [[Intel 80386]] CPU chip in October 1985,&lt;ref&gt;{{Cite web|url=http://www.intel.com/pressroom/kits/quickrefyr.htm#1985|title=Intel® Microprocessor Quick Reference Guide - Year|website=www.intel.com|access-date=2016-04-24|url-status=live|archive-url=https://web.archive.org/web/20160425001839/http://www.intel.com/pressroom/kits/quickrefyr.htm#1985|archive-date=25 April 2016|df=dmy-all}}&lt;/ref&gt; with [[32-bit]] architecture and [[paging]] capabilities, provided personal computers with the ability to run [[Computer multitasking|multitasking]] operating systems like those of earlier [[minicomputer]]s and [[mainframe computer|mainframes]]. Microsoft responded to this progress by hiring [[Dave Cutler]], who had developed the [[OpenVMS|VMS]] operating system for [[Digital Equipment Corporation]]. He would lead the development of the [[Windows NT]] operating system, which continues to serve as the basis for Microsoft's operating systems line. [[Steve Jobs]], a co-founder of [[Apple Inc.]], started [[NeXT]] Computer Inc., which developed the [[NEXTSTEP]] operating system. NEXTSTEP would later be acquired by [[Apple Inc.]] and used, along with code from [[FreeBSD]] as the core of [[macOS|Mac OS X]] (macOS after latest name change).

The [[GNU Project]] was started by activist and programmer [[Richard Stallman]] with the goal of creating a complete [[free software]] replacement to the proprietary [[UNIX]] operating system. While the project was highly successful in duplicating the functionality of various parts of UNIX, development of the [[GNU Hurd]] kernel proved to be unproductive. In 1991, Finnish computer science student [[Linus Torvalds]], with cooperation from volunteers collaborating over the Internet, released the first version of the [[Linux kernel]]. It was soon merged with the GNU [[user space]] components and [[system software]] to form a complete operating system. Since then, the combination of the two major components has usually been referred to as simply "Linux" by the software industry, a naming convention that Stallman and the [[Free Software Foundation]] remain opposed to, preferring the name GNU/Linux. The Berkeley Software Distribution, known as [[BSD (operating system)|BSD]], is the UNIX derivative distributed by the University of California, Berkeley, starting in the 1970s. Freely distributed and [[ported]] to many minicomputers, it eventually also gained a following for use on PCs, mainly as [[FreeBSD]], [[NetBSD]] and [[OpenBSD]].

==Examples==

===Unix and Unix-like operating systems===
{{Main|Unix}}
&lt;imagemap&gt;
File:Unix history-simple.png|256px|thumb|Evolution of [[Unix]] systems
default [[File:Unix history-simple.svg]]
&lt;/imagemap&gt;

Unix was originally written in [[assembly language]].&lt;ref&gt;{{cite web|last=Ritchie|first=Dennis|title=Unix Manual, first edition|url=http://cm.bell-labs.com/cm/cs/who/dmr/1stEdman.html|publisher=Lucent Technologies|access-date=22 November 2012|url-status=dead|archive-url=https://web.archive.org/web/20080518013206/http://cm.bell-labs.com/cm/cs/who/dmr/1stEdman.html|archive-date=18 May 2008|df=dmy-all}}&lt;/ref&gt; [[Ken Thompson]] wrote [[B (programming language)|B]], mainly based on [[BCPL]], based on his experience in the [[MULTICS]] project. B was replaced by [[C (programming language)|C]], and Unix, rewritten in C, developed into a large, complex family of inter-related operating systems which have been influential in every modern operating system (see [[History of operating systems|History]]).

The ''[[Unix-like]]'' family is a diverse group of operating systems, with several major sub-categories including [[System V]], [[Berkeley Software Distribution|BSD]], and [[Linux]]. The name "[[Unix|UNIX]]" is a trademark of [[The Open Group]] which licenses it for use with any operating system that has been shown to conform to their definitions. "UNIX-like" is commonly used to refer to the large set of operating systems which resemble the original UNIX.

Unix-like systems run on a wide variety of [[computer architecture]]s. They are used heavily for [[server (computing)|servers]] in business, as well as [[workstation]]s in academic and engineering environments. [[Free software|Free]] UNIX variants, such as [[Linux]] and [[Berkeley Software Distribution|BSD]], are popular in these areas.

Four operating systems are certified by [[The Open Group]] (holder of the Unix trademark) as Unix. HP's [[HP-UX]] and IBM's [[AIX operating system|AIX]] are both descendants of the original System V Unix and are designed to run only on their respective vendor's hardware. In contrast, [[Sun Microsystems]]'s [[Solaris (operating system)|Solaris]] can run on multiple types of hardware, including [[x86]] and [[Sparc]] servers, and PCs. Apple's [[macOS]], a replacement for Apple's earlier (non-Unix) Mac OS, is a [[hybrid kernel]]-based BSD variant derived from [[NeXTSTEP]], [[Mach (kernel)|Mach]], and [[FreeBSD]].

Unix interoperability was sought by establishing the [[POSIX]] standard. The POSIX standard can be applied to any operating system, although it was originally created for various Unix variants.

====BSD and its descendants====
{{Main|Berkeley Software Distribution}}
[[File:First Web Server.jpg|thumb|256px|The [[CERN httpd|first server]] for the [[World Wide Web]] ran on NeXTSTEP, based on BSD.]]

A subgroup of the Unix family is the [[Berkeley Software Distribution]] family, which includes [[FreeBSD]], [[NetBSD]], and [[OpenBSD]]. These operating systems are most commonly found on [[webserver]]s, although they can also function as a personal computer OS. The Internet owes much of its existence to BSD, as many of the protocols now commonly used by computers to connect, send and receive data over a network were widely implemented and refined in BSD. The [[World Wide Web]] was also first demonstrated on a number of computers running an OS based on BSD called [[NeXTSTEP]].

In 1974, [[University of California, Berkeley]] installed its first Unix system. Over time, students and staff in the computer science department there began adding new programs to make things easier, such as text editors. When Berkeley received new [[VAX]] computers in 1978 with Unix installed, the school's undergraduates modified Unix even more in order to take advantage of the computer's hardware possibilities. The [[Defense Advanced Research Projects Agency]] of the US [[United States Department of Defense|Department of Defense]] took interest, and decided to fund the project. Many schools, corporations, and government organizations took notice and started to use Berkeley's version of Unix instead of the official one distributed by AT&amp;T.

[[Steve Jobs]], upon leaving Apple Inc. in 1985, formed [[NeXT|NeXT Inc.]], a company that manufactured high-end computers running on a variation of BSD called [[NeXTSTEP]]. One of these computers was used by [[Tim Berners-Lee]] as the first webserver to create the World Wide Web.

Developers like [[Keith Bostic]] encouraged the project to replace any non-free code that originated with Bell Labs. Once this was done, however, AT&amp;T sued. After two years of legal disputes, the BSD project spawned a number of free derivatives, such as [[NetBSD]] and [[FreeBSD]] (both in 1993), and [[OpenBSD]] (from NetBSD in 1995).

====macOS====
{{Main|macOS}}

'''macOS''' (formerly "Mac OS X" and later "OS X")  is a line of [[open core]] graphical operating systems developed, marketed, and sold by [[Apple Inc.]], the latest of which is pre-loaded on all currently shipping [[Macintosh]] computers. macOS is the successor to the original [[classic Mac OS]], which had been Apple's primary operating system since 1984. Unlike its predecessor, macOS is a [[UNIX]] operating system built on technology that had been developed at [[NeXT]] through the second half of the 1980s and up until Apple purchased the company in early 1997.
The operating system was first released in 1999 as [[Mac OS X Server 1.0]], followed in March 2001 by a client version ([[Mac OS X v10.0|Mac OS X v10.0 "Cheetah"]]). Since then, six more distinct "client" and "[[macOS Server|server]]" editions of macOS have been released, until the two were merged in [[Mac OS X Lion|OS X 10.7 "Lion"]].

Prior to its merging with macOS, the server edition{{snd}} [[macOS Server]]{{snd}} was [[software architecture|architecturally]] identical to its desktop counterpart and usually ran on Apple's line of Macintosh [[server (computing)|server]] hardware. macOS Server included work group management and administration software tools that provide simplified access to key [[network service]]s, including a [[Message transfer agent|mail transfer agent]], a [[Samba (software)|Samba server]], an [[Lightweight Directory Access Protocol|LDAP]] server, a [[Domain Name System|domain name server]], and others. With [[Mac OS X Lion|Mac OS X v10.7 Lion]], all server aspects of Mac OS X Server have been integrated into the client version and the product re-branded as "OS X" (dropping "Mac" from the name). The server tools are now offered as an application.&lt;ref&gt;{{cite web |url=https://www.apple.com/macosx/lion/ |title=OS X Mountain Lion – Move your Mac even further ahead |publisher=Apple |access-date=2012-08-07 |url-status=live |archive-url=https://web.archive.org/web/20110523090205/http://www.apple.com/macosx/lion/ |archive-date=23 May 2011 |df=dmy-all }}&lt;/ref&gt;

====Linux====
{{Main|Linux|Linux kernel}}
[[File:Ubuntu 19.04 "Disco Dingo".png|thumb|250px|[[Ubuntu (operating system)|Ubuntu]], desktop [[Linux distribution]] ]]
[[File:Tux.svg|thumb|[[Linux]], a [[unix-like]] operating system was first time released on September 17, 1991, by [[Linus Torvalds]].&lt;ref&gt;{{cite web | title = Twenty Years of Linux according to Linus Torvalds | url = http://www.zdnet.com/article/twenty-years-of-linux-according-to-linus-torvalds/ | publisher = ZDNet | date = April 13, 2011 | access-date = September 19, 2016 | url-status=live | archive-url = https://web.archive.org/web/20160919232940/http://www.zdnet.com/article/twenty-years-of-linux-according-to-linus-torvalds/ | archive-date = September 19, 2016 | df = mdy-all }}&lt;/ref&gt;&lt;ref&gt;{{ cite newsgroup | title = Free minix-like kernel sources for 386-AT | author = Linus Benedict Torvalds | date = October 5, 1991 | newsgroup = comp.os.minix | url = https://groups.google.com/group/comp.os.minix/msg/2194d253268b0a1b?pli=1 |access-date=September 30, 2011}}&lt;/ref&gt;&lt;ref&gt;{{cite web | title = What Is Linux: An Overview of the Linux Operating System | url = https://medium.com/@theinfovalley097/what-is-linux-an-overview-of-the-linux-operating-system-77bc7421c7e5?sk=b80b38575284317290c86e56001e43b1 | publisher = Medium| access-date = December 21, 2019 | df = mdy-all }}&lt;/ref&gt; Picture of [[Tux (mascot)|Tux]] the [[penguin]], mascot of Linux.&lt;ref name="LinuxOnLine2008"&gt;{{cite web | url = http://www.linux.org/info/logos.html | title = Linux Logos and Mascots |access-date=August 11, 2009 | last = Linux Online | year = 2008 | archive-url = https://web.archive.org/web/20100815085106/http://www.linux.org/info/logos.html | archive-date = August 15, 2010 }}&lt;/ref&gt;]]

The Linux kernel originated in 1991, as a project of [[Linus Torvalds]], while a university student in Finland. He posted information about his project on a newsgroup for computer students and programmers, and received support and assistance from volunteers who succeeded in creating a complete and functional kernel.

[[Linux]] is [[Unix-like]], but was developed without any Unix code, unlike BSD and its variants. Because of its open license model, the [[Linux kernel]] code is available for study and modification, which resulted in its use on a wide range of computing machinery from supercomputers to smart-watches. Although estimates suggest that Linux is [[Usage share of operating systems|used on]] only 1.82% of all "desktop" (or laptop) PCs,&lt;ref name="StatCounter"&gt;{{cite web |title=Top 5 Operating Systems from January to April 2011 |url=http://gs.statcounter.com/#os-ww-monthly-201101-201104-bar |publisher=StatCounter |date=October 2009 |access-date=5 November 2009 |url-status=live |archive-url=https://archive.today/20120526/http://gs.statcounter.com/%23mobile_browser-ww-monthly-201012-201111-bar#os-ww-monthly-201101-201104-bar |archive-date=26 May 2012 |df=dmy-all }}&lt;/ref&gt; it has been widely adopted for use in servers&lt;ref&gt;{{cite web |url=http://www.idc.com/about/viewpressrelease.jsp?containerId=prUS22360110&amp;sectionId=null&amp;elementId=null&amp;pageType=SYNOPSIS |title=IDC report into Server market share |publisher=Idc.com |access-date=2012-08-07 |url-status=dead |archive-url=https://web.archive.org/web/20120927155332/http://www.idc.com/about/viewpressrelease.jsp?containerId=prUS22360110&amp;sectionId=null&amp;elementId=null&amp;pageType=SYNOPSIS |archive-date=27 September 2012 |df=dmy-all }}&lt;/ref&gt; and embedded systems&lt;ref&gt;{{cite web |last=LinuxDevices Staff |title=Linux still top embedded OS |url=http://archive.linuxgizmos.com/linux-still-top-embedded-os/ |date=23 April 2008 |website=LinuxGizmos.com |access-date=5 April 2016 |url-status=dead |archive-url=https://web.archive.org/web/20160419010154/http://archive.linuxgizmos.com/linux-still-top-embedded-os/ |archive-date=19 April 2016 |df=dmy-all }}&lt;/ref&gt; such as cell phones. Linux has superseded Unix on many platforms and is used on &lt;!--{{As of|2016|November}}, 99.6% of the world's [[TOP500|500 fastest supercomputers]] run some variant of Linux,&lt;ref name=top500stats&gt;{{cite web |url=http://www.top500.org/statistics/details/osfam/1 |title=TOP500 Supercomputer Sites: Operating system Family / Linux |publisher=Top500.org|access-date=6 February 2017}}&lt;/ref&gt; --&gt;most supercomputers including the top 385.&lt;ref name="top500-list"&gt;{{cite web |url=http://www.top500.org/statistics/sublist/ |title=Sublist Generator |publisher=Top500.org |access-date=6 February 2017}}&lt;/ref&gt; Many of the same computers are also on [[Green500]] (but in different order), and Linux runs on the top 10. Linux is also commonly used on other small energy-efficient computers, such as [[smartphone]]s and [[smartwatch]]es. The Linux kernel is used in some popular distributions, such as [[Red Hat Enterprise Linux|Red Hat]], [[Debian]], [[Ubuntu (operating system)|Ubuntu]], [[Linux Mint]] and [[Google]]'s [[Android (operating system)|Android]], [[Chrome OS]], and [[Chromium OS]].

===Microsoft Windows===
{{Main|Microsoft Windows}}

Microsoft Windows is a family of [[proprietary software|proprietary]] operating systems designed by [[Microsoft|Microsoft Corporation]] and primarily targeted to Intel architecture based computers, with an estimated 88.9 percent total usage share on Web connected computers.&lt;ref name="StatCounter"/&gt;&lt;ref&gt;{{cite news|title=Global Web Stats|url=http://marketshare.hitslink.com/operating-system-market-share.aspx?qprid=8|date=May 2011|publisher=Net Market Share, Net Applications|access-date=2011-05-07|url-status=live|archive-url=https://web.archive.org/web/20100125022803/http://marketshare.hitslink.com/operating-system-market-share.aspx?qprid=8|archive-date=25 January 2010|df=dmy-all}}&lt;/ref&gt;&lt;ref name="w3cstats"&gt;{{cite news|title=Global Web Stats|url=http://www.w3counter.com/globalstats.php|date=September 2009|publisher=W3Counter, Awio Web Services|access-date=2009-10-24|url-status=live|archive-url=https://archive.today/20120628/http://www.w3counter.com/globalstats.php|archive-date=28 June 2012|df=dmy-all}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Operating System Market Share |url=http://marketshare.hitslink.com/operating-system-market-share.aspx?qprid=8 |publisher=Net Applications |date=October 2009 |access-date=5 November 2009 |url-status=live |archive-url=https://web.archive.org/web/20100125022803/http://marketshare.hitslink.com/operating-system-market-share.aspx?qprid=8 |archive-date=25 January 2010 |df=dmy-all }}&lt;/ref&gt; The latest version is [[Windows 10]].

In 2011, Windows 7 overtook Windows XP as most common version in use.&lt;ref name="w3schoolsOSStats"&gt;{{cite web|title=w3schools.com OS Platform Statistics|url=http://www.w3schools.com/browsers/browsers_os.asp|access-date=30 October 2011|url-status=live|archive-url=https://web.archive.org/web/20110805133049/http://w3schools.com/browsers/browsers_os.asp|archive-date=5 August 2011|df=dmy-all}}&lt;/ref&gt;&lt;ref name="gstats2011"&gt;{{cite web|title=Stats Count Global Stats Top Five Operating Systems|url=http://gs.statcounter.com/#os-ww-monthly-201010-201110|access-date=30 October 2011|url-status=live|archive-url=https://archive.today/20120526/http://gs.statcounter.com/%23mobile_browser-ww-monthly-201012-201111-bar#os-ww-monthly-201010-201110|archive-date=26 May 2012|df=dmy-all}}&lt;/ref&gt;&lt;ref name="globstats"&gt;{{cite web|title=Global statistics at w3counter.com|url=http://www.w3counter.com/globalstats.php|access-date=23 January 2012|url-status=live|archive-url=https://archive.today/20120628/http://www.w3counter.com/globalstats.php|archive-date=28 June 2012|df=dmy-all}}&lt;/ref&gt;

Microsoft Windows was first released in 1985, as an [[operating environment]] running on top of [[MS-DOS]], which was the standard operating system shipped on most Intel architecture personal computers at the time. In 1995, [[Windows 95]] was released which only used MS-DOS as a bootstrap. For backwards compatibility, Win9x could run real-mode MS-DOS&lt;ref&gt;{{cite web |url=http://support.microsoft.com/kb/130179/EN-US |title=Troubleshooting MS-DOS Compatibility Mode on Hard Disks |publisher=Support.microsoft.com |access-date=2012-08-07 |url-status=live |archive-url=https://web.archive.org/web/20120810073641/http://support.microsoft.com/kb/130179/EN-US |archive-date=10 August 2012 |df=dmy-all }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://support.microsoft.com/kb/134748/en |title=Using NDIS 2 PCMCIA Network Card Drivers in Windows 95 |publisher=Support.microsoft.com |access-date=2012-08-07 |url-status=live |archive-url=https://web.archive.org/web/20130217043405/http://support.microsoft.com/kb/134748/en |archive-date=17 February 2013 |df=dmy-all }}&lt;/ref&gt; and 16-bit [[Windows 3.x]]&lt;ref&gt;{{cite web |url=http://support.microsoft.com/kb/163354/en |title=INFO: Windows 95 Multimedia Wave Device Drivers Must be 16 bit |publisher=Support.microsoft.com |access-date=2012-08-07 |url-status=live |archive-url=https://web.archive.org/web/20130217043412/http://support.microsoft.com/kb/163354/en |archive-date=17 February 2013 |df=dmy-all }}&lt;/ref&gt; drivers. [[Windows ME]], released in 2000, was the last version in the Win9x family. Later versions have all been based on the [[Windows NT]] [[kernel (computing)|kernel]]. Current client versions of Windows run on [[IA-32]], [[x86-64]] and 32-bit [[ARMv7|ARM]] [[microprocessor]]s.&lt;ref&gt;{{cite news|last=Arthur|first=Charles|title=Windows 8 will run on ARM chips - but third-party apps will need rewrite|url=https://www.theguardian.com/technology/2011/jan/05/microsoft-windows-8-arm-processors|newspaper=The Guardian|url-status=live|archive-url=https://web.archive.org/web/20161012022725/https://www.theguardian.com/technology/2011/jan/05/microsoft-windows-8-arm-processors|archive-date=12 October 2016|df=dmy-all}}&lt;/ref&gt; In addition [[Itanium]] is still supported in older server version [[Windows Server 2008 R2]]. In the past, Windows NT supported additional architectures.

Server editions of Windows are widely used. In recent years, Microsoft has expended significant capital in an effort to promote the use of Windows as a [[server operating system]]. However, Windows' usage on servers is not as widespread as on personal computers as Windows competes against Linux and BSD for server market share.&lt;ref&gt;{{cite web|url=http://news.netcraft.com/SSL-Survey/CMatch/osdv_all|title=Operating System Share by Groups for Sites in All Locations January 2009|url-status=dead|archive-url=https://web.archive.org/web/20090706135203/http://news.netcraft.com/SSL-Survey/CMatch/osdv_all|archive-date=6 July 2009|df=dmy-all|access-date=3 May 2010}}&lt;/ref&gt;&lt;ref&gt;{{cite news|url=http://blogs.zdnet.com/microsoft/?p=5408|title=Behind the IDC data: Windows still No. 1 in server operating systems|date=2010-02-26|work=ZDNet|url-status=live|archive-url=https://web.archive.org/web/20100301032456/http://blogs.zdnet.com/microsoft/?p=5408|archive-date=1 March 2010|df=dmy-all}}&lt;/ref&gt;

[[ReactOS]] is a Windows-alternative operating system, which is being developed on the principles of Windows{{snd}} without using any of Microsoft's code.

===Other===
There have been many operating systems that were significant in their day but are no longer so, such as [[AmigaOS]]; [[OS/2]] from IBM and Microsoft; [[classic Mac OS]], the non-Unix precursor to Apple's macOS; [[BeOS]]; [[XTS-400|XTS-300]]; [[RISC OS]]; [[MorphOS]]; [[Haiku (operating system)|Haiku]]; [[BareMetal]] and [[FreeMint]]. Some are still used in niche markets and continue to be developed as minority platforms for enthusiast communities and specialist applications. [[OpenVMS]], formerly from [[Digital Equipment Corporation|DEC]], is still under active development by [[VMS Software Inc]]. Yet other operating systems are used almost exclusively in academia, for operating systems education or to do research on operating system concepts. A typical example of a system that fulfills both roles is [[MINIX]], while for example [[Singularity (operating system)|Singularity]] is used purely for research. Another example is the [[Oberon (operating system)|Oberon System]] designed at [[ETH Zürich]] by [[Niklaus Wirth]], [[Jürg Gutknecht]] and a group of students at the former Computer Systems Institute in the 1980s. It was used mainly for research, teaching, and daily work in Wirth's group.

Other operating systems have failed to win significant market share, but have introduced innovations that have influenced mainstream operating systems, not least Bell Labs' [[Plan 9 from Bell Labs|Plan 9]].

==Components==
The components of an operating system all exist in order to make the different parts of a computer work together. All user software needs to go through the operating system in order to use any of the hardware, whether it be as simple as a mouse or keyboard or as complex as an Internet component.

===Kernel===
{{Main|Kernel (computing)}}
[[File:Kernel Layout.svg|thumb|A kernel connects the application software to the hardware of a computer.]]

With the aid of the [[firmware]] and [[device driver]]s, the kernel provides the most basic level of control over all of the computer's hardware devices. It manages memory access for programs in the [[Random-access memory|RAM]], it determines which programs get access to which hardware resources, it sets up or resets the CPU's operating states for optimal operation at all times, and it organizes the data for long-term [[non-volatile storage]] with [[file system]]s on such media as disks, tapes, flash memory, etc.

====Program execution====
{{Main|Process (computing)}}

The operating system provides an interface between an application program and the computer hardware, so that an application program can interact with the hardware only by obeying rules and procedures programmed into the operating system.  The operating system is also a set of services which simplify development and execution of application programs. Executing an application program involves the creation of a process by the operating system [[kernel (computer science)|kernel]] which assigns memory space and other resources, establishes a priority for the process in multi-tasking systems, loads program binary code into memory, and initiates execution of the application program which then interacts with the user and with hardware devices.

====Interrupts====
{{Main|Interrupt}}

[[Interrupt]]s are central to operating systems, as they provide an efficient way for the operating system to interact with and react to its environment.  The alternative{{snd}} having the operating system "watch" the various sources of input for events (polling) that require action{{snd}} can be found in older systems with very small [[Call stack|stacks]] (50 or 60 bytes) but is unusual in modern systems with large stacks. [[Interrupt]]-based programming is directly supported by most modern CPUs. Interrupts provide a computer with a way of automatically saving local register contexts, and running specific code in response to events. Even very basic computers support hardware interrupts, and allow the programmer to specify code which may be run when that event takes place.

When an interrupt is received, the computer's hardware automatically suspends whatever program is currently running, saves its status, and runs computer code previously associated with the interrupt; this is analogous to placing a bookmark in a book in response to a phone call.  In modern operating systems, interrupts are handled by the operating system's [[kernel (computer science)|kernel]]. Interrupts may come from either the computer's hardware or the running program.

When a hardware device triggers an interrupt, the operating system's kernel decides how to deal with this event, generally by running some processing code. The amount of code being run depends on the priority of the interrupt (for example: a person usually responds to a smoke detector alarm before answering the phone). The processing of hardware interrupts is a task that is usually delegated to software called a [[device drivers|device driver]], which may be part of the operating system's kernel, part of another program, or both. Device drivers may then relay information to a running program by various means.

A program may also trigger an interrupt to the operating system. If a program wishes to access hardware, for example, it may interrupt the operating system's kernel, which causes control to be passed back to the kernel. The kernel then processes the request.  If a program wishes additional resources (or wishes to shed resources) such as memory, it triggers an interrupt to get the kernel's attention.

====Modes====
{{Main|User mode|Supervisor mode}}
[[File:Priv rings.svg|300px|thumb|right|Privilege rings for the [[x86]] microprocessor architecture available in [[protected mode]]. Operating systems determine which processes run in each mode.]]

Modern [[microprocessor]]s (CPU or MPU) support multiple modes of operation. CPUs with this capability offer at least two modes: [[user mode]] and [[supervisor mode]]. In general terms, supervisor mode operation allows unrestricted access to all machine resources, including all MPU instructions.  User mode operation sets limits on instruction use and typically disallows direct access to machine resources. CPUs might have other modes similar to user mode as well, such as the virtual modes in order to emulate older processor types, such as 16-bit processors on a 32-bit one, or 32-bit processors on a [[64-bit computing|64-bit]] one.

At power-on or reset, the system begins in supervisor mode. Once an operating system [[kernel (computer science)|kernel]] has been loaded and started, the boundary between user mode and supervisor mode (also known as kernel mode) can be established.

Supervisor mode is used by the kernel for low level tasks that need unrestricted access to hardware, such as controlling how memory is accessed, and communicating with devices such as disk drives and video display devices. User mode, in contrast, is used for almost everything else. Application programs, such as word processors and database managers, operate within user mode, and can only access machine resources by turning control over to the kernel, a process which causes a switch to supervisor mode.  Typically, the transfer of control to the kernel is achieved by executing a [[software interrupt]] instruction, such as the Motorola 68000 &lt;code&gt;TRAP&lt;/code&gt; instruction.  The software interrupt causes the microprocessor to switch from user mode to supervisor mode and begin executing code that allows the kernel to take control.

In user mode, programs usually have access to a restricted set of microprocessor instructions, and generally cannot execute any instructions that could potentially cause disruption to the system's operation.  In supervisor mode, instruction execution restrictions are typically removed, allowing the kernel unrestricted access to all machine resources.

The term "user mode resource" generally refers to one or more CPU registers, which contain information that the running program isn't allowed to alter. Attempts to alter these resources generally causes a switch to supervisor mode, where the operating system can deal with the illegal operation the program was attempting, for example, by forcibly terminating ("killing") the program).

====Memory management====
{{Main|Memory management}}

Among other things, a multiprogramming operating system [[kernel (computer science)|kernel]] must be responsible for managing all system memory which is currently in use by programs. This ensures that a program does not interfere with memory already in use by another program. Since programs time share, each program must have independent access to memory.

Cooperative memory management, used by many early operating systems, assumes that all programs make voluntary use of the [[kernel (computer science)|kernel]]'s memory manager, and do not exceed their allocated memory. This system of memory management is almost never seen any more, since programs often contain bugs which can cause them to exceed their allocated memory. If a program fails, it may cause memory used by one or more other programs to be affected or overwritten. Malicious programs or viruses may purposefully alter another program's memory, or may affect the operation of the operating system itself. With cooperative memory management, it takes only one misbehaved program to crash the system.

[[Memory protection]] enables the [[kernel (computer science)|kernel]] to limit a process' access to the computer's memory. Various methods of memory protection exist, including [[memory segmentation]] and [[paging]]. All methods require some level of hardware support (such as the [[80286]] MMU), which doesn't exist in all computers.

In both segmentation and paging, certain [[protected mode]] registers specify to the CPU what memory address it should allow a running program to access. Attempts to access other addresses trigger an interrupt which cause the CPU to re-enter [[supervisor mode]], placing the [[kernel (computer science)|kernel]] in charge. This is called a [[segmentation violation]] or Seg-V for short, and since it is both difficult to assign a meaningful result to such an operation, and because it is usually a sign of a misbehaving program, the [[kernel (computer science)|kernel]] generally resorts to terminating the offending program, and reports the error.

Windows versions 3.1 through ME had some level of memory protection, but programs could easily circumvent the need to use it. A [[general protection fault]] would be produced, indicating a segmentation violation had occurred; however, the system would often crash anyway.

====Virtual memory====
{{Main|Virtual memory}}
{{Further|Page fault}}
[[File:Virtual memory.svg|thumb|250px|Many operating systems can "trick" programs into using memory scattered around the hard disk and RAM as if it is one continuous chunk of memory, called virtual memory.]]

The use of virtual memory addressing (such as paging or segmentation) means that the kernel can choose what memory each program may use at any given time, allowing the operating system to use the same memory locations for multiple tasks.

If a program tries to access memory that isn't in its current range of accessible memory, but nonetheless has been allocated to it, the kernel is interrupted in the same way as it would if the program were to exceed its allocated memory. (See section on memory management.) Under UNIX this kind of interrupt is referred to as a [[page fault]].

When the kernel detects a page fault it generally adjusts the virtual memory range of the program which triggered it, granting it access to the memory requested. This gives the kernel discretionary power over where a particular application's memory is stored, or even whether or not it has actually been allocated yet.

In modern operating systems, memory which is accessed less frequently can be temporarily stored on disk or other media to make that space available for use by other programs. This is called [[paging|swapping]], as an area of memory can be used by multiple programs, and what that memory area contains can be swapped or exchanged on demand.

"Virtual memory" provides the programmer or the user with the perception that there is a much larger amount of RAM in the computer than is really there.&lt;ref name="Operating System"&gt;{{cite book|last=Stallings|first=William|title=Computer Organization &amp; Architecture|year=2008|publisher=Prentice-Hall of India Private Limited|location=New Delhi|isbn=978-81-203-2962-1|page=267}}&lt;/ref&gt;

====Multitasking====
{{Unreferenced section|date=December 2018}}
{{Main|Computer multitasking|Process management (computing)}}
{{Further|Context switch|Preemptive multitasking|Cooperative multitasking}}

[[Computer multitasking|Multitasking]] refers to the running of multiple independent computer programs on the same computer; giving the appearance that it is performing the tasks at the same time. Since most computers can do at most one or two things at one time, this is generally done via time-sharing, which means that each program uses a share of the computer's time to execute.

An operating system [[kernel (computer science)|kernel]] contains a [[scheduling (computing)|scheduling]] program which determines how much time each process spends executing, and in which order execution control should be passed to programs. Control is passed to a process by the kernel, which allows the program access to the [[Central processing unit|CPU]] and memory. Later, control is returned to the kernel through some mechanism, so that another program may be allowed to use the CPU. This so-called passing of control between the kernel and applications is called a [[context switch]].

An early model which governed the allocation of time to programs was called [[cooperative multitasking]]. In this model, when control is passed to a program by the kernel, it may execute for as long as it wants before explicitly returning control to the kernel. This means that a malicious or malfunctioning program may not only prevent any other programs from using the CPU, but it can hang the entire system if it enters an [[infinite loop]].

Modern operating systems extend the concepts of application preemption to device drivers and kernel code, so that the operating system has preemptive control over internal run-times as well.

The philosophy governing [[preemptive multitasking]] is that of ensuring that all programs are given regular time on the CPU. This implies that all programs must be limited in how much time they are allowed to spend on the CPU without being interrupted. To accomplish this, modern operating system kernels make use of a timed interrupt. A [[protected mode]] timer is set by the kernel which triggers a return to supervisor mode after the specified time has elapsed. (See above sections on Interrupts and Dual Mode Operation.)

On many single user operating systems cooperative multitasking is perfectly adequate, as home computers generally run a small number of well tested programs. The [[AmigaOS]] is an exception, having preemptive multitasking from its first version. [[Windows NT]] was the first version of [[Microsoft Windows]] which enforced preemptive multitasking, but it didn't reach the home user market until [[Windows XP]] (since [[Windows NT]] was targeted at professionals).

====Disk access and file systems====
{{Main|Virtual file system}}
{{Unreferenced section|date=December 2018}}
[[File:Dolphin FileManager.png|thumb|256px|File systems allow users and programs to organize and sort files on a computer, often through the use of directories (or "folders").]]

Access to data stored on disks is a central feature of all operating systems. Computers store data on [[Hard disk drive|disks]] using [[Computer file|files]], which are structured in specific ways in order to allow for faster access, higher reliability, and to make better use of the drive's available space. The specific way in which files are stored on a disk is called a [[file system]], and enables files to have names and attributes. It also allows them to be stored in a hierarchy of directories or folders arranged in a [[Directory (computing)|directory tree]].

Early operating systems generally supported a single type of disk drive and only one kind of file system. Early file systems were limited in their capacity, speed, and in the kinds of file names and directory structures they could use. These limitations often reflected limitations in the operating systems they were designed for, making it very difficult for an operating system to support more than one file system.

While many simpler operating systems support a limited range of options for accessing storage systems, operating systems like [[Unix|UNIX]] and [[Linux]] support a technology known as a [[virtual file system]] or VFS. An operating system such as UNIX supports a wide array of storage devices, regardless of their design or [[file system]]s, allowing them to be accessed through a common [[application programming interface]] (API). This makes it unnecessary for programs to have any knowledge about the device they are accessing. A VFS allows the operating system to provide programs with access to an unlimited number of devices with an infinite variety of file systems installed on them, through the use of specific [[device driver]]s and file system drivers.

A connected [[data storage|storage device]], such as a [[hard disk drive|hard drive]], is accessed through a [[device driver]]. The device driver understands the specific language of the drive and is able to translate that language into a standard language used by the operating system to access all disk drives. On UNIX, this is the language of [[block device]]s.

When the kernel has an appropriate device driver in place, it can then access the contents of the disk drive in raw format, which may contain one or more file systems. A file system driver is used to translate the commands used to access each specific file system into a standard set of commands that the operating system can use to talk to all file systems. Programs can then deal with these file systems on the basis of filenames, and directories/folders, contained within a hierarchical structure. They can create, delete, open, and close files, as well as gather various information about them, including access permissions, size, free space, and creation and modification dates.

Various differences between file systems make supporting all file systems difficult. Allowed characters in file names, [[case sensitivity]], and the presence of various kinds of [[file attribute]]s makes the implementation of a single interface for every file system a daunting task. Operating systems tend to recommend using (and so support natively) file systems specifically designed for them; for example, [[NTFS]] in Windows and [[ext3]] and [[ReiserFS]] in Linux. However, in practice, third party drivers are usually available to give support for the most widely used file systems in most general-purpose operating systems (for example, NTFS is available in Linux through [[NTFS-3G|NTFS-3g]], and ext2/3 and ReiserFS are available in Windows through third-party software).

Support for file systems is highly varied among modern operating systems, although there are several common file systems which almost all operating systems include support and drivers for. Operating systems vary on file system support and on the disk formats they may be installed on. Under Windows, each file system is usually limited in application to certain media; for example, CDs must use [[ISO 9660]] or [[Universal Disk Format|UDF]], and as of [[Windows Vista]], NTFS is the only file system which the operating system can be installed on.  It is possible to install Linux onto many types of file systems. Unlike other operating systems, Linux and UNIX allow any file system to be used regardless of the media it is stored in, whether it is a hard drive, a disc (CD, DVD...), a USB flash drive, or even contained within a file located on another file system.

====Device drivers====
{{Main|Device driver}}
{{Unreferenced section|date=December 2018}}
A [[device driver]] is a specific type of computer software developed to allow interaction with hardware devices. Typically this constitutes an interface for communicating with the device, through the specific computer bus or communications subsystem that the hardware is connected to, providing commands to and/or receiving data from the device, and on the other end, the requisite interfaces to the operating system and software applications. It is a specialized hardware-dependent computer program which is also operating system specific that enables another program, typically an operating system or applications software package or computer program running under the operating system kernel, to interact transparently with a hardware device, and usually provides the requisite interrupt handling necessary for any necessary asynchronous time-dependent hardware interfacing needs.

The key design goal of device drivers is [[abstraction (software engineering)|abstraction]]. Every model of hardware (even within the same class of device) is different. Newer models also are released by manufacturers that provide more reliable or better performance and these newer models are often controlled differently. Computers and their operating systems cannot be expected to know how to control every device, both now and in the future. To solve this problem, operating systems essentially dictate how every type of device should be controlled. The function of the device driver is then to translate these operating system mandated function calls into device specific calls. In theory a new device, which is controlled in a new manner, should function correctly if a suitable driver is available. This new driver ensures that the device appears to operate as usual from the operating system's point of view.

Under versions of Windows before Vista and versions of Linux before 2.6, all driver execution was co-operative, meaning that if a driver entered an infinite loop it would freeze the system. More recent revisions of these operating systems incorporate kernel preemption, where the kernel interrupts the driver to give it tasks, and then separates itself from the process until it receives a response from the device driver, or gives it more tasks to do.

===Networking===
{{Main|Computer network}}
{{Unreferenced section|date=December 2018}}
Currently most operating systems support a variety of networking protocols, hardware, and applications for using them. This means that computers running dissimilar operating systems can participate in a common [[computer network|network]] for sharing resources such as [[remote procedure call|computing]], files, printers, and scanners using either wired or wireless connections. Networks can essentially allow a computer's operating system to access the resources of a remote computer to support the same functions as it could if those resources were connected directly to the local computer. This includes everything from simple communication, to using networked file systems or even sharing another computer's graphics or sound hardware. Some network services allow the resources of a computer to be accessed transparently, such as [[Secure Shell|SSH]] which allows networked users direct access to a computer's command line interface.

Client/server networking allows a program on a computer, called a client, to connect via a network to another computer, called a server. Servers offer (or host) various services to other network computers and users. These services are usually provided through ports or numbered access points beyond the server's [[IP address]]. Each port number is usually associated with a maximum of one running program, which is responsible for handling requests to that port. A daemon, being a user program, can in turn access the local hardware resources of that computer by passing requests to the operating system kernel.

Many operating systems support one or more vendor-specific or open networking protocols as well, for example, [[Systems Network Architecture|SNA]] on [[IBM]] systems, [[DECnet]] on systems from [[Digital Equipment Corporation]], and Microsoft-specific protocols ([[Server message block|SMB]]) on Windows. Specific protocols for specific tasks may also be supported such as [[Network File System|NFS]] for file access. Protocols like [[ESound]], or esd can be easily extended over the network to provide sound from local applications, on a remote system's sound hardware.

===Security===
{{Main|Computer security}}

A computer being secure depends on a number of technologies working properly. A modern operating system provides access to a number of resources, which are available to software running on the system, and to external devices like networks via the kernel.&lt;ref&gt;{{Cite web|title=Operating Systems: Security|url=https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/15_Security.html|access-date=2020-11-27|website=www.cs.uic.edu}}&lt;/ref&gt;

The operating system must be capable of distinguishing between requests which should be allowed to be processed, and others which should not be processed. While some systems may simply distinguish between "privileged" and "non-privileged", systems commonly have a form of requester ''identity'', such as a user name. To establish identity there may be a process of ''authentication''. Often a username must be quoted, and each username may have a password. Other methods of authentication, such as magnetic cards or biometric data, might be used instead. In some cases, especially connections from the network, resources may be accessed with no authentication at all (such as reading files over a network share). Also covered by the concept of requester '''identity''' is ''authorization''; the particular services and resources accessible by the requester once logged into a system are tied to either the requester's user account or to the variously configured groups of users to which the requester belongs.{{Citation needed|date=December 2018}}

In addition to the allow or disallow model of security, a system with a high level of security also offers auditing options. These would allow tracking of requests for access to resources (such as, "who has been reading this file?"). Internal security, or security from an already running program is only possible if all possibly harmful requests must be carried out through interrupts to the operating system kernel. If programs can directly access hardware and resources, they cannot be secured.{{Citation needed|date=December 2018}}

External security involves a request from outside the computer, such as a login at a connected console or some kind of network connection. External requests are often passed through device drivers to the operating system's kernel, where they can be passed onto applications, or carried out directly. Security of operating systems has long been a concern because of highly sensitive data held on computers, both of a commercial and military nature. The United States [[Government of the United States|Government]] [[United States Department of Defense|Department of Defense]] (DoD) created the ''[[Trusted Computer System Evaluation Criteria]]'' (TCSEC) which is a standard that sets basic requirements for assessing the effectiveness of security. This became of vital importance to operating system makers, because the TCSEC was used to evaluate, classify and select [[trusted operating system]]s being considered for the processing, storage and retrieval of sensitive or [[classified information]].

Network services include offerings such as file sharing, print services, email, web sites, and [[file transfer protocol]]s (FTP), most of which can have compromised security. At the front line of security are hardware devices known as [[firewall (networking)|firewalls]] or intrusion detection/prevention systems. At the operating system level, there are a number of software firewalls available, as well as intrusion detection/prevention systems. Most modern operating systems include a software firewall, which is enabled by default. A software firewall can be configured to allow or deny network traffic to or from a service or application running on the operating system. Therefore, one can install and be running an insecure service, such as Telnet or FTP, and not have to be threatened by a security breach because the firewall would deny all traffic trying to connect to the service on that port.

An alternative strategy, and the only [[sandbox (computer security)|sandbox]] strategy available in systems that do not meet the [[Popek and Goldberg virtualization requirements]], is where the operating system is not running user programs as native code, but instead either [[emulator|emulates]] a processor or provides a host for a [[p-code machine|p-code]] based system such as Java.

Internal security is especially relevant for multi-user systems; it allows each user of the system to have private files that the other users cannot tamper with or read. Internal security is also vital if auditing is to be of any use, since a program can potentially bypass the operating system, inclusive of bypassing auditing.

===User interface===
{{Main|Shell (computing){{!}}Operating system user interface}}
[[File:Command line.png|thumb|256px|A screenshot of the [[Bash (Unix shell)|Bash]] command line. Each command is typed out after the 'prompt', and then its output appears below, working its way down the screen. The current command prompt is at the bottom.]]

Every computer that is to be operated by an individual requires a [[user interface]]. The user interface is usually referred to as a [[shell (computing)|shell]] and is essential if human interaction is to be supported.  The user interface views the [[directory structure]] and requests services from the operating system that will acquire data from [[input device|input hardware devices]], such as a [[keyboard (computing)|keyboard]], [[mouse (computing)|mouse]] or [[credit card|credit card reader]], and requests operating system services to display [[Command-line interface#Command prompt|prompts]], [[status message]]s and such on [[output device|output hardware devices]], such as a [[computer monitor|video monitor]] or [[printer (computing)|printer]]. The two most common forms of a user interface have historically been the [[command-line interface]], where computer commands are typed out line-by-line, and the [[graphical user interface]], where a visual environment (most commonly a [[WIMP (computing)|WIMP]]) is present.

====Graphical user interfaces====
[[File:KDE Plasma 5.16.png|thumb|left|256px|A screenshot of the [[KDE Plasma 5]] graphical user interface. Programs take the form of images on the screen, and the files, folders (directories), and applications take the form of icons and symbols. A mouse is used to navigate the computer.]]

Most of the modern computer systems support [[graphical user interface]]s (GUI), and often include them. In some computer systems, such as the original implementation of the [[classic Mac OS]], the GUI is integrated into the [[kernel (computer science)|kernel]].

While technically a graphical user interface is not an operating system service, incorporating support for one into the operating system kernel can allow the GUI to be more responsive by reducing the number of [[context switch]]es required for the GUI to perform its output functions. Other operating systems are [[modular programming|modular]], separating the graphics subsystem from the kernel and the Operating System. In the 1980s UNIX, VMS and many others had operating systems that were built this way. Linux and macOS are also built this way. Modern releases of Microsoft Windows such as [[Windows Vista]] implement a graphics subsystem that is mostly in user-space; however the graphics drawing routines of versions between [[Windows NT 4.0]] and [[Windows Server 2003]] exist mostly in kernel space. [[Windows 9x]] had very little distinction between the interface and the kernel.

Many computer operating systems allow the user to install or create any user interface they desire. The [[X&amp;nbsp;Window System]] in conjunction with [[GNOME]] or [[KDE Plasma 5]] is a commonly found setup on most Unix and [[Unix-like]] (BSD, Linux, Solaris) systems. A number of [[Windows shell replacement]]s have been released for Microsoft Windows, which offer alternatives to the included [[Windows shell]], but the shell itself cannot be separated from Windows.

Numerous Unix-based GUIs have existed over time, most derived from X11. Competition among the various vendors of Unix (HP, IBM, Sun) led to much fragmentation, though an effort to standardize in the 1990s to [[Common Open Software Environment|COSE]] and [[Common Desktop Environment|CDE]] failed for various reasons, and were eventually eclipsed by the widespread adoption of GNOME and [[KDE|K Desktop Environment]]. Prior to [[free software]]-based toolkits and desktop environments, Motif was the prevalent toolkit/desktop combination (and was the basis upon which CDE was developed).

Graphical user interfaces evolve over time. For example, Windows has modified its user interface almost every time a new major version of Windows is released, and the Mac&amp;nbsp;OS GUI changed dramatically with the introduction of Mac&amp;nbsp;OS&amp;nbsp;X in 1999.&lt;ref name="intro-date"&gt;Poisson, Ken. [http://www.islandnet.com/~kpolsson/compsoft/soft1998.htm "Chronology of Personal Computer Software"] {{webarchive|url=https://web.archive.org/web/20080514022217/http://www.islandnet.com/~kpolsson/compsoft/soft1998.htm |date=14 May 2008 }}. Retrieved on 2008-05-07. Last checked on 2009-03-30.&lt;/ref&gt;

==Real-time operating systems==
{{Main|Real-time operating system}}

A real-time operating system (RTOS) is an operating system intended for applications with fixed deadlines ([[real-time computing]]). Such applications include some small [[embedded system]]s, automobile engine controllers, industrial robots, spacecraft, industrial control, and some large-scale computing systems.

An early example of a large-scale real-time operating system was [[Transaction Processing Facility]] developed by [[American Airlines]] and [[IBM]] for the [[Sabre (computer system)|Sabre Airline Reservations System]].

Embedded systems that have fixed deadlines use a [[real-time operating system]] such as [[VxWorks]], [[PikeOS]], [[eCos]], [[QNX]], [[MontaVista|MontaVista Linux]] and [[RTLinux]]. [[Windows CE]] is a [[real-time operating system]] that shares similar APIs to desktop Windows but shares none of desktop Windows' codebase.&lt;ref&gt;{{Cite web|url=https://courses.lumenlearning.com/sanjacinto-computerapps-v2/chapter/reading-operating-system/|title=Reading: Operating System|website=Lumen|access-date=5 January 2019}}&lt;/ref&gt; [[Symbian|Symbian OS]] also has an RTOS kernel (EKA2) starting with version 8.0b.

Some embedded systems use operating systems such as [[Palm OS]], [[BSD (operating system)|BSD]], and [[Linux]], although such operating systems do not support real-time computing.

==Operating system development as a hobby==
{{main|Hobbyist operating system development}}
A hobby operating system may be classified as one whose code has not been directly derived from an existing operating system, and has few users and active developers.{{citation needed|date=November 2020}}

In some cases, hobby development is in support of a "[[Homebrew Computer Club|homebrew]]" computing device, for example, a simple [[single-board computer]] powered by a [[6502 microprocessor]].  Or, development may be for an architecture already in widespread use.  Operating system development may come from entirely new concepts, or may commence by modeling an existing operating system.  In either case, the hobbyist is his/her own developer, or may interact with a small and sometimes unstructured group of individuals who have like interests.

Examples of a hobby operating system include [[Syllable (operating system)|Syllable]] and [[TempleOS]].

==Diversity of operating systems and portability==
Application software is generally written for use on a specific operating system, and sometimes even for specific hardware.{{Citation needed|date = April 2015}} When porting the application to run on another OS, the functionality required by that application may be implemented differently by that OS (the names of functions, meaning of arguments, etc.) requiring the application to be adapted, changed, or otherwise [[software maintenance|maintained]].&lt;!--There really ought to be a discussion of ''software modules'' somewhere, such as those that are neither API's nor Plug-Ins (not sure what those are), but which are either hard (on cartridge), soft (on diskette), or otherwise installable by downloading). --&gt;

Unix was the first operating system not written in assembly language, making it very [[software portability|portable]] to systems different from its native [[PDP-11]].&lt;ref name="byte198308"&gt;{{cite news | url=https://archive.org/stream/byte-magazine-1983-08/1983_08_BYTE_08-08_The_C_Language#page/n189/mode/2up | title=The History of Unix | work=BYTE | date=August 1983 | access-date=31 January 2015 | pages=188}}&lt;/ref&gt;

This cost in supporting operating systems diversity can be avoided by instead writing applications against [[software platform]]s such as [[Java (software platform)|Java]] or [[Qt (software)|Qt]]. These abstractions have already borne the cost of adaptation to specific operating systems and their [[system library|system libraries]].

Another approach is for operating system vendors to adopt standards. For example, [[POSIX]] and [[operating system abstraction layer|OS abstraction layers]] provide commonalities that reduce porting costs.

==Market share==

{{Further|Usage share of operating systems}}

==See also==

{{div col}}
* [[Comparison of operating systems]]
* [[Crash (computing)]]
* [[Hypervisor]]
* [[Interruptible operating system]]
* [[List of important publications in computer science#Operating systems|List of important publications in operating systems]]
* [[List of operating systems]]
* [[List of pioneers in computer science]]
* [[Live CD]]
* [[Glossary of operating systems terms]]
* [[Microcontroller]]
* [[Mobile device]]
* [[Mobile operating system]]
* [[Network operating system]]
* [[Object-oriented operating system]]
* [[Operating System Projects]]
* [[System Commander]]
* [[System image]]
* [[Timeline of operating systems]]
{{div col end}}

==References==
{{Reflist|30em}}

==Further reading==
{{Refbegin}}
* {{cite journal | last =Auslander | first =Marc A. |author2=Larkin, David C. |author3=Scherr, Allan L.| title = The evolution of the MVS Operating System | publisher = IBM J. Research &amp; Development | year=1981 | url=http://www.research.ibm.com/journal/rd/255/auslander.pdf }}
* {{cite book | last = Deitel | first = Harvey M. | author2 = Deitel, Paul | author3 = Choffnes, David | title = Operating Systems | date = 25 December 2015 | publisher = Pearson/Prentice Hall | isbn = 978-0-13-092641-8 | url-access = registration | url = https://archive.org/details/modernoperatings00tane }}
* {{cite book | last = Bic| first = Lubomur F. |author2=Shaw, Alan C. | title = Operating Systems | publisher = [[Prentice Hall]] | year = 2003 | location = Pearson  }}
* {{cite book | last = Silberschatz | first = Avi |author2=Galvin, Peter |author3=Gagne, Greg | title = Operating Systems Concepts | publisher = [[John Wiley &amp; Sons]] | year = 2008 | isbn = 978-0-470-12872-5 }}
* O'Brien, J. A., &amp; Marakas, G. M.(2011). ''Management Information Systems''. 10e. McGraw-Hill Irwin.
* {{cite book |last1=Leva |first1=Alberto |last2=Maggio |first2=Martina |last3=Papadopoulos |first3=Alessandro Vittorio |last4=Terraneo |first4=Federico |title=Control-based Operating System Design |publisher=[[Institution of Engineering and Technology|IET]] |year=2013 |isbn=978-1-84919-609-3}}
* {{cite book |last1=Arpaci-Dusseau |first1=Remzi |last2=Arpaci-Dusseau |first2=Andrea |year=2015 |url=http://pages.cs.wisc.edu/~remzi/OSTEP/ |title=Operating Systems: Three Easy Pieces}}
{{Refend}}

==External links==
{{Wiktionary}}
{{Commons category|Operating systems}}
{{Wikiversity|Operating Systems}}
* {{curlie|Computers/Software/Operating_Systems|Operating Systems}}
* [http://www.cbi.umn.edu/iterations/haigh.html Multics History] and the history of operating systems

{{Operating system}}
{{Systems science}}
{{Computer science}}
{{Authority control}}

[[Category:Operating systems| ]]
[[Category:Computer science]]</text>
      <sha1>5wfzz2h576zg66vvjlevkfq5vszojq4</sha1>
    </revision>
  </page>
  <page>
    <title>Kernel (operating system)</title>
    <ns>0</ns>
    <id>21346982</id>
    <revision>
      <id>1012960036</id>
      <parentid>1012959075</parentid>
      <timestamp>2021-03-19T07:51:02Z</timestamp>
      <contributor>
        <username>PohranicniStraze</username>
        <id>13080272</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/2001:56A:74A3:8B00:870:A8D3:BFBE:A636|2001:56A:74A3:8B00:870:A8D3:BFBE:A636]] ([[User talk:2001:56A:74A3:8B00:870:A8D3:BFBE:A636|talk]]) to last version by Tea2min</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="76066" xml:space="preserve">{{short description|Core of a computer operating system}}
{{redirect|Kernel (computing)||Kernel (disambiguation)#Computing{{!}}Kernel (disambiguation)}}
{{redirect distinguish|Kernel (computer science)|Compute kernel|Kernel method|Kernel (image processing)}}

The '''kernel''' is a [[computer program]] at the core of a computer's [[operating system]] that has complete control over everything in the system.&lt;ref name=Linfo /&gt; It is the "portion of the operating system code that is always resident in memory",&lt;ref&gt;{{cite book |author1=Randal E. Bryant |author2=David R. O’Hallaron |title=Computer Systems: A Programmer's Perspective |date=2016 |publisher=Pearson |isbn=978-0134092669 |page=17 |edition=Third}}&lt;/ref&gt; and facilitates interactions between hardware and software components. On most systems, the kernel is one of the first programs loaded on [[Booting|startup]] (after the [[bootloader]]). It handles the rest of startup as well as memory, [[peripheral]]s, and [[input/output]] (I/O) requests from [[software]], translating them into [[Data processing|data-processing]] instructions for the [[central processing unit]].

[[File:Kernel Layout.svg|thumb|A kernel connects the [[application software]] to the hardware of a computer.]]

The critical code of the kernel is usually loaded into a separate area of memory, which is protected from access by [[Application software|application programs]] or other, less critical parts of the operating system. The kernel performs its tasks, such as running processes, managing hardware devices such as the [[hard disk]], and handling interrupts, in this protected [[kernel space]]. In contrast, [[application program]]s like browsers, word processors, or audio or video players  use a separate area of memory, [[user space]]. This separation prevents user data and kernel data from interfering with each other and causing instability and slowness,&lt;ref name="Linfo"&gt;{{cite web |url=http://www.linfo.org/kernel.html |title=Kernel |website=Linfo |publisher=Bellevue Linux Users Group |access-date=15 September 2016}}&lt;/ref&gt; as well as preventing malfunctioning application programs from crashing the entire operating system.

The kernel's [[Application programming interface|interface]] is a [[High- and low-level|low-level]] [[abstraction layer]]. When a [[Process (computing)|process]] requests a service to the kernel, it must invoke a [[system call]], usually through a wrapper function that is exposed to userspace applications by system libraries which embed the assembly code for entering the kernel after loading the CPU [[Register allocation|registers]] with the syscall number and its parameters (e.g., UNIX-like operating systems accomplish this task using the [[C standard library]]).

There are different kernel architecture designs. [[Monolithic kernel]]s run entirely in a single [[address space]] with the CPU executing in [[Protection ring|supervisor mode]], mainly for speed. [[Microkernel]]s run most but not all of their services in user space,&lt;ref&gt;cf. [[Daemon (computing)]]&lt;/ref&gt; like user processes do, mainly for resilience and [[Modular programming|modularity]].&lt;ref name="mono-micro"&gt;Roch 2004&lt;/ref&gt; [[MINIX 3]] is a notable example of microkernel design. Instead, the [[Linux kernel]] is monolithic, although it is also modular, for it can insert and remove [[loadable kernel module]]s at runtime.

This central component of a computer system is responsible for 'running' or 'executing' programs. The kernel takes responsibility for deciding at any time which of the many running programs should be allocated to the processor or processors.

== Random-access memory ==
[[Random-access memory]] (RAM) is used to store both program instructions and data.{{NoteTag|It may depend on the [[Computer architecture]]}} Typically, both need to be present in memory in order for a program to execute. Often multiple programs will want access to memory, frequently demanding more memory than the computer has available. The kernel is responsible for deciding which memory each process can use, and determining what to do when not enough memory is available.

== Input/output devices ==
I/O devices include such peripherals as keyboards, mice, disk drives, printers, [[USB]] devices, network adapters, and [[display device]]s. The kernel allocates requests from applications to perform I/O to an appropriate device and provides convenient methods for using the device (typically abstracted to the point where the application does not need to know implementation details of the device).

==Resource management==
Key aspects necessary in [[Resource management (computing)|resource management]] are defining the execution domain ([[Virtual address space|address space]]) and the protection mechanism used to mediate access to the resources within a domain.&lt;ref name="Wulf74"&gt;Wulf 1974 pp.337–345&lt;/ref&gt; Kernels also provide methods for [[synchronization (computer science)|synchronization]] and [[inter-process communication]] (IPC). These implementations may be within the kernel itself or the kernel can also rely on other processes it is running. Although the kernel must provide IPC in order to provide access to the facilities provided by each other, kernels must also provide running programs with a method to make requests to access these facilities. The kernel is also responsible for context switching between processes or threads.

==Memory management==
{{More|Memory management (operating systems)}}
The kernel has full access to the system's memory and must allow processes to safely access this memory as they require it. Often the first step in doing this is [[virtual addressing]], usually achieved by [[paging]] and/or [[Segmentation (memory)|segmentation]]. Virtual addressing allows the kernel to make a given physical address appear to be another address, the virtual address. Virtual address spaces may be different for different processes; the memory that one process accesses at a particular (virtual) address may be different memory from what another process accesses at the same address. This allows every program to behave as if it is the only one (apart from the kernel) running and thus prevents applications from crashing each other.&lt;ref name="OS-Concepts"&gt;Silberschatz 1991&lt;/ref&gt;

On many systems, a program's virtual address may refer to data which is not currently in memory. The layer of indirection provided by virtual addressing allows the operating system to use other data stores, like a [[hard drive]], to store what would otherwise have to remain in main memory ([[Random-access memory|RAM]]). As a result, operating systems can allow programs to use more memory than the system has physically available. When a program needs data which is not currently in RAM, the CPU signals to the kernel that this has happened, and the kernel responds by writing the contents of an inactive memory block to disk (if necessary) and replacing it with the data requested by the program. The program can then be resumed from the point where it was stopped. This scheme is generally known as [[demand paging]].

Virtual addressing also allows creation of virtual partitions of memory in two disjointed areas, one being reserved for the kernel ([[kernel space]]) and the other for the applications ([[user space]]). The applications are not permitted by the processor to address kernel memory, thus preventing an application from damaging the running kernel. This fundamental partition of memory space has contributed much to the current designs of actual general-purpose kernels and is almost universal in such systems, although some research kernels (e.g., [[Singularity (operating system)|Singularity]]) take other approaches.

==Device management==
To perform useful functions, processes need access to the [[peripheral]]s connected to the computer, which are controlled by the kernel through [[device driver]]s. A device driver is a computer program that enables the operating system to interact with a hardware device. It provides the operating system with information of how to control and communicate with a certain piece of hardware. The driver is an important and vital piece to a program application. The design goal of a driver is abstraction; the function of the driver is to translate the OS-mandated abstract function calls (programming calls) into device-specific calls. In theory, the device should work correctly with the suitable driver. Device drivers are used for such things as video cards, sound cards, printers, scanners, modems, and LAN cards.

At the hardware level, common abstractions of device drivers include:
* Interfacing directly
* Using a high-level interface (Video [[BIOS]])
* Using a lower-level device driver (file drivers using disk drivers)
* Simulating work with hardware, while doing something entirely different

And at the software level, device driver abstractions include:
* Allowing the operating system direct access to hardware resources
* Only implementing primitives
* Implementing an interface for non-driver software such as [[TWAIN]]
* Implementing a language (often a high-level language such as [[PostScript]])

For example, to show the user something on the screen, an application would make a request to the kernel, which would forward the request to its display driver, which is then responsible for actually plotting the character/pixel.&lt;ref name="OS-Concepts"/&gt;

A kernel must maintain a list of available devices. This list may be known in advance (e.g., on an [[embedded system]] where the kernel will be rewritten if the available hardware changes), configured by the user (typical on older PCs and on systems that are not designed for personal use) or detected by the operating system at run time (normally called [[plug and play]]). In plug-and-play systems, a device manager first performs a scan on different [[peripheral bus]]es, such as [[Peripheral Component Interconnect]] (PCI) or [[Universal Serial Bus]] (USB), to detect installed devices, then searches for the appropriate drivers.

As device management is a very [[Operating system|OS]]-specific topic, these drivers are handled differently by each kind of kernel design, but in every case, the kernel has to provide the [[Input/Output|I/O]] to allow drivers to physically access their devices through some [[Port (computer networking)|port]] or memory location. Important decisions have to be made when designing the device management system, as in some designs accesses may involve [[context switch]]es, making the operation very CPU-intensive and easily causing a significant performance overhead.{{Citation needed|date=July 2007}}

==System calls==
{{Main|System call}}
In computing, a system call is how a process requests a service from an operating system's kernel that it does not normally have permission to run. System calls provide the interface between a process and the operating system. Most operations interacting with the system require permissions not available to a user-level process, e.g., I/O performed with a device present on the system, or any form of communication with other processes requires the use of system calls.&lt;!-- This seems a very "narrow perspective" section, a more general approach would help --&gt;

A system call is a mechanism that is used by the application program to request a service from the operating system. They use a [[Machine code|machine-code]] instruction that causes the processor to change mode. An example would be from supervisor mode to protected mode. This is where the operating system performs actions like accessing hardware devices or the [[memory management unit]]. Generally the operating system provides a library that sits between the operating system and normal user programs. Usually it is a [[C (programming language)|C library]] such as [[Glibc]] or Windows API. The library handles the low-level details of passing information to the kernel and switching to supervisor mode. System calls include close, open, read, wait and write.

To actually perform useful work, a process must be able to access the services provided by the kernel. This is implemented differently by each kernel, but most provide a [[C library]] or an [[Application programming interface|API]], which in turn invokes the related kernel functions.&lt;ref&gt;{{cite book |last= Tanenbaum|first=Andrew S.|author-link=Andrew S. Tanenbaum |title=Modern Operating Systems |edition=3rd |year=2008 |publisher=Prentice Hall |isbn=978-0-13-600663-3 |pages=50–51 |quote=. . . nearly all system calls [are] invoked from C programs by calling a library procedure . . . The library procedure . . . executes a TRAP instruction to switch from user mode to kernel mode and start execution . . . }}&lt;/ref&gt;

The method of invoking the kernel function varies from kernel to kernel. If memory isolation is in use, it is impossible for a user process to call the kernel directly, because that would be a violation of the processor's access control rules. A few possibilities are:
* Using a software-simulated [[interrupt]]. This method is available on most hardware, and is therefore very common.
* Using a [[call gate]]. A call gate is a special address stored by the kernel in a list in kernel memory at a location known to the processor. When the processor detects a call to that address, it instead redirects to the target location without causing an access violation. This requires hardware support, but the hardware for it is quite common.
* Using a special [[system call]] instruction. This technique requires special hardware support, which common architectures (notably, [[x86]]) may lack. System call instructions have been added to recent models of x86 processors, however, and some operating systems for PCs make use of them when available.
* Using a memory-based queue. An application that makes large numbers of requests but does not need to wait for the result of each may add details of requests to an area of memory that the kernel periodically scans to find requests.

==Kernel design decisions==

===Protection===
An important consideration in the design of a kernel is the support it provides for protection from faults ([[fault tolerance]]) and from malicious behaviours ([[computer security|security]]). These two aspects are usually not clearly distinguished, and the [[Separation of protection and security|adoption of this distinction]] in the kernel design leads to the rejection of a [[hierarchical protection domains|hierarchical structure for protection]].&lt;ref name="Wulf74" /&gt;

The mechanisms or policies provided by the kernel can be classified according to several criteria, including: static (enforced at [[compile time]]) or dynamic (enforced at [[Run time (program lifecycle phase)|run time]]); pre-emptive or post-detection; according to the protection principles they satisfy (e.g., [[Peter J. Denning|Denning]]&lt;ref name="Denning76"&gt;Denning 1976&lt;/ref&gt;&lt;ref name="Swift05Denning76"&gt;Swift 2005, p.29 quote: "isolation, resource control, decision verification (checking), and error recovery."&lt;/ref&gt;); whether they are hardware supported or language based;  whether they are more an open mechanism or a binding policy; and many more.

Support for hierarchical protection domains&lt;ref name="Schroeder72"&gt;Schroeder 72&lt;/ref&gt; is typically implemented using [[CPU modes]].

Many kernels provide implementation of "capabilities", i.e., objects that are provided to user code which allow limited access to an underlying object managed by the kernel. A common example is file handling: a file is a representation of information stored on a permanent storage device. The kernel may be able to perform many different operations, including read, write, delete or execute, but a user-level application may only be permitted to perform some of these operations (e.g., it may only be allowed to read the file).  A common implementation of this is for the kernel to provide an object to the application (typically so called a "file handle") which the application may then invoke operations on, the validity of which the kernel checks at the time the operation is requested. Such a system may be extended to cover all objects that the kernel manages, and indeed to objects provided by other user applications.

An efficient and simple way to provide hardware support of capabilities is to delegate to the [[memory management unit]] (MMU) the responsibility of checking access-rights for every memory access, a mechanism called [[capability-based addressing]].&lt;ref name="LindenCapabilityAddressing"&gt;Linden 76&lt;/ref&gt; Most commercial computer architectures lack such MMU support for capabilities.

An alternative approach is to simulate capabilities using commonly supported hierarchical domains. In this approach, each protected object must reside in an address space that the application does not have access to; the kernel also maintains a list of capabilities in such memory.  When an application needs to access an object protected by a capability, it performs a system call and the kernel then checks whether the application's capability grants it permission to perform the requested action, and if it is permitted performs the access for it (either directly, or by delegating the request to another user-level process).  The performance cost of address space switching limits the practicality of this approach in systems with complex interactions between objects, but it is used in current operating systems for objects that are not accessed frequently or which are not expected to perform quickly.&lt;ref name="EranianMosberger"&gt;Stephane Eranian and David Mosberger, [http://www.informit.com/articles/article.aspx?p=29961 Virtual Memory in the IA-64 Linux Kernel], Prentice Hall PTR, 2002&lt;/ref&gt;&lt;ref&gt;Silberschatz &amp; Galvin, Operating System Concepts, 4th ed, pp. 445 &amp; 446&lt;/ref&gt;

If the firmware does not support protection mechanisms, it is possible to simulate protection at a higher level, for example by simulating capabilities by manipulating [[page table]]s, but there are performance implications.&lt;ref name="HochBrowne"&gt;{{cite journal | last = Hoch  | first = Charles |author2=J. C. Browne  |date=July 1980
 | title = An implementation of capabilities on the PDP-11/45
 | journal = ACM SIGOPS Operating Systems Review
 | volume = 14
 | issue = 3
 | pages = 22–32
 | doi = 10.1145/850697.850701
 | s2cid = 17487360 
 }}&lt;/ref&gt; Lack of hardware support may not be an issue, however, for systems that choose to use language-based protection.&lt;ref name="Schneider"&gt;[https://www.cs.cmu.edu/~rwh/papers/langsec/dagstuhl.pdf A Language-Based Approach to Security], Schneider F., Morrissett G. (Cornell University) and Harper R. (Carnegie Mellon University)&lt;/ref&gt;

An important kernel design decision is the choice of the abstraction levels where the security mechanisms and policies should be implemented. Kernel security mechanisms play a critical role in supporting security at higher levels.&lt;ref name="LindenCapabilityAddressing" /&gt;&lt;ref name="Loscocco98"/&gt;&lt;ref&gt;{{Cite book |doi = 10.1145/504450.504477|chapter = The persistent relevance of the local operating system to global applications|title = Proceedings of the 7th workshop on ACM SIGOPS European workshop Systems support for worldwide applications - EW 7|pages = 133|year = 1996|last1 = Lepreau|first1 = Jay|last2 = Ford|first2 = Bryan|last3 = Hibler|first3 = Mike|s2cid = 10027108}}&lt;/ref&gt;&lt;ref&gt;J. Anderson, ''[http://csrc.nist.gov/publications/history/ande72.pdf Computer Security Technology Planning Study] {{Webarchive|url=https://web.archive.org/web/20110721060319/http://csrc.nist.gov/publications/history/ande72.pdf |date=2011-07-21 }}, Air Force Elect. Systems Div., ESD-TR-73-51, October 1972.&lt;/ref&gt;&lt;ref&gt;* {{cite journal|author1=Jerry H. Saltzer |author2=Mike D. Schroeder | title = The protection of information in computer systems| journal = Proceedings of the IEEE| volume = 63
| issue = 9| pages = 1278–1308| date = September 1975| url = http://web.mit.edu/Saltzer/www/publications/protection/| doi = 10.1109/PROC.1975.9939 |citeseerx=10.1.1.126.9257 |s2cid=269166 }}&lt;/ref&gt;

One approach is to use firmware and kernel support for fault tolerance (see above), and build the security policy for malicious behavior on top of that (adding features such as [[cryptography]] mechanisms where necessary), delegating some responsibility to the [[compiler]]. Approaches that delegate enforcement of security policy to the compiler and/or the application level are often called ''[[language-based security]]''.

The lack of many critical security mechanisms in current mainstream operating systems impedes the implementation of adequate security policies at the application [[abstraction level]].&lt;ref name="Loscocco98"&gt;P. A. Loscocco, S. D. Smalley, P. A. Muckelbauer, R. C. Taylor, S. J. Turner, and J. F. Farrell. ''[http://www.jya.com/paperF1.htm The Inevitability of Failure: The Flawed Assumption of Security in Modern Computing Environments] {{webarchive|url=https://web.archive.org/web/20070621155813/http://jya.com/paperF1.htm |date=2007-06-21 }}''. In Proceedings of the 21st National Information Systems Security Conference, pages 303–314, Oct. 1998. [http://csrc.nist.gov/nissc/1998/proceedings/paperF1.pdf].&lt;/ref&gt; In fact, a common misconception in computer security is that any security policy can be implemented in an application regardless of kernel support.&lt;ref name="Loscocco98"/&gt;

====Hardware- or language-based protection====
Typical computer systems today use hardware-enforced rules about what programs are allowed to access what data. The processor monitors the execution and stops a program that violates a rule, such as a user process that tries to write to kernel memory. In systems that lack support for capabilities, processes are isolated from each other by using separate address spaces.&lt;ref&gt;{{cite journal|
doi=10.1145/319344.319163|
title=EROS: a fast capability system|author1=Jonathan S. Shapiro |author2=Jonathan M. Smith |author3=David J. Farber |
journal=Proceedings of the Seventeenth ACM Symposium on Operating Systems Principles|
volume=33|
issue=5|
pages=170–185|
year=1999}}&lt;/ref&gt; Calls from user processes into the kernel are regulated by requiring them to use one of the above-described system call methods.

An alternative approach is to use language-based protection. In a [[Language-based system|language-based protection system]], the kernel will only allow code to execute that has been produced by a trusted language [[compiler]]. The language may then be designed such that it is impossible for the programmer to instruct it to do something that will violate a security requirement.&lt;ref name="Schneider"/&gt;

Advantages of this approach include:
* No need for separate address spaces. Switching between address spaces is a slow operation that causes a great deal of overhead, and a lot of optimization work is currently performed in order to prevent unnecessary switches in current operating systems. Switching is completely unnecessary in a language-based protection system, as all code can safely operate in the same address space.
* Flexibility. Any protection scheme that can be designed to be expressed via a programming language can be implemented using this method. Changes to the protection scheme (e.g. from a hierarchical system to a capability-based one) do not require new hardware.

Disadvantages include:
* Longer application startup time. Applications must be verified when they are started to ensure they have been compiled by the correct compiler, or may need recompiling either from source code or from [[bytecode]].
* Inflexible [[type system]]s. On traditional systems, applications frequently perform operations that are not [[type safety|type safe]]. Such operations cannot be permitted in a language-based protection system, which means that applications may need to be rewritten and may, in some cases, lose performance.

Examples of systems with language-based protection include [[JX (operating system)|JX]] and [[Microsoft]]'s [[Singularity (operating system)|Singularity]].

===Process cooperation===
[[Edsger Dijkstra]] proved that from a logical point of view, [[Atomicity (programming)|atomic]] [[Lock (computer science)|lock]] and unlock operations operating on binary [[Semaphore (programming)|semaphores]] are sufficient primitives to express any functionality of process cooperation.&lt;ref name="Dijkstra65"&gt;Dijkstra, E. W. ''Cooperating Sequential Processes''. Math. Dep., Technological U., Eindhoven, Sept. 1965.&lt;/ref&gt; However this approach is generally held to be lacking in terms of safety and efficiency, whereas a [[message passing]] approach is more flexible.&lt;ref name="Hansen70"&gt;Brinch Hansen 70 pp.238–241&lt;/ref&gt;  A number of other approaches (either lower- or higher-level) are available as well, with many modern kernels providing support for systems such as [[Shared memory (interprocess communication)|shared memory]] and [[remote procedure call]]s.

===I/O device management===
The idea of a kernel where I/O devices are handled uniformly with other processes, as parallel co-operating processes, was first proposed and implemented by [[Brinch Hansen]] (although similar ideas were suggested in 1967&lt;ref&gt;{{cite web | title=SHARER, a time sharing system for the CDC 6600 | url=http://portal.acm.org/citation.cfm?id=363778&amp;dl=ACM&amp;coll=GUIDE&amp;CFID=11111111&amp;CFTOKEN=2222222 | access-date=2007-01-07}}&lt;/ref&gt;&lt;ref&gt;{{cite web | title=Dynamic Supervisors – their design and construction | url=http://portal.acm.org/citation.cfm?id=811675&amp;dl=ACM&amp;coll=GUIDE&amp;CFID=11111111&amp;CFTOKEN=2222222 | access-date=2007-01-07}}&lt;/ref&gt;). In Hansen's description of this, the "common" processes are called ''internal processes'', while the I/O devices are called ''external processes''.&lt;ref name="Hansen70" /&gt;

Similar to physical memory, allowing applications direct access to controller ports and registers can cause the controller to malfunction, or system to crash. With this, depending on the complexity of the device, some devices can get surprisingly complex to program, and use several different controllers. Because of this, providing a more abstract interface to manage the device is important. This interface is normally done by a [[device driver]] or hardware abstraction layer. Frequently, applications will require access to these devices. The kernel must maintain the list of these devices by querying the system for them in some way. This can be done through the BIOS, or through one of the various system buses (such as PCI/PCIE, or USB). When an application requests an operation on a device (Such as displaying a character), the kernel needs to send this request to the current active video driver. The video driver, in turn, needs to carry out this request. This is an example of [[inter-process communication]] (IPC).

==Kernel-wide design approaches==
Naturally, the above listed tasks and features can be provided in many ways that differ from each other in design and implementation.

The principle of ''[[separation of mechanism and policy]]'' is the substantial difference between the philosophy of micro and monolithic kernels.&lt;ref&gt;Baiardi 1988&lt;/ref&gt;&lt;ref name="Levin75"&gt;Levin 75&lt;/ref&gt; Here a ''mechanism'' is the support that allows the implementation of many different policies, while a policy is a particular "mode of operation". Example:  

* '''Mechanism:''' User login attempts are routed to an authorization server
* '''Policy:''' Authorization server requires a password which is verified against stored passwords in a database

Because the mechanism and policy are separated, the policy can be easily changed to e.g. require the use of a [[security token]].

In minimal microkernel just some very basic policies are included,&lt;ref name="Levin75" /&gt; and its mechanisms allows what is running on top of the kernel (the remaining part of the operating system and the other applications) to decide which policies to adopt (as memory management, high level process scheduling, file system management, etc.).&lt;ref name="Wulf74" /&gt;&lt;ref name="Hansen70" /&gt; A monolithic kernel instead tends to include many policies, therefore restricting the rest of the system to rely on them.

[[Per Brinch Hansen]] presented arguments in favour of separation of mechanism and policy.&lt;ref name="Wulf74" /&gt;&lt;ref name="Hansen70" /&gt; The failure to properly fulfill this separation is one of the major causes of the lack of substantial innovation in existing operating systems,&lt;ref name="Wulf74" /&gt; a problem common in computer architecture.&lt;ref name="Denning80"&gt;Denning 1980&lt;/ref&gt;&lt;ref name="Nehmer91"&gt;Jürgen Nehmer, "[http://portal.acm.org/citation.cfm?id=723612 The Immortality of Operating Systems, or: Is Research in Operating Systems still Justified?]", ''Lecture Notes In Computer Science''; Vol. 563. Proceedings of the International Workshop on Operating Systems of the 90s and Beyond. pp. 77–83 (1991) {{ISBN|3-540-54987-0}} [https://link.springer.com/chapter/10.1007%2FBFb0024528#page-1] quote: "The past 25 years have shown that research on operating system architecture had a minor effect on existing main stream{{sic}} systems."&lt;/ref&gt;&lt;ref&gt;Levy 84, p.1 quote: "Although the complexity of computer applications increases yearly, the underlying hardware architecture for applications has remained unchanged for decades."&lt;/ref&gt; The monolithic design is induced by the "kernel mode"/"user mode" architectural approach to protection (technically called [[hierarchical protection domains]]), which is common in conventional commercial systems;&lt;ref name="Levy84privilegedmode"&gt;Levy 84, p.1 quote: "Conventional architectures support a single privileged mode of
operation. This structure leads to monolithic design; any module needing protection must be part of the single operating system kernel. If, instead, any module could execute within a protected domain, systems could be built as a collection of independent modules extensible by any user."&lt;/ref&gt; in fact, every module needing protection is therefore preferably included into the kernel.&lt;ref name="Levy84privilegedmode"/&gt; This link between monolithic design and "privileged mode" can be reconducted to the key issue of mechanism-policy separation;&lt;ref name="Wulf74"/&gt; in fact the "privileged mode" architectural approach melds together the protection mechanism with the security policies, while the major alternative architectural approach, [[capability-based addressing]], clearly distinguishes between the two, leading naturally to a microkernel design&lt;ref name="Wulf74"/&gt; (see [[Separation of protection and security]]).

While [[monolithic kernel]]s execute all of their code in the same address space ([[kernel space]]), [[microkernel]]s try to run most of their services in user space, aiming to improve maintainability and modularity of the codebase.&lt;ref name="mono-micro"/&gt; Most kernels do not fit exactly into one of these categories, but are rather found in between these two designs. These are called [[hybrid kernel]]s. More exotic designs such as [[nanokernel]]s and [[exokernel]]s are available, but are seldom used for production systems. The [[Xen]] hypervisor, for example, is an exokernel.

===Monolithic kernels===
{{Main|Monolithic kernel}}
[[File:kernel-simple.svg|thumb|upright|Diagram of a monolithic kernel]]
In a monolithic kernel, all OS services run along with the main kernel thread, thus also residing in the same memory area. This approach provides rich and powerful hardware access. Some developers, such as [[Unix|UNIX]] developer [[Ken Thompson]], maintain that it is "easier to implement a monolithic kernel"&lt;ref name="Linuxisobsoletedebate"&gt;{{cite web|url=https://www.oreilly.com/openbook/opensources/book/appa.html|title=Open Sources: Voices from the Open Source Revolution|date=29 March 1999|website=1-56592-582-3}}&lt;/ref&gt; than microkernels. The main disadvantages of monolithic kernels are the dependencies between system components{{snd}} a bug in a device driver might crash the entire system{{snd}} and the fact that large kernels can become very difficult to maintain.

Monolithic kernels, which have traditionally been used by Unix-like operating systems, contain all the operating system core functions and the device drivers. This is the traditional design of UNIX systems. A monolithic kernel is one single program that contains all of the code necessary to perform every kernel-related task. Every part which is to be accessed by most programs which cannot be put in a library is in the kernel space: Device drivers, scheduler, memory handling, file systems, and network stacks. Many system calls are provided to applications, to allow them to access all those services. A monolithic kernel, while initially loaded with subsystems that may not be needed, can be tuned to a point where it is as fast as or faster than the one that was specifically designed for the hardware, although more relevant in a general sense. Modern monolithic kernels, such as those of [[Linux_kernel|Linux]] (one of the kernels of the [[GNU]] operating system) and [[FreeBSD]], both of which fall into the category of Unix-like operating systems, feature the ability to load modules at runtime, thereby allowing easy extension of the kernel's capabilities as required, while helping to minimize the amount of code running in kernel space. In the monolithic kernel, some advantages hinge on these points:

* Since there is less software involved it is faster.
* As it is one single piece of software it should be smaller both in source and compiled forms.
* Less code generally means fewer bugs which can translate to fewer security problems.

Most work in the monolithic kernel is done via system calls. These are interfaces, usually kept in a tabular structure, that access some subsystem within the kernel such as disk operations. Essentially calls are made within programs and a checked copy of the request is passed through the system call. Hence, not far to travel at all. The monolithic [[Linux_kernel|Linux]] kernel can be made extremely small not only because of its ability to dynamically load modules but also because of its ease of customization. In fact, there are some versions that are small enough to fit together with a large number of utilities and other programs on a
single floppy disk and still provide a fully functional operating system (one of the most popular of which is [[muLinux]]). This ability to miniaturize its kernel has also led to a rapid growth in the use of [[GNU]]/[[Linux_kernel|Linux]] in [[embedded system]]s.

These types of kernels consist of the core functions of the operating system and the device drivers with the ability to load modules at runtime. They provide rich and powerful abstractions of the underlying hardware. They provide a small set of simple hardware abstractions and use applications called servers to provide more functionality. This particular approach defines a high-level virtual interface over the hardware, with a set of system calls to implement operating system services such as process management, concurrency and memory management in several modules that run in supervisor mode.
This design has several flaws and limitations:
* Coding in kernel can be challenging, in part because one cannot use common libraries (like a full-featured [[C standard library|libc]]), and because one needs to use a source-level debugger like [[GNU Debugger|gdb]].  Rebooting the computer is often required. This is not just a problem of convenience to the developers. When debugging is harder, and as difficulties become stronger, it becomes more likely that code will be "buggier".
* Bugs in one part of the kernel have strong side effects; since every function in the kernel has all the privileges, a bug in one function can corrupt data structure of another, totally unrelated part of the kernel, or of any running program.
* Kernels often become very large and difficult to maintain.
* Even if the modules servicing these operations are separate from the whole, the code integration is tight and difficult to do correctly.
* Since the modules run in the same [[address space]], a bug can bring down the entire system.
* Monolithic kernels are not portable; therefore, they must be rewritten for each new architecture that the operating system is to be used on.

[[File:Kernel-microkernel.svg|thumb|260px|In the [[microkernel]] approach, the kernel itself only provides basic functionality that allows the execution of [[Server (computing)|servers]], separate programs that assume former kernel functions, such as device drivers, GUI servers, etc.]]

Examples of monolithic kernels are [[IBM AIX|AIX]] kernel, HP-UX kernel and Solaris kernel.

===Microkernels===&lt;!-- This section is linked from [[Unix philosophy]] --&gt;
{{Main|Microkernel}}

Microkernel (also abbreviated μK or uK) is the term describing an approach to operating system design by which the functionality of the system is moved out of the traditional "kernel", into a set of "servers" that communicate through a "minimal" kernel, leaving as little as possible in "system space" and as much as possible in "user space". A microkernel that is designed for a specific platform or device is only ever going to have what it needs to operate. The microkernel approach consists of defining a simple abstraction over the hardware, with a set of primitives or [[system call]]s to implement minimal OS services such as [[memory management]], [[Computer multitasking|multitasking]], and [[inter-process communication]]. Other services, including those normally provided by the kernel, such as [[Computer networking|networking]], are implemented in user-space programs, referred to as ''servers''. Microkernels are easier to maintain than monolithic kernels, but the large number of system calls and [[context switch]]es might slow down the system because they typically generate more overhead than plain function calls.

Only parts which really require being in a privileged mode are in kernel space: IPC (Inter-Process Communication), basic scheduler, or scheduling primitives, basic memory handling, basic I/O primitives. Many critical parts are now running in user space: The complete scheduler, memory handling, file systems, and network stacks. Micro kernels were invented as a reaction to traditional "monolithic" kernel design, whereby all system functionality was put in a one static program running in a special "system" mode of the processor. In the microkernel, only the most fundamental of tasks are performed such as being able to access some (not necessarily all) of the hardware, manage memory and coordinate message passing between the processes. Some systems that use micro kernels are QNX and the HURD. In the case of [[QNX]] and [[GNU Hurd|Hurd]] user sessions can be entire snapshots of the system itself or views as it is referred to. The very essence of the microkernel architecture illustrates some of its advantages:

* Easier to maintain
* Patches can be tested in a separate instance, and then swapped in to take over a production instance.
* Rapid development time and new software can be tested without having to reboot the kernel.
* More persistence in general, if one instance goes haywire, it is often possible to substitute it with an operational mirror.

Most microkernels use a [[message passing]] system to handle requests from one server to another. The message passing system generally operates on a [[Port (computer networking)|port]] basis with the microkernel. As an example, if a request for more memory is sent, a port is opened with the microkernel and the request sent through. Once within the microkernel, the steps are similar to system calls. The rationale was that it would bring modularity in the system architecture, which would entail a cleaner system, easier to debug or dynamically modify, customizable to users' needs, and more performing. They are part of the operating systems like [[GNU Hurd]], [[MINIX]], [[MkLinux]], [[QNX]] and [[Redox OS]].  Although microkernels are very small by themselves, in combination with all their required auxiliary code they are, in fact, often larger than monolithic kernels. Advocates of monolithic kernels also point out that the two-tiered structure of microkernel systems, in which most of the operating system does not interact directly with the hardware, creates a not-insignificant cost in terms of system efficiency. These types of kernels normally provide only the minimal services such as defining memory address spaces, inter-process communication (IPC) and the process management. The other functions such as running the hardware processes are not handled directly by microkernels. Proponents of micro kernels point out those monolithic kernels have the disadvantage that an error in the kernel can cause the entire system to crash. However, with a microkernel, if a kernel process crashes, it is still possible to prevent a crash of the system as a whole by merely restarting the service that caused the error.

Other services provided by the kernel such as networking are implemented in user-space programs referred to as ''servers''. Servers allow the operating system to be modified by simply starting and stopping programs. For a machine without networking support, for instance, the networking server is not started. The task of moving in and out of the kernel to move data between the various applications and servers creates overhead which is detrimental to the efficiency of micro kernels in comparison with monolithic kernels.

Disadvantages in the microkernel exist however. Some are:

* Larger running [[memory footprint]]
* More software for interfacing is required, there is a potential for performance loss.
* Messaging bugs can be harder to fix due to the longer trip they have to take versus the one off copy in a monolithic kernel.
* Process management in general can be very complicated.

The disadvantages for microkernels are extremely context-based. As an example, they work well for small single-purpose (and critical) systems because if not many processes need to run, then the complications of process management are effectively mitigated.

A microkernel allows the implementation of the remaining part of the operating system as a normal application program written in a [[high-level language]], and the use of different operating systems on top of the same unchanged kernel. It is also possible to dynamically switch among operating systems and to have more than one active simultaneously.&lt;ref name="Hansen70" /&gt;

===Monolithic kernels vs. microkernels===
As the computer kernel grows, so grows the size and vulnerability of its [[trusted computing base]]; and, besides reducing security, there is the problem of enlarging the [[memory footprint]]. This is mitigated to some degree by perfecting the [[virtual memory]] system, but not all [[computer architecture]]s have virtual memory support.&lt;ref&gt;Virtual addressing is most commonly achieved through a built-in [[memory management unit]].&lt;/ref&gt; To reduce the kernel's footprint, extensive editing has to be performed to carefully remove unneeded code, which can be very difficult with non-obvious interdependencies between parts of a kernel with millions of lines of code.

By the early 1990s, due to the various shortcomings of monolithic kernels versus microkernels, monolithic kernels were considered obsolete by virtually all operating system researchers.{{citation needed|date = June 2015}} As a result, the design of [[Linux (kernel)|Linux]] as a monolithic kernel rather than a microkernel was the topic of a famous debate between [[Linus Torvalds]] and [[Andrew S. Tanenbaum|Andrew Tanenbaum]].&lt;ref name="TorvaldsTanenbaum"&gt;Recordings of the debate between Torvalds and Tanenbaum can be found at [http://www.dina.dk/~abraham/Linus_vs_Tanenbaum.html dina.dk] {{webarchive|url=https://web.archive.org/web/20121003060514/http://www.dina.dk/~abraham/Linus_vs_Tanenbaum.html |date=2012-10-03 }}, [http://groups.google.com/group/comp.os.minix/browse_thread/thread/c25870d7a41696d2/f447530d082cd95d?tvc=2#f447530d082cd95d groups.google.com], [http://www.oreilly.com/catalog/opensources/book/appa.html oreilly.com] and [http://www.cs.vu.nl/~ast/reliable-os/ Andrew Tanenbaum's website]&lt;/ref&gt; There is merit on both sides of the argument presented in the [[Tanenbaum–Torvalds debate]].

====Performance====
[[Monolithic kernel]]s are designed to have all of their code in the same address space ([[kernel space]]), which some developers argue is necessary to increase the performance of the system.&lt;ref name="MatthewRussell"/&gt; Some developers also maintain that monolithic systems are extremely efficient if well written.&lt;ref name="MatthewRussell"&gt;{{cite web|
url=http://oreilly.com/pub/a/mac/2005/09/27/what-is-darwin.html?page=2|
title=What Is Darwin (and How It Powers Mac OS X)|
author=Matthew Russell|
publisher=[[O'Reilly Media]]}} quote: "The tightly coupled nature of a monolithic kernel allows it to make very efficient use of the underlying hardware [...] Microkernels, on the other hand, run a lot more of the core processes in userland. [...] Unfortunately, these benefits come at the cost of the microkernel having to pass a lot of information in and out of the kernel space through a process known as a context switch. Context switches introduce considerable overhead and therefore result in a performance penalty."&lt;/ref&gt; The monolithic model tends to be more efficient&lt;ref&gt;{{cite web|url=https://en.wikiversity.org/wiki/Operating_Systems/Kernel_Models|title=Operating Systems/Kernel Models - Wikiversity|website=en.wikiversity.org}}&lt;/ref&gt; through the use of shared kernel memory, rather than the slower IPC system of microkernel designs, which is typically based on [[message passing]].{{Citation needed|date=July 2007}}

The performance of microkernels was poor in both the 1980s and early 1990s.&lt;ref name="Liedtke95"&gt;Liedtke 95&lt;/ref&gt;&lt;ref name="Hartig97"&gt;Härtig 97&lt;/ref&gt; However, studies that empirically measured the performance of these microkernels did not analyze the reasons of such inefficiency.&lt;ref name="Liedtke95"/&gt; The explanations of this data were left to "folklore"&lt;!-- Someone needs to clarify what is meant by folklore --&gt;, with the assumption that they were due to the increased frequency of switches from "kernel-mode" to "user-mode", to the increased frequency of [[inter-process communication]] and to the increased frequency of [[context switch]]es.&lt;ref name="Liedtke95"/&gt; &lt;!-- Remains to be covered in this section the impact (particularly on context switch frequency) of the implementation of device drivers as processes or procedures --&gt;

In fact, as guessed in 1995, the reasons for the poor performance of microkernels might as well have been: (1) an actual inefficiency of the whole microkernel ''approach'', (2) the particular ''concepts'' implemented in those microkernels, and (3) the particular ''implementation'' of those concepts. Therefore it remained to be studied if the solution to build an efficient microkernel was, unlike previous attempts, to apply the correct construction techniques.&lt;ref name="Liedtke95"/&gt;

On the other end, the [[hierarchical protection domains]] architecture that leads to the design of a monolithic kernel&lt;ref name="Levy84privilegedmode"/&gt; has a significant performance drawback each time there's an interaction between different levels of protection (i.e., when a process has to manipulate a data structure both in "user mode" and "supervisor mode"), since this requires message copying [[Call-by-value|by value]].&lt;ref name="Hansen73SupervisorMode"&gt;Hansen 73, section 7.3 p.233 "''interactions between different levels of protection require transmission of messages by value''"&lt;/ref&gt;

[[File:Kernel-hybrid.svg|thumb|260px|The [[hybrid kernel]] approach combines the speed and simpler design of a monolithic kernel with the modularity and execution safety of a microkernel.]]

===Hybrid (or modular) kernels===
{{Main|Hybrid kernel}}

Hybrid kernels are used in most commercial operating systems such as [[Microsoft Windows]] NT 3.1, NT 3.5, NT 3.51, NT 4.0, 2000, XP, Vista, 7, 8, 8.1 and 10. [[Apple Inc]]'s own [[macOS]] uses a hybrid kernel called [[XNU]] which is based upon code from [[OSF/1]]'s [[Mach kernel]] (OSFMK 7.3)&lt;ref&gt;{{cite web|url=https://www.youtube.com/watch?v=ggnFoDqzGMU|title=Apple WWDC 2000 Session 106 - Mac OS X: Kernel|last=Apple WWDC Videos|date=19 February 2017|via=YouTube}}&lt;/ref&gt; and [[FreeBSD]]'s [[monolithic kernel]]. They are similar to micro kernels, except they include some additional code in kernel-space to increase performance. These kernels represent a compromise that was implemented by some developers to accommodate the major advantages of both monolithic and micro kernels. These types of kernels are extensions of micro kernels with some properties of monolithic kernels. Unlike monolithic kernels, these types of kernels are unable to load modules at runtime on their own. Hybrid kernels are micro kernels that have some "non-essential" code in kernel-space in order for the code to run more quickly than it would were it to be in user-space. Hybrid kernels are a compromise between the monolithic and microkernel designs. This implies running some services (such as the [[network stack]] or the [[filesystem]]) in kernel space to reduce the performance overhead of a traditional microkernel, but still running kernel code (such as device drivers) as servers in user space.

Many traditionally monolithic kernels are now at least adding (or else using) the module capability. The most well known of these kernels is the Linux kernel. The modular kernel essentially can have parts of it that are built into the core kernel binary or binaries that load into memory on demand. It is important to note that a code tainted module has the potential to destabilize a running kernel. Many people become confused on this point when discussing micro kernels. It is possible to write a driver for a microkernel in a completely separate memory space and test it before "going" live. When a kernel module is loaded, it accesses the monolithic portion's memory space by adding to it what it needs, therefore, opening the doorway to possible pollution. A few advantages to the modular (or) Hybrid kernel are:

* Faster development time for drivers that can operate from within modules. No reboot required for testing (provided the kernel is not destabilized).
* On demand capability versus spending time recompiling a whole kernel for things like new drivers or subsystems.
* Faster integration of third party technology (related to development but pertinent unto itself nonetheless).

Modules, generally, communicate with the kernel using a module interface of some sort. The interface is generalized (although particular to a given operating system) so it is not always possible to use modules. Often the device drivers may need more flexibility than the module interface affords. Essentially, it is two system calls and often the safety checks that only have to be done once in the monolithic kernel now may be done twice. Some of the disadvantages of the modular approach are:

* With more interfaces to pass through, the possibility of increased bugs exists (which implies more security holes).
* Maintaining modules can be confusing for some administrators when dealing with problems like symbol differences.

===Nanokernels===
{{Main|Nanokernel}}

A nanokernel delegates virtually all services{{snd}} including even the most basic ones like [[Programmable Interrupt Controller|interrupt controllers]] or the [[timer]]{{snd}} to [[device driver]]s to make the kernel memory requirement even smaller than a traditional microkernel.&lt;ref&gt;[http://www.cis.upenn.edu/~KeyKOS/NanoKernel/NanoKernel.html KeyKOS Nanokernel Architecture] {{webarchive|url=https://web.archive.org/web/20110621235229/http://www.cis.upenn.edu/~KeyKOS/NanoKernel/NanoKernel.html |date=2011-06-21 }}&lt;/ref&gt;

===Exokernels===
{{Main|Exokernel}}

Exokernels are a still-experimental approach to operating system design. They differ from the other types of kernels in that their functionality is limited to the protection and multiplexing of the raw hardware, providing no hardware abstractions on top of which to develop applications. This separation of hardware protection from hardware management enables application developers to determine how to make the most efficient use of the available hardware for each specific program.

Exokernels in themselves are extremely small. However, they are accompanied by library operating systems (see also [[unikernel]]), providing application developers with the functionalities of a conventional operating system. A major advantage of exokernel-based systems is that they can incorporate multiple library operating systems, each exporting a different [[API]], for example one for high level [[User Interface|UI]] development and one for [[Real-time computing|real-time]] control.

==History of kernel development==

===Early operating system kernels===
{{Main|History of operating systems}}

Strictly speaking, an operating system (and thus, a kernel) is not ''required'' to run a computer. Programs can be directly loaded and executed on the "bare metal" machine, provided that the authors of those programs are willing to work without any hardware abstraction or operating system support. Most early computers operated this way during the 1950s and early 1960s, which were reset and reloaded between the execution of different programs. Eventually, small ancillary programs such as [[program loader]]s and [[debugger]]s were left in memory between runs, or loaded from [[Read-only memory|ROM]]. As these were developed, they formed the basis of what became early operating system kernels. The [[Bare machine|"bare metal"]] approach is still used today on some [[video game console]]s and [[embedded system]]s,&lt;ref name="Ball2002"&gt;Ball: Embedded Microprocessor Designs, p. 129&lt;/ref&gt; but in general, newer computers use modern operating systems and kernels.

In 1969, the [[RC 4000 Multiprogramming System]] introduced the system design philosophy of a small nucleus "upon which operating systems for different purposes could be built in an orderly manner",&lt;ref name="Hansen2001RC4k"&gt;Hansen 2001 (os), pp.17–18&lt;/ref&gt; what would be called the microkernel approach.

===Time-sharing operating systems===
{{Main|Time-sharing}}

In the decade preceding [[Unix]], computers had grown enormously in power{{snd}} to the point where computer operators were looking for new ways to get people to use their spare time on their machines. One of the major developments during this era was [[time-sharing]], whereby a number of users would get small slices of computer time, at a rate at which it appeared they were each connected to their own, slower, machine.&lt;ref&gt;{{cite web|url=http://cm.bell-labs.com/cm/cs/who/dmr/cacm.html|title=BSTJ version of C.ACM Unix paper|website=bell-labs.com}}&lt;/ref&gt;

The development of time-sharing systems led to a number of problems. One was that users, particularly at universities where the systems were being developed, seemed to want to [[Hacker (computer security)|hack]] the system to get more [[Central processing unit|CPU]] time. For this reason, [[Computer security|security]] and [[access control]] became a major focus of the [[Multics]] project in 1965.&lt;ref&gt;[http://www.multicians.org/fjcc1.html Introduction and Overview of the Multics System], by F. J. Corbató and V. A. Vissotsky.&lt;/ref&gt; Another ongoing issue was properly handling computing resources: users spent most of their time staring at the terminal and thinking about what to input instead of actually using the resources of the computer, and a time-sharing system should give the CPU time to an active user during these periods. Finally, the systems typically offered a [[memory hierarchy]] several layers deep, and partitioning this expensive resource led to major developments in [[virtual memory]] systems.

===Amiga===
{{Main|AmigaOS}}

The [[Commodore International|Commodore]] [[Amiga]] was released in 1985, and was among the first{{snd}} and certainly most successful{{snd}} home computers to feature &lt;!-- indispute at it's page: hybrid--&gt; an advanced kernel architecture. The AmigaOS kernel's executive component, ''exec.library'', uses a microkernel message-passing design, but there are other kernel components, like ''graphics.library'', that have direct access to the hardware. There is no memory protection, and the kernel is almost always running in user mode. Only special actions are executed in kernel mode, and user-mode applications can ask the operating system to execute their code in kernel mode.

===Unix===
{{Main|Unix}}
[[File:Unix history-simple.svg|300px|thumb|A diagram of the predecessor/successor family relationship for [[Unix-like]] systems]]

During the design phase of [[Unix]], programmers decided to model every high-level [[Device file|device as a file]], because they believed the purpose of [[computation]] was [[data transformation]].&lt;ref name="unix"&gt;{{cite web |url=https://www.unix.org/what_is_unix/single_unix_specification.html |title=The Single Unix Specification |work=The open group |access-date=2016-09-29 |archive-url=https://web.archive.org/web/20161004051725/http://www.unix.org/what_is_unix/single_unix_specification.html |archive-date=2016-10-04 |url-status=dead }}&lt;/ref&gt;

For instance, [[Printer (computing)|printers]] were represented as a "file" at a known location{{snd}} when data was copied to the file, it printed out. Other systems, to provide a similar functionality, tended to virtualize devices at a lower level{{snd}} that is, both devices ''and'' files would be instances of some [[Loadable kernel module|lower level]] concept. [[Virtualizing]] the system at the file level allowed users to manipulate the entire system using their existing [[file management]] utilities and concepts, dramatically simplifying operation. As an extension of the same paradigm, Unix allows programmers to manipulate files using a series of small programs, using the concept of [[pipeline (Unix)|pipes]], which allowed users to complete operations in stages, feeding a file through a chain of single-purpose tools. Although the end result was the same, using smaller programs in this way dramatically increased flexibility as well as ease of development and use, allowing the user to modify their workflow by adding or removing a program from the chain.

In the Unix model, the ''operating system'' consists of two parts: first, the huge collection of utility programs that drive most operations; second, the kernel that runs the programs.&lt;ref name="unix"/&gt; Under Unix, from a programming standpoint, the distinction between the two is fairly thin; the kernel is a program, running in supervisor mode,&lt;ref name="supervisor"&gt;The highest privilege level has various names throughout different architectures, such as supervisor mode, kernel mode, CPL0, DPL0, ring 0, etc. See [[Ring (computer security)]] for more information.&lt;/ref&gt; that acts as a program loader and supervisor for the small utility programs making up the rest of the system, and to provide [[lock (software engineering)|locking]] and [[Input/output|I/O]] services for these programs; beyond that, the kernel didn't intervene at all in [[user space]].

Over the years the computing model changed, and Unix's treatment of [[everything is a file|everything as a file]] or byte stream no longer was as universally applicable as it was before. Although a [[computer terminal|terminal]] could be treated as a file or a byte stream, which is printed to or read from, the same did not seem to be true for a [[graphical user interface]]. [[Computer networking|Networking]] posed another problem. Even if network communication can be compared to file access, the low-level packet-oriented architecture dealt with discrete chunks of data and not with whole files. As the capability of computers grew, Unix became increasingly cluttered with code. It is also because the modularity of the Unix kernel is extensively scalable.&lt;ref&gt;{{cite web|url=http://www.asymco.com/2010/09/29/unixs-revenge/|title=Unix's Revenge|date=29 September 2010|website=asymco.com}}&lt;/ref&gt; While kernels might have had 100,000 [[Source lines of code|lines of code]] in the seventies and eighties, kernels like [[Linux kernel|Linux]], of modern Unix successors like [[GNU]], have more than 13 million lines.&lt;ref&gt;[http://www.dwheeler.com/essays/linux-kernel-cost.html Linux Kernel 2.6: It's Worth More!], by David A. Wheeler, October 12, 2004&lt;/ref&gt;

Modern Unix-derivatives are generally based on module-loading monolithic kernels. Examples of this are the [[Linux kernel]] in the many [[Linux distributions|distributions]] of [[GNU]], [[IBM AIX]], as well as the [[Berkeley Software Distribution]] variant kernels such as [[FreeBSD]], [[DragonflyBSD]], [[OpenBSD]], [[NetBSD]], and [[macOS]]. Apart from these alternatives, amateur developers maintain an active [[Operating system development|operating system development community]], populated by self-written hobby kernels which mostly end up sharing many features with Linux, FreeBSD, DragonflyBSD, OpenBSD or NetBSD kernels and/or being compatible with them.&lt;ref&gt;This community mostly gathers at [http://www.osdever.net Bona Fide OS Development],  [http://www.mega-tokyo.com/forum The Mega-Tokyo Message Board] and other operating system enthusiast web sites.&lt;/ref&gt;

===Mac OS===
{{Main|Classic Mac OS|macOS}}

[[Apple Inc.|Apple]] first launched its [[classic Mac OS]] in 1984, bundled with its [[Macintosh]] [[personal computer]]. Apple moved to a nanokernel design in Mac OS 8.6. Against this, the modern [[macOS]] (originally named Mac OS X) is based on [[Darwin (operating system)|Darwin]], which uses a hybrid kernel called [[XNU]], which was created by combining the [[BSD#4;SD|4.3BSD]] kernel and the [[Mach (kernel)|Mach kernel]].&lt;ref&gt;[http://www.kernelthread.com/mac/osx/arch_xnu.html XNU: The Kernel] {{webarchive|url=https://web.archive.org/web/20110812000315/http://osxbook.com/book/bonus/ancient/whatismacosx//arch_xnu.html |date=2011-08-12 }}&lt;/ref&gt;

===Microsoft Windows===
{{Main|History of Microsoft Windows}}

[[Microsoft Windows]] was first released in 1985 as an add-on to [[MS-DOS]].  Because of its dependence on another operating system, initial releases of Windows, prior to Windows 95, were considered an [[operating environment]] (not to be confused with an [[operating system]]).  This product line continued to evolve through the 1980s and 1990s, with the [[Windows 9x]] series adding 32-bit addressing and pre-emptive multitasking; but ended with the release of [[Windows Me]] in 2000.

Microsoft also developed [[Windows NT]], an operating system with a very similar interface, but intended for high-end and business users. This line started with the release of [[Windows NT 3.1]] in 1993, and was introduced to general users with the release of [[Windows XP]] in October 2001—replacing [[Windows 9x]] with a completely different, much more sophisticated operating system. This is the line that continues with [[Windows 10]].

The [[architecture of Windows NT]]'s kernel is considered a hybrid kernel because the kernel itself contains tasks such as the Window Manager and the IPC Managers, with a client/server layered subsystem model.&lt;ref&gt;{{cite web|url=http://windows.com/|title=Windows - Official Site for Microsoft Windows 10 Home &amp; Pro OS, laptops, PCs, tablets &amp; more|website=windows.com}}&lt;/ref&gt; It was designed as a modified [[microkernel]], as the Windows NT kernel was influenced by the [[Mach (kernel)|Mach microkernel]] but does not meet all of the criteria of a pure microkernel.

=== IBM Supervisor ===
Supervisory program or supervisor is a [[computer program]], usually part of an [[operating system]], that controls the execution of other [[Subroutine|routines]] and regulates [[Scheduling (computing)|work scheduling]], [[input/output]] operations, [[Exception handling|error actions]], and similar functions and regulates the flow of work in a [[data processing]] system.

Historically, this term was essentially associated with [[IBM]]'s line of [[Mainframe computer|mainframe]] operating systems starting with [[OS/360]]. In other operating systems, the supervisor is generally called the kernel.

In the 1970s, IBM further abstracted the supervisor [[State (computer science)|state]] from the hardware, resulting in a [[hypervisor]] that enabled [[full virtualization]], i.e. the capacity to run multiple operating systems on the same machine totally independently from each other. Hence the first such system was called ''Virtual Machine'' or ''[[VM (operating system)|VM]]''.

===Development of microkernels===
Although [[Mach (kernel)|Mach]], developed by [[Richard Rashid]] at [[Carnegie Mellon University]], is the best-known general-purpose microkernel, other microkernels have been developed with more specific aims. The [[L4 microkernel family]] (mainly the L3 and the L4 kernel) was created to demonstrate that microkernels are not necessarily slow.&lt;ref name="l4"&gt;{{cite web|url=http://os.inf.tu-dresden.de/L4/overview.html|title=The L4 microkernel family - Overview|website=os.inf.tu-dresden.de}}&lt;/ref&gt; Newer implementations such as [[Fiasco (L4 clone)|Fiasco]] and [[Pistachio (L4 clone)|Pistachio]] are able to run [[Linux]] next to other L4 processes in separate address spaces.&lt;ref&gt;{{cite web|url=http://os.inf.tu-dresden.de/fiasco/overview.html|title=The Fiasco microkernel - Overview|website=os.inf.tu-dresden.de}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.l4ka.org/|title=L4Ka - L4Ka Project|first=Heinz|last=Zoller (inaktiv)|date=7 December 2013|website=www.l4ka.org}}&lt;/ref&gt;

Additionally, [[QNX]] is a microkernel which is principally used in [[embedded system]]s,&lt;ref&gt;{{cite web|url=http://blackberry.qnx.com/en/products/neutrino-rtos/index|title=QNX Operating Systems|website=blackberry.qnx.com}}&lt;/ref&gt; and the [[open-source software]] [[MINIX]], while originally created for educational purposes, is now focussed on being a [[high availability|highly reliable]] and [[Self-healing (computer science)|self-healing]] microkernel OS.

==See also==
* [[Comparison of operating system kernels]]
* [[Inter-process communication]]
* [[Operating system]]
* [[Virtual memory]]

==Notes==
{{NoteFoot|30em}}
{{Reflist|30em}}

==References==
{{Refbegin|colwidth=30em}}
* {{cite web|url=http://www.vmars.tuwien.ac.at/courses/akti12/journal/04ss/article_04ss_Roch.pdf |title=Monolithic kernel vs. Microkernel |access-date=2006-10-12 |last=Roch |first=Benjamin |year=2004 |url-status=dead |archive-url=https://web.archive.org/web/20061101012856/http://www.vmars.tuwien.ac.at/courses/akti12/journal/04ss/article_04ss_Roch.pdf |archive-date=2006-11-01 }}
* {{cite book |last=Silberschatz |first=Abraham |author-link=Abraham Silberschatz |author2=James L. Peterson |author3=Peter B. Galvin  |title=Operating system concepts |url=http://portal.acm.org/citation.cfm?id=95329&amp;dl=acm&amp;coll=&amp;CFID=15151515&amp;CFTOKEN=6184618 |year=1991 |publisher=Addison-Wesley |location=[[Boston, Massachusetts]] |isbn=978-0-201-51379-0 |page=696}}
* {{cite book |last=Ball |first=Stuart R. |title=Embedded Microprocessor Systems: Real World Designs |orig-year=2002 |edition=first |year=2002 |publisher=Elsevier Science |isbn=978-0-7506-7534-5 }}
* {{cite book |last=Deitel |first=Harvey M. |title=An introduction to operating systems |orig-year=1982 |url=https://archive.org/details/introductiontoopdeit00deit/page/673 |edition=revisited first |year=1984 |publisher=Addison-Wesley |isbn=978-0-201-14502-1 |page=[https://archive.org/details/introductiontoopdeit00deit/page/673 673] }}
* {{cite journal | author= Denning, Peter J. |title=Fault tolerant operating systems | journal = [[ACM Computing Surveys]] | pages=359–389 | volume =8 | issue = 4 |date=December 1976 |issn=0360-0300 |doi=10.1145/356678.356680 |s2cid=207736773 |author-link=P. J. Denning }}
* {{cite journal |last=Denning |first=Peter J. |author-link=Peter J. Denning |date=April 1980 |title=Why not innovations in computer architecture? |journal=ACM SIGARCH Computer Architecture News |volume=8 |issue=2 |pages=4–7 |issn=0163-5964 |doi=10.1145/859504.859506 |s2cid=14065743 }}
* {{cite journal |last=Hansen |first=Per Brinch |author-link=Per Brinch Hansen |date=April 1970 |title=The nucleus of a Multiprogramming System |journal=[[Communications of the ACM]] |volume=13 |issue=4 |pages=238–241 |issn= 0001-0782 |doi=10.1145/362258.362278 |citeseerx=10.1.1.105.4204 |s2cid=9414037 }}
* {{cite book |last=Hansen |first=Per Brinch |author-link=Per Brinch Hansen |title=Operating System Principles |url=https://archive.org/details/operatingsystemp0000brin/page/496 |publisher=Prentice Hall |location=[[Englewood Cliffs]] |isbn=978-0-13-637843-3 |page=[https://archive.org/details/operatingsystemp0000brin/page/496 496] |year=1973 }}
* {{cite journal
 | author =Hansen, Per Brinch
 | author-link =Per Brinch Hansen
 | title = The evolution of operating systems
 | year = 2001
 | url = http://brinch-hansen.net/papers/2001b.pdf
 | access-date = 2006-10-24
}} included in book: {{cite book |editor=Per Brinch Hansen |title=Classic operating systems: from batch processing to distributed systems |url=http://portal.acm.org/citation.cfm?id=360596&amp;dl=ACM&amp;coll=&amp;CFID=15151515&amp;CFTOKEN=6184618 |publisher=Springer-Verlag |location= New York |isbn=978-0-387-95113-3 |pages=1–36 |chapter=1 |chapter-url=http://brinch-hansen.net/papers/2001b.pdf |year=2001}}
* [[Hermann Härtig]], Michael Hohmuth, [[Jochen Liedtke]], Sebastian Schönberg, Jean Wolter ''[http://os.inf.tu-dresden.de/pubs/sosp97/#Karshmer:1991:OSA The performance of μ-kernel-based systems]'', {{cite book |doi=10.1145/268998.266660 |chapter=The performance of μ-kernel-based systems |title=Proceedings of the sixteenth ACM symposium on Operating systems principles - SOSP '97 |pages=66 |year=1997 |last1=Härtig |first1=Hermann |last2=Hohmuth |first2=Michael |last3=Liedtke |first3=Jochen |last4=Schönberg |first4=Sebastian |isbn=978-0897919166 |citeseerx=10.1.1.56.3314 |s2cid=1706253 }} ACM SIGOPS Operating Systems Review, v.31 n.5, p.&amp;nbsp;66–77, Dec. 1997
* Houdek, M. E., Soltis, F. G., and Hoffman, R. L. 1981. ''[http://portal.acm.org/citation.cfm?id=800052.801885 IBM System/38 support for capability-based addressing]''. In Proceedings of the 8th ACM International Symposium on Computer Architecture. ACM/IEEE, pp.&amp;nbsp;341–348.
* [[Intel Corporation]] (2002) ''[http://www.intel.com/design/pentium4/manuals/24547010.pdf The IA-32 Architecture Software Developer's Manual, Volume 1: Basic Architecture]''
* {{cite journal |doi=10.1145/1067629.806531 |last1=Levin |first1=R. |first2=E. |last2=Cohen |first3=W. |last3=Corwin |first4=F. |last4=Pollack |first5=William |last5=Wulf |author-link5=William Wulf |year=1975 |title=Policy/mechanism separation in Hydra |journal=ACM Symposium on Operating Systems Principles / Proceedings of the Fifth ACM Symposium on Operating Systems Principles |volume=9 |issue=5 |pages=132–140 }}
* {{Cite book |author=Levy, Henry M. |title=Capability-based computer systems |publisher=Digital Press |location=Maynard, Mass |year=1984 |isbn=978-0-932376-22-0 |url=http://www.cs.washington.edu/homes/levy/capabook/index.html}}
* [[Jochen Liedtke|Liedtke, Jochen]]. ''[https://web.archive.org/web/20070313142519/http://i30www.ira.uka.de/research/publications/papers/index.php?lid=en&amp;docid=642 On µ-Kernel Construction]'', ''Proc. 15th ACM Symposium on Operating System Principles (SOSP)'', December 1995
* {{cite journal |last=Linden |first=Theodore A. |title=Operating System Structures to Support Security and Reliable Software | journal = [[ACM Computing Surveys]] | pages=409–445 | volume =8 | issue = 4 |date=December 1976 |issn=0360-0300 |doi=10.1145/356678.356682 |hdl=2027/mdp.39015086560037 |s2cid=16720589 |hdl-access=free }}, {{cite web|url=http://csrc.nist.gov/publications/history/lind76.pdf |title=Operating System Structures to Support Security and Reliable Software |access-date=2010-06-19}}
* {{cite book |last=Lorin |first=Harold |title=Operating systems |url=https://archive.org/details/operatingsystems0000lori/page/161 |year=1981 |publisher=Addison-Wesley |isbn=978-0-201-14464-2 |pages=[https://archive.org/details/operatingsystems0000lori/page/161 161–186] |location=[[Boston, Massachusetts]] }}
* {{cite journal |last=Schroeder |first=Michael D. |author-link=Michael Schroeder |author2=Jerome H. Saltzer  |date=March 1972 |title=A hardware architecture for implementing protection rings |journal=[[Communications of the ACM]] |volume=15 |issue=3 |pages=157–170 |issn=0001-0782 |doi=10.1145/361268.361275 |citeseerx=10.1.1.83.8304 |s2cid=14422402 }}
* {{cite book |last=Shaw |first=Alan C. |title=The logical design of Operating systems |url=https://archive.org/details/logicaldesignofo00shaw/page/304 |year=1974 |publisher=Prentice-Hall |isbn=978-0-13-540112-5 |page=[https://archive.org/details/logicaldesignofo00shaw/page/304 304] }}
* {{cite book |last= Tanenbaum |first=Andrew S. |author-link=Andrew S. Tanenbaum |title=Structured Computer Organization |year=1979 |publisher=Prentice-Hall |location=[[Englewood Cliffs, New Jersey]]  |isbn=978-0-13-148521-1}}
* {{cite journal |last=Wulf |first=W. |author-link=William Wulf |author2=E. Cohen |author3=W. Corwin |author4=A. Jones |author5=R. Levin |author6=C. Pierson |author7=F. Pollack |date=June 1974 |title=HYDRA: the kernel of a multiprocessor operating system |journal=Communications of the ACM |volume=17 |issue=6 |pages=337–345 |issn=0001-0782 |url=http://www.cs.virginia.edu/papers/p337-wulf.pdf |doi=10.1145/355616.364017 |s2cid=8011765 |access-date=2007-07-18 |archive-url=https://web.archive.org/web/20070926161655/http://www.cs.virginia.edu/papers/p337-wulf.pdf |archive-date=2007-09-26 |url-status=dead }}
* {{cite book |last=Baiardi |first=F. |author2=A. Tomasi |author3=M. Vanneschi |title=Architettura dei Sistemi di Elaborazione, volume 1 |url=http://www.pangloss.it/libro.php?isbn=882042746X&amp;id=4357&amp;PHPSESSID=9da1895b18ed1cda115cf1c7ace9bdf0 |year=1988 |publisher=Franco Angeli |language=it |isbn=978-88-204-2746-7 |access-date=2006-10-10 |archive-url=https://web.archive.org/web/20120627162353/http://www.pangloss.it/libro.php?isbn=882042746X&amp;id=4357&amp;PHPSESSID=9da1895b18ed1cda115cf1c7ace9bdf0 |archive-date=2012-06-27 |url-status=dead }}
* {{cite book |last=Swift |first=Michael M. |author2=Brian N. Bershad |author3=Henry M. Levy  |url=http://nooks.cs.washington.edu/nooks-tocs.pdf |title=Improving the reliability of commodity operating systems}}
* {{cite journal|url=http://doi.acm.org/10.1145/1047915.1047919 |title=Improving the reliability of commodity operating systems |journal=Software: Practice and Experience |volume=20 |pages=S35–S67 |doi=10.1002/spe.4380201404 |access-date=2010-06-19|year=1990 |last1=Gettys |first1=James |last2=Karlton |first2=Philip L. |last3=McGregor |first3=Scott |s2cid=26329062 }}
* {{cite web|title=ACM Transactions on Computer Systems (TOCS), v.23 n.1, p.&amp;nbsp;77–110, February 2005 }}
{{refend}}

==Further reading==
* [[Andrew Tanenbaum]], ''Operating Systems – Design and Implementation (Third edition)'';
* Andrew Tanenbaum, ''Modern Operating Systems (Second edition)'';
* [[Daniel P. Bovet]], [[Marco Cesati]], ''The Linux Kernel'';
* [[David A. Peterson]], [[Nitin Indurkhya]], Patterson, ''Computer Organization and Design'', [[Morgan Koffman]] &lt;small&gt;({{ISBN|1-55860-428-6}})&lt;/small&gt;;
* [[B.S. Chalk]], ''Computer Organisation and Architecture'', Macmillan P.({{ISBN|0-333-64551-0}}).

==External links==
{{Wikiversity|at=Operating Systems/Kernel Models|Kernel Models}}
* [http://widefox.pbwiki.com/Kernel%20Comparison%20Linux%20vs%20Windows Detailed comparison between most popular operating system kernels]

{{Operating System}}

{{Authority control}}

{{DEFAULTSORT:Kernel (Computing)}}
[[Category:Operating system kernels|*]]
[[Category:Operating systems]]
[[Category:Computer science]]</text>
      <sha1>mfv8olegpry40pd5nklfzmupi06y6g5</sha1>
    </revision>
  </page>
  <page>
    <title>Computational tools for artificial intelligence</title>
    <ns>0</ns>
    <id>65031309</id>
    <revision>
      <id>996349041</id>
      <parentid>995829153</parentid>
      <timestamp>2020-12-26T01:58:59Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: s2cid. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Suggested by Abductive | [[Category:Artificial intelligence applications‎]] | via #UCB_Category 42/146</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="54579" xml:space="preserve">{{Lead too short|date=October 2020}}
This article discusses computational tools used in [[artificial intelligence]].

== Search and optimization ==
{{Main|Search algorithm|Mathematical optimization|Evolutionary computation}}
Many problems in AI can be solved theoretically by intelligently searching through many possible solutions:&lt;ref name="Search"&gt;[[Search algorithm|Search algorithms]]:

* {{Harvnb|Russell|Norvig|2003|pp=59–189}}
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=113–163}}
* {{Harvnb|Luger|Stubblefield|2004|pp=79–164, 193–219}}
* {{Harvnb|Nilsson|1998|loc=chpt. 7–12}}&lt;/ref&gt; [[Applications of artificial intelligence#Deduction, reasoning, problem solving|Reasoning]] can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from [[Premise|premises]] to [[Logical consequence|conclusions]], where each step is the application of an [[inference rule]].&lt;ref name="Logic as search"&gt;[[Forward chaining]], [[backward chaining]], [[Horn clause|Horn clauses]], and logical deduction as search:

* {{Harvnb|Russell|Norvig|2003|pp=217–225, 280–294}}
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=~46–52}}
* {{Harvnb|Luger|Stubblefield|2004|pp=62–73}}
* {{Harvnb|Nilsson|1998|loc=chpt. 4.2, 7.2}}&lt;/ref&gt; [[Automated planning and scheduling|Planning]] algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called [[means-ends analysis]].&lt;ref name="Planning as search"&gt;[[State space search]] and [[Automated planning and scheduling|planning]]:

* {{Harvnb|Russell|Norvig|2003|pp=382–387}}
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=298–305}}
* {{Harvnb|Nilsson|1998|loc=chpt. 10.1–2}}&lt;/ref&gt; [[Robotics]] algorithms for moving limbs and grasping objects use [[Local search (optimization)|local searches]] in [[Configuration space (physics)|configuration space]].&lt;ref name="Configuration space"&gt;Moving and [[Configuration space (physics)|configuration space]]:

* {{Harvnb|Russell|Norvig|2003|pp=916–932}}&lt;/ref&gt; Many [[Machine learning|learning]] algorithms use search algorithms based on [[Optimization (mathematics)|optimization]].

Simple exhaustive searches&lt;ref name="Uninformed search"&gt;Uninformed searches ([[breadth first search]], [[depth first search]] and general [[state space search]]):

* {{Harvnb|Russell|Norvig|2003|pp=59–93}}
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=113–132}}
* {{Harvnb|Luger|Stubblefield|2004|pp=79–121}}
* {{Harvnb|Nilsson|1998|loc=chpt. 8}}&lt;/ref&gt; are rarely sufficient for most real-world problems: the [[Search algorithm|search space]] (the number of places to search) quickly grows to [[Astronomically large|astronomical numbers]]. The result is a search that is [[Computation time|too slow]] or never completes. The solution, for many problems, is to use "[[heuristics]]" or "rules of thumb" that prioritize choices in favor of those more likely to reach a goal and to do so in a shorter number of steps. In some search methodologies heuristics can also serve to entirely eliminate some choices unlikely to lead to a goal (called "[[Pruning (algorithm)|pruning]] the [[search tree]]"). [[Heuristics]] supply the program with a "best guess" for the path on which the solution lies.&lt;ref name="Informed search"&gt;[[Heuristic]] or informed searches (e.g., greedy [[Best-first search|best first]] and [[A* search algorithm|A*]]):

* {{Harvnb|Russell|Norvig|2003|pp=94–109}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=pp. 132–147}},
* {{Harvnb|Luger|Stubblefield|2004|pp=133–150}},
* {{Harvnb|Nilsson|1998|loc=chpt. 9}},&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Poole|first1=David|url=http://artint.info/index.html|title=Artificial Intelligence: Foundations of Computational Agents|last2=Mackworth|first2=Alan|publisher=Cambridge University Press|year=2017|isbn=978-1-107-19539-4|edition=2nd|at=Section 3.6|author-link=David Poole (researcher)|author2-link=Alan Mackworth}}&lt;/ref&gt; Heuristics limit the search for solutions into a smaller sample size.&lt;ref&gt;{{cite journal|last=Tecuci|first=Gheorghe|date=March–April 2012|title=Artificial Intelligence|journal=Wiley Interdisciplinary Reviews: Computational Statistics|volume=4|issue=2|pages=168–180|doi=10.1002/wics.200}}&lt;/ref&gt;

A very different kind of search came to prominence in the 1990s, based on the mathematical theory of [[Optimization (mathematics)|optimization]]. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind [[hill climbing]]: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other optimization algorithms are [[simulated annealing]], [[beam search]] and [[random optimization]].&lt;ref name="Optimization search"&gt;[[Optimization (mathematics)|Optimization]] searches:

* {{Harvnb|Russell|Norvig|2003|pp=110–116,120–129}}
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=56–163}}
* {{Harvnb|Luger|Stubblefield|2004|pp=127–133}}&lt;/ref&gt;
[[File:ParticleSwarmArrowsAnimation.gif|thumb|A [[Particle swarm optimization|particle swarm]] seeking the [[global minimum]]]]
[[Evolutionary computation]] uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, [[Artificial selection|selecting]] only the fittest to survive each generation (refining the guesses). Classic [[evolutionary algorithms]] include [[genetic algorithms]], [[gene expression programming]], and [[genetic programming]].&lt;ref name="Genetic programming"&gt;[[Genetic programming]] and [[genetic algorithms]]:

* {{Harvnb|Luger|Stubblefield|2004|pp=509–530}},
* {{Harvnb|Nilsson|1998|loc=chpt. 4.2}}.&lt;/ref&gt;*&lt;ref&gt;{{cite book|last=Holland|first=John H.|url=https://archive.org/details/adaptationinnatu00holl|title=Adaptation in Natural and Artificial Systems|publisher=University of Michigan Press|year=1975|isbn=978-0-262-58111-0|url-access=registration}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Koza|first=John R.|title=Genetic Programming (On the Programming of Computers by Means of Natural Selection)|publisher=MIT Press|year=1992|isbn=978-0-262-11170-6|bibcode=1992gppc.book.....K}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Poli|first1=R.|url=http://www.gp-field-guide.org.uk/|title=A Field Guide to Genetic Programming|last2=Langdon|first2=W. B.|last3=McPhee|first3=N. F.|publisher=Lulu.com|year=2008|isbn=978-1-4092-0073-4|via=gp-field-guide.org.uk}}&lt;/ref&gt; Alternatively, distributed search processes can coordinate via [[swarm intelligence]] algorithms. Two popular swarm algorithms used in search are [[particle swarm optimization]] (inspired by bird [[Flocking (behavior)|flocking]]) and [[ant colony optimization]] (inspired by [[Ant trail|ant trails]]).&lt;ref name="Society based learning"&gt;[[Artificial life]] and society based learning:

* {{Harvnb|Luger|Stubblefield|2004|pp=530–541}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author1=Daniel Merkle|title=Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques|author2=Martin Middendorf|date=2013|publisher=Springer Science &amp; Business Media|isbn=978-1-4614-6940-7|editor1-last=Burke|editor1-first=Edmund K.|language=en|chapter=Swarm Intelligence|editor2-last=Kendall|editor2-first=Graham}}&lt;/ref&gt;

== Logic ==
{{Main|Logic programming|Automated reasoning}}
[[Logic]]&lt;ref name="Logic"&gt;[[Logic]]:
* {{Harvnb|Russell|Norvig|2003|pp=194–310}},
* {{Harvnb|Luger|Stubblefield|2004|pp=35–77}},
* {{Harvnb|Nilsson|1998|loc=chpt. 13–16}}&lt;/ref&gt;&lt;ref name="ACM1998"&gt;{{cite web|year=1998|title=ACM Computing Classification System: Artificial intelligence|url=http://www.acm.org/class/1998/I.2.html|url-status=dead|archive-url=https://web.archive.org/web/20071012025921/http://www.acm.org/class/1998/I.2.html|archive-date=12 October 2007|access-date=30 August 2007|publisher=[[Association for Computing Machinery|ACM]]|ref={{harvid|ACM|1998}}|df=dmy-all|at=~I.2.3 and ~I.2.4}}&lt;/ref&gt; is used for knowledge representation and problem solving, but it can be applied to other problems as well. For example, the [[satplan]] algorithm uses logic for [[Automated planning and scheduling|planning]]&lt;ref name="Satplan"&gt;[[Satplan]]:

* {{Harvnb|Russell|Norvig|2003|pp=402–407}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=300–301}},
* {{Harvnb|Nilsson|1998|loc=chpt. 21}}&lt;/ref&gt; and [[inductive logic programming]] is a method for [[Machine learning|learning]].&lt;ref name="Symbolic learning techniques"&gt;[[Explanation based learning]], relevance based learning, [[inductive logic programming]], [[case based reasoning]]:

* {{Harvnb|Russell|Norvig|2003|pp=678–710}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=414–416}},
* {{Harvnb|Luger|Stubblefield|2004|pp=~422–442}},
* {{Harvnb|Nilsson|1998|loc=chpt. 10.3, 17.5}}&lt;/ref&gt;

Several different forms of logic are used in AI research. [[Propositional logic]]&lt;ref name="Propositional logic"&gt;[[Propositional logic]]:

* {{Harvnb|Russell|Norvig|2003|pp=204–233}},
* {{Harvnb|Luger|Stubblefield|2004|pp=45–50}}
* {{Harvnb|Nilsson|1998|loc=chpt. 13}}&lt;/ref&gt; involves [[Truth function|truth functions]] such as "or" and "not". [[First-order logic]]&lt;ref name="First-order logic"&gt;[[First-order logic]] and features such as [[Equality (mathematics)|equality]]:
* {{Harvnb|Russell|Norvig|2003|pp=240–310}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=268–275}},
* {{Harvnb|Luger|Stubblefield|2004|pp=50–62}},
* {{Harvnb|Nilsson|1998|loc=chpt. 15}}&lt;/ref&gt;&lt;ref name="ACM1998"/&gt; adds [[Quantifier (logic)|quantifiers]] and [[Predicate (mathematical logic)|predicates]], and can express facts about objects, their properties, and their relations with each other. [[Fuzzy set theory]] assigns a "degree of truth" (between 0 and 1) to vague statements such as "Alice is old" (or rich, or tall, or hungry) that are too linguistically imprecise to be completely true or false. [[Fuzzy logic]] is successfully used in [[Control system|control systems]] to allow experts to contribute vague rules such as "if you are close to the destination station and moving fast, increase the train's brake pressure"; these vague rules can then be numerically refined within the system. Fuzzy logic fails to scale well in knowledge bases; many AI researchers question the validity of chaining fuzzy-logic inferences.{{efn|"There exist many different types of uncertainty, vagueness, and ignorance... [We] independently confirm the inadequacy of systems for reasoning about uncertainty that propagates numerical factors according to only to which connectives appear in assertions."&lt;ref&gt;{{cite journal|last1=Elkan|first1=Charles|title=The paradoxical success of fuzzy logic|journal=IEEE Expert|date=1994|volume=9|issue=4|pages=3–49|doi=10.1109/64.336150|citeseerx=10.1.1.100.8402|s2cid=113687}}&lt;/ref&gt;}}&lt;ref name="Fuzzy logic"&gt;[[Fuzzy logic]]:

* {{Harvnb|Russell|Norvig|2003|pp=526–527}}&lt;/ref&gt;&lt;ref&gt;{{cite news|title=What is 'fuzzy logic'? Are there computers that are inherently fuzzy and do not apply the usual binary logic?|language=en|work=Scientific American|url=https://www.scientificamerican.com/article/what-is-fuzzy-logic-are-t/|access-date=5 May 2018}}&lt;/ref&gt;

[[Default logic|Default logics]], [[Non-monotonic logic|non-monotonic logics]] and [[Circumscription (logic)|circumscription]]&lt;ref name="Default reasoning and non-monotonic logic"&gt;Default reasoning and [[default logic]], [[Non-monotonic logic|non-monotonic logics]], [[Circumscription (logic)|circumscription]], [[closed world assumption]], [[Abductive reasoning|abduction]] (Poole ''et al.'' places abduction under "default reasoning". Luger ''et al.'' places this under "uncertain reasoning"):

* {{Harvnb|Russell|Norvig|2003|pp=354–360}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=248–256, 323–335}},
* {{Harvnb|Luger|Stubblefield|2004|pp=335–363}},
* {{Harvnb|Nilsson|1998|loc=~18.3.3}}&lt;/ref&gt; are forms of logic designed to help with default reasoning and the [[qualification problem]]. Several extensions of logic have been designed to handle specific domains of [[Knowledge representation|knowledge]], such as: [[Description logic|description logics]];&lt;ref name="Representing categories and relations"&gt;Representing categories and relations: [[Semantic network|Semantic networks]], [[Description logic|description logics]], [[Inheritance (computer science)|inheritance]] (including [[Frame (artificial intelligence)|frames]] and [[Scripts (artificial intelligence)|scripts]]):

* {{Harvnb|Russell|Norvig|2003|pp=349–354}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=174–177}},
* {{Harvnb|Luger|Stubblefield|2004|pp=248–258}},
* {{Harvnb|Nilsson|1998|loc=chpt. 18.3}}&lt;/ref&gt; [[situation calculus]], [[event calculus]] and [[fluent calculus]] (for representing events and time);&lt;ref name="Representing time"&gt;Representing events and time:[[Situation calculus]], [[event calculus]], [[fluent calculus]] (including solving the [[frame problem]]):

* {{Harvnb|Russell|Norvig|2003|pp=328–341}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=281–298}},
* {{Harvnb|Nilsson|1998|loc=chpt. 18.2}}&lt;/ref&gt; [[Causality#Causal calculus|causal calculus]];&lt;ref name="Representing causation"&gt;[[Causality#Causal calculus|Causal calculus]]:

* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=335–337}}&lt;/ref&gt; [[Belief revision|belief calculus (belief revision)]];&lt;ref&gt;"The Belief Calculus and Uncertain Reasoning", Yen-Teh Hsia&lt;/ref&gt; and [[Modal logic|modal logics]].&lt;ref name="Representing knowledge about knowledge"&gt;Representing knowledge about knowledge: Belief calculus, [[Modal logic|modal logics]]:

* {{Harvnb|Russell|Norvig|2003|pp=341–344}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=275–277}}&lt;/ref&gt; Logics to model contradictory or inconsistent statements arising in multi-agent systems have also been designed, such as [[Paraconsistent logic|paraconsistent logics]].

== Probabilistic methods for uncertain reasoning ==
{{Main|Bayesian network|Hidden Markov model|Kalman filter|Particle filter|Decision theory|Utility theory}}
[[File:EM_Clustering_of_Old_Faithful_data.gif|right|frame|[[Expectation-maximization]] clustering of [[Old Faithful]] eruption data starts from a random guess but then successfully converges on an accurate clustering of the two physically distinct modes of eruption.]]
Many problems in AI (in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of powerful tools to solve these problems using methods from [[probability]] theory and economics.&lt;ref name="Stochastic methods for uncertain reasoning"&gt;Stochastic methods for uncertain reasoning:
* {{Harvnb|Russell|Norvig|2003|pp=462–644}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=345–395}},
* {{Harvnb|Luger|Stubblefield|2004|pp=165–191, 333–381}},
* {{Harvnb|Nilsson|1998|loc=chpt. 19}}&lt;/ref&gt;&lt;ref name="ACM1998"/&gt;

[[Bayesian network|Bayesian networks]]&lt;ref name="Bayesian networks"&gt;[[Bayesian network|Bayesian networks]]:

* {{Harvnb|Russell|Norvig|2003|pp=492–523}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=361–381}},
* {{Harvnb|Luger|Stubblefield|2004|pp=~182–190, ≈363–379}},
* {{Harvnb|Nilsson|1998|loc=chpt. 19.3–4}}&lt;/ref&gt; are a very general tool that can be used for various problems: reasoning (using the [[Bayesian inference]] algorithm),&lt;ref name="Bayesian inference"&gt;[[Bayesian inference]] algorithm:

* {{Harvnb|Russell|Norvig|2003|pp=504–519}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=361–381}},
* {{Harvnb|Luger|Stubblefield|2004|pp=~363–379}},
* {{Harvnb|Nilsson|1998|loc=chpt. 19.4 &amp; 7}}&lt;/ref&gt; [[Machine learning|learning]] (using the [[expectation-maximization algorithm]]),{{efn|Expectation-maximization, one of the most popular algorithms in machine learning, allows clustering in the presence of unknown [[latent variables]]&lt;ref name="Domingos2005"/&gt;{{rp|210}}}}&lt;ref name="Bayesian learning"&gt;[[Bayesian learning]] and the [[expectation-maximization algorithm]]:

* {{Harvnb|Russell|Norvig|2003|pp=712–724}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=424–433}},
* {{Harvnb|Nilsson|1998|loc=chpt. 20}}&lt;/ref&gt; [[Automated planning and scheduling|planning]] (using [[Decision network|decision networks]])&lt;ref name="Bayesian decision networks"&gt;[[Bayesian decision theory]] and Bayesian [[Decision network|decision networks]]:

* {{Harvnb|Russell|Norvig|2003|pp=597–600}}&lt;/ref&gt; and [[Machine perception|perception]] (using [[Dynamic Bayesian network|dynamic Bayesian networks]]).&lt;ref name="Stochastic temporal models"&gt;Stochastic temporal models:

* {{Harvnb|Russell|Norvig|2003|pp=537–581}}
[[Dynamic Bayesian network|Dynamic Bayesian networks]]:

* {{Harvnb|Russell|Norvig|2003|pp=551–557}}
[[Hidden Markov model]]:

* {{Harv|Russell|Norvig|2003|pp=549–551}}
[[Kalman filter|Kalman filters]]:

* {{Harvnb|Russell|Norvig|2003|pp=551–557}}&lt;/ref&gt; Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping [[Machine perception|perception]] systems to analyze processes that occur over time (e.g., [[Hidden Markov model|hidden Markov models]] or [[Kalman filter|Kalman filters]]).&lt;ref name="Stochastic temporal models" /&gt; Compared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be [[conditionally independent]] of one another. Complicated graphs with diamonds or other "loops" (undirected [[Cycle (graph theory)|cycles]]) can require a sophisticated method such as [[Markov chain Monte Carlo]], which spreads an ensemble of [[Random walk|random walkers]] throughout the Bayesian network and attempts to converge to an assessment of the conditional probabilities. Bayesian networks are used on [[Xbox Live]] to rate and match players; wins and losses are "evidence" of how good a player is{{citation needed|date=July 2019}}. [[Google AdSense|AdSense]] uses a Bayesian network with over 300&amp;nbsp;million edges to learn which ads to serve.&lt;ref name="Domingos2005"&gt;{{cite book|last1=Domingos|first1=Pedro|title=The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World|title-link=The Master Algorithm|publisher=Basic Books|year=2015|isbn=978-0-465-06192-1|author-link=Pedro Domingos}}&lt;/ref&gt;{{rp|chapter 6}}

A key concept from the science of economics is "[[utility]]": a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using [[decision theory]], [[decision analysis]], &lt;ref name="Decisions theory and analysis"&gt;[[decision theory]] and [[decision analysis]]:

* {{Harvnb|Russell|Norvig|2003|pp=584–597}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=381–394}}&lt;/ref&gt; and [[Applied information economics|information value theory]].&lt;ref name="Information value theory"&gt;[[Applied information economics|Information value theory]]:

* {{Harvnb|Russell|Norvig|2003|pp=600–604}}&lt;/ref&gt; These tools include models such as [[Markov decision process|Markov decision processes]],&lt;ref name="Markov decision process"&gt;[[Markov decision process|Markov decision processes]] and dynamic [[Decision network|decision networks]]:

* {{Harvnb|Russell|Norvig|2003|pp=613–631}}&lt;/ref&gt; dynamic [[Decision network|decision networks]],&lt;ref name="Stochastic temporal models" /&gt; [[game theory]] and [[mechanism design]].&lt;ref name="Game theory and mechanism design"&gt;[[Game theory]] and [[mechanism design]]:

* {{Harvnb|Russell|Norvig|2003|pp=631–643}}&lt;/ref&gt;

== Classifiers and statistical learning methods ==
{{Main|Classifier (mathematics)|Statistical classification|Machine learning}}
The simplest AI applications can be divided into two types: classifiers ("if shiny then diamond") and controllers ("if shiny then pick up"). Controllers do, however, also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems. [[Classifier (mathematics)|Classifiers]] are functions that use [[pattern matching]] to determine a closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class is a decision that has to be made. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.&lt;ref name="Classifiers"&gt;Statistical learning methods and [[Classifier (mathematics)|classifiers]]:

* {{Harvnb|Russell|Norvig|2003|pp=712–754}},
* {{Harvnb|Luger|Stubblefield|2004|pp=453–541}}&lt;/ref&gt;

A classifier can be trained in various ways; there are many statistical and [[machine learning]] approaches. The [[Decision tree learning|decision tree]]&lt;ref name="Decision tree"&gt;[[Alternating decision tree|Decision tree]]:

* {{Harvnb|Russell|Norvig|2003|pp=653–664}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=403–408}},
* {{Harvnb|Luger|Stubblefield|2004|pp=408–417}}&lt;/ref&gt; is perhaps the most widely used machine learning algorithm.&lt;ref name="Domingos2005"/&gt;{{rp|88}} Other widely used classifiers are the [[Artificial neural network|neural network]],&lt;ref name="Neural networks"&gt;Neural networks and connectionism:
* {{Harvnb|Russell|Norvig|2003|pp=736–748}},
* {{Harvnb|Poole|Mackworth|Goebel|1998|pp=408–414}},
* {{Harvnb|Luger|Stubblefield|2004|pp=453–505}},
* {{Harvnb|Nilsson|1998|loc=chpt. 3}}&lt;/ref&gt; [[k-nearest neighbor algorithm]],{{efn|The most widely used analogical AI until the mid-1990s&lt;ref name="Domingos2005"/&gt;{{rp|187}}}}&lt;ref name="K-nearest neighbor algorithm"&gt;[[K-nearest neighbor algorithm]]:

* {{Harvnb|Russell|Norvig|2003|pp=733–736}}&lt;/ref&gt; [[kernel methods]] such as the [[support vector machine]] (SVM),{{efn|SVM displaced k-nearest neighbor in the 1990s&lt;ref name="Domingos2005"/&gt;{{rp|188}}}}&lt;ref name="Kernel methods"&gt;[[kernel methods]] such as the [[support vector machine]]:

* {{Harvnb|Russell|Norvig|2003|pp=749–752}}&lt;/ref&gt; [[Gaussian mixture model]],&lt;ref name="Gaussian mixture model"&gt;[[Gaussian mixture model]]:

* {{Harvnb|Russell|Norvig|2003|pp=725–727}}&lt;/ref&gt; and the extremely popular [[naive Bayes classifier]].{{efn|Naive Bayes is reportedly the "most widely used learner" at Google, due in part to its scalability.&lt;ref name="Domingos2005"/&gt;{{rp|152}}}}&lt;ref name="Naive Bayes classifier"&gt;[[Naive Bayes classifier]]:

* {{Harvnb|Russell|Norvig|2003|p=718}}&lt;/ref&gt; Classifier performance depends greatly on the characteristics of the data to be classified, such as the dataset size, distribution of samples across classes, the dimensionality, and the level of noise. Model-based classifiers perform well if the assumed model is an extremely good fit for the actual data. Otherwise, if no matching model is available, and if accuracy (rather than speed or scalability) is the sole concern, conventional wisdom is that discriminative classifiers (especially SVM) tend to be more accurate than model-based classifiers such as "naive Bayes" on most practical data sets.&lt;ref name="Classifier performance"&gt;{{cite web|last1=van der Walt|first1=Christiaan|last2=Bernard|first2=Etienne|year=2006|title=Data characteristics that determine classifier performance|url=http://www.patternrecognition.co.za/publications/cvdwalt_data_characteristics_classifiers.pdf|url-status=dead|archive-url=https://web.archive.org/web/20090325194051/http://www.patternrecognition.co.za/publications/cvdwalt_data_characteristics_classifiers.pdf|archive-date=25 March 2009|access-date=5 August 2009}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last1=Russell|first1=Stuart J.|title=[[Artificial Intelligence: A Modern Approach]] &lt;!-- | url = http://aima.cs.berkeley.edu/ --&gt;|last2=Norvig|first2=Peter|publisher=Prentice Hall|year=2009|isbn=978-0-13-604259-4|edition=3rd|location=Upper Saddle River, New Jersey|author-link=Stuart J. Russell|author2-link=Peter Norvig|at=18.12: Learning from Examples: Summary}}&lt;/ref&gt;

== Artificial neural networks ==
{{Main|Artificial neural network|Connectionism}}
[[File:Artificial_neural_network.svg|thumb|A neural network is an interconnected group of nodes, akin to the vast network of [[Neuron|neurons]] in the [[human brain]].]]
Neural networks were inspired by the architecture of neurons in the human brain. A simple "neuron" ''N'' accepts input from other neurons, each of which, when activated (or "fired"), casts a weighted "vote" for or against whether neuron ''N'' should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed "[[Hebbian learning|fire together, wire together]]") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. The neural network forms "concepts" that are distributed among a subnetwork of shared{{efn|Each individual neuron is likely to participate in more than one concept.}} neurons that tend to fire together; a concept meaning "leg" might be coupled with a subnetwork meaning "foot" that includes the sound for "foot". Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes. Modern neural networks can learn both continuous functions and, surprisingly, digital logical operations. Neural networks' early successes included predicting the stock market and (in 1995) a mostly self-driving car.{{efn|Steering for the 1995 "[[History of autonomous cars#1990s|No Hands Across America]]" required "only a few human assists".}}&lt;ref name="Domingos2005"/&gt;{{rp|Chapter 4}} In the 2010s, advances in neural networks using deep learning thrust AI into widespread public consciousness and contributed to an enormous upshift in corporate AI spending; for example, AI-related [[Mergers and acquisitions|M&amp;A]] in 2017 was over 25 times as large as in 2015.&lt;ref&gt;{{cite news|date=2016|title=Why Deep Learning Is Suddenly Changing Your Life|work=Fortune|url=http://fortune.com/ai-artificial-intelligence-deep-machine-learning/|access-date=12 March 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite news|date=2017|title=Google leads in the race to dominate artificial intelligence|language=en|work=The Economist|url=https://www.economist.com/news/business/21732125-tech-giants-are-investing-billions-transformative-technology-google-leads-race|access-date=12 March 2018}}&lt;/ref&gt;

The study of non-learning [[Artificial neural network|artificial neural networks]]&lt;ref name="Neural networks"/&gt; began in the decade before the field of AI research was founded, in the work of [[Walter Pitts]] and [[Warren McCullouch]]. [[Frank Rosenblatt]] invented the [[perceptron]], a learning network with a single layer, similar to the old concept of [[linear regression]]. Early pioneers also include [[Alexey Grigorevich Ivakhnenko]], [[Teuvo Kohonen]], [[Stephen Grossberg]], [[Kunihiko Fukushima]], [[Christoph von der Malsburg]], David Willshaw, [[Shun-Ichi Amari]], [[Bernard Widrow]], [[John Hopfield]], [[Eduardo R. Caianiello]], and others{{citation needed|date=July 2019}}.

The main categories of networks are acyclic or [[Feedforward neural network|feedforward neural networks]] (where the signal passes in only one direction) and [[Recurrent neural network|recurrent neural networks]] (which allow feedback and short-term memories of previous input events). Among the most popular feedforward networks are [[Perceptron|perceptrons]], [[Multi-layer perceptron|multi-layer perceptrons]] and [[Radial basis network|radial basis networks]].&lt;ref name="Feedforward neural networks"&gt;[[Feedforward neural network|Feedforward neural networks]], [[Perceptron|perceptrons]] and [[Radial basis network|radial basis networks]]:

* {{Harvnb|Russell|Norvig|2003|pp=739–748, 758}}
* {{Harvnb|Luger|Stubblefield|2004|pp=458–467}}&lt;/ref&gt; Neural networks can be applied to the problem of [[intelligent control]] (for robotics) or [[Machine learning|learning]], using such techniques as [[Hebbian learning]] ("fire together, wire together"), [[GMDH]] or [[competitive learning]].&lt;ref name="Learning in neural networks"&gt;[[Competitive learning]], [[Hebbian theory|Hebbian]] coincidence learning, [[Hopfield network|Hopfield networks]] and attractor networks:

* {{Harvnb|Luger|Stubblefield|2004|pp=474–505}}&lt;/ref&gt;

Today, neural networks are often trained by the [[backpropagation]] algorithm, which has been around since 1970 as the reverse mode of [[automatic differentiation]] published by [[Seppo Linnainmaa]],&lt;ref name="lin1970"&gt;[[Seppo Linnainmaa]] (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors. Master's Thesis (in Finnish), Univ. Helsinki, 6–7.&lt;/ref&gt;&lt;ref name="grie2012"&gt;Griewank, Andreas (2012). Who Invented the Reverse Mode of Differentiation?. Optimization Stories, Documenta Matematica, Extra Volume ISMP (2012), 389–400.&lt;/ref&gt; and was introduced to neural networks by [[Paul Werbos]].&lt;ref name="WERBOS1974"&gt;[[Paul Werbos]], "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences", ''PhD thesis, Harvard University'', 1974.&lt;/ref&gt;&lt;ref name="werbos1982"&gt;[[Paul Werbos]] (1982). Applications of advances in nonlinear sensitivity analysis. In System modeling and optimization (pp. 762–770). Springer Berlin Heidelberg. [http://werbos.com/Neural/SensitivityIFIPSeptember1981.pdf Online] {{webarchive|url=https://web.archive.org/web/20160414055503/http://werbos.com/Neural/SensitivityIFIPSeptember1981.pdf|date=14 April 2016}}&lt;/ref&gt;&lt;ref name="Backpropagation"&gt;[[Backpropagation]]:

* {{Harvnb|Russell|Norvig|2003|pp=744–748}},
* {{Harvnb|Luger|Stubblefield|2004|pp=467–474}},
* {{Harvnb|Nilsson|1998|loc=chpt. 3.3}}&lt;/ref&gt;

[[Hierarchical temporal memory]] is an approach that models some of the structural and algorithmic properties of the [[neocortex]].&lt;ref name="Hierarchical temporal memory"&gt;{{cite book|last1=Hawkins|first1=Jeff|title=On Intelligence|title-link=On Intelligence|last2=Blakeslee|first2=Sandra|publisher=Owl Books|year=2005|isbn=978-0-8050-7853-4|location=New York, NY|author-link=Jeff Hawkins}}&lt;/ref&gt;

To summarize, most neural networks use some form of [[gradient descent]] on a hand-created neural topology. However, some research groups, such as [[Uber]], argue that simple [[neuroevolution]] to mutate new neural network topologies and weights may be competitive with sophisticated gradient descent approaches{{citation needed|date=July 2019}}. One advantage of neuroevolution is that it may be less prone to get caught in "dead ends".&lt;ref&gt;{{cite news|date=10 January 2018|title=Artificial intelligence can 'evolve' to solve problems|language=en|work=Science {{!}} AAAS|url=http://www.sciencemag.org/news/2018/01/artificial-intelligence-can-evolve-solve-problems|access-date=7 February 2018}}&lt;/ref&gt;

=== Deep feedforward neural networks ===
{{Main|Deep learning}}
[[Deep learning]] is the use of [[Artificial neural network|artificial neural networks]] which have several layers of neurons between the network's inputs and outputs. Deep learning has transformed many important subfields of artificial intelligence{{why|date=July 2019}}, including [[computer vision]], [[speech recognition]], [[natural language processing]] and others.&lt;ref name="goodfellow2016"&gt;Ian Goodfellow, Yoshua Bengio, and Aaron Courville (2016). Deep Learning. MIT Press. [http://www.deeplearningbook.org Online] {{webarchive|url=https://web.archive.org/web/20160416111010/http://www.deeplearningbook.org/|date=16 April 2016}}&lt;/ref&gt;&lt;ref name="HintonDengYu2012"&gt;{{cite journal|last1=Hinton|first1=G.|last2=Deng|first2=L.|last3=Yu|first3=D.|last4=Dahl|first4=G.|last5=Mohamed|first5=A.|last6=Jaitly|first6=N.|last7=Senior|first7=A.|last8=Vanhoucke|first8=V.|last9=Nguyen|first9=P.|last10=Sainath|first10=T.|last11=Kingsbury|first11=B.|year=2012|title=Deep Neural Networks for Acoustic Modeling in Speech Recognition – The shared views of four research groups|journal=IEEE Signal Processing Magazine|volume=29|issue=6|pages=82–97|bibcode=2012ISPM...29...82H|doi=10.1109/msp.2012.2205597|s2cid=206485943}}&lt;/ref&gt;&lt;ref name="schmidhuber2015"&gt;{{cite journal|last=Schmidhuber|first=J.|year=2015|title=Deep Learning in Neural Networks: An Overview|journal=Neural Networks|volume=61|pages=85–117|arxiv=1404.7828|doi=10.1016/j.neunet.2014.09.003|pmid=25462637|s2cid=11715509}}&lt;/ref&gt;

According to one overview,&lt;ref name="scholarpedia"&gt;{{cite journal|last1=Schmidhuber|first1=Jürgen|author-link=Jürgen Schmidhuber|year=2015|title=Deep Learning|journal=Scholarpedia|volume=10|issue=11|page=32832|bibcode=2015SchpJ..1032832S|doi=10.4249/scholarpedia.32832|doi-access=free|df=dmy-all}}&lt;/ref&gt; the expression "Deep Learning" was introduced to the [[machine learning]] community by [[Rina Dechter]] in 1986&lt;ref name="dechter1986"&gt;[[Rina Dechter]] (1986). Learning while searching in constraint-satisfaction problems. University of California, Computer Science Department, Cognitive Systems Laboratory.[https://www.researchgate.net/publication/221605378_Learning_While_Searching_in_Constraint-Satisfaction-Problems Online] {{webarchive|url=https://web.archive.org/web/20160419054654/https://www.researchgate.net/publication/221605378_Learning_While_Searching_in_Constraint-Satisfaction-Problems|date=19 April 2016}}&lt;/ref&gt; and gained traction after Igor Aizenberg and colleagues introduced it to [[Artificial neural network|artificial neural networks]] in 2000.&lt;ref name="aizenberg2000"&gt;Igor Aizenberg, Naum N. Aizenberg, Joos P.L. Vandewalle (2000). Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications. Springer Science &amp; Business Media.&lt;/ref&gt; The first functional Deep Learning networks were published by [[Alexey Grigorevich Ivakhnenko]] and V. G. Lapa in 1965.&lt;ref&gt;{{Cite book|last=Ivakhnenko|first=Alexey|title=Cybernetic Predicting Devices|publisher=Naukova Dumka|year=1965|location=Kiev}}&lt;/ref&gt;{{page needed|date=December 2016}} These networks are trained one layer at a time. Ivakhnenko's 1971 paper&lt;ref name="ivak1971"&gt;{{Cite journal|last1=Ivakhnenko|first1=A. G.|year=1971|title=Polynomial Theory of Complex Systems|journal=IEEE Transactions on Systems, Man, and Cybernetics|issue=4|pages=364–378|doi=10.1109/TSMC.1971.4308320|s2cid=17606980}}&lt;/ref&gt; describes the learning of a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by [[Geoffrey Hinton]] and Ruslan Salakhutdinov introduced another way of pre-training many-layered [[Feedforward neural network|feedforward neural networks]] (FNNs) one layer at a time, treating each layer in turn as an [[Unsupervised learning|unsupervised]] [[restricted Boltzmann machine]], then using [[Supervised learning|supervised]] [[backpropagation]] for fine-tuning.&lt;ref&gt;{{cite journal|last=Hinton|first=G. E.|year=2007|title=Learning multiple layers of representation|journal=Trends in Cognitive Sciences|volume=11|issue=10|pages=428–434|doi=10.1016/j.tics.2007.09.004|pmid=17921042|s2cid=15066318}}&lt;/ref&gt; Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships.

Deep learning often uses [[Convolutional neural network|convolutional neural networks]] (CNNs), whose origins can be traced back to the [[Neocognitron]] introduced by [[Kunihiko Fukushima]] in 1980.&lt;ref name="FUKU1980"&gt;{{cite journal|last1=Fukushima|first1=K.|year=1980|title=Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position|journal=Biological Cybernetics|volume=36|issue=4|pages=193–202|doi=10.1007/bf00344251|pmid=7370364|s2cid=206775608}}&lt;/ref&gt; In 1989, [[Yann LeCun]] and colleagues applied [[backpropagation]] to such an architecture. In the early 2000s, in an industrial application, CNNs already processed an estimated 10% to 20% of all the checks written in the US.&lt;ref name="lecun2016slides"&gt;[[Yann LeCun]] (2016). Slides on Deep Learning [https://indico.cern.ch/event/510372/ Online] {{webarchive|url=https://web.archive.org/web/20160423021403/https://indico.cern.ch/event/510372/|date=23 April 2016}}&lt;/ref&gt; Since 2011, fast implementations of CNNs on GPUs have won many visual pattern recognition competitions.&lt;ref name="schmidhuber2015" /&gt;

CNNs with 12 convolutional layers were used with [[reinforcement learning]] by Deepmind's "[[AlphaGo]] Lee", the program that beat a top [[Go (game)|Go]] champion in 2016.&lt;ref name="Nature2017"&gt;{{cite journal|last1=Silver|first1=David|last2=Schrittwieser|first2=Julian|last3=Simonyan|first3=Karen|last4=Antonoglou|first4=Ioannis|last5=Huang|first5=Aja|author-link5=Aja Huang|last6=Guez|first6=Arthur|last7=Hubert|first7=Thomas|last8=Baker|first8=Lucas|last9=Lai|first9=Matthew|last10=Bolton|first10=Adrian|last11=Chen|first11=Yutian|date=19 October 2017|title=Mastering the game of Go without human knowledge|url=http://discovery.ucl.ac.uk/10045895/1/agz_unformatted_nature.pdf|journal=[[Nature (journal)|Nature]]|volume=550|issue=7676|pages=354–359|bibcode=2017Natur.550..354S|doi=10.1038/nature24270|issn=0028-0836|pmid=29052630|quote=AlphaGo Lee... 12 convolutional layers|last12=Lillicrap|author-link11=Chen Yutian|author-link1=David Silver (programmer)|author-link17=Demis Hassabis|first13=Hui|last17=Hassabis|first17=Demis|last16=Graepel|first16=Thore|last15=Driessche|first15=George van den|last14=Sifre|first14=Laurent|author-link13=Fan Hui|last13=Fan|first12=Timothy|s2cid=205261034}}{{closed access}}&lt;/ref&gt;

=== Deep recurrent neural networks ===
{{Main|Recurrent neural networks}}
Early on, deep learning was also applied to sequence learning with [[Recurrent neural network|recurrent neural networks]] (RNNs)&lt;ref name="Recurrent neural networks"&gt; [[Recurrent neural networks]], [[Hopfield nets]]:
* {{Harvnb|Russell|Norvig|2003|p=758}}
* {{Harvnb|Luger|Stubblefield|2004|pp=474–505}}
&lt;/ref&gt; which are theoretically Turing complete&lt;ref&gt;{{cite journal|last1=Hyötyniemi|first1=Heikki|date=1996|title=Turing machines are recurrent neural networks|journal=Proceedings of STeP '96/Publications of the Finnish Artificial Intelligence Society|pages=13–24}}&lt;/ref&gt; and can run arbitrary programs to process arbitrary sequences of inputs. The depth of an RNN is unlimited and depends on the length of its input sequence; thus, an RNN is an example of deep learning.&lt;ref name="schmidhuber2015" /&gt; RNNs can be trained by [[gradient descent]]&lt;ref&gt;P. J. Werbos. Generalization of backpropagation with application to a recurrent gas market model" ''Neural Networks'' 1, 1988.&lt;/ref&gt;&lt;ref&gt;A. J. Robinson and F. Fallside. The utility driven dynamic error propagation network. Technical Report CUED/F-INFENG/TR.1, Cambridge University Engineering Department, 1987.&lt;/ref&gt;&lt;ref&gt;R. J. Williams and D. Zipser. Gradient-based learning algorithms for recurrent networks and their computational complexity. In Back-propagation: Theory, Architectures and Applications. Hillsdale, NJ: Erlbaum, 1994.&lt;/ref&gt; but suffer from the [[vanishing gradient problem]].&lt;ref name="goodfellow2016" /&gt;&lt;ref name="hochreiter1991"&gt;[[Sepp Hochreiter]] (1991), [http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf Untersuchungen zu dynamischen neuronalen Netzen] {{webarchive|url=https://web.archive.org/web/20150306075401/http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf|date=6 March 2015}}, Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber.&lt;/ref&gt; In 1992, it was shown that unsupervised pre-training of a stack of [[Recurrent neural network|recurrent neural networks]] can speed up subsequent supervised learning of deep sequential problems.&lt;ref name="SCHMID1992"&gt;{{cite journal|last1=Schmidhuber|first1=J.|year=1992|title=Learning complex, extended sequences using the principle of history compression|journal=Neural Computation|volume=4|issue=2|pages=234–242|citeseerx=10.1.1.49.3934|doi=10.1162/neco.1992.4.2.234|s2cid=18271205}}&lt;/ref&gt;

Numerous researchers now use variants of a deep learning recurrent NN called the [[long short-term memory]] (LSTM) network published by Hochreiter &amp; Schmidhuber in 1997.&lt;ref name="lstm"&gt;[[Sepp Hochreiter|Hochreiter, Sepp]]; and [[Jürgen Schmidhuber|Schmidhuber, Jürgen]]; ''Long Short-Term Memory'', Neural Computation, 9(8):1735–1780, 1997&lt;/ref&gt; LSTM is often trained by [[Connectionist temporal classification|Connectionist Temporal Classification]] (CTC).&lt;ref name="graves2006"&gt;Alex Graves, Santiago Fernandez, Faustino Gomez, and [[Jürgen Schmidhuber]] (2006). Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural nets. Proceedings of ICML'06, pp. 369–376.&lt;/ref&gt; At Google, Microsoft and Baidu this approach has revolutionized [[speech recognition]].&lt;ref name="hannun2014"&gt;{{cite arXiv|eprint=1412.5567|class=cs.CL|first1=Awni|last1=Hannun|first2=Carl|last2=Case|title=Deep Speech: Scaling up end-to-end speech recognition|last3=Casper|first9=Shubho|year=2014|author11-link=Andrew Ng|first11=Andrew Y.|last11=Ng|first10=Adam|last10=Coates|first8=Sanjeev|last9=Sengupta|first3=Jared|last8=Satheesh|last7=Prenger|first6=Erich|last6=Elsen|first5=Greg|last5=Diamos|first4=Bryan|last4=Catanzaro|first7=Ryan}}&lt;/ref&gt;&lt;ref name="sak2014"&gt;Hasim Sak and Andrew Senior and Francoise Beaufays (2014). Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling. Proceedings of Interspeech 2014.&lt;/ref&gt;&lt;ref name="liwu2015"&gt;{{cite arXiv|eprint=1410.4281|class=cs.CL|first1=Xiangang|last1=Li|first2=Xihong|last2=Wu|title=Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition|year=2015}}&lt;/ref&gt; For example, in 2015, Google's speech recognition experienced a dramatic performance jump of 49% through CTC-trained LSTM, which is now available through [[Google Voice]] to billions of smartphone users.&lt;ref name="sak2015"&gt;Haşim Sak, Andrew Senior, Kanishka Rao, Françoise Beaufays and Johan Schalkwyk (September 2015): [http://googleresearch.blogspot.ch/2015/09/google-voice-search-faster-and-more.html Google voice search: faster and more accurate.] {{webarchive|url=https://web.archive.org/web/20160309191532/http://googleresearch.blogspot.ch/2015/09/google-voice-search-faster-and-more.html|date=9 March 2016}}&lt;/ref&gt; Google also used LSTM to improve machine translation,&lt;ref name="sutskever2014"&gt;{{cite arXiv|eprint=1409.3215|class=cs.CL|first1=Ilya|last1=Sutskever|first2=Oriol|last2=Vinyals|title=Sequence to Sequence Learning with Neural Networks|last3=Le|first3=Quoc V.|year=2014}}&lt;/ref&gt; Language Modeling&lt;ref name="vinyals2016"&gt;{{cite arXiv|eprint=1602.02410|class=cs.CL|first1=Rafal|last1=Jozefowicz|first2=Oriol|last2=Vinyals|title=Exploring the Limits of Language Modeling|last3=Schuster|first3=Mike|last4=Shazeer|first4=Noam|last5=Wu|first5=Yonghui|year=2016}}&lt;/ref&gt; and Multilingual Language Processing.&lt;ref name="gillick2015"&gt;{{cite arXiv|eprint=1512.00103|class=cs.CL|first1=Dan|last1=Gillick|first2=Cliff|last2=Brunk|title=Multilingual Language Processing From Bytes|last3=Vinyals|first3=Oriol|last4=Subramanya|first4=Amarnag|year=2015}}&lt;/ref&gt; LSTM combined with CNNs also improved automatic image captioning&lt;ref name="vinyals2015"&gt;{{cite arXiv|eprint=1411.4555|class=cs.CV|first1=Oriol|last1=Vinyals|first2=Alexander|last2=Toshev|title=Show and Tell: A Neural Image Caption Generator|last3=Bengio|first3=Samy|last4=Erhan|first4=Dumitru|year=2015}}&lt;/ref&gt; and a plethora of other applications.

== Evaluating progress ==
{{Further|Progress in artificial intelligence|Competitions and prizes in artificial intelligence}}AI, like electricity or the steam engine, is a general purpose technology. There is no consensus on how to characterize which tasks AI tends to excel at.&lt;ref&gt;{{cite news|last1=Brynjolfsson|first1=Erik|last2=Mitchell|first2=Tom|date=22 December 2017|title=What can machine learning do? Workforce implications|language=en|pages=1530–1534|work=Science|url=http://science.sciencemag.org/content/358/6370/1530|access-date=7 May 2018|bibcode=2017Sci...358.1530B|doi=10.1126/science.aap8062}}&lt;/ref&gt; While projects such as [[AlphaZero]] have succeeded in generating their own knowledge from scratch, many other machine learning projects require large training datasets.&lt;ref&gt;{{cite news|last1=Sample|first1=Ian|date=18 October 2017|title='It's able to create knowledge itself': Google unveils AI that learns on its own|language=en|work=the Guardian|url=https://www.theguardian.com/science/2017/oct/18/its-able-to-create-knowledge-itself-google-unveils-ai-learns-all-on-its-own|access-date=7 May 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite news|date=5 July 2017|title=The AI revolution in science|language=en|work=Science {{!}} AAAS|url=http://www.sciencemag.org/news/2017/07/ai-revolution-science|access-date=7 May 2018}}&lt;/ref&gt; Researcher [[Andrew Ng]] has suggested, as a "highly imperfect rule of thumb", that "almost anything a typical human can do with less than one second of mental thought, we can probably now or in the near future automate using AI."&lt;ref&gt;{{cite news|date=2017|title=Will your job still exist in 10 years when the robots arrive?|language=en|work=[[South China Morning Post]]|url=http://www.scmp.com/tech/innovation/article/2098164/robots-are-coming-here-are-some-jobs-wont-exist-10-years|access-date=7 May 2018}}&lt;/ref&gt; [[Moravec's paradox]] suggests that AI lags humans at many tasks that the human brain has specifically evolved to perform well.&lt;ref name="The Economist"&gt;{{cite news|date=2018|title=IKEA furniture and the limits of AI|language=en|work=The Economist|url=https://www.economist.com/news/leaders/21740735-humans-have-had-good-run-most-recent-breakthrough-robotics-it-clear|access-date=24 April 2018}}&lt;/ref&gt;

Games provide a well-publicized benchmark for assessing rates of progress. [[AlphaGo]] around 2016 brought the era of classical board-game benchmarks to a close. Games of imperfect knowledge provide new challenges to AI in [[game theory]].&lt;ref&gt;{{cite news|last1=Borowiec|first1=Tracey Lien, Steven|date=2016|title=AlphaGo beats human Go champ in milestone for artificial intelligence|work=latimes.com|url=https://www.latimes.com/world/asia/la-fg-korea-alphago-20160312-story.html|access-date=7 May 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite news|last1=Brown|first1=Noam|last2=Sandholm|first2=Tuomas|date=26 January 2018|title=Superhuman AI for heads-up no-limit poker: Libratus beats top professionals|language=en|pages=418–424|work=Science|url=http://science.sciencemag.org/content/359/6374/418|access-date=7 May 2018|doi=10.1126/science.aao1733}}&lt;/ref&gt; [[Esports|E-sports]] such as [[StarCraft]] continue to provide additional public benchmarks.&lt;ref&gt;{{cite journal|last1=Ontanon|first1=Santiago|last2=Synnaeve|first2=Gabriel|last3=Uriarte|first3=Alberto|last4=Richoux|first4=Florian|last5=Churchill|first5=David|last6=Preuss|first6=Mike|date=December 2013|title=A Survey of Real-Time Strategy Game AI Research and Competition in StarCraft|journal=IEEE Transactions on Computational Intelligence and AI in Games|volume=5|issue=4|pages=293–311|citeseerx=10.1.1.406.2524|doi=10.1109/TCIAIG.2013.2286295|s2cid=5014732}}&lt;/ref&gt;&lt;ref&gt;{{cite news|date=2017|title=Facebook Quietly Enters StarCraft War for AI Bots, and Loses|work=WIRED|url=https://www.wired.com/story/facebook-quietly-enters-starcraft-war-for-ai-bots-and-loses/|access-date=7 May 2018}}&lt;/ref&gt; Many competitions and prizes, such as the [[ImageNet|Imagenet Challenge]], promote research in artificial intelligence. The most common areas of competition include general machine intelligence, conversational behavior, data-mining, [[Autonomous car|robotic cars]], and robot soccer as well as conventional games.&lt;ref&gt;{{Cite web|title=ILSVRC2017|url=http://image-net.org/challenges/LSVRC/2017/|access-date=2018-11-06|website=image-net.org|language=en}}&lt;/ref&gt;

The "imitation game" (an interpretation of the 1950 [[Turing test]] that assesses whether a computer can imitate a human) is nowadays considered too exploitable to be a meaningful benchmark.&lt;ref&gt;{{cite journal|last1=Schoenick|first1=Carissa|last2=Clark|first2=Peter|last3=Tafjord|first3=Oyvind|last4=Turney|first4=Peter|last5=Etzioni|first5=Oren|date=23 August 2017|title=Moving beyond the Turing Test with the Allen AI Science Challenge|journal=Communications of the ACM|volume=60|issue=9|pages=60–64|arxiv=1604.04315|doi=10.1145/3122814|s2cid=6383047}}&lt;/ref&gt; A derivative of the Turing test is the Completely Automated Public Turing test to tell Computers and Humans Apart ([[CAPTCHA]]). As the name implies, this helps to determine that a user is an actual person and not a computer posing as a human. Unlike the standard Turing test, CAPTCHA is administered by a machine and targeted to a human as opposed to being administered by a human and targeted to a machine. A computer asks a user to complete a simple test then generates a grade for that test. Computers are unable to solve the problem, so correct solutions are deemed to be the result of a person taking the test. A common type of CAPTCHA is the test that requires the typing of distorted letters, numbers or symbols that appear in an image undecipherable by a computer.&lt;ref&gt;{{cite book|last1=O'Brien|first1=James|title=Management Information Systems|last2=Marakas|first2=George|publisher=McGraw-Hill/Irwin|year=2011|isbn=978-0-07-337681-3|edition=10th}}&lt;/ref&gt;

Proposed "universal intelligence" tests aim to compare how well machines, humans, and even non-human animals perform on problem sets that are generic as possible. At an extreme, the test suite can contain every possible problem, weighted by [[Kolmogorov complexity]]; unfortunately, these problem sets tend to be dominated by impoverished pattern-matching exercises where a tuned AI can easily exceed human performance levels.&lt;ref&gt;{{cite journal|last=Hernandez-Orallo|first=Jose|year=2000|title=Beyond the Turing Test|journal=Journal of Logic, Language and Information|volume=9|issue=4|pages=447–466|doi=10.1023/A:1008367325700|s2cid=14481982}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Dowe|first1=D. L.|last2=Hajek|first2=A. R.|year=1997|title=A computational extension to the Turing Test|url=http://www.csse.monash.edu.au/publications/1997/tr-cs97-322-abs.html|url-status=dead|journal=Proceedings of the 4th Conference of the Australasian Cognitive Science Society|archive-url=https://web.archive.org/web/20110628194905/http://www.csse.monash.edu.au/publications/1997/tr-cs97-322-abs.html|archive-date=28 June 2011|df=dmy-all}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Hernandez-Orallo|first1=J.|last2=Dowe|first2=D. L.|year=2010|title=Measuring Universal Intelligence: Towards an Anytime Intelligence Test|journal=Artificial Intelligence|volume=174|issue=18|pages=1508–1539|citeseerx=10.1.1.295.9079|doi=10.1016/j.artint.2010.09.006}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Hernández-Orallo|first1=José|last2=Dowe|first2=David L.|last3=Hernández-Lloreda|first3=M.Victoria|date=March 2014|title=Universal psychometrics: Measuring cognitive abilities in the machine kingdom|journal=Cognitive Systems Research|volume=27|pages=50–74|doi=10.1016/j.cogsys.2013.06.001|hdl-access=free|hdl=10251/50244|s2cid=26440282}}&lt;/ref&gt;

=== Hardware improvements ===
Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.&lt;ref&gt;{{cite web|last1=Research|first1=AI|date=23 October 2015|title=Deep Neural Networks for Acoustic Modeling in Speech Recognition|url=http://airesearch.com/ai-research-papers/deep-neural-networks-for-acoustic-modeling-in-speech-recognition/|access-date=23 October 2015|website=airesearch.com}}&lt;/ref&gt; By 2019, graphic processing units ([[GPU|GPUs]]), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.&lt;ref&gt;{{cite news|date=December 2019|title=GPUs Continue to Dominate the AI Accelerator Market for Now|language=en|work=InformationWeek|url=https://www.informationweek.com/big-data/ai-machine-learning/gpus-continue-to-dominate-the-ai-accelerator-market-for-now/a/d-id/1336475|access-date=11 June 2020}}&lt;/ref&gt; [[OpenAI]] estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.&lt;ref&gt;{{cite news|last1=Ray|first1=Tiernan|date=2019|title=AI is changing the entire nature of compute|language=en|work=ZDNet|url=https://www.zdnet.com/article/ai-is-changing-the-entire-nature-of-compute/|access-date=11 June 2020}}&lt;/ref&gt;&lt;ref&gt;{{cite web|date=16 May 2018|title=AI and Compute|url=https://openai.com/blog/ai-and-compute/|access-date=11 June 2020|website=OpenAI|language=en}}&lt;/ref&gt;

== Notes ==
{{notelist}}

== References ==
{{Reflist}}

=== Sources ===

* {{Cite book|last1=Russell|first1=Stuart J.|url=http://aima.cs.berkeley.edu/|title=Artificial Intelligence: A Modern Approach|last2=Norvig|first2=Peter|publisher=Prentice Hall|year=2003|isbn=978-0-13-790395-5|edition=2nd|location=Upper Saddle River, New Jersey|author-link=Stuart J. Russell|author2-link=Peter Norvig}}
* {{cite book|last1=Poole|first1=David|url=https://archive.org/details/computationalint00pool|title=Computational Intelligence: A Logical Approach|last2=Mackworth|first2=Alan|last3=Goebel|first3=Randy|publisher=Oxford University Press|year=1998|isbn=978-0-19-510270-3|location=New York|author-link=David Poole (researcher)|author2-link=Alan Mackworth|author3-link=Randy Goebel}}
* {{cite book|last1=Luger|first1=George|url=https://archive.org/details/artificialintell0000luge|title=Artificial Intelligence: Structures and Strategies for Complex Problem Solving|last2=Stubblefield|first2=William|publisher=Benjamin/Cummings|year=2004|isbn=978-0-8053-4780-7|edition=5th|author-link=George Luger|author2-link=William Stubblefield|url-access=registration}}
* {{cite book|last=Nilsson|first=Nils|url=https://archive.org/details/artificialintell0000nils|title=Artificial Intelligence: A New Synthesis|publisher=Morgan Kaufmann|year=1998|isbn=978-1-55860-467-4|author-link=Nils Nilsson (researcher)|url-access=registration}}

[[Category:Artificial intelligence applications]]
[[Category:Computer science]]</text>
      <sha1>l3cqxypoky72dlemz26zfp9msbdo6od</sha1>
    </revision>
  </page>
  <page>
    <title>Computer science and engineering</title>
    <ns>0</ns>
    <id>524425</id>
    <revision>
      <id>1014186636</id>
      <parentid>1010042675</parentid>
      <timestamp>2021-03-25T17:31:35Z</timestamp>
      <contributor>
        <username>Yamin Chowdhury</username>
        <id>39089376</id>
      </contributor>
      <comment>/* Example universities with CSE majors */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5789" xml:space="preserve">{{short description|University academic program}}

'''Computer Science &amp; Engineering''' ('''CSE''') is an academic program at many [[University|universities]] which comprises scientific and engineering aspects of computing. CSE is also a term often used in Europe to translate the name of [[engineering informatics]] academic programs.

==Academic courses==
Academic programs vary between colleges. Courses usually include introduction to [[Computer programming|programming]], introduction to [[algorithms]] and [[data structures]], [[computer architecture]], [[operating systems]], [[computer networks]], [[parallel computing]], [[embedded systems]], [[algorithmics|algorithms design]], [[Network analysis (electrical circuits)|circuit analysis]] and [[electronics]], [[digital logic]] and [[Processor (computing)|processor]] design, [[computer graphics (computer science)|computer graphics]], [[scientific computing]], [[software engineering]], [[database|database systems]], [[digital signal processing]], [[virtualization]], [[computer simulation]]s and [[game programming|games]] programming. CSE programs also include core subjects of theoretical computer science such as [[theory of computation]], [[numerical methods]], [[machine learning]], [[programming language theory|programming theory]] and [[Programming paradigm|paradigms]]. Modern academic programs also cover emerging computing fields like [[image processing]], [[data science]], [[robotics]], [[bio-inspired computing]], [[computational biology]], [[autonomic computing]] and [[artificial intelligence]].&lt;ref name=":0"&gt;{{Cite web|title=Courses in Computer Science and Engineering {{!}} Paul G. Allen School of Computer Science &amp; Engineering|url=https://www.cs.washington.edu/education/courses/|access-date=2020-08-22|website=www.cs.washington.edu}}&lt;/ref&gt; Most of the above CSE areas require initial [[mathematics|mathematical]] knowledge, hence the first year of study is dominated by mathematical courses, primarily [[discrete mathematics]], [[mathematical analysis]], [[linear algebra]] and [[statistics]], as well as the basics of [[physics]] - [[Field theory (physics)|field theory]] and [[electromagnetism]].

== Example universities with CSE majors ==
* [[Massachusetts Institute of Technology]]&lt;ref&gt;{{Cite web|title=Home {{!}} MIT Schwarzman College of Computing {{!}} Massachusetts Institute of Technology|url=https://computing.mit.edu/|website=computing.mit.edu}}&lt;/ref&gt;
* [[North South University]]&lt;ref&gt;{{Cite web|title=Home {{!}} School of Engineering and Physical Science {{!}} North South University|url=http://www.northsouth.edu/academic/seps/|website=www.northsouth.edu}}&lt;/ref&gt;
* [[Dhaka University]]&lt;ref&gt;{{Cite web|title=Home {{!}} Dhaka University Computer Science and Engineering {{!}} Dhaka University|url=http://www.cse.du.ac.bd/|website=www.du.ac.bd}}&lt;/ref&gt;
* [[University of Chittagong]]
* [[American University of Beirut]]&lt;ref&gt;{{Cite web|title=Computer Science and Engineering at American University of Beirut (AUB)|url=https://www.aub.edu.lb/registrar/Documents/catalogue/undergraduate20-21/ece.pdf}}&lt;/ref&gt;
* [[American International University-Bangladesh]]&lt;ref&gt;{{Cite web|title=Department of Computer Science and Engineering|url=http://cs.aiub.edu/}}&lt;/ref&gt;
* [[Santa Clara University]]
* [[University of Michigan]]&lt;ref&gt;{{cite web|title=Computer Science and Engineering at Michigan|url=https://cse.engin.umich.edu/}}&lt;/ref&gt;
* [[UNSW School of Computer Science and Engineering | University of New South Wales]]&lt;ref&gt;{{cite web|title=Computer Science and Engineering at UNSW|url=https://www.cse.unsw.edu.au/}}&lt;/ref&gt;
* [[University of Washington]]&lt;ref&gt;{{Cite web|title=Welcome to Paul G. Allen School of Computer Science &amp; Engineering {{!}} Paul G. Allen School of Computer Science &amp; Engineering|url=https://www.cs.washington.edu/|access-date=2020-08-22|website=www.cs.washington.edu}}&lt;/ref&gt;
* [[Bucknell University]]&lt;ref&gt;{{Cite web|title=Computer Science Majors|url=https://www.bucknell.edu/academics/college-engineering/majors-departments/computer-science|access-date=2021-02-05|website=www.bucknell.edu}}&lt;/ref&gt;
* [[Indian Institute of Technology Kanpur]]&lt;ref&gt;{{cite web|title=Computer Science and Engineering at IITK|url=https://www.cse.iitk.ac.in/}}&lt;/ref&gt;
* [[Stanford University]]
* [[Indian Institute of Technology Bombay]]&lt;ref&gt;{{cite web|title=Computer Science and Engineering at IITB|url=https://www.cse.iitb.ac.in/}}&lt;/ref&gt;
* [[Indian Institute of Technology Delhi]]&lt;ref&gt;{{cite web|title=Computer Science and Engineering at IITD|url=https://www.cse.iitd.ac.in/}}&lt;/ref&gt;
* [[Indian Institute of Technology Madras]]&lt;ref&gt;{{cite web|title=Computer Science and Engineering at IITM|url=https://www.cse.iitm.ac.in/}}&lt;/ref&gt;
* [[Amrita Vishwa Vidyapeetham ]]&lt;ref&gt;{{cite web|title=B.Tech Computer Science and Engineering at Amrita School of Engineering|url=https://www.amrita.edu/program/btech-computer-science-and-engineering}}&lt;/ref&gt;
* [[University of Nevada, Reno|University of Nevada]]&lt;ref&gt;{{Cite web|title=Computer Science &amp; Engineering|url=https://www.unr.edu/cse|access-date=2020-08-22|website=University of Nevada, Reno|language=en}}&lt;/ref&gt;
* [[University of Notre Dame]]&lt;ref&gt;{{Cite web|title=Department of Computer Science and Engineering|url=https://cse.nd.edu/|access-date=2020-08-22|website=cse.nd.edu}}&lt;/ref&gt;
*[[Delft University of Technology]]&lt;ref&gt;{{Cite web|title=Bachelor of Computer Science and Engineering|url=https://www.tudelft.nl/en/education/programmes/bachelors/cse/bachelor-of-computer-science-and-engineering/|access-date=2020-12-08|website=TU Delft|language=en}}&lt;/ref&gt;

==See also==
* [[Computer science]]
* [[Computer graphics (computer science)]]

==References==
{{Reflist}}

[[Category:Computer science education]]
[[Category:Computer science]]
[[Category:Computer engineering]]</text>
      <sha1>thd2arnb79im92kj0635codp5i6axr0</sha1>
    </revision>
  </page>
  <page>
    <title>Bachelor of Computer Science</title>
    <ns>0</ns>
    <id>2701254</id>
    <revision>
      <id>1007827542</id>
      <parentid>991815106</parentid>
      <timestamp>2021-02-20T03:35:25Z</timestamp>
      <contributor>
        <username>BattyBot</username>
        <id>15996738</id>
      </contributor>
      <minor/>
      <comment>/* Statistics */Removed/fixed incorrect author parameter(s), performed [[WP:AWB/GF|general fixes]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8476" xml:space="preserve">{{More citations needed|date=July 2017}}
The '''Bachelor of Computer Science''' or '''Bachelor of Science in Computer Science''' (abbreviated '''BCompSc''' or '''BCS''' or '''BS CS''' or '''B.Sc. CS''') is a type of [[bachelor's degree]], usually awarded after three or four years of collegiate study in [[computer science]], but possibly awarded in fewer years depending on factors such as an institution's course requirements and academic calendar. In some cases it can be awarded in five years. In general, computer science degree programs emphasize the mathematical and theoretical foundations of computing.&lt;ref&gt;{{cite web |url=http://www.uowdubai.ac.ae/computer-science-and-engineering-programs/bachelor-of-computer-science-bcompsc-degree |title=Bachelor of Computer Science (BCOMPSC) Degree |publisher=[[University of Wollongong in Dubai]]}}&lt;/ref&gt;

The same core curriculum may, depending on the school, result in other degrees, including:
* [[Bachelor of Arts]] (BA) in Computer Science 
* Bachelor of Applied Science (BASc) in Computer Science
* Bachelor of Technology in Computer Science and Engineering (B.Tech)
* Bachelor of Science in Information Technology 
* Bachelor of Mathematics in Computer Science  
* Bachelor of Engineering (BEng or BE) in Computer Science 
* Bachelor of Computing in Computer Science 
* [[Bachelor of Science]] in Engineering (Computer Science) - BSE (CS)
* Bachelor of Computer Security in Computer Science
* Bachelor of Science (BSc or BS) in Computer Science (BSc CS or BSCS or BSc (Comp))

In many post-secondary institutions, an '''Honors Bachelor of Computer Science''' degree has been introduced as an upgrade to the regular bachelor's program and usually requires at least one additional year of study.

== Statistics ==
Through the data shown in pictures, jobs about software developers and applications are most welcome and have the highest revenue. Even in the prediction for the next decade, it's still most popular.&lt;ref&gt;{{Cite web|url=https://www.computerscience.org/degrees/bachelors/|title=Bachelor's in Computer Science|author=Staff Writers|date=2019-08-20|website=ComputerScience.org|language=en-US|access-date=2019-10-17}}&lt;/ref&gt;

In the survey of payments from 1999 to 2010, statistics show that computer science major students' work have obviously higher salaries than most majors' students' jobs.&lt;ref&gt;{{cite web|url=https://appliedcomputing.wisconsin.edu/about-applied-computing/computer-science-jobs/|title=Computer Science Jobs and Career Outlook}}&lt;/ref&gt;

== Professional qualifications after finishing the degree ==
The required skills and qualifications for working as a Computer or Software Engineer comprise a large number of theoretical aspects within the areas of Computer Science and Electronics. The following list shows a classification according to the professional profiles that are currently demanded:[https://orientacion.universia.net.co/carreras_universitarias-52/perfil-profesional---ingenieria-informatica-68.html]

* Knowledge of, at least, one programming language (currently in use) or a specific technology in depth.
* Being able to read English, since most of the documents relating to the areas of work as a computer engineer are written in this language.
* Handling of version control systems. Although this is not mandatory, most companies employing computer engineers make use of version control systems.
* Knowledge related to Information Theory and Telecommunications, enabling optimised and legally-compliant designs and facilitating self-control and audits if required.
* Computability Theory to calculate the viability of the problem to be solved.
* Efficiency awareness for industrial mechanization of information (scalability, reliability, etc ...).
* Automata Theory and Algorithm Design Theory to design suitable automation solutions in information processing.
* Software Engineering understanding to evaluate the best techniques of design, development and maintenance of software, subject to calculations of quality constraints, time, cost, etc..
* Artificial Intelligence or Knowledge Engineering such as pattern recognition or neural networks to calculate and design knowledge production systems as an industrial competitive advantage in information management.
* Electronics to calculate and design communication and control interfaces between computers and various mechanical and electrical devices, such as data acquisition systems.
* Industrial and business organization understanding needed for planning, management and control of computer projects and, management of ICT departments.
* Hardware knowledge to analyze and design solutions in the field of microprocessor architecture.

== Typical requirements ==
Because computer science is a wide field, courses required to earn a bachelor of computer science degree vary. A typical list of course requirements includes topics such as:&lt;ref 
name="monash_bcs_course_description"&gt;[http://www.monash.edu.au/study/coursefinder/course/2380/] Course description of the Bachelor of Computer Science at [[Monash University]], [[Melbourne]], [[Australia]]&lt;/ref&gt;
* [[Computer programming]] 
* [[Programming paradigm]]s
* [[Algorithms]]
* [[Data structures]] 
* [[Logic]] &amp; [[Computation]]
* [[Computer architecture]]
 
Some schools may place more emphasis on [[mathematics]]  and require additional courses such as:&lt;ref name="purdue_bcs_requirements"&gt;[http://www.cs.purdue.edu/academic_programs/future_students/majors_minors.shtml#Major] {{Webarchive|url=https://web.archive.org/web/20101116005122/http://www.cs.purdue.edu/academic_programs/future_students/majors_minors.shtml#Major |date=2010-11-16 }} Bachelor of Computer Science at [[Purdue University]], [[West Lafayette]], [[Indiana]], U.S.&lt;/ref&gt;
* [[Linear algebra]]
* [[Calculus]]
* [[Probability theory]] and [[statistics]]
* [[Combinatorics]] and [[discrete mathematics]]
* [[Differential calculus]] and [[mathematics]]

Beyond the basic set of computer science courses, students can typically choose additional courses from a variety of different fields, such as:&lt;ref name="purdue_cs_courselist"&gt;[https://esa-oas-prod-wl.itap.purdue.edu/prod/bzwsrch.p_search_catalog?subject=CS&amp;college=S] Classes available through Purdue University's Computer Science Department&lt;/ref&gt;
* [[Theory of computation]]
* [[Operating systems]]
* [[Numerical computation]]
* [[Compilers]], [[compiler design]]
* [[Real-time computing]]
* [[Distributed system]]s
* [[Computer network]]ing
* [[Data communication]]
* [[Computer graphics]]
* [[Artificial intelligence]]
* [[Human-computer interaction]]
* [[Information theory]]
* [[Software testing]]
* [[Information assurance]]

Some schools allow students to specialize in a certain area of computer science.&lt;ref name="stevens_cs_concetrations"&gt;{{cite web|url=http://www.stevens.edu/compsci/undergrad/bs_aaca.html|title=Computer Science concentrations offered by Stevens Institute|publisher=[[Stevens Institute of Technology]]|access-date=2011-12-01|archive-url=https://web.archive.org/web/20110810200703/http://www.stevens.edu/compsci/undergrad/bs_aaca.html|archive-date=2011-08-10|url-status=dead}}&lt;/ref&gt;&lt;ref name="saint_leo_cs_description"&gt;{{cite web|url=http://www.saintleo.edu/Academics/School-of-Business/Undergraduate-Degree-Programs/Bachelor-of-Computer-Science-Degree|title=Saint Leo University program description offering Information assurance specialization|publisher=[[Saint Leo University]]|access-date=2011-12-01|archive-url=https://web.archive.org/web/20111123122734/http://www.saintleo.edu/Academics/School-of-Business/Undergraduate-Degree-Programs/Bachelor-of-Computer-Science-Degree|archive-date=2011-11-23|url-status=dead}}&lt;/ref&gt;&lt;ref name="fairleigh_cs_concentration"&gt;{{cite web|url=http://view.fdu.edu/default.aspx?id=7262|title=B.S. Computer Science -  Cybersecurity Concentration |publisher=[[Fairleigh Dickinson University]]}}&lt;/ref&gt;

==Related degrees==
* [[Bachelor of Software Engineering]]
* [[Bachelor of Science in Information Technology]]
* [[Bachelor of Computing]]
* [[Bachelor of Information Technology]]
* [[Bachelor of Computer Information Systems]]
* [[Bachelor in computer design]]

==See also==
* [[Computer science]]
* [[Computer science and engineering]]

==References==
{{Reflist}}

{{Academic degrees}}

{{DEFAULTSORT:Bachelor Of Computer Science}}
[[Category:Bachelor's degrees|Computer Science]]
[[Category:Computer science education]]
[[Category:Computer science educators]]
[[Category:Computer science]]</text>
      <sha1>7w8416sdlvjdwx8p09cgn9wrq922sog</sha1>
    </revision>
  </page>
  <page>
    <title>Polling (computer science)</title>
    <ns>0</ns>
    <id>4516638</id>
    <revision>
      <id>987548890</id>
      <parentid>977039961</parentid>
      <timestamp>2020-11-07T19:34:28Z</timestamp>
      <contributor>
        <username>Brianjychan</username>
        <id>40311879</id>
      </contributor>
      <comment>make algorithm more concise and add details about read bit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7582" xml:space="preserve">{{about|the computer science term|the mathematical model|Polling system|other uses|Polling (disambiguation)}}
{{more citations needed|date=January 2015}}

'''Polling''', or '''polled''' operation, in [[computer science]], refers to actively sampling the status of an [[external device]] by a [[client program]] as a synchronous activity. Polling is most often used in terms of [[input/output]] ({{nowrap|I/O}}), and is also referred to as '''polled {{nowrap|I/O}}''' or '''software-driven {{nowrap|I/O}}'''.

==Description==
Polling is the process where the computer or controlling device waits for an [[external device]] to check for its readiness or state, often with low-level hardware. For example, when a [[printer (computing)|printer]] is connected via a parallel port, the computer waits until the printer has received the next character. These processes can be as minute as only reading [[status register|one bit]]. This is sometimes used synonymously with '[[busy waiting|busy-wait]]' polling. In this situation, when an {{nowrap|I/O}} operation is required, the computer does nothing other than check the status of the {{nowrap|I/O}} device until it is ready, at which point the device is accessed. In other words, the computer waits until the device is ready. Polling also refers to the situation where a device is repeatedly checked for readiness, and if it is not, the computer returns to a different task. Although not as wasteful of [[CPU]] cycles as busy waiting, this is generally not as efficient as the alternative to polling, [[interrupt]]-driven {{nowrap|I/O}}.

In a simple single-purpose system, even busy-wait is perfectly appropriate if no action is possible until the {{nowrap|I/O}} access, but more often than not this was traditionally a consequence of simple hardware or non-[[Computer multitasking|multitasking]] [[operating systems]].

Polling is often intimately involved with very [[machine code|low-level hardware]]. For example, polling a parallel printer port to check whether it is ready for another character involves examining as little as one [[bit]] of a [[byte]]. That bit represents, at the time of reading, whether a single wire in the printer cable is at low or high voltage. The {{nowrap|I/O}} instruction that reads this byte directly transfers the voltage state of eight real world wires to the eight circuits ([[flip flop (electronics)|flip flop]]s) that make up one byte of a CPU register.

Polling has the disadvantage that if there are too many devices to check, the time required to poll them can exceed the time available to service the I/O device.

=== Algorithm ===
Polling can be described in the following steps:

Host actions:
#The host repeatedly reads the [[status register|busy bit]] of the controller until it becomes clear (with a value of 0).
#When clear, the host writes the command into the command [[hardware register|register]]. If the host is sending output, it sets the write bit and writes a byte into the data-out register. If the host is receiving input, it reads the controller-written data from the data-in register, and sets the read bit to 0 as the next command.
#The host sets the command-ready bit to 1.
Controller actions:
#When the controller notices that the command-ready bit is set, it sets the busy bit to 1.
#The controller reads the command register. If the write bit inside is set, it reads from the data-out register and performs the necessary {{nowrap|I/O}} operations on the device. If the read bit is set, data from the device is loaded into the data-in register for the host to read.
#Once the operations are over, the controller clears the command-ready bit, clears the error bit to show the operation was successful, and clears the busy bit.

== Types ==
A '''polling cycle''' is the time in which each element is monitored once. The optimal polling cycle will vary according to several factors, including the desired speed of response and the overhead (e.g., [[Scheduling (computing)|processor time]] and [[Bandwidth (computing)|bandwidth]]) of the polling.

In '''roll call polling''', the polling device or process queries each element on a list in a fixed sequence. Because it waits for a response from each element, a timing mechanism is necessary to prevent lock-ups caused by non-responding elements. Roll call polling can be inefficient if the overhead for the polling messages is high, there are numerous elements to be polled in each polling cycle and only a few elements are active.

In ''hub polling'', also referred to as token polling, each element polls the next element in some fixed sequence. This continues until the first element is reached, at which time the polling cycle starts all over again.

Polling can be employed in various computing contexts in order to control the execution or transmission sequence of the elements involved. For example, in multitasking operating systems, polling can be used to allocate processor time and other resources to the various competing processes.

In networks, polling is used to determine which nodes want to access the network. It is also used by routing protocols to retrieve routing information, as is the case with EGP ([[exterior gateway protocol]]).

An alternative to polling is the use of [[interrupt]]s, which are signals generated by devices or processes to indicate that they need attention, want to communicate, etc. Although polling can be very simple, in many situations (e.g., multitasking operating systems) it is more efficient to use interrupts because it can reduce processor usage and/or bandwidth consumption.

== Poll message ==
A '''poll message''' is a control-acknowledgment message.

In a multidrop line arrangement (a central [[computer]] and different terminals in which the [[Terminal (telecommunication)|terminal]]s share a single communication line to and from the computer), the system uses a [[Master/slave (technology)|master/slave]] polling arrangement whereby the central computer sends message (called polling message) to a specific terminal on the outgoing line. All terminals listen to the outgoing line, but only the terminal that is polled replies by sending any information that it has ready for transmission on the incoming line.&lt;ref name="mpb"&gt;{{Cite web |url=http://www.pulsewan.com/data101/multidrop_polling_basics.htm |title=Multi-Drop Polling |year=2007 |publisher=RAD Data Communications/Pulse Supply |access-date=2014-07-13 |archive-url=https://web.archive.org/web/20140217174920/http://www.pulsewan.com/data101/multidrop_polling_basics.htm |archive-date=2014-02-17 |url-status=dead }}&lt;/ref&gt;

In [[star network]]s, which, in its simplest form, consists of one central [[Network switch|switch]], [[Ethernet hub|hub]], or computer that acts as a conduit to transmit messages, polling is not required to avoid chaos on the lines, but it is often used to allow the master to acquire input in an orderly fashion. These poll messages differ from those of the multidrop lines case because there are no site addresses needed, and each terminal only receives those polls that are directed to it.&lt;ref name="mpb" /&gt;

==See also==
* [[Abstraction (computer science)]]
* [[Asynchronous I/O]]
* [[Bit banging]]
* [[Infinite loop]] 
* [[Interrupt request (PC architecture)]]
* [[Integer (computer science)]]
* [[kqueue]]
* [[Multiple asynchronous periodic polling]]
* [[Pull technology]]
* [[select (Unix)]]

==References==
{{Reflist}}

{{DEFAULTSORT:Polling (Computer Science)}}
[[Category:Events (computing)]]
[[Category:Input/output]]
[[Category:Computer science]]

[[fr:Attente active]]</text>
      <sha1>a34ql7wh9w0wepyilrpq4azx1hd4ynr</sha1>
    </revision>
  </page>
  <page>
    <title>Abstraction (computer science)</title>
    <ns>0</ns>
    <id>60491</id>
    <revision>
      <id>1010510005</id>
      <parentid>1005262367</parentid>
      <timestamp>2021-03-05T21:18:12Z</timestamp>
      <contributor>
        <username>Munja</username>
        <id>35253960</id>
      </contributor>
      <minor/>
      <comment>added [[Category:Object-oriented programming]] using [[WP:HC|HotCat]] This is one of 4 pillars of OOP</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="33838" xml:space="preserve">{{short description|Technique for arranging complexity of computer systems}}
{{More citations needed|date=June 2011}}
{{Use dmy dates|date=December 2019}}
{{Quote box|quote=The essence of abstraction is preserving information that is relevant in a given context, and forgetting information that is irrelevant in that context.|source=– [[John Guttag|John V. Guttag]]&lt;ref&gt;{{Cite book | edition = Spring 2013 | publisher = The MIT Press | isbn = 9780262519632 | last = Guttag | first = John V. | title = Introduction to Computation and Programming Using Python | location = Cambridge, Massachusetts | date = 18 January 2013}}&lt;/ref&gt;|width=25%}}

In [[software engineering]] and [[computer science]], '''abstraction''' is:

* the process of removing physical, spatial, or temporal details&lt;ref name=":1"&gt;{{Cite journal|last1=Colburn|first1=Timothy|last2=Shute|first2=Gary|s2cid=5927969|date=5 June 2007|title=Abstraction in Computer Science|journal=Minds and Machines|language=en|volume=17|issue=2|pages=169–184|doi=10.1007/s11023-007-9061-7|issn=0924-6495}}&lt;/ref&gt; or [[Attribute (computing)|attributes]] in the study of objects or [[system]]s to focus attention on details of greater importance;&lt;ref name=":0"&gt;{{Cite journal|last=Kramer|first=Jeff|s2cid=12481509|date=1 April 2007|title=Is abstraction the key to computing?|journal=Communications of the ACM|volume=50|issue=4|pages=36–42|doi=10.1145/1232743.1232745|issn=0001-0782}}&lt;/ref&gt; it is similar in nature to the process of [[generalization]];
* the creation of [[Abstract and concrete|abstract]] [[concept]]-[[Object (philosophy)|objects]] by mirroring common features or attributes of various non-abstract objects or systems of study&lt;ref name=":0" /&gt; – the result of the process of abstraction.

[[Abstraction|Abstraction, in general]], is a fundamental concept in computer science and [[software development]].&lt;ref&gt;{{Cite journal|last=Ben-Ari|first=Mordechai|date=1 March 1998|title=Constructivism in computer science education|journal=ACM SIGCSE Bulletin|volume=30|issue=1|pages=257, 257–261|doi=10.1145/274790.274308|issn=0097-8418|doi-access=free}}&lt;/ref&gt; The process of abstraction can also be referred to as '''modeling''' and is closely related to the concepts of ''[[theory]]'' and ''[[design]]''.&lt;ref&gt;{{Cite journal|last1=Comer|first1=D. E.|last2=Gries|first2=David|last3=Mulder|first3=Michael C.|last4=Tucker|first4=Allen|last5=Turner|first5=A. Joe|last6=Young|first6=Paul R. /Denning|s2cid=723103|date=1 January 1989|title=Computing as a discipline|journal=Communications of the ACM|volume=32|issue=1|pages=9–23|doi=10.1145/63238.63239|issn=0001-0782}}&lt;/ref&gt; [[Conceptual model|Models]] can also be considered types of abstractions per their generalization of aspects of [[reality]].

Abstraction in computer science is closely related to [[Abstraction (mathematics)|abstraction in mathematics]] due to their common focus on building abstractions as objects,&lt;ref name=":1" /&gt; but is also related to other notions of abstraction used in other fields [[Abstraction (art)|such as art]].&lt;ref name=":0" /&gt;

Abstractions may also refer to real-world objects and systems, rules of [[Computation|computational systems]] or rules of [[programming language]]s that carry or utilize features of abstraction itself, such as:

* the usage of [[data type]]s to perform ''data abstraction'' to separate usage from working representations of [[data structure]]s within [[Computer program|programs]];&lt;ref&gt;{{Cite journal|last=Liskov|first=Barbara|s2cid=14219043|date=1 May 1988|title=Keynote address – data abstraction and hierarchy|journal=ACM SIGPLAN Notices|publisher=ACM|volume=23|pages=17–34|doi=10.1145/62138.62141|isbn=0897912667}}&lt;/ref&gt;
* the concept of [[Procedure (computer science)|procedures, functions, or subroutines]] which represent a specific of implementing [[control flow]] in programs;
* the rules commonly named "abstraction" that generalize [[Expression (mathematics)|expressions]] using [[Free variables and bound variables|free and bound variables]] in the various versions of [[lambda calculus]];&lt;ref&gt;{{Cite book|title=The lambda calculus : its syntax and semantics|first=Hendrik Pieter|last=Barendregt|date=1984|publisher=North-Holland|isbn=0444867481|edition=Revised|location=Amsterdam|oclc=10559084}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|title=Lambda calculus with types|first=Hendrik Pieter|last=Barendregt|date=2013|publisher=Cambridge University Press|others=Dekkers, Wil., Statman, Richard., Alessi, Fabio., Association for Symbolic Logic.|isbn=9780521766142|location=Cambridge, UK|oclc=852197712}}&lt;/ref&gt;
* the usage of [[S-expression]]s as an abstraction of data structures and programs in the [[Lisp (programming language)|Lisp programming language]];&lt;ref&gt;{{Cite book|last1=Newell|first1=Allen|last2=Simon|first2=Herbert A.|date=1 January 2007|title=Computer science as empirical inquiry: symbols and search|publisher=ACM|pages=1975|doi=10.1145/1283920.1283930|isbn=9781450310499}}&lt;/ref&gt;
* the process of reorganizing common behavior from non-abstract [[Class (computer programming)|classes]] into "abstract classes" using [[Inheritance (object-oriented programming)|inheritance]] to abstract over [[Inheritance (object-oriented programming)#Subclasses and superclasses|sub-classes]] as seen in the [[Object-oriented programming|object-oriented]] [[C++]] and [[Java (programming language)|Java]] programming languages.

==Rationale==
Computing mostly operates independently of the concrete world. The hardware implements a [[model of computation]] that is interchangeable with others.{{Citation needed|date=June 2018}} The software is structured in [[software architecture|architecture]]s to enable humans to create the enormous systems by concentrating on a few issues at a time. These architectures are made of specific choices of abstractions. [[Greenspun's Tenth Rule]] is an [[aphorism]] on how such an architecture is both inevitable and complex.

A central form of abstraction in computing is language abstraction: new artificial languages are developed to express specific aspects of a system. ''[[Modeling languages]]'' help in planning. ''[[Computer language]]s'' can be processed with a computer. An example of this abstraction process is the generational development of [[programming language]]s from the [[First-generation programming language|machine language]] to the [[Second-generation programming language|assembly language]] and the [[Third-generation programming language|high-level language]]. Each stage can be used as a stepping stone for the next stage. The language abstraction continues for example in [[scripting language]]s and [[domain-specific programming language]]s.

Within a programming language, some features let the programmer create new abstractions. These include [[subroutine]]s, [[module (programming)|modules]], [[polymorphism (computer science)|polymorphism]], and [[software component]]s. Some other abstractions such as [[software design pattern]]s and [[software architecture#Architecture examples|architectural styles]] remain invisible to a [[translator (computing)|translator]] and operate only in the design of a system.

Some abstractions try to limit the range of concepts a programmer needs to be aware of, by completely hiding the abstractions that they in turn are built on. The software engineer and writer [[Joel Spolsky]] has criticised these efforts by claiming that all abstractions are ''[[leaky abstraction|leaky]]'' – that they can never completely hide the details below;&lt;ref&gt;{{cite web|url=http://www.joelonsoftware.com/articles/LeakyAbstractions.html|title=The Law of Leaky Abstractions|last1=Spolsky|first=Joel}}&lt;/ref&gt; however, this does not negate the usefulness of abstraction.

Some abstractions are designed to inter-operate with other abstractions – for example, a programming language may contain a [[foreign function interface]] for making calls to the lower-level language.

==Abstraction features==

===Programming languages===
{{Main|Programming language}}

Different programming languages provide different types of abstraction, depending on the intended applications for the language. For example:

* In [[object-oriented programming language]]s such as [[C++]], [[Object Pascal]], or [[Java (programming language)|Java]], the concept of '''abstraction''' has itself become a declarative statement – using the [[Syntax (programming languages)|syntax]] &lt;code&gt;''function''(''parameters'') = 0;&lt;/code&gt; (in [[C++]]) or the [[keyword (computer programming)|keyword]]s ''&lt;code&gt;abstract&lt;/code&gt;''&lt;ref name="Oracle Java abstract"&gt;{{cite web|url=http://docs.oracle.com/javase/tutorial/java/IandI/abstract.html|title=Abstract Methods and Classes|website=The Java™ Tutorials|publisher=Oracle|access-date=4 September 2014}}&lt;/ref&gt; and ''&lt;code&gt;interface&lt;/code&gt;''&lt;ref name="Oracle Java interface"&gt;{{cite web|url=http://docs.oracle.com/javase/tutorial/java/IandI/interfaceAsType.html|title=Using an Interface as a Type|website=The Java™ Tutorials|publisher=Oracle|access-date=4 September 2014}}&lt;/ref&gt; (in [[Java (programming language)|Java]]). After such a declaration, it is the responsibility of the programmer to implement a [[Class (computer science)|class]] to instantiate the [[Object (computer science)|object]] of the declaration.
* [[Functional programming language]]s commonly exhibit abstractions related to functions, such as [[lambda abstraction]]s (making a term into a function of some variable) and [[higher-order function]]s (parameters are functions). &lt;!-- This has to be merged in the following sections. --&gt;
* Modern members of the Lisp programming language family such as [[Clojure]], [[Scheme (programming language)|Scheme]] and [[Common Lisp]] support [[Macro (computer science)#Syntactic macros|macro systems]] to allow syntactic abstraction. Other programming languages such as [[Scala (programming language)|Scala]] also have macros, or very similar [[metaprogramming]] features (for example, [[Haskell (programming language)|Haskell]] has [[Template Haskell]], and [[OCaml]] has [[MetaOCaml]]). These can allow a programmer to eliminate [[boilerplate code]], abstract away tedious function call sequences, implement new [[Control flow|control flow structures]], and implement [[Domain-specific language|Domain Specific Languages (DSLs)]], which allow domain-specific concepts to be expressed in concise and elegant ways. All of these, when used correctly, improve both the programmer's efficiency and the clarity of the code by making the intended purpose more explicit. A consequence of syntactic abstraction is also that any Lisp dialect and in fact almost any programming language can, in principle, be implemented in any modern Lisp with significantly reduced (but still non-trivial in some cases) effort when compared to "more traditional" programming languages such as [[Python (programming language)|Python]], [[C (programming language)|C]] or [[Java (programming language)|Java]].

===Specification methods===
{{Main|Formal specification}}

Analysts have developed various methods to formally specify software systems.  Some known methods include:

* Abstract-model based method (VDM, Z);
* Algebraic techniques (Larch, CLEAR, OBJ, ACT ONE, CASL);
* Process-based techniques (LOTOS, SDL, Estelle);
* Trace-based techniques (SPECIAL, TAM);
* Knowledge-based techniques (Refine, Gist).

===Specification languages===
{{Main|Specification language}}

Specification languages generally rely on abstractions of one kind or another, since specifications are typically defined earlier in a project, (and at a more abstract level) than an eventual implementation. The [[Unified Modeling Language|UML]] specification language, for example, allows the definition of ''abstract'' classes, which in a waterfall project, remain abstract during the architecture and specification phase of the project.

==Control abstraction==
{{Main|Control flow}}

Programming languages offer control abstraction as one of the main purposes of their use. Computer machines understand operations at the very low level such as moving some bits from one location of the memory to another location and producing the sum of two sequences of bits. Programming languages allow this to be done in the higher level. For example, consider this statement written in a [[Pascal (programming language)|Pascal]]-like fashion:

:&lt;code&gt;a := (1 + 2) * 5&lt;/code&gt;

To a human, this seems a fairly simple and obvious calculation (''"one plus two is three, times five is fifteen"''). However, the low-level steps necessary to carry out this evaluation, and return the value "15", and then assign that value to the variable "a", are actually quite subtle and complex. The values need to be converted to binary representation (often a much more complicated task than one would think) and the calculations decomposed (by the compiler or interpreter) into assembly instructions (again, which are much less intuitive to the programmer: operations such as shifting a binary register left, or adding the binary complement of the contents of one register to another, are simply not how humans think about the abstract arithmetical operations of addition or multiplication). Finally, assigning the resulting value of "15" to the variable labeled "a", so that "a" can be used later, involves additional 'behind-the-scenes' steps of looking up a variable's label and the resultant location in physical or virtual memory, storing the binary representation of "15" to that memory location, etc.

Without control abstraction, a programmer would need to specify ''all'' the register/binary-level steps each time they simply wanted to add or multiply a couple of numbers and assign the result to a variable. Such duplication of effort has two serious negative consequences:

# it forces the programmer to constantly repeat fairly common tasks every time a similar operation is needed
# it forces the programmer to program for the particular hardware and instruction set

===Structured programming===
{{Main|Structured programming}}

Structured programming involves the splitting of complex program tasks into smaller pieces with clear flow-control and interfaces between components, with a reduction of the complexity potential for side-effects.

In a simple program, this may aim to ensure that loops have single or obvious exit points and (where possible) to have single exit points from functions and procedures.

In a larger system, it may involve breaking down complex tasks into many different modules. Consider a system which handles payroll on ships and at shore offices:

* The uppermost level may feature a menu of typical end-user operations.
* Within that could be standalone executables or libraries for tasks such as signing on and off employees or printing checks.
* Within each of those standalone components there could be many different source files, each containing the program code to handle a part of the problem, with only selected interfaces available to other parts of the program. A sign on program could have source files for each data entry screen and the database interface (which may itself be a standalone third party library or a statically linked set of library routines).
*Either the database or the payroll application also has to initiate the process of exchanging data with between ship and shore, and that data transfer task will often contain many other components.

These layers produce the effect of isolating the implementation details of one component and its assorted internal methods from the others. Object-oriented programming embraces and extends this concept.

==Data abstraction==
{{Main|Abstract data type}}

Data abstraction enforces a clear separation between the ''abstract'' properties of a [[data type]] and the ''concrete'' details of its implementation. The abstract properties are those that are visible to client code that makes use of the data type—the ''interface'' to the data type—while the concrete implementation is kept entirely private, and indeed can change, for example to incorporate efficiency improvements over time. The idea is that such changes are not supposed to have any impact on client code, since they involve no difference in the abstract behaviour.

For example, one could define an [[abstract data type]] called ''lookup table'' which uniquely associates ''keys'' with ''values'', and in which values may be retrieved by specifying their corresponding keys. Such a lookup table may be implemented in various ways: as a [[hash table]], a [[binary search tree]], or even a simple linear [[List (computing)|list]] of (key:value) pairs. As far as client code is concerned, the abstract properties of the type are the same in each case.

Of course, this all relies on getting the details of the interface right in the first place, since any changes there can have major impacts on client code. As one way to look at this: the interface forms a ''contract'' on agreed behaviour between the data type and client code; anything not spelled out in the contract is subject to change without notice.

== Manual data abstraction ==
While much of data abstraction occurs through computer science and automation, there are times when this process is done manually and without programming intervention. One way this can be understood is through data abstraction within the process of conducting a [[systematic review]] of the literature. In this methodology, data is abstracted by one or several abstractors when conducting a [[meta-analysis]], with errors reduced through dual data abstraction followed by independent checking, known as [[adjudication]].&lt;ref&gt;{{Cite journal|last1=E|first1=Jian‐Yu|last2=Saldanha|first2=Ian J.|last3=Canner|first3=Joseph|last4=Schmid|first4=Christopher H.|last5=Le|first5=Jimmy T.|last6=Li|first6=Tianjing|date=2020|title=Adjudication rather than experience of data abstraction matters more in reducing errors in abstracting data in systematic reviews|journal=Research Synthesis Methods|language=en|volume=11|issue=3|pages=354–362|doi=10.1002/jrsm.1396|pmid=31955502|issn=1759-2879}}&lt;/ref&gt;

==Abstraction in object oriented programming==
{{Main|Object (computer science)}}

In [[object-oriented programming]] theory, '''abstraction''' involves the facility to define objects that represent abstract "actors" that can perform work, report on and change their state, and "communicate" with other objects in the system. The term [[Encapsulation (object-oriented programming)|encapsulation]] refers to the hiding of [[state (computer science)|state]] details, but extending the concept of ''data type'' from earlier programming languages to associate ''behavior'' most strongly with the data, and standardizing the way that different data types interact, is the beginning of '''abstraction'''.  When abstraction proceeds into the operations defined, enabling objects of different types to be substituted, it is called [[polymorphism (computer science)|polymorphism]]. When it proceeds in the opposite direction, inside the types or classes, structuring them to simplify a complex set of relationships, it is called [[Delegation (object-oriented programming)|delegation]] or [[Inheritance (computer science)|inheritance]].

Various object-oriented programming languages offer similar facilities for abstraction, all to support a general strategy of [[polymorphism (computer science)|polymorphism]] in object-oriented programming, which includes the substitution of one [[type in object-oriented programming|type]] for another in the same or similar role. Although not as generally supported, a [[configuration in object-oriented programming|configuration]] or image or package may predetermine a great many of these [[name binding|bindings]] at [[compile-time]], [[link-time]], or [[loadtime]]. This would leave only a minimum of such bindings to change at [[Run time (program lifecycle phase)|run-time]].

[[Common Lisp Object System]] or [[Self (programming language)|Self]], for example, feature less of a class-instance distinction and more use of delegation for [[polymorphism in object-oriented programming|polymorphism]]. Individual objects and functions are abstracted more flexibly to better fit with a shared functional heritage from [[Lisp programming language|Lisp]].

C++ exemplifies another extreme: it relies heavily on [[generic programming|templates]] and [[method overloading|overloading]] and other static bindings at compile-time, which in turn has certain flexibility problems.

Although these examples offer alternate strategies for achieving the same abstraction, they do not fundamentally alter the need to support abstract nouns in code – all programming relies on an ability to abstract verbs as functions, nouns as data structures, and either as processes.

Consider for example a sample [[Java (programming language)|Java]] fragment to represent some common farm "animals" to a level of abstraction suitable to model simple aspects of their hunger and feeding. It defines an &lt;code&gt;Animal&lt;/code&gt; class to represent both the state of the animal and its functions:

&lt;syntaxhighlight lang="java"&gt;
public class Animal extends LivingThing
{
     private Location loc;
     private double energyReserves;

     public boolean isHungry() {
         return energyReserves &lt; 2.5;
     }
     public void eat(Food food) {
         // Consume food
         energyReserves += food.getCalories();
     }
     public void moveTo(Location location) {
         // Move to new location
         this.loc = location;
     }
}
&lt;/syntaxhighlight&gt;
With the above definition, one could create objects of type {{samp|Animal}} and call their methods like this:

&lt;syntaxhighlight lang="java"&gt;
thePig = new Animal();
theCow = new Animal();
if (thePig.isHungry()) {
    thePig.eat(tableScraps);
}
if (theCow.isHungry()) {
    theCow.eat(grass);
}
theCow.moveTo(theBarn);
&lt;/syntaxhighlight&gt;
In the above example, the class ''&lt;code&gt;Animal&lt;/code&gt;'' is an abstraction used in place of an actual animal, ''&lt;code&gt;LivingThing&lt;/code&gt;'' is a further abstraction (in this case a generalisation) of ''&lt;code&gt;Animal&lt;/code&gt;''.

If one requires a more differentiated hierarchy of animals – to differentiate, say, those who provide milk from those who provide nothing except meat at the end of their lives – that is an intermediary level of abstraction, probably DairyAnimal (cows, goats) who would eat foods suitable to giving good milk, and MeatAnimal (pigs, steers) who would eat foods to give the best meat-quality.

Such an abstraction could remove the need for the application coder to specify the type of food, so s/he could concentrate instead on the feeding schedule. The two classes could be related using [[Inheritance (computer science)|inheritance]] or stand alone, and the programmer could define varying degrees of [[polymorphism (computer science)|polymorphism]] between the two types. These facilities tend to vary drastically between languages, but in general each can achieve anything that is possible with any of the others. A great many operation overloads, data type by data type, can have the same effect at compile-time as any degree of inheritance or other means to achieve polymorphism. The class notation is simply a coder's convenience.

===Object-oriented design===
{{Main|Object-oriented design}}

Decisions regarding what to abstract and what to keep under the control of the coder become the major concern of object-oriented design and [[domain analysis]]—actually determining the relevant relationships in the real world is the concern of [[object-oriented analysis and design|object-oriented analysis]] or [[legacy analysis]].

In general, to determine appropriate abstraction, one must make many small decisions about scope (domain analysis), determine what other systems one must cooperate with (legacy analysis), then perform a detailed object-oriented analysis which is expressed within project time and budget constraints as an object-oriented design. In our simple example, the domain is the barnyard, the live pigs and cows and their eating habits are the legacy constraints, the detailed analysis is that coders must have the flexibility to feed the animals what is available and thus there is no reason to code the type of food into the class itself, and the design is a single simple Animal class of which pigs and cows are instances with the same functions. A decision to differentiate DairyAnimal would change the detailed analysis but the domain and legacy analysis would be unchanged—thus it is entirely under the control of the programmer, and it is called an abstraction in object-oriented programming as distinct from abstraction in domain or legacy analysis.

==Considerations==
When discussing [[formal semantics of programming languages]], [[formal methods]] or [[abstract interpretation]], '''abstraction''' refers to the act of considering a less detailed, but safe, definition of the observed program behaviors. For instance, one may observe only the final result of program executions instead of considering all the intermediate steps of executions. Abstraction is defined to a '''concrete''' (more precise) model of execution.

Abstraction may be '''exact''' or '''faithful''' with respect to a property if one can answer a question about the property equally well on the concrete or abstract model. For instance, if one wishes to know what the result of the evaluation of a mathematical expression involving only integers +, -, ×, is worth [[modular arithmetic|modulo]] ''n'', then one needs only perform all operations modulo ''n'' (a familiar form of this abstraction is [[casting out nines]]).

Abstractions, however, though not necessarily '''exact''', should be '''sound'''. That is, it should be possible to get sound answers from them—even though the abstraction may simply yield a result of [[undecidable problem|undecidability]]. For instance, students in a class may be abstracted by their minimal and maximal ages; if one asks whether a certain person belongs to that class, one may simply compare that person's age with the minimal and maximal ages; if his age lies outside the range, one may safely answer that the person does not belong to the class; if it does not, one may only answer "I don't know".

The level of abstraction included in a programming language can influence its overall [[usability]]. The [[Cognitive dimensions]] framework includes the concept of ''abstraction gradient'' in a formalism. This framework allows the designer of a programming language to study the trade-offs between abstraction and other characteristics of the design, and how changes in abstraction influence the language usability.

Abstractions can prove useful when dealing with computer programs, because non-trivial properties of computer programs are essentially [[undecidable problem|undecidable]] (see [[Rice's theorem]]). As a consequence, automatic methods for deriving information on the behavior of computer programs either have to drop termination (on some occasions, they may fail, crash or never yield out a result), soundness (they may provide false information), or precision (they may answer "I don't know" to some questions).

Abstraction is the core concept of [[abstract interpretation]]. [[Model checking]] generally takes place on abstract versions of the studied systems.

==Levels of abstraction==
{{Main|Abstraction layer}}

Computer science commonly presents ''levels'' (or, less commonly, ''layers'') of abstraction, wherein each level represents a different model of the same information and processes, but with varying amounts of detail. Each level uses a system of expression involving a unique set of objects and compositions that apply only to a particular domain.
&lt;ref&gt;[[Luciano Floridi]], [http://www.cs.ox.ac.uk/activities/ieg/research_reports/ieg_rr221104.pdf ''Levellism and the Method of Abstraction'']
IEG – Research Report 22.11.04&lt;/ref&gt;
Each relatively abstract, "higher" level builds on a relatively concrete, "lower" level, which tends to provide an increasingly "granular" representation. For example, gates build on electronic circuits, binary on gates, machine language on binary, programming language on machine language, applications and operating systems on programming languages. Each level is embodied, but not determined, by the level beneath it, making it a language of description that is somewhat self-contained.

===Database systems===
{{Main|Database management system}}

Since many users of database systems lack in-depth familiarity with computer data-structures, database developers often hide complexity through the following levels:

[[Image:Data abstraction levels.png|thumb|Data abstraction levels of a database system]]

'''Physical level:''' The lowest level of abstraction describes ''how'' a system actually stores data. The physical level describes complex low-level data structures in detail.

'''Logical level:''' The next higher level of abstraction describes ''what'' data the database stores, and what relationships exist among those data. The logical level thus describes an entire database in terms of a small number of relatively simple structures. Although implementation of the simple structures at the logical level may involve complex physical level structures, the user of the logical level does not need to be aware of this complexity. This is referred to as [[physical data independence]]. [[Database administrator]]s, who must decide what information to keep in a database, use the logical level of abstraction.

'''View level:''' The highest level of abstraction describes only part of the entire database. Even though the logical level uses simpler structures, complexity remains because of the variety of information stored in a large database. Many users of a database system do not need all this information; instead, they need to access only a part of the database. The view level of abstraction exists to simplify their interaction with the system. The system may provide many [[view (database)|view]]s for the same database.

===Layered architecture===
{{Main|Abstraction layer}}
The ability to provide a [[design]] of different levels of abstraction can

* simplify the design considerably
* enable different role players to effectively work at various levels of abstraction
* support the portability of [[software artifact]]s (model-based ideally)

[[Systems design]] and [[Business process modeling|business process design]] can both use this. Some [[Software modeling|design processes]] specifically generate designs that contain various levels of abstraction.

Layered architecture partitions the concerns of the application into stacked groups (layers).
It is a technique used in designing computer software, hardware, and communications in which system or network components are isolated in layers so that changes can be made in one layer without affecting the others.

==See also==
* [[Abstraction principle (computer programming)]]
* [[Abstraction inversion]] for an anti-pattern of one danger in abstraction
* [[Abstract data type]] for an abstract description of a set of data
* [[Algorithm]] for an abstract description of a computational procedure
* [[Bracket abstraction]] for making a term into a function of a variable
* [[Data modeling]] for structuring data independent of the processes that use it
* [[Encapsulation (object-oriented programming)|Encapsulation]] for abstractions that hide implementation details
* [[Greenspun's Tenth Rule]] for an aphorism about an (the?) optimum point in the space of abstractions
* [[Higher-order function]] for abstraction where functions produce or consume other functions
* [[Lambda abstraction]] for making a term into a function of some variable
* [[List of abstractions (computer science)]]
* [[Program refinement|Refinement]] for the opposite of abstraction in computing
* [[Integer (computer science)]]
* [[Heuristic (computer science)]]

==References==
{{Reflist}}
{{refbegin}}
* {{FOLDOC}}
{{refend}}

==Further reading==
{{refbegin}}
* {{cite book|author1=Harold Abelson|author2=Gerald Jay Sussman|author3=Julie Sussman|title=Structure and Interpretation of Computer Programs|url=http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-10.html|access-date=22 June 2012|edition=2|date=25 July 1996|publisher=MIT Press|isbn=978-0-262-01153-2|archive-url=https://web.archive.org/web/20090226050622/http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-10.html|archive-date=26 February 2009|url-status=dead}}
* {{cite web|last=Spolsky|first=Joel|title=The Law of Leaky Abstractions|url=http://www.joelonsoftware.com/articles/LeakyAbstractions.html|work=Joel on Software|date=11 November 2002}}
* [http://www.cs.cornell.edu/courses/cs211/2006sp/Lectures/L08-abstraction/08_abstraction.html Abstraction/information hiding] – CS211 course, Cornell University.
* {{cite book|author=Eric S. Roberts|title=Programming Abstractions in C A Second Course in Computer Science|date=1997}}
* {{cite web|last=Palermo|first=Jeffrey|title=The Onion Architecture|url=http://jeffreypalermo.com/blog/the-onion-architecture-part-1/|work=Jeffrey Palermo|date=29 July 2008}} 
*{{Cite journal
| last1=Vishkin | first1=Uzi
| journal=Communications of the ACM
| volume=54
| issue=1
| date=January 2011 
| title=Using simple abstraction to reinvent computing for parallelism
| pages=75–85
| doi=10.1145/1866739.1866757
| doi-access=free
}}
{{refend}}

==External links==
* [https://sites.google.com/site/simulationarchitecture/ SimArch] example of layered architecture for distributed simulation systems.

{{DEFAULTSORT:Abstraction (computer science)}}
[[Category:Data management]]
[[Category:Articles with example Java code]]
[[Category:Abstraction]]
[[Category:Computer science]]
[[Category:Object-oriented programming]]</text>
      <sha1>o1zwszav5no1t5w5mjsdlzuy1u8prpo</sha1>
    </revision>
  </page>
  <page>
    <title>Integer (computer science)</title>
    <ns>0</ns>
    <id>14794</id>
    <revision>
      <id>1008325057</id>
      <parentid>1008307560</parentid>
      <timestamp>2021-02-22T19:06:48Z</timestamp>
      <contributor>
        <username>Omnissiahs hierophant</username>
        <id>38027938</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="25909" xml:space="preserve">{{short description|Datum of integral data type}}
In computer science, an '''integer''' is a [[data|datum]] of '''integral data type''', a [[data type]] that represents some [[interval (mathematics)|range]] of mathematical [[integer]]s. Integral data types may be of different sizes and may or may not be allowed to contain negative values. Integers are commonly represented in a computer as a group of binary digits (bits). The size of the grouping varies so the set of integer sizes available varies between different types of computers. Computer hardware nearly always provide a way to represent a processor [[word size|register]] or memory address as an integer.

== Value and representation ==
The ''value'' of an item with an integral type is the mathematical integer that it corresponds to. Integral types may be ''unsigned'' (capable of representing only non-negative integers) or ''signed'' (capable of representing negative integers as well).&lt;ref&gt;{{cite web |url=http://www.swarthmore.edu/NatSci/echeeve1/Ref/BinaryMath/NumSys.html |title=Representation of numbers |last=Cheever |first=Eric |publisher=Swarthmore College |access-date=2011-09-11}}&lt;/ref&gt;

An integer value is typically specified in the [[source code]] of a program as a sequence of digits optionally prefixed with + or −. Some programming languages allow other notations, such as hexadecimal (base 16) or octal (base 8). Some programming languages also permit [[digit group separator]]s.&lt;ref&gt;{{cite web|author=Madhusudhan Konda |url=http://radar.oreilly.com/2011/09/java7-features.html |title=A look at Java 7's new features - O'Reilly Radar |publisher=Radar.oreilly.com |date=2011-09-02 |access-date=2013-10-15}}&lt;/ref&gt;

The ''internal representation'' of this datum is the way the value is stored in the computer's memory. Unlike mathematical integers, a typical datum in a computer has some minimal and maximum possible value.

The most common representation of a positive integer is a string of [[bit]]s, using the [[binary numeral system]]. The order of the memory [[byte]]s storing the bits varies; see [[endianness]]. The ''width'' or ''precision'' of an integral type is the number of bits in its representation. An integral type with ''n'' bits can encode 2&lt;sup&gt;''n''&lt;/sup&gt; numbers; for example an unsigned type typically represents the non-negative values 0 through 2&lt;sup&gt;''n''&lt;/sup&gt;−1. Other encodings of integer values to bit patterns are sometimes used, for example [[binary-coded decimal]] or [[Gray code]], or as printed character codes such as [[ASCII]].

There are four well-known [[signed number representations|ways to represent signed numbers]] in a binary computing system. The most common is [[two's complement]], which allows a signed integral type with ''n'' bits to represent numbers from −2&lt;sup&gt;(''n''−1)&lt;/sup&gt; through 2&lt;sup&gt;(''n''−1)&lt;/sup&gt;−1. Two's complement arithmetic is convenient because there is a perfect [[bijection|one-to-one correspondence]] between representations and values (in particular, no separate +0 and −0), and because [[addition]], [[subtraction]] and [[multiplication]] do not need to distinguish between signed and unsigned types. Other possibilities include [[offset binary]], [[sign-magnitude]], and [[ones' complement]].

Some computer languages define integer sizes in a machine-independent way; others have varying definitions depending on the underlying processor word size. Not all language implementations define variables of all integer sizes, and defined sizes may not even be distinct in a particular implementation. An integer in one [[programming language]] may be a different size in a different language or on a different processor.

== Common integral data types ==
{| class="wikitable"
|-
! rowspan="2" | Bits
! rowspan="2" | Name
! rowspan="2" | Range (assuming [[two's complement]] for [[Signed number representations|signed]])
! rowspan="2" | Decimal digits
! rowspan="2" | Uses
! colspan="7" scope="col" | Implementations
|-
! [[C (programming language)|C]]/[[C++]]
! [[C Sharp (programming language)|C#]]
! [[Pascal (programming language)|Pascal]] and [[Delphi (programming language)|Delphi]]
! [[Java (programming language)|Java]]
! [[SQL]]{{efn |name=notesqla    | Not all SQL dialects have unsigned datatypes.&lt;ref name=SybDT&gt;{{cite web|url=http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.infocenter.dc36271.1550/html/blocks/blocks20.htm |title=Sybase Adaptive Server Enterprise 15.5: Exact Numeric Datatypes}}&lt;/ref&gt;&lt;ref name=MySQLDT&gt;{{cite web|url=http://dev.mysql.com/doc/refman/5.6/en/numeric-types.html |title=MySQL 5.6 Numeric Datatypes}}&lt;/ref&gt;}}
! [[Fortran|FORTRAN]]
! [[D (programming language)|D]]
|-
|rowspan=2| &lt;div style="float:right;"&gt;4&lt;/div&gt;
|rowspan=2| [[nibble]], semioctet
|''[[Signed number representations|Signed:]]'' From −8 to 7, from −(2&lt;sup&gt;3&lt;/sup&gt;) to 2&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:3*ln2/ln10 round 2}}&lt;/div&gt;
| rowspan="2" | [[Binary-coded decimal]], single decimal digit representation
| rowspan="2" | n/a
| rowspan="2" | n/a
| rowspan="2" | n/a
| rowspan="2" | n/a
| rowspan="2" | n/a
| rowspan="2" | n/a
| rowspan="2" | n/a
|-
|''Unsigned:'' From 0 to 15, which equals 2&lt;sup&gt;4&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:4*ln2/ln10 round 2}}&lt;/div&gt;
|-
|rowspan=2| &lt;div style="float:right;"&gt;8&lt;/div&gt;
|rowspan=2| [[byte]], [[octet (computing)|octet]], i8, u8
|''Signed:'' From −128 to 127, from −(2&lt;sup&gt;7&lt;/sup&gt;) to 2&lt;sup&gt;7&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:7*ln2/ln10 round 2}}&lt;/div&gt;
| rowspan="2" | [[ASCII]] characters, [[code unit]]s in the [[UTF-8]] [[character encoding]]
| {{mono|int8_t}}, {{mono|signed char}}{{efn|name=notescb|garbage=8 char}}
| {{mono|sbyte}}
| {{mono|Shortint}}
| {{mono|byte}}
| {{mono|tinyint}}
| {{mono|integer(1)}}
| {{mono|byte}}
|-
|''Unsigned:'' From 0 to 255, which equals 2&lt;sup&gt;8&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:8*ln2/ln10 round 2}}&lt;/div&gt;
| {{mono|uint8_t}}, {{mono|unsigned char}}{{efn|name=notescb|garbage=8 char}}
| {{mono|byte}}
| {{mono|Byte}}
| n/a
| {{mono|unsigned tinyint}}
| n/a
| {{mono|ubyte}}
|-
|rowspan=2| &lt;div style="float:right;"&gt;16&lt;/div&gt;
|rowspan=2| halfword, [[Word (data type)|word]], short, i16, u16
|''Signed:'' From −32,768 to 32,767, from −(2&lt;sup&gt;15&lt;/sup&gt;) to 2&lt;sup&gt;15&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:15*ln2/ln10 round 2}}&lt;/div&gt;
| rowspan="2" | [[Universal Character Set|UCS-2]] characters, [[code unit]]s in the [[UTF-16]] [[character encoding]]
| {{mono|int16_t}}, {{mono|short}}{{efn|name=notescb|garbage=16 short}}, {{mono|int}}{{efn|name=notescb|garbage=16 int}}
| {{mono|short}}
| {{mono|Smallint}}
| {{mono|short}}
| {{mono|smallint}}
| {{mono|integer(2)}}
| {{mono|short}}
|-
|''Unsigned:'' From 0 to 65,535, which equals 2&lt;sup&gt;16&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:16*ln2/ln10 round 2}}&lt;/div&gt;
| {{mono|uint16_t, unsigned}}{{efn|name=notescb|garbage=16 int}}, {{mono|unsigned int}}{{efn|name=notescb|garbage=16 int}}
| {{mono|ushort}}
| {{mono|Word}}
| {{mono|char}}{{efn|name=notejavad}}
| {{mono|unsigned smallint}}
| n/a
| {{mono|ushort}}
|-
|rowspan=2| &lt;div style="float:right;"&gt;32&lt;/div&gt;
|rowspan=2| word, [[Unsigned long integer|long]], doubleword, longword, int, i32, u32
|''Signed:'' From [[2147483647 (number)|−2,147,483,648 to 2,147,483,647]], from −(2&lt;sup&gt;31&lt;/sup&gt;) to 2&lt;sup&gt;31&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:31*ln2/ln10 round 2}}&lt;/div&gt;
| rowspan="2"| [[UTF-32]] characters, [[24-bit color|true color]] with alpha, [[FourCC]], pointers in [[32-bit computing]]
| {{mono|int32_t}}, {{mono|int}}{{efn|name=notescb|garbage=32 int}}, {{mono|long}}{{efn|name=notescb|garbage=32 long}}
| {{mono|int}}
| {{mono|LongInt}}; {{mono|Integer}}{{efn|name=notedelphic|garbage=signed}}
| {{mono|int}}
| {{mono|int}}
| {{mono|integer(4)}}
| {{mono|int}}
|-
|''Unsigned:'' From 0 to 4,294,967,295, which equals 2&lt;sup&gt;32&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:32*ln2/ln10 round 2}}&lt;/div&gt;
| {{mono|uint32_t, unsigned}}{{efn|name=notescb|garbage=16 int}}, {{mono|unsigned int}}{{efn|name=notescb|garbage=16 int}}, {{mono|unsigned long}}{{efn|name=notescb|garbage=16 int}}
| {{mono|uint}}
| {{mono|LongWord}}; {{mono|DWord}}; {{mono|Cardinal}}{{efn|name=notedelphic|garbage=unsigned}}
| n/a
| {{mono|unsigned int}}
| n/a
| {{mono|uint}}
|-
| rowspan="2" | &lt;div style="float:right;"&gt;64&lt;/div&gt;
| rowspan="2" | word, doubleword, longword, long long, quad, quadword, qword, int64, i64, u64
|''Signed:'' From −9,223,372,036,854,775,808 to [[9223372036854775807|9,223,372,036,854,775,807]], from −(2&lt;sup&gt;63&lt;/sup&gt;) to 2&lt;sup&gt;63&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:63*ln2/ln10 round 2}}&lt;/div&gt;
| rowspan="2" | Time (milliseconds since the [[Unix epoch]]), pointers in [[64-bit computing]]
| {{mono|int64_t}}, {{mono|long}}{{efn|name=notescb|garbage=64 long}}, {{mono|long long}}{{efn|name=notescb|garbage=64 long long}}
| {{mono|long}}
| {{mono|Int64}}
| {{mono|long}}
| {{mono|bigint}}
| {{mono|integer(8)}}
| {{mono|long}}
|-
|''Unsigned:'' From 0 to 18,446,744,073,709,551,615, which equals 2&lt;sup&gt;64&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:64*ln2/ln10 round 2}}&lt;/div&gt;
| {{mono|uint64_t}}, {{mono|unsigned long long}}{{efn|name=notescb|garbage=16 int}}
| {{mono|ulong}}
| {{mono|UInt64}}; {{mono|QWord}}
| n/a
| {{mono|unsigned bigint}}
| n/a
| {{mono|ulong}}
|-
|rowspan=2| &lt;div style="float:right;"&gt;128&lt;/div&gt;
|rowspan=2| octaword, double quadword, i128, u128
|''Signed:'' From −170,141,183,460,469,231,731,687,303,715,884,105,728 to 170,141,183,460,469,231,731,687,303,715,884,105,727, from −(2&lt;sup&gt;127&lt;/sup&gt;) to 2&lt;sup&gt;127&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
|&lt;div style="float:right;"&gt;{{#expr:127*ln2/ln10 round 2}}&lt;/div&gt;
|rowspan=2| Complex scientific calculations,
[[IPv6]] addresses,
[[GUID]]s
|rowspan=2| C: only available as non-standard compiler-specific extension
|rowspan=2| n/a
|rowspan=2| n/a
|rowspan=2| n/a
| rowspan="2" | n/a
| {{mono|integer(16)}}
| {{mono|cent}}{{efn|name=notede|garbage=reserved}}
|-
| ''Unsigned:'' From 0 to 340,282,366,920,938,463,463,374,607,431,768,211,455, which equals 2&lt;sup&gt;128&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1
| &lt;div style="float:right;"&gt;{{#expr:128*ln2/ln10 round 2}}&lt;/div&gt;
| n/a
| {{mono|ucent}}{{efn|name=notede|garbage=reserved}}
|-
| rowspan="2" | &lt;div style="float:right;"&gt;''n''&lt;/div&gt;
| rowspan="2" | ''n''-bit integer&lt;br /&gt; (general case)
| ''Signed:'' −(2&lt;sup&gt;''n''−1&lt;/sup&gt;) to (2&lt;sup&gt;''n''−1&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1)
| colspan="2" | (''n''&amp;nbsp;−&amp;nbsp;1) log&lt;sub&gt;10&lt;/sub&gt;&amp;nbsp;2
| colspan="7" | [[Ada (programming language)|Ada]]: {{mono|range -2**(n-1)..2**(n-1)-1}}
|-
| ''Unsigned:'' 0 to (2&lt;sup&gt;''n''&lt;/sup&gt; − 1)
| colspan="2" | ''n'' log&lt;sub&gt;10&lt;/sub&gt;&amp;nbsp;2
| colspan="7" | Ada: {{mono|range 0..2**n-1}}, {{mono|mod 2**n}}; standard libraries' or third-party arbitrary arithmetic libraries' BigDecimal or Decimal classes in many languages such as Python, C++, etc.
|}

Different [[Central processing unit|CPUs]] support different integral data types. Typically, hardware will support both signed and unsigned types, but only a small, fixed set of widths.

The table above lists integral type widths that are supported in hardware by common processors. High level programming languages provide more possibilities. It is common to have a 'double width' integral type that has twice as many bits as the biggest hardware-supported type. Many languages also have ''bit-field'' types (a specified number of bits, usually constrained to be less than the maximum hardware-supported width) and ''range'' types (that can represent only the integers in a specified range).

Some languages, such as [[Lisp programming language|Lisp]], [[Smalltalk]], [[REXX]], [[Haskell (programming language)|Haskell]], [[Python (programming language)|Python]], and [[Raku (programming language)|Raku]] support ''arbitrary precision'' integers (also known as ''infinite precision integers'' or ''[[bignum]]s''). Other languages that do not support this concept as a top-level construct may have libraries available to represent very large numbers using arrays of smaller variables, such as Java's {{mono|BigInteger}} class or [[Perl]]'s "{{mono|bigint}}" package.&lt;ref&gt;{{cite web |url=http://download.oracle.com/javase/6/docs/api/java/math/BigInteger.html |title=BigInteger (Java Platform SE 6) |publisher=Oracle |access-date=2011-09-11 }}&lt;/ref&gt; These use as much of the computer's memory as is necessary to store the numbers; however, a computer has only a finite amount of storage, so they too can only represent a finite subset of the mathematical integers. These schemes support very large numbers, for example one kilobyte of memory could be used to store numbers up to 2466 decimal digits long.

A [[Boolean datatype|Boolean]] or [[Flag (computing)|Flag]] type is a type that can represent only two values: 0 and 1, usually identified with ''false'' and ''true'' respectively. &lt;!-- Pascal has them the other way around --&gt; This type can be stored in memory using a single bit, but is often given a full byte for convenience of addressing and speed of access.

A four-bit quantity is known as a ''[[nibble]]'' (when eating, being smaller than a ''bite'') or ''nybble'' (being a pun on the form of the word ''byte''). One nibble corresponds to one digit in [[hexadecimal]] and holds one digit or a sign code in binary-coded decimal.

=== Bytes and octets ===
{{Main article|Byte|Octet (computing)}}
The term ''byte'' initially meant 'the smallest addressable unit of memory'. In the past, 5-, 6-, 7-, 8-, and 9-bit bytes have all been used. There have also been computers that could address individual bits ('bit-addressed machine'), or that could only address 16- or 32-bit quantities ('word-addressed machine'). The term ''byte'' was usually not used at all in connection with bit- and word-addressed machines.

The term ''octet'' always refers to an 8-bit quantity. It is mostly used in the field of [[computer network]]ing, where computers with different byte widths might have to communicate.

In modern usage ''byte'' almost invariably means eight bits, since all other sizes have fallen into disuse; thus ''byte'' has come to be synonymous with ''octet''.

=== Words ===
{{Main article|Word (computer architecture)}}
The term 'word' is used for a small group of bits that are handled simultaneously by processors of a particular [[computer architecture|architecture]]. The size of a word is thus CPU-specific. Many different word sizes have been used, including 6-, 8-, 12-, 16-, 18-, 24-, 32-, 36-, 39-, 40-, 48-, 60-, and 64-bit. Since it is architectural, the size of a ''word'' is usually set by the first CPU in a family, rather than the characteristics of a later compatible CPU. The meanings of terms derived from ''word'', such as ''longword'', ''doubleword'', ''quadword'', and ''halfword'', also vary with the CPU and OS.&lt;ref name="agnerfog" /&gt;

Practically all new desktop processors are capable of using 64-bit words, though [[Embedded system|embedded processors]] with 8- and 16-bit word size are still common. The [[36-bit|36-bit word length]] was common in the early days of computers.

One important cause of non-portability of software is the incorrect assumption that all computers have the same word size as the computer used by the programmer. For example, if a programmer using the C language incorrectly declares as {{mono|int}} a variable that will be used to store values greater than 2&lt;sup&gt;15&lt;/sup&gt;−1, the program will fail on computers with 16-bit integers. That variable should have been declared as {{mono|long}}, which has at least 32 bits on any computer. Programmers may also incorrectly assume that a pointer can be converted to an integer without loss of information, which may work on (some) 32-bit computers, but fail on 64-bit computers with 64-bit pointers and 32-bit integers. This issue is resolved by C99 in [[stdint.h]] in the form of {{code|intptr_t}}.

===Short integer===
A ''short integer'' can represent a whole number that may take less storage, while having a smaller range, compared with a standard integer on the same machine.

In [[C (programming language)|C]], it is denoted by {{mono|short}}. It is required to be at least 16 bits, and is often smaller than a standard integer, but this is not required.&lt;ref name="c99" /&gt;&lt;ref name="drdobbsinteger" /&gt; A conforming program can assume that it can safely store values between −(2&lt;sup&gt;15&lt;/sup&gt;−1)&lt;ref name="c-std-6.2.6.2p2"&gt;{{cite web |url=http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1570.pdf |at=section 6.2.6.2, paragraph 2|title=ISO/IEC 9899:201x |access-date=2016-06-20 |publisher=open-std.org}}&lt;/ref&gt; and 2&lt;sup&gt;15&lt;/sup&gt;−1,&lt;ref name="c-std-5.2.4.2.1"&gt;{{cite web |url=http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1570.pdf |at=section 5.2.4.2.1|title=ISO/IEC 9899:201x |access-date=2016-06-20 |publisher=open-std.org}}&lt;/ref&gt; but it may not assume that the range isn't larger. In [[Java (programming language)|Java]], a {{mono|short}} is ''always'' a 16-bit integer. In the [[Windows API]], the datatype {{mono|SHORT}} is defined as a 16-bit signed integer on all machines.&lt;ref name="agnerfog" /&gt;

{| class="wikitable"
|+ Common short integer sizes
|-
! [[Programming language]]
! Data type name
! [[Signedness]]
! Size in [[bytes]]
! Minimum value
! Maximum value
|-
| rowspan="2" | [[C (programming language)|C]] and [[C++]]
| {{mono|short}}
| signed
| style="text-align:right;" | 2
| style="text-align:right;" | −32,767{{efn|The ISO C standard allows implementations to reserve the value with sign bit 1 and all other bits 0 (for sign–magnitude and two's complement representation) or with all bits 1 (for ones' complement) for use as a "trap" value, used to indicate (for example) an overflow.&lt;ref name="c-std-6.2.6.2p2" /&gt;}}
| style="text-align:right;" | +32,767
|-
| {{mono|unsigned short}}
| unsigned
| style="text-align:right;" | 2
| style="text-align:right;" | 0
| style="text-align:right;" | 65,535
|-
| rowspan="2" | [[C Sharp (programming language)|C#]]
| {{mono|short}}
| signed
| style="text-align:right;" | 2
| style="text-align:right;" | −32,768
| style="text-align:right;" | +32,767
|-
| {{mono|ushort}}
| unsigned
| style="text-align:right;" | 2
| style="text-align:right;" | 0
| style="text-align:right;" | 65,535
|-
| [[Java (programming language)|Java]]
| {{mono|short}}
| signed
| style="text-align:right;" | 2
| style="text-align:right;" | −32,768
| style="text-align:right;" | +32,767
|}

===Long integer===
A ''long integer'' can represent a whole [[integer]] whose [[range (computer science)|range]] is greater than or equal to that of a standard integer on the same machine.

In [[C (programming language)|C]], it is denoted by {{mono|long}}. It is required to be at least 32 bits, and may or may not be larger than a standard integer. A conforming program can assume that it can safely store values between −(2&lt;sup&gt;31&lt;/sup&gt;−1)&lt;ref name="c-std-6.2.6.2p2" /&gt; and 2&lt;sup&gt;31&lt;/sup&gt;−1,&lt;ref name="c-std-5.2.4.2.1" /&gt; but it may not assume that the range isn't larger.

{| class="wikitable"
|+ Common long integer sizes
|-
! [[Programming language]]
! Approval Type
! [[Platform (computing)|Platform]]s
! Data type name
! Storage in [[bytes]]
! [[Signedness|Signed]] range
! [[Signedness|Unsigned]] range
|-
| [[C (programming)|C]] ISO/ANSI C99
| International Standard
| [[Unix]],16/32-bit systems&lt;ref name="agnerfog" /&gt;&lt;br&gt;[[Windows]],16/32/64-bit systems&lt;ref name="agnerfog" /&gt;
| {{mono|long}}{{efn|name=cross1|The terms {{mono|long}} and {{mono|int}} are equivalent&lt;ref&gt;{{cite web |url=http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1570.pdf |title=ISO/IEC 9899:201x |access-date=2013-03-27 |publisher=open-std.org}}&lt;/ref&gt;}}
| 4&lt;br&gt;(minimum requirement 4)
| −2,147,483,647 to +2,147,483,647
| 0 to 4,294,967,295&lt;br&gt;(minimum requirement)
|-
| [[C (programming)|C]] ISO/ANSI C99
| International Standard
| [[Unix]],&lt;br&gt;64-bit systems&lt;ref name="agnerfog" /&gt;&lt;ref name="drdobbsinteger" /&gt;
| {{mono|long}}{{efn|name=cross1}}
| 8&lt;br&gt;(minimum requirement 4)
| −9,223,372,036,854,775,807 to +9,223,372,036,854,775,807
| 0 to 18,446,744,073,709,551,615
|-
| [[C++]] ISO/ANSI
| International Standard
| [[Unix]], [[Windows]],&lt;br&gt;16/32-bit system
| {{mono|long}}{{efn|name=cross1}}
| 4 &lt;ref&gt;{{cite web
 | title=Fundamental types in C++|url=http://cppreference.com/wiki/language/types|publisher=cppreference.com|access-date=5 December 2010}}&lt;/ref&gt;&lt;br&gt;(minimum requirement 4)
| −2,147,483,648 to +2,147,483,647&lt;br&gt;
| 0 to 4,294,967,295&lt;br&gt;(minimum requirement)
|-
| [[C++/CLI]]
| International Standard&lt;br&gt;[[ECMA-372]]
| [[Unix]], [[Windows]],&lt;br&gt;16/32-bit systems
| {{mono|long}}{{efn|name=cross1}}
| 4 &lt;ref&gt;{{cite web| url=http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-372.pdf |title=Chapter 8.6.2 on page 12|publisher=ecma-international.org}}&lt;/ref&gt;&lt;br&gt;(minimum requirement 4)
| −2,147,483,648 to +2,147,483,647&lt;br&gt;
| 0 to 4,294,967,295&lt;br&gt;(minimum requirement)
|-
| [[Visual Basic|VB]]
| Company Standard
| [[Microsoft Windows|Windows]]
| {{mono|Long}}
| 4 &lt;ref&gt;VB 6.0 help file&lt;/ref&gt;
| −2,147,483,648 to +2,147,483,647
| N/A
|-
| [[Visual Basic for Applications|VBA]]
| Company Standard
| [[Microsoft Windows|Windows]], [[Mac OS X]]
| {{mono|Long}}
| 4 &lt;ref&gt;{{cite web |url=http://msdn2.microsoft.com/en-us/library/aa164754(office.10).aspx |title=The Integer, Long, and Byte Data Types (VBA) |access-date=2006-12-19 |publisher=microsoft.com}}&lt;/ref&gt;
| −2,147,483,648 to +2,147,483,647
| N/A
|-
| [[Microsoft SQL Server|SQL Server]]
| Company Standard
| [[Microsoft Windows|Windows]]
| {{mono|BigInt}}
| 8
| −9,223,372,036,854,775,808 to +9,223,372,036,854,775,807
| 0 to 18,446,744,073,709,551,615
|-
| [[C Sharp (programming language)|C#]]/ [[Visual Basic .NET|VB.NET]]
| ECMA International Standard
| [[Microsoft .NET]]
| {{mono|long}} or {{mono|Int64}}
| 8
| −9,223,372,036,854,775,808 to +9,223,372,036,854,775,807
| 0 to 18,446,744,073,709,551,615
|-
| [[Java (programming language)|Java]]
| International/Company Standard
| [[Java platform]]
| {{mono|long}}
| 8
| −9,223,372,036,854,775,808 to +9,223,372,036,854,775,807
| N/A
|-
| [[Pascal (programming language)|Pascal]]
| ?
| [[Microsoft Windows|Windows]], [[UNIX]]
| {{mono|int64}}
| 8
| −9,223,372,036,854,775,808 to +9,223,372,036,854,775,807
| 0 to 18,446,744,073,709,551,615 (Qword type)
|}

===Long long===
{{redirect-distinguish|long long|long (disambiguation){{!}}long|Long, Long, Long}}
In the [[C99]] version of the [[C (programming language)|C programming language]] and the [[C++11]] version of [[C++]], a &lt;CODE&gt;long long&lt;/CODE&gt; type is supported that has double the minimum capacity of the standard &lt;CODE&gt;long&lt;/CODE&gt;. This type is not supported by compilers that require C code to be compliant with the previous C++ standard, C++03, because the {{mono|long long}} type did not exist in C++03. For an ANSI/ISO compliant compiler, the minimum requirements for the specified ranges, that is, −(2&lt;sup&gt;63&lt;/sup&gt;&amp;minus;1)&lt;ref name="c-std-6.2.6.2p2" /&gt; to 2&lt;sup&gt;63&lt;/sup&gt;−1 for signed and 0 to 2&lt;sup&gt;64&lt;/sup&gt;−1 for unsigned,&lt;ref name="c-std-5.2.4.2.1" /&gt; must be fulfilled; however, extending this range is permitted.&lt;ref&gt;{{cite web| url=http://www.ericgiguere.com/articles/ansi-c-summary.html|title=The ANSI Standard: A Summary for the C Programmer|first=Eric|last=Giguere|date=December 18, 1987|access-date=2010-09-04}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://flash-gordon.me.uk/ansi.c.txt|title=American National Standard Programming Language C specifies the syntax and semantics of programs written in the C programming language.|access-date=2010-09-04|url-status=dead|archive-url=https://web.archive.org/web/20100822072551/http://flash-gordon.me.uk/ansi.c.txt|archive-date=2010-08-22}}&lt;/ref&gt; This can be an issue when exchanging code and data between platforms, or doing direct hardware access. Thus, there are several sets of headers providing platform independent exact width types. The C [[standard library]] provides ''[[stdint.h]]''; this was introduced in C99 and C++11.

== See also ==
* [[Arbitrary-precision arithmetic]]
* [[Binary-coded decimal]] (BCD)
* [[C data types]]
* [[Integer overflow]]
* [[Signed number representations]]

== Notes ==
{{Notelist|notes=

{{efn |name=notejavad   | Java does not directly support arithmetic on {{mono|char}} types. The results must be cast back into {{mono|char}} from an {{mono|int}}.}}
{{efn |name=notede      | Reserved for future use. Not implemented yet. }}
{{efn |name=notedelphic | The sizes of Delphi's {{mono|Integer}} and {{mono|Cardinal}} are not guaranteed, varying from platform to platform; usually defined as {{mono|LongInt}} and {{mono|LongWord}} respectively.}}
{{efn |name=notescb     | The sizes of {{mono|char}}, {{mono|short}}, {{mono|int}}, {{mono|long}} and {{mono|long long}} in C/C++ are dependent upon the implementation of the language.}}

}}

== References ==
{{Reflist|30em|refs=

&lt;ref name=drdobbsinteger&gt;{{cite web |url=http://www.drdobbs.com/184401323 |title=The New C: Integers in C99, Part 1 |date=2000-12-01 |access-date=2010-09-04 |last=Meyers |first=Randy |publisher=drdobbs.com }}&lt;/ref&gt;
&lt;ref name=c99&gt;{{cite web| url=http://www.ericgiguere.com/articles/ansi-c-summary.html|title=The ANSI Standard: A Summary for the C Programmer |first=Eric |last=Giguere |date=1987-12-18 |access-date=2010-09-04}}&lt;/ref&gt;
&lt;ref name=agnerfog&gt;{{cite web|url=http://www.agner.org/optimize/calling_conventions.pdf |title=Calling conventions for different C++ compilers and operating systems: Chapter 3, Data Representation |date=2010-02-16 |access-date=2010-08-30 |last=Fog |first=Agner}}&lt;/ref&gt;

}}

{{Data types}}

{{DEFAULTSORT:Integer (Computer Science)}}
[[Category:Data types]]
[[Category:Computer arithmetic]]
[[Category:Primitive types]]
[[Category:computer science]]</text>
      <sha1>233zpt0rgg768lf47v98ibkztjgsdxl</sha1>
    </revision>
  </page>
  <page>
    <title>Heuristic (computer science)</title>
    <ns>0</ns>
    <id>14220429</id>
    <revision>
      <id>1014216311</id>
      <parentid>1004428732</parentid>
      <timestamp>2021-03-25T20:41:55Z</timestamp>
      <contributor>
        <ip>80.251.244.40</ip>
      </contributor>
      <comment>/* Trade-off */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10941" xml:space="preserve">{{other uses|Heuristic (disambiguation)}}

In [[mathematical optimization]] and [[computer science]], '''heuristic''' (from Greek εὑρίσκω "I find, discover") is a technique designed for [[problem solving|solving a problem]] more quickly when classic methods are too slow, or for finding an approximate solution when classic methods fail to find any exact solution.  This is achieved by trading optimality, completeness, [[Accuracy and precision|accuracy]], or [[Accuracy and precision|precision]] for speed.  In a way, it can be considered a shortcut.

A '''heuristic function''', also called simply a '''heuristic''', is a [[Function (mathematics)|function]] that ranks alternatives in [[search algorithm]]s at each branching step based on available information to decide which branch to follow. For example, it may approximate the exact solution.&lt;ref&gt;{{cite book |last=Pearl |first=Judea |title=Heuristics: intelligent search strategies for computer problem solving |year=1984 |publisher=Addison-Wesley Pub. Co., Inc., Reading, MA |location=United States |page=3|osti=5127296 }}&lt;/ref&gt;

== Definition and motivation ==

The objective of a heuristic is to produce a solution in a reasonable time frame that is good enough for solving the problem at hand.  This solution may not be the best of all the solutions to this problem, or it may simply approximate the exact solution. But it is still valuable because finding it does not require a prohibitively long time.

Heuristics may produce results by themselves, or they may be used in conjunction with optimization algorithms to improve their efficiency (e.g., they may be used to generate good seed values).

Results about [[NP-hard]]ness in theoretical computer science make heuristics the only viable option for a variety of complex optimization problems that need to be routinely solved in real-world applications.

Heuristics underlie the whole field of Artificial Intelligence and the computer simulation of thinking, as they may be used in situations where there are no known [[algorithm]]s.&lt;ref&gt;{{cite book|last=Apter|first=Michael J.|title=The Computer Simulation of Behaviour|year=1970|publisher=Hutchinson &amp; Co|location=London|page=83|isbn=9781351021005|url=https://books.google.com/books?id=-b5aDwAAQBAJ&amp;q=Heuristic}}&lt;/ref&gt;

== Trade-off ==

The trade-off criteria for deciding whether to use a heuristic for solving a given problem include the following:

* ''Optimality:'' When several solutions exist for a given problem, does the heuristic guarantee that the best solution will be found? Is it actually necessary to find the best solution?
* ''Completeness:'' When several solutions exist for a given problem, can the heuristic find them all? Do we actually need all solutions? Many heuristics are only meant to find one solution.
* ''Accuracy and precision:'' Can the heuristic provide a [[confidence interval]] for the purported solution? Is the error bar on the solution unreasonably large?
* ''Execution time'': Is this the best known heuristic for solving this type of problem? Some heuristics converge faster than others. Some heuristics are only marginally quicker than classic methods, in which case the 'overhead' on calculating the heuristic might have negative impact.

In some cases, it may be difficult to decide whether the solution found by the heuristic is good enough, because the theory underlying heuristics is not very elaborate.

== Examples ==

=== Simpler problem ===

One way of achieving the computational performance gain expected of a heuristic consists of solving a simpler problem whose solution is also a solution to the initial problem.

=== Travelling salesman problem ===

An example of approximation is described by [[Jon Bentley (computer scientist)|Jon Bentley]] for solving the [[travelling salesman problem]] (TSP):
* "Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city and returns to the origin city?"
so as to select the order to draw using a [[pen plotter]]. TSP is known to be [[NP-Hard]] so an optimal solution for even a moderate size problem is difficult to solve. Instead, the [[greedy algorithm]] can be used to give a good but not optimal solution (it is an approximation to the optimal answer) in a reasonably short amount of time. The greedy algorithm heuristic says to pick whatever is currently the best next step regardless of whether that prevents (or even makes impossible) good steps later. It is a heuristic in that practice says it is a good enough solution, theory says there are better solutions (and even can tell how much better in some cases).&lt;ref&gt;{{cite book|last=Jon Louis Bentley|title=Writing Efficient Programs|url=https://archive.org/details/writingefficient00bent|url-access=registration|year=1982|publisher=Prentice Hall|page=[https://archive.org/details/writingefficient00bent/page/11 11]}}&lt;/ref&gt;

=== Search ===

Another example of heuristic making an algorithm faster occurs in certain search problems. Initially, the heuristic tries every possibility at each step, like the full-space search algorithm. But it can stop the search at any time if the current possibility is already worse than the best solution already found. In such search problems, a heuristic can be used to try good choices first so that bad paths can be eliminated early (see [[alpha-beta pruning]]). In the case of [[best-first search]] algorithms, such as [[A* search]], the heuristic improves the algorithm's convergence while maintaining its correctness as long as the heuristic is [[admissible heuristic|admissible]]..

=== Newell and Simon: heuristic search hypothesis ===

In their [[Turing Award]] acceptance speech, [[Allen Newell]] and [[Herbert A. Simon]] discuss the heuristic search hypothesis: a physical symbol system will repeatedly generate and modify known symbol structures until the created structure matches the solution structure. Each following step depends upon the step before it, thus the heuristic search learns what avenues to pursue and which ones to disregard by measuring how close the current step is to the solution. Therefore, some possibilities will never be generated as they are measured to be less likely to complete the solution.

A heuristic method can accomplish its task by using search trees. However, instead of generating all possible solution branches, a heuristic selects branches more likely to produce outcomes than other branches. It is selective at each decision point, picking branches that are more likely to produce solutions.&lt;ref&gt;{{cite journal|last=Allen Newell and Herbert A. Simon|title=Computer Science as Empirical Inquiry: Symbols and Search|journal=Comm. ACM|volume=19|issue=3|pages=113–126|year=1976|url=http://lidecc.cs.uns.edu.ar/~grs/InteligenciaArtificial/NewellSimon-1975.pdf|doi=10.1145/360018.360022|s2cid=5581562}}&lt;/ref&gt;

=== Antivirus software ===

[[Antivirus software]] often uses heuristic rules for detecting viruses and other forms of malware. Heuristic scanning looks for code and/or behavioral patterns common to a class or family of viruses, with different sets of rules for different viruses. If a file or executing process is found to contain matching code patterns and/or to be performing that set of activities, then the scanner infers that the file is infected. The most advanced part of behavior-based heuristic scanning is that it can work against highly randomized self-modifying/mutating ([[Polymorphic code|polymorphic]]) viruses that cannot be easily detected by simpler string scanning methods. Heuristic scanning has the potential to detect future viruses without requiring the virus to be first detected somewhere else, submitted to the virus scanner developer, analyzed, and a detection update for the scanner provided to the scanner's users.

== Pitfalls ==

Some heuristics have a strong underlying theory; they are either derived in a top-down manner from the theory or are arrived at based on either experimental or real world data. Others are just [[rule of thumb|rules of thumb]] based on real-world observation or experience without even a glimpse of theory. The latter are exposed to a larger number of pitfalls.

When a heuristic is reused in various contexts because it has been seen to "work" in one context, without having been mathematically proven to meet a given set of requirements, it is possible that the current data set does not necessarily represent future data sets (see: [[overfitting]]) and that purported "solutions" turn out to be akin to noise.

[[Statistical analysis]] can be conducted when employing heuristics to estimate the probability of incorrect outcomes. To use a heuristic for solving a [[search problem]] or a [[knapsack problem]], it is necessary to check that the heuristic is [[admissible heuristic|admissible]]. Given a heuristic function &lt;math&gt;h(v_i, v_g)&lt;/math&gt; meant to approximate the true optimal distance &lt;math&gt;d^\star(v_i,v_g)&lt;/math&gt; to the goal node &lt;math&gt;v_g&lt;/math&gt; in a directed graph &lt;math&gt;G&lt;/math&gt; containing &lt;math&gt;n&lt;/math&gt; total nodes or vertexes labeled &lt;math&gt;v_0,v_1,\cdots,v_n&lt;/math&gt;, "admissible" means roughly that the heuristic underestimates the cost to the goal or formally that &lt;math&gt;h(v_i, v_g) \leq d^\star(v_i,v_g)&lt;/math&gt; for ''all'' &lt;math&gt;(v_i, v_g)&lt;/math&gt; where &lt;math&gt;{i,g} \in [0, 1, ... , n]&lt;/math&gt;.

If a heuristic is not admissible, it may never find the goal, either by ending up in a dead end of graph &lt;math&gt;G&lt;/math&gt; or by skipping back and forth between two nodes &lt;math&gt;v_i&lt;/math&gt; and &lt;math&gt;v_j&lt;/math&gt; where &lt;math&gt;{i, j}\neq g&lt;/math&gt;.

== Etymology ==
{{wiktionary|heuristic}}
The word "heuristic" came into usage in the early 19th century. It is formed irregularly from the [[Greek language|Greek]] word ''heuriskein'', meaning "to find".&lt;ref&gt;{{cite web|url=https://en.oxforddictionaries.com/definition/heuristic |title=Definition of ''heuristic'' in English |publisher=Oxford University Press |access-date=22 October 2016 |archive-url=https://web.archive.org/web/20161023011059/https://en.oxforddictionaries.com/definition/heuristic |archive-date=23 October 2016 |url-status=live }}&lt;/ref&gt;

== See also ==
*[[Algorithm]]
*[[Constructive heuristic]]
*[[Genetic algorithm]]
*[[Heuristic]]
*[[Heuristic routing]]
*[[Heuristic evaluation]]: Method for identifying [[usability]] problems in user interfaces.
*[[Metaheuristic]]: Methods for controlling and tuning basic heuristic algorithms, usually with usage of memory and learning.
*[[Matheuristics]]: Optimization algorithms made by the interoperation of metaheuristics and mathematical programming (MP) techniques.
*Reactive search optimization: Methods using online [[machine learning]] principles for self-tuning of heuristics.
* [[Recursion (computer science)]]
* [[Macro (computer science)]]

== References ==
{{reflist}}

[[Category:Heuristic algorithms| ]]
[[Category:Computer science]]

[[de:Heuristik#Informatik]]</text>
      <sha1>tagtyw0xq24f6m6tagf0s559yedboqc</sha1>
    </revision>
  </page>
  <page>
    <title>Macro (computer science)</title>
    <ns>0</ns>
    <id>20560</id>
    <revision>
      <id>1014121864</id>
      <parentid>1014093267</parentid>
      <timestamp>2021-03-25T09:08:52Z</timestamp>
      <contributor>
        <username>Chatul</username>
        <id>8789570</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/2603:8000:F403:61B0:9CB1:12D4:CAAA:4F20|2603:8000:F403:61B0:9CB1:12D4:CAAA:4F20]] ([[User talk:2603:8000:F403:61B0:9CB1:12D4:CAAA:4F20|talk]]): Vandalism</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="30381" xml:space="preserve">{{short description|In computer science, a concise representation of a pattern}}
{{Redirect|Macro language|ISO macrolanguages|ISO 639 macrolanguage}}
{{Programming paradigms}}
[[File:Jedit macro recorder.png|thumb|250px|[[jEdit|jEdit's]] macro editor]]
A '''macro''' (short for "macroinstruction", from [[Greek language|Greek]] combining form {{lang|grc|μακρο-}} 'long, large'&lt;ref&gt;''[[Oxford English Dictionary]]'', ''s.v.'' [https://www.oed.com/view/Entry/111926 macro], [https://www.oed.com/view/Entry/233194 macro-instruction], and [https://www.oed.com/view/Entry/111927 macro-]&lt;/ref&gt;) in [[computer science]] is a rule or [[pattern]] that specifies how a certain input should be mapped to a replacement output. Applying a macro to an input is ''macro expansion''. The input and output may be a sequence of [[lexical token]]s or [[Character (computing)|characters]], or a [[abstract syntax tree|syntax tree]]. Character macros are supported in [[software application]]s to make it easy to invoke common command sequences. Token and tree macros are supported in some [[programming language]]s to enable [[code reuse]] or to extend the language, sometimes for [[domain-specific languages]].

Macros are used to make a sequence of computing instructions available to the [[Computer programming|programmer]] as a single program statement, making the programming task less tedious and less error-prone.&lt;ref&gt;{{cite journal | last = Greenwald | first = Irwin D. |author2=Maureen Kane | title = The Share 709 System: Programming and Modification | journal = Journal of the ACM | volume = 6 | issue = 2  | pages = 128–133 | publisher = ACM | location = New York, NY, USA | date = April 1959 | doi = 10.1145/320964.320967 | s2cid = 27424222 | quote= One of the important uses of programmer macros is to save time and clerical-type errors in writing sequence of instructions which are often repeated in the course of a program.}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last = Strachey| first = Christopher | title = A General Purpose Macrogenerator| journal = Computer Journal| volume = 8 | issue = 3 | pages = 225–241|date=October 1965 | doi = 10.1093/comjnl/8.3.225 |author-link=Christopher Strachey| doi-access = free}}&lt;/ref&gt; (Thus, they are called "macros" because a "big" block of code can be expanded from a "small" sequence of characters.) Macros often allow positional or keyword parameters that dictate what the [[Conditional assembly language|conditional assembler]] program generates and have been used to create entire [[Computer program|programs]] or program suites according to such variables as [[operating system]], [[Computing platform|platform]] or other factors. The term derives from "macro instruction", and such expansions were originally used in generating [[assembly language]] code.

==Keyboard and mouse macros==
'''Keyboard macros''' and '''mouse macros''' allow short sequences of keystrokes and mouse actions to transform into other, usually more time-consuming, sequences of keystrokes and mouse actions. In this way, frequently used or repetitive sequences of keystrokes and mouse movements can be [[automate]]d. Separate programs for creating these macros are called [[macro recorder]]s.

During the 1980s, macro programs&amp;nbsp;– originally [[SmartKey]], then SuperKey, KeyWorks, Prokey&amp;nbsp;– were very popular, first as a means to automatically format [[screenplay]]s, then for a variety of user input tasks. These programs were based on the TSR ([[Terminate and stay resident program|terminate and stay resident]]) mode of operation and applied to all keyboard input, no matter in which context it occurred. They have to some extent fallen into obsolescence following the advent of mouse-driven user interfaces and the availability of keyboard and mouse macros in applications such as [[word processor]]s and [[spreadsheet]]s, making it possible to create application-sensitive keyboard macros.

Keyboard macros can be used in [[massively multiplayer online role-playing game]]s (MMORPGs) to perform repetitive, but lucrative tasks, thus accumulating resources.  As this is done without human effort, it can skew the economy of the game. For this reason, use of macros is a violation of the [[Terms of Service|TOS]] or [[EULA]] of most MMORPGs, and their administrators spend considerable effort to suppress them.&lt;ref&gt;{{cite web |url=http://www.runescape.com/ |title=Runescape: The Massive Online Adventure Game by Jagex Ltd. |access-date=2008-04-03}}&lt;/ref&gt;

===Application macros and scripting===
Keyboard and mouse macros that are created using an application's built-in macro features are sometimes called '''application macros'''. They are created by carrying out the sequence once and letting the application record the actions. An underlying macro programming language, most commonly a [[scripting language]], with direct access to the features of the application may also exist.

The programmers' text editor, [[Emacs]], (short for "editing macros") follows this idea to a conclusion. In effect, most of the editor is made of macros. Emacs was originally devised as a set of macros in the editing language [[Text Editor and Corrector|TECO]]; it was later ported to dialects of [[Lisp (programming language)|Lisp]].

Another programmers' text editor, [[Vim (text editor)|Vim]] (a descendant of [[vi]]), also has full implementation of macros. It can record into a register (macro) what a person types on the keyboard and it can be replayed or edited just like [[Visual Basic for Applications|VBA]] macros for Microsoft Office. Vim also has a scripting language called [[Vimscript]]&lt;ref&gt;{{cite web|url=https://www.vim.org/scripts/index.php|title=scripts : vim online|website=www.vim.org}}&lt;/ref&gt; to create macros.

[[Visual Basic for Applications]] (VBA) is a programming language included in [[Microsoft Office]] from Office 97 through Office 2019 (although it was available in some components of Office prior to Office 97). However, its function has evolved from and replaced the macro languages that were originally included in some of these applications.

[[XEDIT]], running on the [[Conversational Monitor System]] (CMS) component of [[VM (operating system)|VM]], supports macros written in [[CMS EXEC|EXEC]], [[EXEC2]] and [[REXX]], and some CMS commands were actually wrappers around XEDIT macros. [[The Hessling Editor]] (THE), a partial clone of XEDIT, supports Rexx macros using Regina and Open [[Object REXX]] (oorexx). Many common applications, and some on PCs, use Rexx as a scripting language.

====Macro virus====
{{Main article|Macro virus (computing)}}
[[Visual Basic for Applications|VBA]] has access to most [[Win32 API|Microsoft Windows system call]]s and executes when documents are opened. This makes it relatively easy to write [[computer virus]]es in VBA, commonly known as [[Macro virus (computing)|macro virus]]es. In the mid-to-late 1990s, this became one of the most common types of computer virus. However, during the late 1990s and to date, [[Microsoft]] has been patching and updating their programs. In addition, current anti-virus programs immediately counteract such attacks.

==Parameterized macro==
A '''parameterized macro''' is a macro that is able to insert given objects into its expansion. This gives the macro some of the power of a [[function (computer science)|function]].

As a simple example, in the [[C (programming language)|C programming language]], this is a typical macro that is ''not'' a parameterized macro:
  '''#define''' PI   3.14159
This causes the string "PI" to be replaced with "3.14159" wherever it occurs. It will always be replaced by this string, and the resulting string cannot be modified in any way. An example of a parameterized macro, on the other hand, is this:
  '''#define''' pred(x)  ((x)-1)
What this macro expands to depends on what [[argument (computer science)|argument]] ''x'' is passed to it. Here are some possible expansions:
  pred(2)    →  ((2)   -1)
  pred(y+2)  →  ((y+2) -1)
  pred(f(5)) →  ((f(5))-1)
Parameterized macros are a useful source-level mechanism for performing [[inline expansion|in-line expansion]], but in languages such as [[C (programming language)|C]] where they use simple textual substitution, they have a number of severe disadvantages over other mechanisms for performing in-line expansion, such as [[inline function]]s.

The parameterized macros used in languages such as [[Lisp programming language|Lisp]], [[PL/I]] and [[Scheme (programming language)|Scheme]], on the other hand, are much more powerful, able to make decisions about what code to produce based on their arguments; thus, they can effectively be used to perform [[run-time code generation]].

==Text-substitution macros==
{{See also|General-purpose macro processor|Assembly language#Macros|Algorithm}}
Languages such as [[C (programming language)|C]] and some [[assembly language]]s have rudimentary macro systems, implemented as [[preprocessor]]s to the compiler or assembler. [[C preprocessor]] macros work by simple textual substitution at the [[Lexical token|token]], rather than the character level. However, the macro facilities of more sophisticated assemblers, e.g., [[IBM High Level Assembler]] (HLASM) can't be implemented with a preprocessor; the code for assembling instructions and data is interspersed with the code for assembling macro invocations.
 
A classic use of macros is in the computer typesetting system [[TeX]] and its derivatives, where most of the functionality is based on macros.

[[MacroML]] is an experimental system that seeks to reconcile [[static typing]] and macro systems. [[Nemerle]] has typed syntax macros, and one productive way to think of these syntax macros is as a [[Metaprogramming|multi-stage computation]].

Other examples:
* [[m4 (computer language)|m4]] is a sophisticated stand-alone macro processor.
* [[TRAC programming language|TRAC]]
* [[METAL|Macro Extension TAL]], accompanying [[Template Attribute Language]]
* SMX: for web pages
* [[ML/I|ML/1]] (Macro Language One)
* The [[General Purpose Macroprocessor]] is a contextual pattern matching macro processor, which could be described as a combination of [[regular expression]]s, [[EBNF]] and [[AWK (programming language)|AWK]]{{citation needed|date=February 2020}}
* [[SAM76]]
* [[troff]] and [[nroff]]: for typesetting and formatting Unix manpages.
* [[CMS EXEC]]: for command-line macros and application macros
* [[EXEC 2]] in [[Conversational Monitor System]] (CMS): for command-line macros and application macros
* [[CLIST]] in IBM's [[Time Sharing Option]] (TSO): for command-line macros and application macros
* [[REXX]]: for command-line macros and application macros in, e.g., [[AmigaOS]], CMS, [[OS/2]], TSO
* [[SCRIPT (markup)#SCRIPT macros|SCRIPT]]: for formatting documents
* Various [[Shell (computing)#Text (CLI) shells|shells]] for, e.g., [[Linux]]

Some major applications have been written as text macro invoked by other applications, e.g., by [[XEDIT]] in CMS.

===Embeddable languages===
Some languages, such as [[PHP]], can be embedded in free-format text, or the source code of other languages. The mechanism by which the code fragments are recognised (for instance, being bracketed by &lt;code&gt;&lt;?php&lt;/code&gt; and &lt;code&gt;?&gt;&lt;/code&gt;) is similar to a textual macro language, but they are much more powerful, fully featured languages.

==Procedural macros==
{{unreferenced section|date=June 2014}}
Macros in the [[PL/I]] language are written in a subset of PL/I itself: the compiler executes "[[preprocessor]] statements" at compilation time, and the output of this execution forms part of the code that is compiled. The ability to use a familiar [[procedural language]] as the macro language gives power much greater than that of text substitution macros, at the expense of a larger and slower compiler.

[[Frame technology (software engineering)|Frame technology]]'s frame macros have their own command syntax but can also contain text in any language. Each frame is both a generic component in a hierarchy of nested subassemblies, and a procedure for integrating itself with its subassembly frames (a recursive process that resolves integration conflicts in favor of higher level subassemblies). The outputs are custom documents, typically compilable source modules. Frame technology can avoid the proliferation of similar but subtly different components, an issue that has plagued software development since the invention of macros and [[subroutine]]s.

Most assembly languages have less powerful procedural macro facilities, for example allowing a block of code to be repeated N times for [[loop unwinding|loop unrolling]]; but these have a completely different syntax from the actual assembly language.

== Syntactic macros ==
Macro systems—such as the C preprocessor described earlier—that work at the level of lexical tokens cannot preserve the lexical structure reliably.
Syntactic macro systems work instead at the level of [[abstract syntax tree]]s, and preserve the lexical structure of the original program. The most widely used implementations of syntactic macro systems are found in [[Lisp (programming language)|Lisp]]-like languages. These languages are especially suited for this style of macro due to their uniform, parenthesized syntax (known as [[S-expression]]s). In particular, uniform syntax makes it easier to determine the invocations of macros. Lisp macros transform the program structure itself, with the full language available to express such transformations. While syntactic macros are often found in Lisp-like languages, they are also available in other languages such as [[Prolog]], [[Dylan (programming language)|Dylan]], [[Scala (programming language)|Scala]], [[Nemerle]], [[Rust (programming language)|Rust]], [[Elixir (programming language)|Elixir]], [[Nim (programming language)|Nim]], [[Haxe]],&lt;ref&gt;{{cite web|url=https://haxe.org/manual/macro.html|title=Macros|website=Haxe - The Cross-platform Toolkit}}&lt;/ref&gt; and [[Julia (programming language)|Julia]]. They are also available as third-party extensions to [[JavaScript]],&lt;ref&gt;{{cite web|url=https://www.sweetjs.org/|title=Sweet.js - Hygienic Macros for JavaScript|website=www.sweetjs.org}}&lt;/ref&gt; [[C Sharp (programming language)|C#]] and [[Python (programming language)|Python]].&lt;ref&gt;{{cite web|url=https://github.com/lihaoyi/macropy|title=Macros in Python: quasiquotes, case classes, LINQ and more!: lihaoyi/macropy|date=7 February 2019|via=GitHub}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://ecsharp.net/lemp/|title=LeMP Home Page · Enhanced C#|website=ecsharp.net}}&lt;/ref&gt;

=== Early Lisp macros ===
Before Lisp had macros, it had so-called [[Fexpr|FEXPRs]], function-like operators whose inputs were not the values computed by the arguments but rather the syntactic forms of the arguments, and whose output were values to be used in the computation. In other words, FEXPRs were implemented at the same level as EVAL, and provided a window into the meta-evaluation layer. This was generally found to be a difficult model to reason about effectively.&lt;ref&gt;{{cite web|last=Marshall|first=Joe|title=untitled email|url=http://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt|access-date=May 3, 2012}}&lt;/ref&gt;

In 1963, Timothy Hart proposed adding macros to Lisp 1.5 in [[AI Memo]] 57: MACRO Definitions for LISP.&lt;ref&gt;{{cite document|title=AIM-057, MACRO Definitions for LISP, Timothy P. Hart|hdl=1721.1/6111}}&lt;/ref&gt;

=== Anaphoric macros ===
{{Main article|Anaphoric macro}}
An anaphoric macro is a type of programming macro that deliberately captures some form supplied to the macro which may be referred to by an anaphor (an expression referring to another). Anaphoric macros first appeared in Paul Graham's On Lisp and their name is a reference to linguistic anaphora—the use of words as a substitute for preceding words.

=== Hygienic macros ===
{{Main article|Hygienic macro}}

In the mid-eighties, a number of papers&lt;ref&gt;{{cite news | last1 = Kohlbecker | first1 = Eugene | last2 = Friedman | first2 = Daniel | last3 = Felleisen | first3 = Matthias | last4 = Duba | first4 = Bruce | title = Hygienic Macro Expansion | doi = 10.1145/319838.319859}}&lt;/ref&gt;&lt;ref&gt;[http://portal.acm.org/citation.cfm?id=99583.99607] Clinger, Rees. "Macros that Work"&lt;/ref&gt; introduced the notion of [[hygienic macro]] expansion (&lt;CODE&gt;syntax-rules&lt;/CODE&gt;), a pattern-based system where the syntactic environments of the macro definition and the macro use are distinct, allowing macro definers and users not to worry about inadvertent variable capture (cf. [[referential transparency]]). Hygienic macros have been standardized for Scheme in the [[R5RS]], [[R6RS]], and [[R7RS]] standards. A number of competing implementations of hygienic macros exist such as &lt;code&gt;syntax-rules&lt;/code&gt;, &lt;code&gt;syntax-case&lt;/code&gt;, explicit renaming, and syntactic closures. Both &lt;code&gt;syntax-rules&lt;/code&gt; and &lt;code&gt;syntax-case&lt;/code&gt; have been standardized in the Scheme standards.

Recently, [[Racket (programming language)|Racket]] has combined the notions of hygienic macros with a "[[tower of evaluators]]", so that the syntactic expansion time of one macro system is the ordinary runtime of another block of code,&lt;ref&gt;{{cite news | last1 = Flatt | first1 = Matthew | title = Composable and compilable macros: you want it when? |url=http://www.cs.utah.edu/plt/publications/macromod.pdf}}&lt;/ref&gt; and showed how to apply interleaved expansion and parsing in a non-parenthesized language.&lt;ref&gt;{{cite news | last1 = Rafkind | first1 = Jon | last2 = Flatt | first2 = Matthew | title = Honu: Syntactic Extension for Algebraic Notation through Enforestation |url=http://www.cs.utah.edu/plt/publications/gpce12-rf.pdf}}&lt;/ref&gt;

A number of languages other than Scheme either implement hygienic macros or implement partially hygienic systems. Examples include [[Scala (programming language)|Scala]], [[Rust (programming language)|Rust]], [[Elixir (programming language)|Elixir]], [[Julia (programming language)|Julia]], [[Dylan (programming language)|Dylan]], [[Nim (programming language)|Nim]], and [[Nemerle]].

=== Applications ===
; Evaluation order
:Macro systems have a range of uses. Being able to choose the order of evaluation (see [[lazy evaluation]] and [[Strict function|non-strict functions]]) enables the creation of new syntactic constructs (e.g. [[control structures]]) indistinguishable from those built into the language. For instance, in a Lisp dialect that has &lt;CODE&gt;cond&lt;/CODE&gt; but lacks &lt;CODE&gt;if&lt;/CODE&gt;, it is possible to define the latter in terms of the former using macros. For example, Scheme has both [[continuation]]s and hygienic macros, which enables a programmer to design their own control abstractions, such as looping and early exit constructs, without the need to build them into the language.
; Data sub-languages and domain-specific languages
: Next, macros make it possible to define data languages that are immediately compiled into code, which means that constructs such as state machines can be implemented in a way that is both natural and efficient.&lt;ref&gt;{{cite web|url=http://cs.brown.edu/~sk/Publications/Papers/Published/sk-automata-macros/|title=Automata via Macros|website=cs.brown.edu}}&lt;/ref&gt;
; Binding constructs
:Macros can also be used to introduce new binding constructs. The most well-known example is the transformation of &lt;CODE&gt;let&lt;/CODE&gt; into the application of a function to a set of arguments.

[[Matthias Felleisen|Felleisen]] conjectures&lt;ref name="three-uses"&gt;[http://people.csail.mit.edu/gregs/ll1-discuss-archive-html/msg01539.html], Matthias Felleisen, LL1 mailing list posting&lt;/ref&gt; that these three categories make up the primary legitimate uses of macros in such a system. Others have proposed alternative uses of macros, such as [[anaphoric macro]]s in macro systems that are unhygienic or allow selective unhygienic transformation.

The interaction of macros and other language features has been a productive area of research. For example, [[Software component|component]]s and [[Modular programming|module]]s are useful for large-scale programming, but the interaction of macros and these other constructs must be defined for their use together. Module and component-systems that can interact with macros have been proposed for Scheme and other languages with macros. For example, the [[Racket (programming language)|Racket]] language extends the notion of a macro system to a syntactic tower, where macros can be written in languages including macros, using hygiene to ensure that syntactic layers are distinct and allowing modules to export macros to other modules.

==Macros for machine-independent software==
Macros are normally used to map a short string (macro invocation) to a longer sequence of instructions. Another, less common, use of macros is to do the reverse: to map a sequence of instructions to a macro string. This was the approach taken by the STAGE2 Mobile Programming System, which used a rudimentary macro compiler (called SIMCMP) to map the specific instruction set of a given computer to counterpart ''machine-independent'' macros. Applications (notably compilers) written in these machine-independent macros can then be run without change on any computer equipped with the rudimentary macro compiler. The first application run in such a context is a more sophisticated and powerful macro compiler, written in the machine-independent macro language. This macro compiler is applied to itself, in a [[Bootstrapping (computing)|bootstrap]] fashion, to produce a compiled and much more efficient version of itself. The advantage of this approach is that complex applications can be ported from one computer to a very different computer with very little effort (for each target machine architecture, just the writing of the rudimentary macro compiler).&lt;ref&gt;{{cite journal
 | last = Orgass | first = Richard J. |author2=William M. Waite | title = A base for a mobile programming system | journal = Communications of the ACM | volume = 12 | issue = 9 | pages = 507–510 | publisher = ACM | location = New York, NY, USA | date = September 1969 | doi = 10.1145/363219.363226
| s2cid = 8164996 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last = Waite | first = William M. | title = The mobile programming system: STAGE2 | journal = Communications of the ACM | volume = 13 | issue = 7 | pages = 415–421 | publisher = ACM | location = New York, NY, USA | date = July 1970 | doi = 10.1145/362686.362691
| s2cid = 11733598 }}&lt;/ref&gt; The advent of modern programming languages, notably [[C (programming language)|C]], for which compilers are available on virtually all computers, has rendered such an approach superfluous. This was, however, one of the first instances (if not the first) of [[Bootstrapping (compilers)|compiler bootstrapping]].

==Assembly language==
While ''macro instructions'' can be defined by a programmer for any set of native assembler program instructions, typically macros are associated with macro libraries delivered with the operating system allowing access to operating system functions such as
* peripheral access by [[access methods]] (including macros such as OPEN, CLOSE, READ and WRITE) 
* operating system functions such as ATTACH, WAIT and POST for subtask creation and synchronization.&lt;ref&gt;{{cite web|title=University of North Florida|url=https://www.unf.edu/~cwinton/html/cop3601/s10/class.notes/asm6-Macros.pdf}}&lt;/ref&gt; Typically such macros expand into executable code, e.g., for the EXIT macroinstruction, 
* a list of ''define constant'' instructions, e.g., for the [[Data Control Block|DCB]] macro—DTF (Define The File) for [[DOS/360 and successors|DOS]]&lt;ref&gt;{{cite web
|url=https://www.ibm.com/support/knowledgecenter?origURL=api/redirect/zvm/v5r4/index.jsp |title=DTF (DOS/VSE)}}&lt;/ref&gt;—or a combination of code and constants, with the details of the expansion depending on the parameters of the macro instruction (such as a reference to a file and a data area for a READ instruction); 
* the executable code often terminated in either a ''branch and link register'' instruction to call a routine, or a [[supervisor call]] instruction to call an operating system function directly.

In older operating systems such as those used on IBM mainframes, full operating system functionality was only available to assembler language programs, not to high level language programs (unless assembly language subroutines were used, of course), as the standard macro instructions did not always have counterparts in routines available to high-level languages.

==History==
In the mid-1950s, when [[assembly language]] programming was commonly used to write programs for [[digital computer]]s, the use of '''macro instructions''' was initiated for two main purposes: to reduce the amount of program coding that had to be written by generating several assembly language statements from one macro instruction and to enforce program writing standards, e.g. specifying input/output commands in standard ways.&lt;ref&gt;{{cite web|title=IBM Knowledge Center|url=http://www.ibm.com/support/knowledgecenter/SSLTBW_2.1.0/com.ibm.zos.v2r1.asma400/asmr102115.htm|website=IBM Knowledge Center}}&lt;/ref&gt; Macro instructions were effectively a middle step between assembly language programming and the [[high-level programming languages]] that followed, such as [[FORTRAN]] and [[COBOL]]. Two of the earliest programming installations to develop "macro languages" for the IBM 705 computer were at Dow Chemical Corp. in Delaware and the Air Material Command, Ballistics Missile Logistics Office in California. A macro instruction written in the format of the target assembly language would be processed by a macro compiler, which was a pre-processor to the assembler, to generate one or more assembly language instructions to be processed next by the assembler program that would translate the assembly language instructions into [[machine language]] instructions.&lt;ref name=cisco&gt;{{cite web|title=Assembler Language Macro Instructions|url=http://www.cisco.com/c/en/us/td/docs/ios/sw_upgrades/interlink/r2_0/api_ref/ammac.html#wp1686|website=Cisco}}&lt;/ref&gt;

By the late 1950s the macro language was followed by the Macro Assemblers. This was a combination of both where one program served both functions, that of a macro pre-processor and an assembler in the same package.&lt;ref name=cisco/&gt;{{Failed verification|date=February 2020}}

In 1959, Douglas E. Eastwood and [[Douglas McIlroy]] of [[Bell Labs]] introduced conditional and recursive macros into the popular [[Symbolic Assembly Program|SAP]] assembler,&lt;ref name="CSTR99"&gt;{{cite web |url=http://cm.bell-labs.com/cm/cs/cstr/99.html |archive-url=https://archive.is/20140902215751/http://cm.bell-labs.com/cm/cs/cstr/99.html |url-status=dead |archive-date=September 2, 2014 |title=Computing Science Technical Report No. 99 – A History of Computing Research at Bell Laboratories (1937–1975) |first1=Bernard D. |last1=Holbrook |first2=W. Stanley |last2=Brown |publisher=[[Bell Labs]] |access-date=February 2, 2020}}&lt;/ref&gt; creating what is known as Macro SAP.&lt;ref name="MSAP"&gt;{{cite encyclopedia |title=Macro SAP – Macro compiler modification of SAP |encyclopedia=HOPL: Online Historical Encyclopaedia of Programming Languages |url=http://hopl.murdoch.edu.au/showlanguage.prx?exp=91 |archive-url=https://web.archive.org/web/20080813125120/http://hopl.murdoch.edu.au/showlanguage.prx?exp=91 |archive-date=August 13, 2008}}&lt;/ref&gt; McIlroy's 1960 paper was seminal in the area of extending any (including [[high-level programming language|high-level]]) programming languages through [[general-purpose macro processor|macro processors]].&lt;ref name="Lay85"&gt;{{cite journal |last=Layzell |first=P. |author-link=Paul Layzell |year=1985 |title=The History of Macro Processors in Programming Language Extensibility |journal=The Computer Journal |volume=28 |issue=1 |pages=29–33|doi=10.1093/comjnl/28.1.29 |doi-access=free }}&lt;/ref&gt;&lt;ref name="CSTR99"/&gt;

Macro Assemblers allowed assembly language programmers to implement their own macro-language and allowed limited portability of code between two machines running the same CPU but different operating systems, for example, early versions of MSDOS and CPM-86. The macro library would need to be written for each target machine but not the overall assembly language program. Note that more powerful macro assemblers allowed use of conditional assembly constructs in macro instructions that could generate different code on different machines or different operating systems, reducing the need for multiple libraries.{{citation needed|date=February 2020}}

In the 1980s and early 1990s, desktop PCs were only running at a few MHz and assembly language routines were commonly used to speed up programs written in C, Fortran, Pascal and others. These languages, at the time, used different calling conventions. Macros could be used to interface routines written in assembly language to the front end of applications written in almost any language. Again, the basic assembly language code remained the same, only the macro libraries needed to be written for each target language.{{citation needed|date=February 2020}}

In modern operating systems such as Unix and its derivatives, operating system access is provided through subroutines, usually provided by dynamic libraries. High-level languages such as C offer comprehensive access to operating system functions, obviating the need for assembler language programs for such functionality.{{citation needed|date=February 2020}}

==See also==
* {{annotated link|Anaphoric macro}}s
* {{section link|Assembly language|Macros}} (the origin of the concept of macros)
* {{annotated link|Extensible programming}}
* {{annotated link|Hygienic macro}}s
* {{annotated link|Programming by demonstration}}
* {{annotated link|String interpolation}}
* [[Computer science and engineering]]
* [[Computer science]]

==References==
{{reflist}}

==External links==
* [http://www.ibm.com/support/knowledgecenter/SSLTBW_2.1.0/com.ibm.zos.v2r1.asma400/macifmt.htm  How to write Macro Instructions]
*[http://meseec.ce.rit.edu/eecc250-winter99/250-2-2-2000.pdf  Rochester Institute of Technology, Professors Powerpoint]

{{Types of programming languages}}

{{Authority control}}

[[Category:Programming constructs]]
[[Category:Source code]]
[[Category:Automation software]]
[[Category:Computer science]]</text>
      <sha1>7zjaczlwwnk157tu67qy49dcx3wn8eb</sha1>
    </revision>
  </page>
  <page>
    <title>AP Computer Science</title>
    <ns>0</ns>
    <id>4234887</id>
    <revision>
      <id>1000468208</id>
      <parentid>975380633</parentid>
      <timestamp>2021-01-15T06:51:46Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 8 templates: hyphenate params (3×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5215" xml:space="preserve">{{short description|Concept in Computer Science}}
{{Advanced Placement}}
In the United States, '''Advanced Placement Computer Science''' is a suite of [[Advanced Placement]] courses and examinations covering areas of [[computer science]]. They are offered by the [[College Board]] to [[Secondary education in the United States|high school]] students as an opportunity to earn college credit for [[college]]-level courses.&lt;ref&gt;{{cite web | url = https://apstudent.collegeboard.org/creditandplacement | title = Credit &amp; Placement | work = AP Students | publisher = The [[College Board]] | year = 2017 | access-date = January 30, 2017}}&lt;/ref&gt;  The suite consists of two current classes and one discontinued class.

AP Computer Science was taught in [[Pascal (programming language)|Pascal]] for the 1984–1998 exams, in [[C++]] for 1999–2003, and in [[Java (programming language)|Java]] since 2004.&lt;ref&gt;{{Cite web|url=http://www.apsi.thecubscientist.com/05_DailySchedule/historyAPCS.pdf|title=AP Computer Science: A Brief History|last=Lew|first=Michael|website=Thecubscientist|access-date=2017-08-29}}&lt;/ref&gt;

==AP Computer Science A==
[[AP Computer Science A]] is a programming class.&lt;ref name=CSAcoursedetails&gt;{{cite web | url = https://apstudent.collegeboard.org/apcourse/ap-computer-science-a/course-details | title = AP Computer Science A: Course Details | work = AP Students | publisher = The College Board  | year = 2017 | access-date = January 30, 2017}}&lt;/ref&gt;  The course emphasizes [[object-oriented programming]] methodology, especially problem solving and [[algorithm]] development, plus an overview of data structures and abstraction. The [[AP Computer Science A]] exam tests students on their knowledge of [[Java (programming language)|Java]].

It is meant to be the equivalent of a first-semester course in computer science. 

The [[Microsoft]]-sponsored program [[Technology Education and Literacy in Schools]] (TEALS) aims to increase the number of students taking AP Computer Science classes.&lt;ref name="Bishop2012-07-27"&gt;{{cite news|last=Bishop |first=Todd |date=2012-07-27 |title=Geek of the Week: Kevin Wang is putting computer scientists into high schools |url=http://www.geekwire.com/2012/kevin-wang/ |newspaper=[[GeekWire]] |access-date=2015-07-05 |archive-url=https://www.webcitation.org/6Zo1zm7iP?url=http://www.geekwire.com/2012/kevin-wang/ |archive-date=2015-07-05 |url-status=live }}&lt;/ref&gt;

==AP Computer Science AB (discontinued)==
[[AP Computer Science AB]] included all the topics of AP Computer Science A, as well as a more formal and a more in-depth study of [[algorithms]], [[data structures]], and [[data abstraction]]. For example, [[binary trees]] were studied in AP Computer Science AB but not in AP Computer Science A. The use of [[Recursion (computer science)|recursive]] data structures and [[dynamic allocation|dynamically allocated]] structures were fundamental to AP Computer Science AB. 

AP Computer Science AB was equivalent to a full-year college course.&lt;ref name=CSABhomepage&gt;{{cite web | url = http://apcentral.collegeboard.com/apc/public/courses/teachers_corner/8153.html | title = AP Computer Science AB Course Home Page | work = AP Central | publisher = The College Board | year = 2008 | url-status = dead | archive-url = https://web.archive.org/web/20080516202349/http://apcentral.collegeboard.com/apc/public/courses/teachers_corner/8153.html | archive-date = May 16, 2008}}&lt;/ref&gt; 

Due to low numbers of students taking the exam, AP Computer Science AB was discontinued following the May 2009 exam administration.&lt;ref name=CSABdiscontinued&gt;{{cite web | url = http://apcentral.collegeboard.com/apc/public/courses/teachers_corner/195948.html | title = Important Announcement about AP Computer Science AB | work = AP Central | publisher = The College Board | year = 2008 | url-status = dead | archive-url = https://web.archive.org/web/20080409195847/http://apcentral.collegeboard.com/apc/public/courses/teachers_corner/195948.html | archive-date = April 9, 2008}}&lt;/ref&gt;&lt;ref&gt;{{cite news | last = Cech | first = Scott J. | url = http://www.edweek.org/ew/articles/2008/04/09/32ap.h27.html | title = College Board Intends to Drop AP Programs in Four Subjects | work = Education Week | date = April 9, 2008}}&lt;/ref&gt;

==AP Computer Science Principles==
[[AP Computer Science Principles]] is an introductory course to computer science, "with a focus on how computing powers the world".&lt;ref name=CSPcoursedetails&gt;{{cite web | url = https://apstudent.collegeboard.org/apcourse/ap-computer-science-principles/course-details | title = AP Computer Science Principles: Course Details | work = AP Students | publisher = The College Board | year = 2017 | access-date = January 30, 2017}}&lt;/ref&gt; It is designed as a parallel to AP Computer Science A, to emphasize [[computational thinking]] and fluency. It is meant to be the equivalent of a first-semester course in computing.

==See also==

*[[AP Computer Science A]]
*[[Computer science]]
*[[Glossary of computer science]]
* [[Scope (computer science)]]
* [[Computer graphics (computer science)]]

==References==
{{reflist}}


[[Category:Computer science education]]
[[Category:Computer science]]
[[Category:Computer engineering]]</text>
      <sha1>ti11vxybbb8v612002gir3y6ordxoca</sha1>
    </revision>
  </page>
  <page>
    <title>Computer graphics (computer science)</title>
    <ns>0</ns>
    <id>18567168</id>
    <revision>
      <id>1007214782</id>
      <parentid>1007212462</parentid>
      <timestamp>2021-02-17T01:02:36Z</timestamp>
      <contributor>
        <username>Fgnievinski</username>
        <id>6727347</id>
      </contributor>
      <comment>/* Subfields */ too much boldface</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12976" xml:space="preserve">{{short description|Sub-field of computer science}}
{{about|the scientific discipline of computer graphics|a broader overview|Computer graphics|other uses|Computer graphics (disambiguation)}}

[[File:utah teapot simple 2.png|thumb|A modern rendering of the [[Utah teapot]], an iconic model in 3D computer graphics created by [[Martin Newell (computer scientist)|Martin Newell]] in 1975]]

'''Computer graphics''' is a sub-field of [[computer science]] which studies methods for digitally synthesizing and manipulating visual content.  Although the term often refers to the study of [[3D computer graphics|three-dimensional computer graphics]], it also encompasses [[2D computer graphics|two-dimensional graphics]] and [[image processing]].

== Overview ==
Computer graphics studies the manipulation of visual and geometric information using computational techniques.  It focuses on the ''mathematical'' and ''computational'' foundations of image generation and processing rather than purely [[aesthetic]] issues.  Computer graphics is often differentiated from the field of [[visualization (graphic)|visualization]], although the two fields have many similarities.

Connected studies include:
* [[Applied mathematics]]
* [[Computational geometry]]
* [[Computational topology]]
* [[Computer vision]]
* [[Image processing]]
* [[Information visualization]]
* [[Scientific visualization]]

Applications of computer graphics include:
*[[Print design]]
*[[Digital art]]
*[[Special effect]]s
*[[Video game]]s
*[[Visual effects]]

== History ==
{{See also|History of computer animation|Computer graphics#History}}

There are several international conferences and journals where the most significant results in computer graphics are published. Among them are the [[SIGGRAPH]] and [[Eurographics]] conferences and the [[Association for Computing Machinery]] (ACM) Transactions on Graphics journal. The joint Eurographics and [[ACM SIGGRAPH]] symposium series features the major venues for the more specialized sub-fields: Symposium on Geometry Processing,&lt;ref&gt;{{cite web |url = http://www.geometryprocessing.org |title = geometryprocessing.org |website = geometryprocessing.org |access-date=2014-05-01 }}&lt;/ref&gt; Symposium on Rendering, Symposium on Computer Animation,&lt;ref&gt;[http://www.eg.org/events ] {{webarchive |url = https://web.archive.org/web/20070314004027/http://www.eg.org/events |date = March 14, 2007 }}&lt;/ref&gt; and High Performance Graphics.&lt;ref&gt;{{cite web |url = http://www.highperformancegraphics.org |title = High Performance Graphics |website = highperformancegraphics.org }}&lt;/ref&gt; 

As in the rest of computer science, conference publications in computer graphics are generally more significant than journal publications (and subsequently have lower acceptance rates).&lt;ref name="cra memo"&gt;{{cite web |url = http://www.cra.org/reports/tenure_review.html |title=Best Practices Memo |website = Cra.org |access-date=2014-05-01 |archive-url = https://web.archive.org/web/20140502002308/http://www.cra.org/reports/tenure_review.html |archive-date=2014-05-02 |url-status=dead }}&lt;/ref&gt;&lt;ref name="ernst note"&gt;{{cite web |url = http://people.csail.mit.edu/mernst/advice/conferences-vs-journals.html |title=Choosing a venue: conference or journal? |website = People.csail.mit.edu |access-date=2014-05-01}}&lt;/ref&gt;&lt;ref name="graphics acceptance rates"&gt;{{cite web |url = http://vrlab.epfl.ch/~ulicny/statistics/ |title = Graphics/vision publications acceptance rates statistics |website = vrlab.epfl.ch |access-date=2014-05-01 }}&lt;/ref&gt;&lt;ref&gt;An extensive history of computer graphics can be found at [http://accad.osu.edu/~waynec/history/lessons.html this page] {{webarchive |url = https://web.archive.org/web/20070405172134/http://accad.osu.edu/~waynec/history/lessons.html |date=April 5, 2007 }}.&lt;/ref&gt;

== Subfields ==
A broad classification of major subfields in computer graphics might be:
# [[Geometry]]: ways to represent and process surfaces
# [[Animation]]: ways to represent and manipulate motion
# [[Rendering (computer graphics)|Rendering]]: [[algorithm]]s to reproduce light transport
# [[Digital imaging|Imaging]]: image acquisition or image editing

=== Geometry ===
[[File:Stanford bunny qem.png|thumb|Successive approximations of a surface computed using quadric error metrics]]

The subfield of geometry studies the representation of three-dimensional objects in a discrete digital setting.  Because the appearance of an object depends largely on its exterior, [[boundary representation]]s are most commonly used.  Two dimensional [[Surface (topology)|surface]]s are a good representation for most objects, though they may be non-[[manifold]].  Since surfaces are not finite, discrete digital approximations are used. [[polygon mesh|Polygonal meshes]] (and to a lesser extent [[subdivision surfaces]]) are by far the most common representation, although point-based representations have become more popular recently (see for instance the Symposium on Point-Based Graphics).&lt;ref&gt;{{cite web |url = http://graphics.ethz.ch/events/pbg/07/ |title=Point Based Graphics 2007 - PBG07 |website = Graphics.ethz.ch |access-date=2014-05-01}}&lt;/ref&gt; These representations are ''Lagrangian,'' meaning the spatial locations of the samples are independent.  Recently, ''Eulerian'' surface descriptions (i.e., where spatial samples are fixed) such as [[level set]]s have been developed into a useful representation for deforming surfaces which undergo many topological changes (with [[fluids]] being the most notable example).&lt;ref name="stanford fedkiw"&gt;{{cite web |url = http://graphics.stanford.edu/~fedkiw/ |title = Ron Fedkiw |website = graphics.stanford.edu |access-date=2014-05-01 }}&lt;/ref&gt;

Geometry subfields include:
* [[Implicit surface]] modeling – an older subfield which examines the use of algebraic surfaces, [[constructive solid geometry]], etc., for surface representation.
* Digital geometry processing – [[3d scanning|surface reconstruction]], simplification, fairing, mesh repair, [[mesh parameterization|parameterization]], remeshing, [[mesh generation]], surface compression, and surface editing all fall under this heading.&lt;ref name="caltech multires dgp"&gt;[http://www.multires.caltech.edu/pubs/DGPCourse/ ] {{webarchive |url = https://web.archive.org/web/20070214021951/http://www.multires.caltech.edu/pubs/DGPCourse/ |date=February 14, 2007 }}&lt;/ref&gt;&lt;ref name="uiuc graphics dgp"&gt;[http://graphics.cs.uiuc.edu/~garland/class/geometry/ CS 598: Digital Geometry Processing (Fall 2004)&lt;!-- Bot generated title --&gt;] {{webarchive|url=https://archive.is/20041025104252/http://graphics.cs.uiuc.edu/~garland/class/geometry/ |date=2004-10-25 }}&lt;/ref&gt;&lt;ref name="ubc sheffa dgp"&gt;{{cite web|url=http://www.cs.ubc.ca/~sheffa/dgp/ |title=Digital Geometry Processing |website = cs.ubc.ca |access-date=2014-05-01}}&lt;/ref&gt;
* Discrete differential geometry – a nascent field which defines geometric quantities for the discrete surfaces used in computer graphics.&lt;ref name="columbia ddg"&gt;{{cite web |url = http://ddg.cs.columbia.edu/ |title=Discrete Differential Geometry |website = ddg.cs.columbia.edu |access-date=2014-05-01}}&lt;/ref&gt;
* Point-based graphics – a recent field which focuses on points as the fundamental representation of surfaces.
* [[Subdivision surfaces]]
* Out-of-core mesh processing – another recent field which focuses on mesh datasets that do not fit in main memory.

=== Animation ===
The subfield of animation studies descriptions for surfaces (and other phenomena) that move or deform over time.  Historically, most work in this field has focused on parametric and data-driven models, but recently [[physical simulation]] has become more popular as computers have become more powerful computationally.

Animation subfields include:
* [[Motion capture|Performance capture]]
* Character animation
* Physical simulation (e.g. [[cloth modeling]],  animation of [[fluid dynamics]], etc.)

=== Rendering ===
[[File:Cornellbox pathtracing irradiancecaching.png|thumb|Indirect diffuse scattering simulated using [[path tracing]] and [[irradiance]] [[Cache (computing)|caching]].]]

Rendering generates images from a model.  Rendering may simulate [[light transport theory|light transport]] to create realistic images or it may create images that have a particular artistic style in [[non-photorealistic rendering]].  The two basic operations in realistic rendering are transport (how much light passes from one place to another) and scattering (how surfaces interact with light).  See [[Rendering (computer graphics)]] for more information.

Rendering subfields include:
* [[light transport theory|Transport]] describes how illumination in a scene gets from one place to another. [[visibility (geometry)|Visibility]] is a major component of light transport.
* Scattering: Models of ''[[scattering]]'' (how light interacts with the surface ''at a given point'') and ''[[shading]]'' (how material properties vary across the surface) are used to describe the appearance of a surface.  In graphics these problems are often studied within the context of rendering since they can substantially affect the design of [[rendering algorithm]]s.  Descriptions of scattering are usually given in terms of a [[bidirectional scattering distribution function]] (BSDF).  The latter issue addresses how different types of scattering are distributed across the surface (i.e., which scattering function applies where).  Descriptions of this kind are typically expressed with a program called a [[shader]].  (Note that there is some confusion since the word "shader" is sometimes used for programs that describe local ''geometric'' variation.)
* [[Non-photorealistic rendering]]
* [[Physically based rendering]] – concerned with generating images according to the laws of [[geometric optics]]
* [[Real-time rendering]] – focuses on rendering for interactive applications, typically using specialized hardware like [[graphics processing unit|GPUs]]
* [[Relighting]] – recent area concerned with quickly re-rendering scenes
&lt;!-- PLEASE RESPECT ALPHABETICAL ORDER--&gt;

== Notable researchers ==
{{div col |colwidth = 22em }}
* Arthur Appel
* James Arvo
* [[Brian A. Barsky]]
* [[Jim Blinn]]
* [[Jack E. Bresenham]]
* [[Loren Carpenter]]
* [[Edwin Catmull]]
* [[James H. Clark]]
* [[Robert L. Cook]]
* [[Franklin C. Crow]]
* [[Paul Debevec]]
* [[David C. Evans]]
* [[Ronald Fedkiw|Ron Fedkiw]]
* [[Steven K. Feiner]]
* [[James D. Foley]]
* [[David Forsyth (computer scientist)|David Forsyth]]
* [[Henry Fuchs]]
* [[Andrew Glassner]]
* [[Henri Gouraud (computer scientist)]]
* [[Donald P. Greenberg]]
* [[Eric Haines]]
* R. A. Hall
* [[Pat Hanrahan]]
* John Hughes
* [[Jim Kajiya]]
* [[Takeo Kanade]]
* [[Kenneth Knowlton]]
* [[Marc Levoy]]
* [[Martin Newell (computer scientist)]]
* [[James F. O'Brien|James O'Brien]]
* [[Ken Perlin]]
* [[Matt Pharr]]
* [[Bui Tuong Phong]]
* [[Przemyslaw Prusinkiewicz]]
* [[William Reeves (animator)|William Reeves]]
* David F. Rogers
* [[Holly Rushmeier]]
* [[Peter Shirley]]
* [[James Sethian]]
* [[Ivan Sutherland]]
* [[Demetri Terzopoulos]]
* Kenneth Torrance
* [[Greg Turk]]
* [[Andries van Dam]]
* [[Henrik Wann Jensen]]
* [[Gregory Ward]]
* [[John Warnock]]
* [[J. Turner Whitted]]
* [[Lance Williams (graphics researcher)|Lance Williams]]
{{div col end}}

== See also ==
{{div col|colwidth=22em}}
* [[Computer facial animation]]
* [[Computer science]]
* [[Computer science and engineering]]
* [[Computer graphics]]
* [[Digital geometry]]
* [[Digital image editing]]
* [[Geometry processing]]
* [[Painter's algorithm]]
* [[Stanford Bunny]]
* [[Utah Teapot]]
{{div col end}}

== References ==
{{Reflist}}

== Further reading ==
* [[James D. Foley|Foley]] ''et al''. ''[[Computer Graphics: Principles and Practice]]''.
* Shirley. ''Fundamentals of Computer Graphics''.
* Watt. ''3D Computer Graphics''.

== External links ==
{{Wiktionary|computer graphics}}
{{Commons category|Computer graphics}}
* [https://web.archive.org/web/20070405172134/http://accad.osu.edu/~waynec/history/lessons.html A Critical History of Computer Graphics and Animation]
* [https://web.archive.org/web/20070302154206/http://hem.passagen.se/des/hocg/hocg_1960.htm ''History of Computer Graphics'' series of articles]

=== Industry ===
Industrial labs doing "blue sky" graphics research include:
*[https://web.archive.org/web/20080325152156/http://www.adobe.com/technology/graphics/ Adobe Advanced Technology Labs]
*[http://www.merl.com/ MERL]
*[http://research.microsoft.com/graphics/ Microsoft Research – Graphics]
*[http://research.nvidia.com/ Nvidia Research]

Major film studios notable for graphics research include:
*[http://www.ilm.com/ ILM]
*[http://www.dreamworksanimation.com/ PDI/Dreamworks Animation]
*[https://web.archive.org/web/20070302102640/http://www.pixar.com/companyinfo/research/ Pixar]

{{-}}
{{Visualization}}
{{Computer graphics}}
{{Computer science}}

{{Authority control}}

[[Category:Computer graphics|+]]
[[Category:Computer science]]</text>
      <sha1>ckpis65os4y55du4bgip9qjrz1kz8vz</sha1>
    </revision>
  </page>
  <page>
    <title>Elements of AI</title>
    <ns>0</ns>
    <id>64301884</id>
    <revision>
      <id>1011860893</id>
      <parentid>1011858888</parentid>
      <timestamp>2021-03-13T07:43:43Z</timestamp>
      <contributor>
        <username>HitroMilanese</username>
        <id>1305296</id>
      </contributor>
      <comment>cleanup</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8790" xml:space="preserve">{{Infobox website
| name = Elements of AI
| type = Online education
| language = English, German, Italian, Finnish, Swedish, Estonian, Latvian, Norwegian, Croatian.
| owner = University of Helsinki, Reaktor Inc.
| url = www.elementsofai.com
| commercial = No
| launch_date = 2018
}}
'''Elements of AI''' is a [[Massive open online course|massive open online course (MOOC)]] teaching the basics of [[artificial intelligence]].&lt;ref&gt;{{Cite news|date=2020-01-03|title=Finland seeks to teach 1% of all Europeans basics on AI|language=en|work=Reuters|url=https://www.reuters.com/article/us-finland-education-ai-idUSKBN1YE1B6|access-date=2020-06-17}}&lt;/ref&gt; The course, originally launched in 2018, is designed and organized by the [[University of Helsinki]] and technology company [[Reaktor (company)|Reaktor]].&lt;ref&gt;{{Cite web|last=European Commission|date=2020-01-07|title=Elements of Artificial Intelligence course gives basic introduction to AI|url=https://ec.europa.eu/digital-single-market/en/news/elements-artificial-intelligence-course-gives-basic-introduction-ai|url-status=live|archive-url=|archive-date=|access-date=2020-06-17|website=Shaping Europe’s digital future - European Commission|language=en}}&lt;/ref&gt; The course includes modules on [[machine learning]], [[Neural network|neural networks]], the philosophy of artificial intelligence, and using artificial intelligence to solve problems.&lt;ref&gt;{{Cite web|title=A country's ambitious plan to teach anyone the basics of AI|url=https://www.technologyreview.com/2019/01/15/137825/a-countrys-ambitious-plan-to-teach-anyone-the-basics-of-ai/|access-date=2020-06-17|website=MIT Technology Review|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=The Elements of AI {{!}} Tietojenkäsittelytiede {{!}} Open University {{!}} University of Helsinki|url=https://courses.helsinki.fi/en/aytkt21018/126531969|access-date=2020-06-17|website=courses.helsinki.fi}}&lt;/ref&gt; It consists of two parts: Introduction to AI and its sequel, Building AI, that was released in late 2020.&lt;ref&gt;{{Cite web|last=News|first=Mirage|date=2020-10-21|title=Finland continues its quest to teach 1 % of world basics of AI - Open online course Building AI published {{!}} Mirage News|url=https://www.miragenews.com/finland-continues-its-quest-to-teach-1-of-world-basics-of-ai-open-online-course-building-ai-published/,%20https://www.miragenews.com/finland-continues-its-quest-to-teach-1-of-world-basics-of-ai-open-online-course-building-ai-published|access-date=2020-10-30|website=www.miragenews.com|language=en-AU}}&lt;/ref&gt;
The course has been ranked the number one artificial intelligence course in the world on Class Central and [[Forbes]].&lt;ref&gt;{{Cite web|last=Marr|first=Bernard|title=The 10 Best Free Online Artificial Intelligence And Machine Learning Courses For 2020|url=https://www.forbes.com/sites/bernardmarr/2020/03/16/the-10-best-free-artificial-intelligence-and-machine-learning-courses-for-2020/|access-date=2020-06-17|website=Forbes|language=en}}&lt;/ref&gt; &lt;ref&gt;{{Cite web|title=Free Online Course: Elements of AI from University of Helsinki|url=https://www.classcentral.com/course/independent-elements-of-ai-12469|access-date=2020-06-17|website=Class Central|language=en}}&lt;/ref&gt;In 2019, the course won the global grand price in the Inclusive Innovation Challenge by [[Massachusetts Institute of Technology|MIT, the Massachusetts Institute of Technology]].&lt;ref&gt;{{Cite web|title=Reaktor Education|url=https://www.mitinclusiveinnovation.com/winners/reaktor/|access-date=2020-06-17|website=MIT Inclusive Innovation Challenge|language=en-US}}&lt;/ref&gt; 

University of Helsinki's computer science department is known as the alma mater of [[Linus Torvalds]], a Finnish-American software engineer who is the creator of the Linux kernel, which is the kernel for [[Linux|Linux operating systems]].&lt;ref&gt;{{Cite web|title=Finland offers Artificial Intelligence course as 'Christmas gift'|url=https://www.aljazeera.com/news/2019/12/finland-offers-artificial-intelligence-christmas-gift-191217210740672.html|access-date=2020-06-17|website=www.aljazeera.com}}&lt;/ref&gt;

== EU’s AI pledge ==

The government of [[Finland]] has pledged to offer the course for all [[European Union|EU]] citizens by the end of 2021, as the course is made available in all the official EU languages.&lt;ref&gt;{{Cite web|last=Vincent|first=James|date=2019-12-18|title=Finland is making its online AI crash course free to the world|url=https://www.theverge.com/2019/12/18/21027840/online-course-basics-of-ai-finland-free-elements|access-date=2020-06-17|website=The Verge|language=en}}&lt;/ref&gt; The initiative was launched as part of Finland's Presidency of the Council of the European Union in 2019, with the [[European Commission]] providing translations of the course materials.&lt;ref&gt;{{Cite web|last=Delcker|first=Janosch|date=2019-01-02|title=Finland's grand AI experiment|url=https://www.politico.eu/article/finland-one-percent-ai-artificial-intelligence-courses-learning-training/|access-date=2020-06-17|website=POLITICO}}&lt;/ref&gt;

In 2017, Finland launched an AI strategy to stay competitive in the field of AI amid growing competition between [[China]] and the [[United States]]. With the support of private companies and the government, Finland’s now-realized goal was to get 1 percent of its citizens to participate in Elements of AI.&lt;ref&gt;{{Cite web|last=Delcker|first=Janosch|date=2019-01-02|title=Finland's grand AI experiment|url=https://www.politico.eu/article/finland-one-percent-ai-artificial-intelligence-courses-learning-training/|access-date=2020-06-17|website=POLITICO}}&lt;/ref&gt;

Other governments have also given their support to the course. For instance, [[Germany|Germany’s]] Federal Minister for Economic Affairs and Energy [[Peter Altmeier]] has encouraged citizens to take part in the course to help Germany gain a competitive advantage in AI.&lt;ref&gt;{{Cite web|last=Altmeier|first=Peter|date=|title=Künstliche Intelligenz (KI) – Warum Deutschland jetzt durchstarten muss und kann|url=https://www.bmwi.de/Redaktion/DE/Artikel/Technologie/kuenstliche-intelligenz-warum-deutschland-jetzt-durchstarten-muss-und-kann.html|url-status=live|archive-url=|archive-date=|access-date=2020-06-17|website=www.bmwi.de|language=de}}&lt;/ref&gt; [[Sweden|Sweden’s]] Minister for Energy and Minister for Digital Development [[Anders Ygeman]] has said that Sweden aims to teach 1 percent of its population the basics of AI like Finland has.&lt;ref&gt;{{Cite news|last1=Åberg|first1=Matias|last2=Emilia Alentola|first2=Anni|date=2019-05-06|title=Populär finsk AI-kurs lanseras i Sverige – svensk minister tackar ja till utmaning|language=sv|work=SVT Nyheter|url=https://www.svt.se/nyheter/uutiset/svenska/popular-finsk-ai-kurs-lanseras-i-sverige-svensk-minister-tackar-ja-till-utmaning|access-date=2020-06-17}}&lt;/ref&gt;

== Participants ==

Elements of AI had enrolled more than 500,000 students from more than 110 countries by October 2020.&lt;ref&gt;{{Cite web|title=Finland to enhance Europeans' digital skills – Elements of AI online course to be launched in EU countries|url=https://um.fi/current-affairs/-/asset_publisher/gc654PySnjTX/content/suomi-vahvistaa-eurooppalaisten-digitaitoja-ja-osaamista-elements-of-ai-verkkokurssin-lanseeraukset-eu-maissa-alkavat|access-date=2020-06-17|website=Ministry for Foreign Affairs|language=en-US}}&lt;/ref&gt;A quarter of the course’s participants are aged 45 and over, and some 40 percent are women. Among Nordic participants, the share of women is nearly 60 percent. &lt;ref&gt;{{Cite web|title=Finland offers Artificial Intelligence course as 'Christmas gift'|url=https://www.aljazeera.com/news/2019/12/finland-offers-artificial-intelligence-christmas-gift-191217210740672.html|access-date=2020-06-17|website=www.aljazeera.com}}&lt;/ref&gt;

In June 2020, the course was available in Finnish, Swedish, Estonian, English, German, Latvian and Norwegian.&lt;ref&gt;{{Cite web|title=Digitaliseringsministeren: - Nå skal det norske folk på kurs|url=https://www.vg.no/i/GG2V5B|access-date=2020-06-17|website=www.vg.no|language=nb}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=Sweden to take up Finnish AI challenge|url=https://www.computerweekly.com/news/252461711/Sweden-to-take-up-Finnish-AI-challenge|access-date=2020-06-17|website=ComputerWeekly.com|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=Digital-Vorreiter Finnland - Künstliche Intelligenz fürs Volk|url=https://www.deutschlandfunk.de/digital-vorreiter-finnland-kuenstliche-intelligenz-fuers.795.de.html?dram:article_id=462289|access-date=2020-06-17|website=Deutschlandfunk|language=de-DE}}&lt;/ref&gt; In December 2020, it was available in Italian thanks to the Minister for Technological Innovation and Digitalization, Paola Pisano.

== References ==
{{reflist}}

[[Category:Artificial intelligence]]
[[Category:Education International]]
[[Category:Computer science]]</text>
      <sha1>hjrl878ledi4fivkgq2t2xep1zcxsyw</sha1>
    </revision>
  </page>
  <page>
    <title>4D vector</title>
    <ns>0</ns>
    <id>50761824</id>
    <revision>
      <id>982782486</id>
      <parentid>946601336</parentid>
      <timestamp>2020-10-10T09:33:13Z</timestamp>
      <contributor>
        <username>Footlessmouse</username>
        <id>33650178</id>
      </contributor>
      <comment>−[[Category:Concepts in physics]]; −[[Category:Vector spaces]]; +[[Category:Computer science]]; +[[Category:Computer hardware]]; +[[Category:Data types]] using [[WP:HC|HotCat]] - Not a concept in physics (the concept is called a "vector" a 4D vector was made up by computer scientists. If you want this to be about the physics concept, we can propose AfD as a duplicate. Also, not a vector space, vector spaces category is not appropriate here)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4503" xml:space="preserve">{{short description|4-component vector data type in computer science}}
{{distinguish|four-vector}}
In [[computer science]], a '''4D vector''' is a 4-component [[Vector (mathematics)|vector]] [[data type]]. Uses include [[homogeneous coordinates]] for [[3-dimensional space]] in [[computer graphics]], and ''red green blue alpha'' ([[RGBA]]) values for [[bitmap]] images with a color and [[alpha channel]] (as such they are widely used in computer graphics). They may also represent [[quaternion]]s (useful for rotations) although the algebra they define is different.

== Computer hardware support ==
&lt;!-- Todo: some earlier workstations must have had similar vector engines. --&gt;
Some [[microprocessor]]s have hardware support for 4D vectors with instructions dealing with 4 [[SIMD lane|lane]] ''single instruction, multiple data'' ([[SIMD]]) instructions, usually with a [[128-bit]] data path and [[32-bit floating point]] fields.&lt;ref&gt;{{cite web|title=intel SSE intrinsics|url=https://software.intel.com/sites/landingpage/IntrinsicsGuide/#techs=SSE}}&lt;/ref&gt;

Specific instructions (e.g., 4 element [[dot product]]) may facilitate the use of one 128-bit register to represent a 4D vector. For example, in chronological order: [[Hitachi SH4]], [[PowerPC]] VMX128 extension,&lt;ref&gt;{{cite web|title=Putting It All Together: Anatomy of the XBox 360 Game Console (see VMX128 dot product)|url=https://www.cis.upenn.edu/~milom/cis371-Spring11/lectures/15_xbox.pdf}}&lt;/ref&gt; and Intel [[x86]] SSE4.&lt;ref&gt;{{cite web|title=intel SSE4 dot product|url=https://software.intel.com/en-us/node/583111}}&lt;/ref&gt;

Some 4-element vector engines (e.g., the [[PS2 vector unit]]s) went further with the ability to broadcast components as multiply sources, and [[cross product]] support.&lt;ref&gt;{{cite web|title=VU0 user manual|url=https://www.dropbox.com/s/e3lsv80kb1jb6sh/VU0E.PDF}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=feasibility study on using the playstation 2 for scientific computing|url=http://gamehacking.org/faqs/VPUThesis.pdf}}&lt;/ref&gt;  Earlier generations of [[graphics processing unit]] (GPU) shader pipelines used ''[[very long instruction word]]'' (VLIW) [[instruction set]]s tailored for similar operations.

== Software support ==
SIMD use for 4D vectors can be conveniently wrapped in a ''[[vector maths library]]'' (commonly implemented in [[C (programming language)|C]] or [[C++]])&lt;ref&gt;{{cite web|title=sce vectormath|url=https://github.com/erwincoumans/sce_vectormath}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=GLM (vector maths library)|url=http://glm.g-truc.net/0.9.7/index.html}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Microsoft DirectX Maths|url=https://msdn.microsoft.com/en-us/library/windows/desktop/ee415652(v=vs.85).aspx}}&lt;/ref&gt; 
commonly used in [[video game development]], along with [[4×4 matrix]] support. These are distinct from more general [[linear algebra libraries]] in other domains focussing on [[Matrix (mathematics)|matrices]] of arbitrary size. Such libraries sometimes support 3D vectors padded to 4D or loading 3D data into 4D registers, with arithmetic mapped efficiently to SIMD operations by per platform [[intrinsic function]] implementations. There is choice between [[AOS and SOA]] approaches given the availability of 4 element registers, versus SIMD instructions that are usually tailored toward homogenous data.

[[Shading language]]s for [[graphics processing unit]] (GPU) programming usually have a 4D datatypes (along with 2D, 3D) with x-y-z-w accessors including ''[[Permutation|permutes]]'' or ''swizzle'' access, e.g., allowing easy swapping of RGBA or ARGB formats, accessing two 2D vectors packed into one 4D vector, etc.&lt;ref&gt;{{cite web|title=GLSL data types &amp; swizzling|url=https://www.opengl.org/wiki/Data_Type_(GLSL)#Swizzling}}&lt;/ref&gt; Modern GPUs have since moved to scalar [[single instruction, multiple threads]] (SIMT) pipelines (for more efficiency in ''[[general-purpose computing on graphics processing units]]'' (GPGPU)) but still support this programming model.&lt;ref&gt;{{cite web|title=AMD graphics core next|url=http://www.anandtech.com/show/4455/amds-graphics-core-next-preview-amd-architects-for-compute/4}}&lt;/ref&gt;

== See also ==
* [[Euclidean space]]
* [[Four-dimensional space]]
* [[Quaternion]]
* [[Dimension]]
* [[RGBA color space]]
* [[Tesseract]]
* [[4×4 matrix]]

==References==
{{Reflist|30em}}

{{DEFAULTSORT:4D Vector}}
[[Category:Mathematical structures]]
[[Category:Vectors (mathematics and physics)]]
[[Category:Computer science]]
[[Category:Computer hardware]]
[[Category:Data types]]</text>
      <sha1>ej8vk9br0t9cmlsduik4rg40qkaoj41</sha1>
    </revision>
  </page>
  <page>
    <title>Glossary of computer science</title>
    <ns>0</ns>
    <id>57143357</id>
    <revision>
      <id>1009018917</id>
      <parentid>1004916013</parentid>
      <timestamp>2021-02-26T08:20:51Z</timestamp>
      <contributor>
        <username>JJMC89</username>
        <id>24812038</id>
      </contributor>
      <minor/>
      <comment>Replace [[:mw:Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="214926" xml:space="preserve">{{short description|List of definitions of terms and concepts commonly used in computer science}}
{{TopicTOC-Computer science}}

This '''glossary of computer science''' is a list of definitions of terms and concepts used in [[computer science]], its sub-disciplines, and related fields, including terms relevant to [[software]], [[data science]], and {{gli|computer programming}}.

{{compact ToC|side=yes|center=yes|nobreak=yes|seealso=yes|refs=yes|}}

==A==
{{glossary}}
{{term|[[abstract data type]] (ADT)}}
{{defn|A [[mathematical model]] for {{gli|data type|data types}} in which a data type is defined by its behavior ({{gli|semantics}}) from the point of view of a {{gli|user}} of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations. This contrasts with {{gli|data structure|data structures}}, which are concrete representations of data from the point of view of an implementer rather than a user.}}

{{term|[[abstract method]]}}
{{defn|One with only a [[method signature|signature]] and no [[method body|implementation body]]. It is often used to specify that a subclass must provide an implementation of the method. Abstract methods are used to specify {{gli|interface|interfaces}} in some computer languages.&lt;ref&gt;{{cite web|title=Abstract Methods and Classes|url=http://docs.oracle.com/javase/tutorial/java/IandI/abstract.html|website=oracle.com|publisher=Oracle Java Documentation|access-date=11 December 2014}}&lt;/ref&gt;}}

{{term|[[Abstraction (software engineering)|abstraction]]}}
{{defn|no=1|In [[software engineering]] and {{gli|computer science}}, the process of removing physical, spatial, or temporal details&lt;ref&gt;{{Cite journal|last1=Colburn|first1=Timothy|last2=Shute|first2=Gary|date=2007-06-05|title=Abstraction in Computer Science|journal=Minds and Machines|language=en|volume=17|issue=2|pages=169–184|doi=10.1007/s11023-007-9061-7|s2cid=5927969|issn=0924-6495}}&lt;/ref&gt; or {{gli|attribute|attributes}} in the study of objects or systems in order to more closely attend to other details of interest;&lt;ref name="abstraction"&gt;{{Cite journal|last=Kramer|first=Jeff|date=2007-04-01|title=Is abstraction the key to computing?|journal=Communications of the ACM|volume=50|issue=4|pages=36–42|doi=10.1145/1232743.1232745|issn=0001-0782|citeseerx=10.1.1.120.6776|s2cid=12481509}}&lt;/ref&gt; it is also very similar in nature to the process of [[generalization]].}}
{{defn|no=2|The result of this process: an [[Abstract and concrete|abstract]] [[concept]]-[[Object (philosophy)|object]] created by keeping common features or attributes to various concrete objects or systems of study.&lt;ref name="abstraction" /&gt;}}

{{term|[[agent architecture]]}}
{{defn|A [[blueprint]] for {{gli|software agent|software agents}} and [[intelligent control]] systems depicting the arrangement of components. The architectures implemented by [[intelligent agent]]s are referred to as [[cognitive architecture]]s.&lt;ref&gt;[http://hri.cogs.indiana.edu/publications/aaai04ws.pdf Comparison of Agent Architectures] {{webarchive |url=https://web.archive.org/web/20080827222057/http://hri.cogs.indiana.edu/publications/aaai04ws.pdf |date=August 27, 2008 }}&lt;/ref&gt;}}

{{term|[[agent-based model]] (ABM)}}
{{defn|A class of {{gli|computational model|computational models}} for [[computer simulation|simulating]] the actions and interactions of autonomous agents (both individual or collective entities such as organizations or groups) with a view to assessing their effects on the system as a whole. It combines elements of [[game theory]], [[complex systems]], [[emergence]], [[computational sociology]], [[multi-agent system]]s, and [[evolutionary programming]]. [[Monte Carlo method]]s are used to introduce randomness.}}

{{term|[[aggregate function]]}}
{{defn|In [[database management]], a {{gli|subroutine|function}} in which the values of multiple rows are grouped together to form a single value of more significant meaning or measurement, such as a sum, count, or max.}}

{{term|[[agile software development]]}}
{{defn|An approach to [[software development]] under which requirements and solutions evolve through the collaborative effort of [[Self-organizing communities|self-organizing]] and [[cross-functional team|cross-functional]] teams and their [[Customer|customer(s)]]/[[End user|end user(s)]].&lt;ref name="Collier 2011"&gt;{{cite book |title= Agile Analytics: A Value-Driven Approach to Business Intelligence and Data Warehousing |last=Collier|first=Ken W. |year=2011 |publisher= Pearson Education |isbn=9780321669544 | pages= 121 ff|quote=What is a self-organizing team?}}&lt;/ref&gt; It advocates adaptive planning, evolutionary development, early delivery, and [[Continual improvement process|continual improvement]], and it encourages rapid and flexible response to change.&lt;ref name="WhatIsAgile"&gt;{{cite web|url = http://www.agilealliance.org/the-alliance/what-is-agile/|title = What is Agile Software Development?|date = 8 June 2013|access-date = 4 April 2015|publisher = Agile Alliance}}&lt;/ref&gt;}}

{{term|[[algorithm]]}}
{{defn|An unambiguous specification of how to solve a class of problems. Algorithms can perform [[calculation]], [[data processing]], and [[automated reasoning]] tasks. They are ubiquitous in computing technologies.}}

{{term|[[algorithm design]]}}
{{defn|A method or mathematical process for problem-solving and for engineering {{gli|algorithm|algorithms}}. The design of algorithms is part of many solution theories of [[operation research]], such as [[dynamic programming]] and [[Divide and conquer algorithm|divide-and-conquer]]. Techniques for designing and implementing algorithm designs are also called algorithm design patterns,&lt;ref&gt;{{citation|url=http://ww3.algorithmdesign.net/ch00-front.html|title=Algorithm Design: Foundations, Analysis, and Internet Examples|last1=Goodrich|first1=Michael T.|author1-link=Michael T. Goodrich|last2=Tamassia|first2=Roberto|author2-link=Roberto Tamassia|publisher=John Wiley &amp; Sons, Inc.|year=2002|isbn=978-0-471-38365-9}}&lt;/ref&gt; such as the template method pattern and decorator pattern.}}

{{term|[[algorithmic efficiency]]}}
{{defn|A property of an {{gli|algorithm}} which relates to the number of [[computational resource]]s used by the algorithm. An algorithm must be [[analysis of algorithms|analyzed]] to determine its resource usage, and the efficiency of an algorithm can be measured based on usage of different resources. Algorithmic efficiency can be thought of as analogous to engineering [[productivity]] for a repeating or continuous process.}}

{{term|[[American Standard Code for Information Interchange]] (ASCII)}}
{{defn|A [[character encoding]] standard for electronic communications. ASCII codes represent text in computers, [[telecommunications equipment]], and other devices. Most modern character-encoding schemes are based on ASCII, although they support many additional characters.}}

{{term|[[application programming interface]] (API)}}
{{defn|A set of {{gli|subroutine}} definitions, [[communication protocols]], and tools for building {{gli|software}}. In general terms, it is a set of clearly defined methods of communication among various components. A good API makes it easier to develop a {{gli|computer program}} by providing all the building blocks, which are then put together by the [[programmer]].}}

{{term|[[application software]]}}
{{ghat|Also simply '''application''' or '''app'''.}}
{{defn|{{gli|software|Computer software}} designed to perform a group of coordinated functions, tasks, or activities for the benefit of the {{gli|user}}. Common examples of applications include [[word processor]]s, [[spreadsheet]]s, [[accounting software|accounting application]]s, [[web browser]]s, [[media player (software)|media player]]s, aeronautical [[flight simulator]]s, [[console game]]s, and [[Raster graphics editor|photo editor]]s. This contrasts with {{gli|system software}}, which is mainly involved with managing the computer's most basic running operations, often without direct input from the user. The collective noun ''application software'' refers to all applications collectively.&lt;ref&gt;{{cite web |title=Application software |url=https://www.pcmag.com/encyclopedia/term/37919/application-program | work=[[PC Magazine]] |publisher=[[Ziff Davis]]}}&lt;/ref&gt;}}

{{term|[[array data structure]]}}
{{ghat|Also simply '''array'''.}}
{{defn|A {{gli|data structure}} consisting of a collection of ''elements'' ({{gli|value|values}} or {{gli|variable|variables}}), each identified by at least one ''array index'' or ''key''. An array is stored such that the position of each element can be computed from its index [[tuple]] by a mathematical formula.&lt;ref&gt;{{cite web|url=https://xlinux.nist.gov/dads/HTML/array.html|title=array|last=Black|first=Paul E.|date=13 November 2008|work=[[Dictionary of Algorithms and Data Structures]]|publisher=[[National Institute of Standards and Technology]]|access-date=22 August 2010}}&lt;/ref&gt;&lt;ref name="andres"&gt;{{cite arXiv |eprint=1008.2909 |author1=Bjoern Andres |author2=Ullrich Koethe |author3=Thorben Kroeger |author4=Hamprecht |title=Runtime-Flexible Multi-dimensional Arrays and Views for C++98 and C++0x |class=cs.DS |year=2010}}&lt;/ref&gt;&lt;ref name="garcia"&gt;{{Cite journal|last1=Garcia|first1=Ronald |first2=Andrew |last2=Lumsdaine|year=2005|title=MultiArray: a C++ library for generic programming with arrays|journal=Software: Practice and Experience|volume=35|issue=2|pages=159–188|issn=0038-0644|doi=10.1002/spe.630|s2cid=10890293 }}&lt;/ref&gt; The simplest type of data structure is a linear array, also called a one-dimensional array.}}

{{term|[[Artifact (software development)|artifact]]}}
{{defn|One of many kinds of tangible by-products produced during the development of {{gli|software}}. Some artifacts (e.g. [[use case]]s, [[class diagram]]s, and other [[Unified Modeling Language]] (UML) models, requirements, and design documents) help describe the function, architecture, and design of software. Other artifacts are concerned with the process of development itself—such as project plans, business cases, and risk assessments.}}

{{term|[[artificial intelligence]] (AI)}}
{{ghat|Also '''machine intelligence'''.}}
{{defn|[[Intelligence]] demonstrated by [[machine]]s, in contrast to the natural intelligence displayed by humans and other animals. In {{gli|computer science}}, AI research is defined as the study of "[[intelligent agent]]s": devices capable of perceiving their environment and taking actions that maximize the chance of successfully achieving their goals.&lt;ref name="Definition of AI"&gt;
Definition of AI as the study of [[intelligent agents]]:
* {{Harvnb|Poole|Mackworth|Goebel|1998|loc=[http://people.cs.ubc.ca/~poole/ci/ch1.pdf p. 1]}}, which provides the version that is used in this article. Note that they use the term "computational intelligence" as a synonym for artificial intelligence.
* {{Harvtxt|Russell|Norvig|2003}} (who prefer the term "rational agent") and write "The whole-agent view is now widely accepted in the field" {{Harv|Russell|Norvig|2003|p=55}}.
* {{Harvnb|Nilsson|1998}}
&lt;!--These textbooks are the most widely used in academic AI.--&gt;
* {{Harvnb|Legg|Hutter|2007}}.
&lt;/ref&gt; Colloquially, the term "artificial intelligence" is applied when a machine mimics "cognitive" functions that humans associate with other [[human mind]]s, such as "learning" and "problem solving".{{sfn|Russell|Norvig|2009|p=2}}}}

{{term|[[ASCII]]}}
{{defn|See ''{{gli|American Standard Code for Information Interchange}}''.}}

{{term|[[Assertion (software development)|assertion]]}}
{{defn|In {{gli|computer programming}}, a {{gli|statement}} that a [[Predicate (mathematical logic)|predicate]] ([[Boolean-valued function]], i.e. a true–false {{gli|expression}}) is always true at that point in code execution. It can help a programmer read the code, help a {{gli|compiler}} compile it, or help the program detect its own defects. For the latter, some programs check assertions by actually evaluating the predicate as they run and if it is not in fact true – an assertion failure – the program considers itself to be broken and typically deliberately {{gli|crash|crashes}} or throws an assertion failure [[exception handling|exception]].}}

{{term|[[associative array]]}}
{{defn|An associative array, map, symbol table, or dictionary is an [[abstract data type]] composed of a [[collection (abstract data type)|collection]] of [[attribute–value pair|(key, value) pairs]], such that each possible key appears at most once in the collection.

Operations associated with this data type allow:&lt;ref name="gt"&gt;{{citation|contribution=9.1 The Map Abstract Data Type|title=Data Structures &amp; Algorithms in Java|last1=Goodrich|first1=Michael T.|author1-link=Michael T. Goodrich|last2=Tamassia|first2=Roberto|author2-link=Roberto Tamassia|publisher=Wiley|edition=4th|year=2006|pages=368–371}}&lt;/ref&gt;&lt;ref name="ms"&gt;{{citation|contribution=4 Hash Tables and Associative Arrays|title=Algorithms and Data Structures: The Basic Toolbox|first1=Kurt|last1=Mehlhorn|author1-link=Kurt Mehlhorn|first2=Peter|last2=Sanders|author2-link=Peter Sanders (computer scientist)|publisher=Springer|year=2008|pages=81–98 |url=http://people.mpi-inf.mpg.de/~mehlhorn/ftp/Toolbox/HashTables.pdf}}&lt;/ref&gt;

* the addition of a pair to the collection
* the removal of a pair from the collection
* the modification of an existing pair
* the lookup of a value associated with a particular key}}

{{term|[[automata theory]]}}
{{defn|The study of [[abstract machine]]s and [[automaton|automata]], as well as the [[computational problem]]s that can be solved using them. It is a theory in {{gli|theoretical computer science}} and [[discrete mathematics]] (a subject of study in both [[mathematics]] and {{gli|computer science}}).}}

{{term|[[automated reasoning]]}}
{{defn|An area of {{gli|computer science}} and [[mathematical logic]] dedicated to understanding different aspects of [[reasoning]]. The study of automated reasoning helps produce [[computer programs]] that allow computers to reason completely, or nearly completely, automatically. Although automated reasoning is considered a sub-field of {{gli|artificial intelligence}}, it also has connections with {{gli|theoretical computer science}}, and even [[philosophy]].}}
{{glossaryend}}

==B==
{{glossary}}
{{term|[[bandwidth (computing)|bandwidth]]}}
{{defn|The maximum rate of data transfer across a given path. Bandwidth may be characterized as ''network bandwidth'',&lt;ref&gt;[[Douglas Comer]], [https://books.google.co.uk/books?id=tm-evHmOs3oC&amp;pg=PA99&amp;dq=%22network+bandwidth%22+%22computer+networks%22&amp;hl=en&amp;ei=mvqcTOHIMIb2tgPbnpXWAQ&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;redir_esc=y#v=onepage&amp;q&amp;f=false Computer Networks and Internets], page 99 ff, Prentice Hall 2008.&lt;/ref&gt; ''data bandwidth'',&lt;ref&gt;Fred Halsall, [https://books.google.com/books?ei=dvycTJ2BDoqosAOhu_DVAQ&amp;ct=result&amp;hl=en&amp;id=HrXbAAAAMAAJ&amp;dq=%100data+bandwidth%100++%100computer+networks%22&amp;q=%100data+bandwidth%100+Introduction to data+communications and computer networks], page 108, Addison-Wesley, 1985.&lt;/ref&gt; or ''digital bandwidth''.&lt;ref&gt;[https://books.google.co.uk/books?ei=rfmcTPKEN5L6swOekeXVAQ&amp;ct=result&amp;hl=en&amp;id=7gqsZmr5HJcC&amp;dq=+0digital+bandwidth+0+%22&amp;redir_esc=y Cisco Networking Academy Program: CCNA 1 and 2 companion guide, Volym 1–2], Cisco Academy 2003&lt;/ref&gt;&lt;ref&gt;Behrouz A. Forouzan, ''Data communications and networking'', McGraw-Hill, 2007&lt;/ref&gt;}}

{{term|[[Bayesian programming]]}}
{{defn|A formalism and a methodology for having a technique to specify [[Probability distribution|probabilistic models]] and solve problems when less than the necessary information is available.}}

{{term|[[benchmark (computing)|benchmark]]}}
{{defn|The act of running a {{gli|computer program}}, a set of programs, or other operations, in order to assess the relative performance of an object, normally by running a number of standard tests and trials against it.&lt;ref&gt;{{Cite journal| doi = 10.1145/5666.5673| issn = 0001-0782| volume = 29| issue = 3| pages = 218–221| last1 = Fleming| first1 = Philip J.| last2 = Wallace| first2 = John J.| title = How not to lie with statistics: the correct way to summarize benchmark results| journal = Communications of the ACM| date = 1986-03-01| s2cid = 1047380}}&lt;/ref&gt; The term ''benchmark'' is also commonly utilized for the purposes of elaborately designed benchmarking programs themselves.}}

{{term|[[best, worst and average case]]}}
{{defn|Expressions of what the {{gli|resource}} usage is ''at least'', ''at most'', and ''on average'', respectively, for a given {{gli|algorithm}}. Usually the resource being considered is running time, i.e. [[time complexity]], but it could also be memory or some other resource. ''Best case'' is the function which performs the minimum number of steps on input data of ''n'' elements; ''worst case'' is the function which performs the maximum number of steps on input data of size ''n''; ''average case'' is the function which performs an average number of steps on input data of ''n'' elements.}}

{{term|[[big data]]}}
{{defn|A term used to refer to [[data set]]s that are too large or complex for traditional [[data processing|data-processing]] {{gli|application software}} to adequately deal with. Data with many cases (rows) offer greater [[statistical power]], while data with higher complexity (more attributes or columns) may lead to a higher [[false discovery rate]].&lt;ref&gt;{{Cite journal|last=Breur|first=Tom|date=July 2016|title=Statistical Power Analysis and the contemporary "crisis" in social sciences|journal=Journal of Marketing Analytics|language=en|volume=4|issue=2–3|pages=61–65|doi=10.1057/s41270-016-0001-3|issn=2050-3318|doi-access=free}}&lt;/ref&gt;}}

{{term|[[big O notation]]}}
{{defn|A mathematical notation that describes the [[asymptotic analysis|limiting behavior]] of a [[function (mathematics)|function]] when the argument tends towards a particular value or infinity. It is a member of a family of notations invented by [[Paul Gustav Heinrich Bachmann|Paul Bachmann]],&lt;ref name=Bachmann&gt;{{cite book |first=Paul |last=Bachmann |author-link=Paul Bachmann |title=Analytische Zahlentheorie |trans-title=Analytic Number Theory |language=de |volume=2 |location=Leipzig |publisher=Teubner |date=1894 |url=https://archive.org/stream/dieanalytischeza00bachuoft#page/402/mode/2up}}&lt;/ref&gt; [[Edmund Landau]],&lt;ref name=Landau&gt;{{cite book |first=Edmund |last=Landau |author-link=Edmund Landau |title=Handbuch der Lehre von der Verteilung der Primzahlen |publisher=B. G. Teubner |date=1909 |location=Leipzig |trans-title=Handbook on the theory of the distribution of the primes |language=de |page=883 | url=https://archive.org/details/handbuchderlehre01landuoft}}&lt;/ref&gt; and others, collectively called ''Bachmann–Landau notation'' or ''asymptotic notation''.}}

{{term|[[binary number]]}}
{{defn|In mathematics and [[digital electronics]], a number expressed in the base-2 numeral system or binary numeral system, which uses only two symbols: typically [[0 (number)|0 (zero)]] and [[1 (number)|1 (one)]].}}

{{term|[[binary search algorithm]]}}
{{ghat|Also simply '''binary search''', '''half-interval search''',&lt;ref name="Williams1976"&gt;{{cite conference|last1=Williams, Jr.|first1=Louis F.|title=A modification to the half-interval search (binary search) method|conference=Proceedings of the 14th ACM Southeast Conference|date=22 April 1976|pages=95–101|doi=10.1145/503561.503582|url=https://dl.acm.org/citation.cfm?doid=503561.503582|publisher=ACM|access-date=29 June 2018|archive-url=https://web.archive.org/web/20170312215255/http://dl.acm.org/citation.cfm?doid=503561.503582|archive-date=12 March 2017|url-status=live|df=dmy-all}}&lt;/ref&gt; '''logarithmic search''',{{Sfn|Knuth|1998|loc=§6.2.1 ("Searching an ordered table"), subsection "Binary search"}} or '''binary chop'''.{{Sfn|Butterfield|Ngondi|2016|p=46}}}}
{{defn|A {{gli|search algorithm}} that finds the position of a target value within a [[sorted array]].{{Sfn|Cormen|Leiserson|Rivest|Stein|2009|p=39}}&lt;ref&gt;{{MathWorld |title=Binary search |id=BinarySearch}}&lt;/ref&gt;}}

{{term|[[binary tree]]}}
{{defn|A [[tree structure|tree]] {{gli|data structure}} in which each node has at most two [[child node|children]], which are referred to as the ''{{visible anchor|left child}}'' and the ''{{visible anchor|right child}}''. A [[recursive definition]] using just [[set theory]] notions is that a (non-empty) binary tree is a [[tuple]] (''L'', ''S'', ''R''), where ''L'' and ''R'' are binary trees or the [[empty set]] and ''S'' is a [[singleton set]].&lt;ref name="GarnierTaylor2009"&gt;{{cite book|author1=Rowan Garnier|author2=John Taylor|title=Discrete Mathematics: Proofs, Structures and Applications, Third Edition|url=https://books.google.com/books?id=WnkZSSc4IkoC&amp;pg=PA620|year=2009|publisher=CRC Press|isbn=978-1-4398-1280-8|page=620}}&lt;/ref&gt; Some authors allow the binary tree to be the empty set as well.&lt;ref name="Skiena2009"&gt;{{cite book|author=Steven S Skiena|title=The Algorithm Design Manual|url=https://books.google.com/books?id=7XUSn0IKQEgC&amp;pg=PA77|year=2009|publisher=Springer Science &amp; Business Media|isbn=978-1-84800-070-4|page=77}}&lt;/ref&gt;}}

{{term|[[bioinformatics]]}}
{{defn|An interdisciplinary field that combines [[biology]], {{gli|computer science}}, [[Information engineering (field)|information engineering]], [[mathematics]], and [[statistics]] to develop methods and [[software tool]]s for analyzing and interpreting biological data. Bioinformatics is widely used for ''[[in silico]]'' analyses of biological queries using mathematical and statistical techniques.}}

{{term|[[bit]]}}
{{defn|A [[Units of information|basic unit of information]] used in {{gli|computing}} and digital communications; a portmanteau of ''binary digit''. A {{gli|binary number|binary}} digit can have one of two possible {{gli|value|values}}, and may be physically represented with a two-state device. These state values are most commonly represented as either a {{gaps|0|or|1}}.&lt;ref name="Mackenzie_1980"&gt;{{cite book |title=Coded Character Sets, History and Development |work=The Systems Programming Series |author-last=Mackenzie |author-first=Charles E. |year=1980 |edition=1 |publisher=[[Addison-Wesley Publishing Company, Inc.]] |isbn=978-0-201-14460-4 |lccn=77-90165 |page=x |url=https://books.google.com/books?id=6-tQAAAAMAAJ |access-date=2016-05-22 |url-status=live |archive-url=https://web.archive.org/web/20161118230039/https://books.google.com/books?id=6-tQAAAAMAAJ |archive-date=18 November 2016 |df=dmy-all }} [https://web.archive.org/web/20160526172151/https://textfiles.meulie.net/bitsaved/Books/Mackenzie_CodedCharSets.pdf]&lt;/ref&gt;}}

{{term|[[bit rate]] (''R'')}}

{{ghat|Also '''bitrate'''.}}

{{defn|In [[telecommunications]] and {{gli|computing}}, the number of {{gli|bit|bits}} that are conveyed or processed per unit of time.&lt;ref&gt;{{cite book |url = https://books.google.com/books?id=-kNn_p6WA38C&amp;q=bit+%22rate+R%22&amp;pg=PA21 |title=Data Communications and Computer Networks | first =Prakash C | last = Gupta |publisher=PHI Learning |year= 2006 |access-date=10 July 2011|isbn=9788120328464 }}&lt;/ref&gt;}}

{{term|[[blacklist (computing)|blacklist]]}}
{{ghat|Also '''block list'''.}}
{{defn|In {{gli|computing}}, a basic [[access control]] mechanism that allows through all elements (email addresses, users, passwords, [[URLs]], [[IP address]]es, [[domain name]]s, file [[MD5 Hash|hashes]], etc.), except those explicitly mentioned in a list of prohibited elements. Those items on the list are denied access. The opposite is a {{gli|whitelist}}, which means only items on the list are allowed through whatever gate is being used while all other elements are blocked. A [[Greylisting (email)|greylist]] contains items that are temporarily blocked (or temporarily allowed) until an additional step is performed.}}

{{term|[[BMP file format]]}}
{{ghat|Also '''bitmap image file''', '''device independent bitmap (DIB) file format''', or simply '''bitmap'''.}}
{{defn|A [[raster graphics]] [[image file format]] used to store [[bitmap]] digital images independently of the [[display device]] (such as a [[graphics adapter]]), used especially on [[Microsoft Windows]]&lt;ref name="bmp"&gt;{{cite book|title=Encyclopedia of Graphics File Formats|edition=Second|date=April 1996|author=James D. Murray|author2=William vanRyper|isbn=978-1-56592-161-0|publisher=[[O'Reilly Media|O'Reilly]]|at=bmp|url=https://archive.org/details/mac_Graphics_File_Formats_Second_Edition_1996|access-date=2014-03-07}}&lt;/ref&gt; and [[OS/2]]&lt;ref name="os2bmp"&gt;{{cite book|title=Encyclopedia of Graphics File Formats|edition=Second|date=April 1996|author=James D. Murray|author2=William vanRyper|isbn=978-1-56592-161-0|publisher=[[O'Reilly Media|O'Reilly]]|at=os2bmp|url=https://archive.org/details/mac_Graphics_File_Formats_Second_Edition_1996|access-date=2014-03-07}}&lt;/ref&gt; operating systems.}}

{{term|[[Boolean data type]]}}
{{defn|A [[data type]] that has one of two possible values (usually denoted ''true'' and ''false''), intended to represent the two [[truth value]]s of [[logic]] and [[Boolean algebra]]. It is named after [[George Boole]], who first defined an algebraic system of logic in the mid-19th century. The Boolean data type is primarily associated with [[Conditional (computer programming)|conditional]] statements, which allow different actions by changing [[control flow]] depending on whether a programmer-specified Boolean ''condition'' evaluates to true or false. It is a special case of a more general ''logical data type'' (see [[probabilistic logic]])—i.e. logic need not always be Boolean.}}

{{term|[[Boolean expression]]}}
{{defn|An {{gli|expression}} used in a {{gli|programming language}} that returns a [[Boolean value]] when evaluated, that is one of ''true'' or ''false''. A Boolean expression may be composed of a combination of the Boolean constants ''true'' or ''false'', [[Boolean data type|Boolean-typed]] variables, Boolean-valued operators, and [[Boolean-valued function]]s.&lt;ref&gt;{{citation
 | last1 = Gries | first1 = David | author1-link = David Gries
 | last2 = Schneider | first2 = Fred B. | author2-link = Fred B. Schneider
 | contribution = Chapter 2. Boolean Expressions
 | isbn = 9780387941158
 | page = 25ff
 | publisher = Springer
 | series = Monographs in Computer Science
 | title = A Logical Approach to Discrete Math
 | url = https://books.google.com/books?id=ZWTDQ6H6gsUC&amp;pg=PA25
 | year = 1993}}&lt;/ref&gt;}}

{{term|[[Boolean algebra]]}}
{{defn|In mathematics and [[mathematical logic]], the branch of [[algebra]] in which the values of the variables are the [[truth value]]s ''true'' and ''false'', usually denoted 1 and 0, respectively. Contrary to [[elementary algebra]], where the values of the variables are numbers and the prime operations are addition and multiplication, the main operations of Boolean algebra are the [[Logical conjunction|conjunction]] ''and'' (denoted as ∧), the [[Logical disjunction|disjunction]] ''or'' (denoted as ∨), and the [[negation]] ''not'' (denoted as ¬). It is thus a formalism for describing logical relations in the same way that elementary algebra describes numeric relations.}}

{{term|[[byte]]}}
{{defn|A [[units of information|unit of digital information]] that most commonly consists of eight {{gli|bit|bits}}, representing a {{gli|binary number}}. Historically, the byte was the number of bits used to encode a single [[character (computing)|character]] of text in a computer&lt;ref name="Buchholz_1962"&gt;{{anchor|Buchholz-1962}}{{citation |title=Planning a Computer System – Project Stretch |author-first1=Gerrit Anne |author-last1=Blaauw |author-link1=Gerrit Anne Blaauw |author-first2=Frederick Phillips |author-last2=Brooks, Jr. |author-link2=Frederick Phillips Brooks, Jr. |author-first3=Werner |author-last3=Buchholz |author-link3=Werner Buchholz |editor-first=Werner |editor-last=Buchholz |editor-link=Werner Buchholz |publisher=[[McGraw-Hill Book Company, Inc.]] / The Maple Press Company, York, PA. |lccn=61-10466 |year=1962 |chapter=4: Natural Data Units |pages=39–40 |chapter-url=http://archive.computerhistory.org/resources/text/IBM/Stretch/pdfs/Buchholz_102636426.pdf |access-date=2017-04-03 |url-status=live |archive-url=https://web.archive.org/web/20170403014651/http://archive.computerhistory.org/resources/text/IBM/Stretch/pdfs/Buchholz_102636426.pdf |archive-date=2017-04-03 |quote=[…] Terms used here to describe the structure imposed by the machine design, in addition to ''[[bit]]'', are listed below.&lt;br /&gt;''Byte'' denotes a group of bits used to encode a character, or the number of bits transmitted in parallel to and from input-output units. A term other than ''[[character (computing)|character]]'' is used here because a given character may be represented in different applications by more than one code, and different codes may use different numbers of bits (i.e., different byte sizes). In input-output transmission the grouping of bits may be completely arbitrary and have no relation to actual characters. (The term is coined from ''[[bite]]'', but respelled to avoid accidental mutation to ''bit''.)&lt;br /&gt;A ''[[Word (unit)|word]]'' consists of the number of data bits transmitted in parallel from or to memory in one memory cycle. [[Word size]] is thus defined as a structural property of the memory. (The term ''[[catena (unit)|catena]]'' was coined for this purpose by the designers of the [[Groupe Bull|Bull]] {{ill|Bull Gamma 60{{!}}GAMMA 60|fr|Gamma 60}} computer.)&lt;br /&gt;''[[Block (data storage)|Block]]'' refers to the number of words transmitted to or from an input-output unit in response to a single input-output instruction. Block size is a structural property of an input-output unit; it may have been fixed by the design or left to be varied by the program. […]}}&lt;/ref&gt;&lt;ref name="Bemer_1959"&gt;{{citation |author-first=Robert William |author-last=Bemer |author-link=Robert William Bemer |title=A proposal for a generalized card code of 256 characters |journal=[[Communications of the ACM]] |volume=2 |number=9 |pages=19–23 |year=1959 |doi=10.1145/368424.368435|s2cid=36115735 }}&lt;/ref&gt; and for this reason it is the smallest [[address space|addressable]] unit of {{gli|memory}} in many {{gli|computer architecture|computer architectures}}.}}

{{term|[[booting]]}}
{{defn|The procedures implemented in starting up a [[computer]] or [[computer appliance]] until it can be used. It can be initiated by hardware such as a button press or by a software command. After the power is switched on, the computer is relatively dumb and can read only part of its storage called {{gli|read-only memory}}. There, a small program is stored called [[firmware]]. It does [[power-on self-test]]s and, most importantly, allows access to other types of memory like a [[hard disk]] and [[main memory]]. The firmware loads bigger [[computer program|program]]s into the computer's [[random-access memory|main memory]] and runs it.}}
{{glossaryend}}

==C==
{{glossary}}
{{term|[[callback (computer programming)|callback]]}}
{{ghat|Also a '''call-after function'''.&lt;ref&gt;{{cite web|url=https://stackoverflow.com/a/7549753/653708|title=What is a callback function?|website=Stack Overflow|access-date=2018-05-16}}&lt;/ref&gt;}}
{{defn|Any [[executable code]] that is passed as an {{gli|argument}} to other code that is expected to "call back" (execute) the argument at a given time. This execution may be immediate, as in a ''synchronous callback'', or it might happen at a later time, as in an ''asynchronous callback''.}}

{{term|[[central processing unit]] (CPU)}}
{{defn|The electronic circuitry within a {{gli|computer}} that carries out the {{gli|instruction|instructions}} of a {{gli|computer program}} by performing the basic arithmetic, logic, controlling, and {{gli|input/output}} (I/O) operations specified by the instructions. The computer industry has used the term "central processing unit" at least since the early 1960s.&lt;ref name="weik1961"&gt;{{cite journal | author = Weik, Martin H. | title = A Third Survey of Domestic Electronic Digital Computing Systems | publisher = [[Ballistic Research Laboratory]] | url = http://ed-thelen.org/comp-hist/BRL61.html | year = 1961 }}&lt;/ref&gt; Traditionally, the term "CPU" refers to a ''processor'', more specifically to its processing unit and {{gli|control unit}} (CU), distinguishing these core elements of a computer from external components such as [[main memory]] and I/O circuitry.&lt;ref name="kuck"&gt;{{cite book|last1= Kuck|first1= David|title= Computers and Computations, Vol 1|date= 1978|publisher= John Wiley &amp; Sons, Inc.|isbn= 978-0471027164|page= 12}}&lt;/ref&gt;}}

{{term|[[character (computing)|character]]}}
{{defn|A [[unit of information]] that roughly corresponds to a [[grapheme]], grapheme-like unit, or symbol, such as in an [[alphabet]] or [[syllabary]] in the written form of a [[natural language]].&lt;ref&gt;{{cite web|url=http://www.merriam-webster.com/dictionary/character|title=Definition of CHARACTER|website=www.merriam-webster.com|access-date=1 April 2018}}&lt;/ref&gt;}}

{{term|[[cipher]]}}
{{ghat|Also '''cypher'''.}}
{{defn|In {{gli|cryptography}}, an {{gli|algorithm}} for performing [[encryption]] or [[decryption]]&amp;mdash;a series of well-defined steps that can be followed as a {{gli|procedure}}.}}

{{term|[[class (computer science)|class]]}}
{{defn|In {{gli|object-oriented programming}}, an extensible program-code-template for creating [[Object (object-oriented programming)|object]]s, providing initial values for state ([[member variable]]s) and implementations of behavior (member functions or [[Method (computer programming)|methods]]).{{sfn|Gamma|Helm|Johnson|Vlissides|1995| p=14}}{{sfn|Bruce|2002|loc=2.1 Objects, classes, and object types, {{Google books|9NGWq3K1RwUC|Objects, classes, and object types|page=18|plainurl=yes}}}} In many languages, the class name is used as the name for the class (the template itself), the name for the default [[Constructor (object-oriented programming)|constructor]] of the class (a {{gli|subroutine}} that creates objects), and as the [[data type|type]] of objects generated by [[Instance (computer science)|instantiating]] the class; these distinct concepts are easily conflated.{{sfn|Bruce|2002|loc=2.1 Objects, classes, and object types, {{Google books|9NGWq3K1RwUC|Objects, classes, and object types|page=18|plainurl=yes}}}}}}

{{term|[[class-based programming]]}}
{{ghat|Also '''class-orientation'''.}}
{{defn|A style of {{gli|object-oriented programming}} (OOP) in which inheritance occurs via defining "{{gli|class|classes}}" of {{gli|object|objects}}, instead of via the objects alone. Compare ''{{gli|prototype-based programming}}''.}}

{{term|[[class-based programming|class-orientation]]}}
{{defn|A style of [[Object-oriented programming]] (OOP) in which inheritance occurs via defining ''[[Class (computer programming)|classes]]'' of [[Object (computer science)|objects]], instead of inheritance occurring via the objects alone (compare [[prototype-based programming]]).}}

{{term|[[client (computing)|client]]}}
{{defn|A piece of [[computer hardware]] or {{gli|software}} that accesses a service made available by a [[Server (computing)|server]]. The server is often (but not always) on another [[computer system]], in which case the client accesses the service by way of a [[Computer network|network]].&lt;ref&gt;Sadoski, Darleen. 
''Client/Server Software Architectures – An Overview'', Software Technology Roadmap, 1997-08-02. Retrieved on 2008-09-16.&lt;/ref&gt; The term applies to the role that programs or devices play in the [[client–server model]].}}

{{term|[[cleanroom software engineering]]}}
{{defn|A [[software development process]] intended to produce software with a certifiable level of [[Reliability engineering|reliability]]. The cleanroom process was originally developed by [[Harlan Mills]] and several of his colleagues including Alan Hevner at [[IBM]].&lt;ref&gt;{{cite journal|last=Mills|first=H.|author-link=Harlan Mills |author2=M. Dyer |author3=R. Linger|title=Cleanroom Software Engineering|journal=IEEE Software|volume=4|issue=5|date=September 1987|pages=19&amp;ndash;25|doi=10.1109/MS.1987.231413|citeseerx=10.1.1.467.2435|s2cid=383170}}&lt;/ref&gt; The focus of the cleanroom process is on defect prevention, rather than defect removal.}}

{{term|[[closure (computer programming)|closure]]}}
{{ghat|Also '''lexical closure''' or '''function closure'''.}}
{{defn|A technique for implementing [[lexically scoped]] [[name binding]] in a language with [[first-class function]]s. [[Operational semantics|Operationally]], a closure is a [[record (computer science)|record]] storing a [[function (computer science)|function]]{{efn|The function may be stored as a [[reference (computer science)|reference]] to a function, such as a [[function pointer]].}} together with an environment.&lt;ref&gt;Sussman and Steele. "Scheme: An interpreter for extended lambda calculus". "... a data structure containing a lambda expression, and an environment to be used when that lambda expression is applied to arguments." ([[s:Page:Scheme - An interpreter for extended lambda calculus.djvu/22|Wikisource]])&lt;/ref&gt;}}

{{term|[[cloud computing]]}}
{{defn|Shared pools of configurable computer [[system resource]]s and higher-level services that can be rapidly [[Provisioning|provisioned]] with minimal management effort, often over the [[Internet]].  Cloud computing relies on sharing of resources to achieve coherence and [[economies of scale]], similar to a [[public utility]].}}

{{term|[[library (computing)|code library]]}}
{{defn|A collection of [[non-volatile memory|non-volatile resources]] used by {{gli|computer program|computer programs}}, often for [[software development]]. These may include configuration data, documentation, help data, message templates, [[Code reuse|pre-written code]] and {{gli|subroutine|subroutines}}, {{gli|class|classes}}, {{gli|value|values}} or {{gli|data type|type}} specifications. In [[OS/360 and successors|IBM's OS/360 and its successors]] they are referred to as [[Partitioned dataset|partitioned data sets]].}}

{{term|[[computer programming|coding]]}}
{{defn|Computer programming is the process of designing and building an {{gli|executable}} {{gli|computer program}} for accomplishing a specific {{gli|computing}} task. Programming involves tasks such as analysis, generating {{gli|algorithm|algorithms}}, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen {{gli|programming language}} (commonly referred to as '''coding'''&lt;ref name="tumblr2014"&gt;{{cite web|url=http://yearofcodes.tumblr.com/what-is-coding|title=What is coding|author=Shaun Bebbington|year=2014|access-date=2014-03-03}}&lt;/ref&gt;&lt;ref name="tumblr1"&gt;{{cite web|url=http://yearofcodes.tumblr.com/what-is-programming|title=What is programming|author=Shaun Bebbington|year=2014|access-date=2014-03-03}}&lt;/ref&gt;). The {{gli|source code}} of a program is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate the performance of a task for solving a given problem. The process of programming thus often requires expertise in several different subjects, including knowledge of the {{gli|domain|application domain}}, specialized algorithms, and formal [[logic]].}}

{{term|[[coding theory]]}}
{{defn|The study of the properties of [[code]]s and their respective fitness for specific applications. Codes are used for {{gli|data compression}}, {{gli|cryptography}}, [[error detection and correction]], [[data transmission]] and [[data storage]]. Codes are studied by various scientific disciplines—such as [[information theory]], [[electrical engineering]], [[mathematics]], [[linguistics]], and {{gli|computer science}}—for the purpose of designing efficient and reliable data transmission methods. This typically involves the removal of redundancy and the correction or detection of errors in the transmitted data.}}

{{term|[[cognitive science]]}}
{{defn|The interdisciplinary, [[science|scientific]] study of the [[mind]] and its processes.&lt;ref&gt;Cognitive science is an interdisciplinary field of researchers from Linguistics, psychology, neuroscience, philosophy, computer science, and anthropology that seek to understand the mind. [http://www.aft.org/newspubs/periodicals/ae/summer2002/willingham.cfm How We Learn: Ask the Cognitive Scientist]&lt;/ref&gt; It examines the nature, the tasks, and the functions of [[cognition]] (in a broad sense). Cognitive scientists study intelligence and behavior, with a focus on how nervous systems represent, process, and transform [[information]]. Mental faculties of concern to cognitive scientists include language, perception, memory, attention, reasoning, and emotion; to understand these faculties, cognitive scientists borrow from fields such as linguistics, psychology, [[artificial intelligence]], [[philosophy of mind|philosophy]], [[neuroscience]], and anthropology.&lt;ref name="stanford1"&gt;[[Thagard, Paul]], [http://plato.stanford.edu/archives/fall2008/entries/cognitive-science/ Cognitive Science], ''[[The Stanford Encyclopedia of Philosophy]]'' (Fall 2008 Edition), [[Edward N. Zalta]] (ed.).&lt;/ref&gt;}}

{{term|[[collection (abstract data type)|collection]]}}
{{defn|A collection or container is a grouping of some variable number of data items (possibly zero) that have some shared significance to the problem being solved and need to be operated upon together in some controlled fashion.  Generally, the data items will be of the same type or, in languages supporting inheritance, derived from some common ancestor type. A collection is a concept applicable to [[abstract data type]]s, and does not prescribe a specific implementation as a concrete [[data structure]], though often there is a conventional choice (see [[Container (type theory)|Container]] for [[type theory]] discussion).}}

{{term|[[comma-separated values]] (CSV)}}
{{defn|A delimited [[text file]] that uses a comma to separate values. A CSV file stores [[Table (information)|tabular]] data (numbers and text) in [[plain text]].  Each line of the file is a data {{gli|record}}.  Each record consists of one or more {{gli|field|fields}}, separated by [[comma]]s. The use of the comma as a field separator is the source of the name for this [[file format]].}}

{{term|[[compiler]]}}
{{defn|A {{gli|computer program}} that transforms computer code written in one {{gli|programming language}} (the source language) into another programming language (the target language). Compilers are a type of [[Translator (computing)|translator]] that support digital devices, primarily computers. The name ''compiler'' is primarily used for programs that translate {{gli|source code}} from a [[high-level programming language]] to a [[lower-level language]] (e.g. [[assembly language]], [[object code]], or [[machine code]]) to create an {{gli|executable}} program.&lt;ref&gt;{{cite web| author = PC Mag Staff | date = 28 February 2017 | title = Encyclopedia: Definition of Compiler | work = PCMag.com | url=https://www.pcmag.com/encyclopedia/term/40105 | access-date=28 February 2017}}&lt;/ref&gt;}}

{{term|[[computability theory]]}}
{{defn|also known as '''recursion theory''', is a branch of [[mathematical logic]], of {{gli|computer science}}, and of the [[theory of computation]] that originated in the 1930s with the study of [[computable function]]s and [[Turing degree]]s. The field has since expanded to include the study of generalized computability and definability. In these areas, recursion theory overlaps with [[proof theory]] and [[effective descriptive set theory]].}}

{{term|[[computation]]}}
{{defn|Any type of calculation&lt;ref&gt;[http://www.merriam-webster.com/dictionary/computation Computation] from the Free Merriam-Webster Dictionary&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Computation: Definition and Synonyms from Answers.com|url=http://www.answers.com:80/topic/computation|website=Answers.com|access-date=26 April 2017|archive-url=https://web.archive.org/web/20090222005439/http://www.answers.com/topic/computation|archive-date=22 February 2009|url-status=dead}}&lt;/ref&gt; that includes both arithmetical and non-arithmetical steps and follows a well-defined [[Model (abstract)|model]], e.g. an {{gli|algorithm}}. The study of computation is paramount to the discipline of {{gli|computer science}}.}}

{{term|[[computational biology]]}}
{{defn|Involves the development and application of data-analytical and theoretical methods, [[mathematical modeling|mathematical modelling]] and computational simulation techniques to the study of biological, ecological, behavioural, and social systems.&lt;ref&gt;"NIH working definition of bioinformatics and computational biology" (PDF). Biomedical Information Science and Technology Initiative. 17 July 2000. Archived from the original (PDF) on 5 September 2012. Retrieved 18 August 2012.&lt;/ref&gt; The field is broadly defined and includes foundations in [[biology]], [[applied mathematics]], [[statistics]], [[biochemistry]], [[chemistry]], [[biophysics]], [[molecular biology]], [[genetics]], [[genomics]], [[computer science]], and [[evolution]].&lt;ref&gt;"About the CCMB". Center for Computational Molecular Biology. Retrieved 18 August 2012.&lt;/ref&gt;  Computational biology is different from [[biological computing]], which is a subfield of [[computer science]] and [[computer engineering]] using [[bioengineering]] and [[biology]] to build [[computer]]s.}}

{{term|[[computational chemistry]]}}
{{defn|A branch of [[chemistry]] that uses [[computer simulation]] to assist in solving chemical problems. It uses methods of [[theoretical chemistry]], incorporated into efficient {{gli|computer program|computer programs}}, to calculate the structures and properties of molecules and solids.}}

{{term|[[computational complexity theory]]}}
{{defn|A subfield of {{gli|computational science}} which focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an {{gli|algorithm}}.}}

{{term|[[computational model]]}}
{{defn|A [[mathematical model]] in {{gli|computational science}} that requires extensive [[computational resource]]s to study the behavior of a complex system by [[computer simulation]].&lt;ref&gt;{{cite book |editor-last=Melnik |editor-first=Roderick |title=Mathematical and Computational Modeling: With Applications in Natural and Social Sciences, Engineering, and the Arts |publisher=Wiley |year=2015 |isbn=978-1-118-85398-6 }}&lt;/ref&gt;}}

{{term|[[computational neuroscience]]}}
{{ghat|Also '''theoretical neuroscience''' or '''mathematical neuroscience'''.}}
{{defn|A branch of [[neuroscience]] which employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern the [[Developmental neuroscience|development]], [[Neuroanatomy|structure]], [[Neurophysiology|physiology]], and [[Cognitive neuroscience|cognitive abilities]] of the [[nervous system]].&lt;ref name="Trappenberg 2002"&gt;{{Cite book|title=Fundamentals of Computational Neuroscience|url=https://archive.org/details/fundamentalscomp00ttra|url-access=limited|last=Trappenberg|first=Thomas P.|publisher=Oxford University Press Inc.|year=2002|isbn=978-0-19-851582-1|location=United States|page=[https://archive.org/details/fundamentalscomp00ttra/page/n16 1]}}&lt;/ref&gt;&lt;ref&gt;What is computational neuroscience? Patricia S. Churchland, Christof Koch, Terrence J. Sejnowski. in Computational Neuroscience pp.46-55. Edited by Eric L. Schwartz. 1993. MIT Press {{cite web |url=http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=7195 |title=Archived copy |access-date=2009-06-11 |url-status=dead |archive-url=https://web.archive.org/web/20110604124206/http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=7195 |archive-date=2011-06-04 }}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://mitpress.mit.edu/books/theoretical-neuroscience|title=Theoretical Neuroscience|last=Press|first=The MIT|website=The MIT Press|language=en|access-date=2018-05-24|archive-url=https://web.archive.org/web/20180531150713/http://mitpress.mit.edu/books/theoretical-neuroscience|archive-date=2018-05-31|url-status=dead}}&lt;/ref&gt;&lt;ref&gt;{{ cite book | author1= Gerstner, W. | author2 = Kistler, W. | author3 = Naud, R. | author4 = Paninski, L.| title = Neuronal Dynamics | publisher = Cambridge University Press | location = Cambridge, UK | year = 2014 | isbn = 9781107447615}}&lt;/ref&gt;}}

{{term|[[computational physics]]}}
{{defn|Is the study and implementation of [[numerical analysis]] to solve problems in [[physics]] for which a [[Scientific theory|quantitative theory]] already exists.&lt;ref&gt;Thijssen, Jos (2007). Computational Physics. Cambridge University Press. {{ISBN|978-0521833462}}.&lt;/ref&gt; Historically, computational physics was the first application of modern computers in science, and is now a subset of [[computational science]].}}

{{term|[[computational science]]}}
{{ghat|Also '''scientific computing''' and '''scientific computation''' ('''SC''').}}
{{defn|An interdisciplinary field that uses advanced computing capabilities to understand and solve complex problems. It is an area of science which spans many disciplines, but at its core it involves the development of computer models and simulations to understand complex natural systems.}}

{{term|[[computational steering]]}}
{{defn|Is the practice of manually intervening with an otherwise autonomous [[computational process]], to change its outcome.}}

{{term|[[computer]]}}
{{defn|A device that can be instructed to carry out sequences of arithmetic or [[Boolean algebra|logical]] operations automatically via {{gli|computer programming}}. Modern computers have the ability to follow generalized sets of operations, called {{gli|computer program|programs}}. These programs enable computers to perform an extremely wide range of tasks.}}

{{term|[[computer architecture]]}}
{{defn|A set of rules and methods that describe the functionality, organization, and implementation of {{gli|computer}} systems. Some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation.&lt;ref&gt;{{cite book|last1=Clements|first1=Alan|title=Principles of Computer Hardware|page=1|edition=Fourth|quote=Architecture describes the internal organization of a computer in an abstract way; that is, it defines the capabilities of the computer and its programming model. You can have two computers that have been constructed in different ways with different technologies but with the same architecture.}}&lt;/ref&gt; In other definitions computer architecture involves [[instruction set architecture]] design, [[microarchitecture]] design, [[logic design]], and [[implementation]].&lt;ref&gt;{{cite book|last1=Hennessy|first1=John|last2=Patterson|first2=David|title=Computer Architecture: A Quantitative Approach|page=11|edition=Fifth|quote=This task has many aspects, including instruction set design, functional organization, logic design,and implementation.}}&lt;/ref&gt;}}

{{term|[[computer data storage]]}}
{{ghat|Also simply '''storage''' or '''memory'''.}}
{{defn|A technology consisting of {{gli|computer}} components and [[Data storage device|recording media]] that are used to retain digital [[data (computing)|data]]. Data storage is a core function and fundamental component of all modern computer systems.&lt;ref&gt;name="Patterson"&gt;{{Cite book |title=Computer Organization and Design: The Hardware/Software Interface |last1=Patterson |first1=David A. |last2=Hennessy |first2=John L. |date=2005 |publisher=[[Morgan Kaufmann Publishers]] |isbn=978-1-55860-604-3 |edition=3rd |location=[[Amsterdam]] |oclc=56213091 |url-access=registration |url=https://archive.org/details/isbn_9781558606043 }}&lt;/ref&gt;{{rp|15–16}}}}

{{term|[[computer ethics]]}}
{{defn|A part of [[practical philosophy]] concerned with how computing professionals should make decisions regarding professional and social conduct.&lt;ref name=BynumVeryShort&gt;{{cite web |url=http://www.southernct.edu/organizations/rccs/resources/research/introduction/bynum_shrt_hist.html#maner|title=A Very Short History of Computer Ethics |last= Bynum |first=Terrell Ward |publisher=Southern Connecticut Wein University|access-date=2011-01-05|archive-url=https://web.archive.org/web/20080418122849/http://www.southernct.edu/organizations/rccs/resources/research/introduction/bynum_shrt_hist.html|archive-date=2008-04-18}}&lt;/ref&gt;}}

{{term|[[computer graphics]]}}
{{defn|Pictures and films created using computers. Usually, the term refers to computer-generated image data created with the help of specialized graphical hardware and software. It is a vast and recently developed area of computer science.}}

{{term|[[computer network]]}}
{{ghat|Also '''data network'''.}}
{{defn|A [[digital signal|digital]] [[telecommunications network]] which allows [[Node (networking)|nodes]] to share resources. In computer networks, [[computing device]]s [[data transmission|exchange data]] with each other using connections ([[data link]]s) between nodes. These data links are established over [[Networking cables|cable media]] such as wires or optic cables, or [[Wireless network|wireless media]] such as {{gli|Wi-Fi}}.}}

{{term|[[computer program]]}}
{{defn|Is a collection of [[instruction set|instructions]]&lt;ref name="aup-ch4-p132"&gt;{{cite book
  | last = Rochkind
  | first = Marc J.
  | title = Advanced Unix Programming, Second Edition
  | publisher = Addison-Wesley
  | year = 2004
  | page = 1.1.2
}}&lt;/ref&gt; that can be [[execution (computing)|executed]] by a [[computer]] to perform a specific task. }}

{{term|[[computer programming]]}}
{{defn|The process of designing and building an {{gli|executable}} {{gli|computer program}} for accomplishing a specific {{gli|computing}} task. Programming involves tasks such as analysis, generating {{gli|algorithm|algorithms}}, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen {{gli|programming language}} (commonly referred to as '''coding'''&lt;ref name="tumblr2014"/&gt;&lt;ref name="tumblr1"/&gt;). The {{gli|source code}} of a program is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate the performance of a task for solving a given problem. The process of programming thus often requires expertise in several different subjects, including knowledge of the {{gli|domain|application domain}}, specialized algorithms, and formal [[logic]].}}

{{term|[[computer science]]}}
{{defn|The theory, experimentation, and engineering that form the basis for the design and use of {{gli|computer|computers}}. It involves the study of {{gli|algorithm|algorithms}} that process, store, and communicate [[digital data|digital information]]. A {{gli|computer scientist}} specializes in the theory of {{gli|computation}} and the design of computational systems.&lt;ref&gt;{{cite web |url=http://wordnetweb.princeton.edu/perl/webwn?s=computer%20scientist |title=WordNet Search—3.1 |publisher=Wordnetweb.princeton.edu |access-date=14 May 2012}}&lt;/ref&gt;}}

{{term|[[computer scientist]]}}
{{defn|A person who has acquired the knowledge of {{gli|computer science}}, the study of the theoretical foundations of information and computation and their application.&lt;ref&gt;{{cite book |last1=Orsucci |first1=Franco F. |last2=Sala |first2=Nicoletta |date=2008 |title=Reflexing Interfaces: The Complex Coevolution of Information Technology Ecosystems, Information Science Reference |url=https://archive.org/details/reflexinginterfa00orsu_453|url-access=limited |page=[https://archive.org/details/reflexinginterfa00orsu_453/page/n359 335] }}&lt;/ref&gt;}}

{{term|[[computer security]]}}
{{ghat|Also '''cybersecurity'''&lt;ref&gt;{{Cite journal|last1=Schatz|first1=Daniel|last2=Bashroush|first2=Rabih|last3=Wall|first3=Julie|date=2017|title=Towards a More Representative Definition of Cyber Security|url=https://commons.erau.edu/jdfsl/vol12/iss2/8/|journal=Journal of Digital Forensics, Security and Law|language=en|volume=12|issue=2|issn=1558-7215}}&lt;/ref&gt; or '''information technology security''' ('''IT security''').}}
{{defn|The protection of [[computer system]]s from theft or damage to their [[computer hardware|hardware]], {{gli|software}}, or [[Data (computing)|electronic data]], as well as from [[denial-of-service attack|disruption]] or [[botnet|misdirection]] of the services they provide.}}

{{term|[[computer vision]]}}
{{defn|An interdisciplinary scientific field that deals with how computers can be made to gain high-level understanding from [[digital image]]s or [[video]]s. From the perspective of engineering, it seeks to automate tasks that the [[human visual system]] can do.&lt;ref&gt;Dana H. Ballard; Christopher M. Brown (1982). Computer Vision. Prentice Hall. {{ISBN|0-13-165316-4}}.&lt;/ref&gt;&lt;ref&gt;Huang, T. (1996-11-19). Vandoni, Carlo, E, ed. Computer Vision : Evolution And Promise (PDF). 19th CERN School of Computing. Geneva: CERN. pp. 21–25. doi:10.5170/CERN-1996-008.21. {{ISBN|978-9290830955}}.&lt;/ref&gt;&lt;ref&gt;Milan Sonka; Vaclav Hlavac; Roger Boyle (2008). Image Processing, Analysis, and Machine Vision. Thomson. {{ISBN|0-495-08252-X}}.&lt;/ref&gt;}}

{{term|[[computing]]}}
{{defn|Is any goal-oriented activity requiring, benefiting from, or creating computing machinery. It includes study of [[algorithm]]ic processes and development of both [[computer hardware|hardware]] and [[software]]. It has scientific, engineering, mathematical, technological and social aspects. Major computing fields include [[computer engineering]], [[computer science]], [[cybersecurity]], [[data science]], [[information systems]], [[information technology]] and [[software engineering]].&lt;ref&gt;{{Cite web|title=Computing Curriculum 2020|url=https://cc2020.nsparc.msstate.edu/wp-content/uploads/2020/11/15September2020-CC2020-Report-v43.pdf}}&lt;/ref&gt;}}

{{term|[[concatenation]]}}
{{defn|In [[formal language|formal language theory]] and [[computer programming]], string concatenation  is the operation of joining [[character string (computer science)|character strings]] [[wikt:end-to-end|end-to-end]].  For example, the concatenation of "snow" and "ball" is "snowball". In certain formalisations of [[concatenation theory]], also called string theory, string concatenation is a [[primitive notion]].}}

{{term|[[concurrency (computer science)|Concurrency]]}}
{{defn|The ability of different parts or units of a program, algorithm, or problem to be executed out-of-order or in partial order, without affecting the final outcome.  This allows for parallel execution of the concurrent units, which can significantly improve overall speed of the execution in multi-processor and multi-core systems. In more technical terms, concurrency refers to the decomposability property of a program, algorithm, or problem into order-independent or partially-ordered components or units.&lt;ref&gt;{{cite journal|last1=Lamport|first1=Leslie|title=Time, Clocks, and the Ordering of Events in a Distributed System|journal=Communications of the ACM|volume=21|issue=7|pages=558–565|date=July 1978|url=http://research.microsoft.com/en-us/um/people/lamport/pubs/time-clocks.pdf|access-date=4 February 2016|doi=10.1145/359545.359563|citeseerx=10.1.1.142.3682|s2cid=215822405}}&lt;/ref&gt;}}

{{term|[[conditional (computer programming)|conditional]]}}
{{ghat|Also '''conditional statement''', '''conditional expression''', and '''conditional construct'''.}}
{{defn|A feature of a {{gli|programming language}} which performs different computations or actions depending on whether a programmer-specified [[Boolean data type|Boolean]] condition evaluates to true or false. Apart from the case of [[branch predication]], this is always achieved by selectively altering the {{gli|control flow}} based on some condition.}}

{{term|[[container (abstract data type)|container]]}}
{{defn|Is a [[Class (computer science)|class]], a [[data structure]],&lt;ref&gt;Paul E. Black (ed.), entry for ''data structure'' in ''[[Dictionary of Algorithms and Data Structures]]. US [[National Institute of Standards and Technology]].15 December 2004. Accessed 4 Oct 2011.&lt;/ref&gt;&lt;ref&gt;Entry ''data structure'' in the [[Encyclopædia Britannica]] (2009) [http://www.britannica.com/EBchecked/topic/152190/data-structure Online entry] Accessed 4 Oct 2011.&lt;/ref&gt; or an [[abstract data type]] (ADT) whose instances are collections of other objects. In other words, they store objects in an organized way that follows specific access rules. The size of the container depends on the number of objects (elements) it contains. Underlying (inherited) implementations of various container types may vary in size and complexity, and provide flexibility in choosing the right implementation for any given scenario.}}

{{term|[[continuation-passing style]] (CPS)}}{{anchor|continuation-passing style}}
{{defn|A style of {{gli|functional programming}} in which {{gli|control flow|control}} is passed explicitly in the form of a [[continuation]]. This is contrasted with [[direct style]], which is the usual style of programming. [[Gerald Jay Sussman]] and [[Guy L. Steele, Jr.]] coined the phrase in [[AI Memo]] 349 (1975), which sets out the first version of the [[Scheme (programming language)|Scheme]] programming language.&lt;ref&gt;{{cite journal|last1=Sussman|first1=Gerald Jay|last2=Steele|first2=Guy L., Jr.|author2-link=Guy L. Steele, Jr.|date=December 1975|title=Scheme: An interpreter for extended lambda calculus|journal=[[AI Memo]]|volume=349|page=19|quote=That is, in this '''continuation-passing programming style''', ''a function always "returns" its result by "sending" it to another function''. This is the key idea.|author1-link=Gerald Jay Sussman|title-link=wikisource:Scheme: An interpreter for extended lambda calculus}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Sussman|first1=Gerald Jay|last2=Steele|first2=Guy L., Jr.|author2-link=Guy L. Steele, Jr.|date=December 1998|title=Scheme: A Interpreter for Extended Lambda Calculus|url=http://www.brics.dk/~hosc/local/HOSC-11-4-pp405-439.pdf|format=reprint|journal=Higher-Order and Symbolic Computation|volume=11|issue=4|pages=405–439|doi=10.1023/A:1010035624696|s2cid=18040106|quote=We believe that this was the first occurrence of the term "'''continuation-passing style'''" in the literature. It has turned out to be an important concept in source code analysis and transformation for compilers and other metaprogramming tools. It has also inspired a set of other "styles" of program expression.|author1-link=Gerald Jay Sussman}}&lt;/ref&gt;}}

{{term|[[control flow]]}}
{{ghat|Also '''flow of control'''.}}
{{defn|The order in which individual [[Statement (computer science)|statements]], [[Instruction (computer science)|instructions]] or [[function call]]s of an [[imperative programming|imperative]] [[computer program|program]] are [[Execution (computing)|executed]] or evaluated. The emphasis on explicit control flow distinguishes an ''[[imperative programming]]'' language from a ''[[declarative programming]]'' language.}}

{{term|[[Creative Commons]] (CC)}}{{anchor|Creative Commons}}
{{defn|An American [[non-profit organization]] devoted to expanding the range of creative works available for others to build upon legally and to share.&lt;ref&gt;{{cite web |url=https://creativecommons.org/faq/|title=Frequently Asked Questions |publisher=Creative Commons |date=4 August 2016|access-date=20 December 2011}}&lt;/ref&gt; The organization has released several [[copyright]]-[[license]]s, known as [[Creative Commons license]]s, free of charge to the public.}}

{{term|[[cryptography]]}}
{{defn|Or cryptology,  is the practice and study of techniques for [[secure communication]] in the presence of third parties called [[adversary (cryptography)|adversaries]].&lt;ref name="rivest90"&gt;{{cite book|first=Ronald L.|last=Rivest|author-link=Ron Rivest|editor=J. Van Leeuwen|title=Handbook of Theoretical Computer Science|chapter=Cryptography|volume=1|publisher=Elsevier|year=1990}}&lt;/ref&gt; More generally, cryptography is about constructing and analyzing [[communications protocol|protocols]] that prevent third parties or the public from reading private messages;&lt;ref name="modern-crypto"&gt;{{Cite book|first1=Mihir|last1=Bellare|first2=Phillip|last2=Rogaway|title=Introduction to Modern Cryptography|chapter=Introduction|page=10|date=21 September 2005}}&lt;/ref&gt; various aspects in [[information security]] such as data [[confidentiality]], [[data integrity]], [[authentication]], and [[non-repudiation]]&lt;ref name="hac"&gt;{{cite book|url=https://archive.org/details/handbookofapplie0000mene|title=Handbook of Applied Cryptography|last1=Menezes|first1=A.J.|last2=van Oorschot|first2=P.C.|last3=Vanstone|first3=S.A.|year=1997|isbn=978-0-8493-8523-0}}&lt;/ref&gt; are central to modern cryptography. Modern cryptography exists at the intersection of the disciplines of [[mathematics]], [[computer science]], [[electrical engineering]], [[communication science]], and [[physics]]. Applications of cryptography include [[electronic commerce]], [[Credit card chip|chip-based payment cards]], [[digital currencies]], [[password|computer passwords]], and [[military communications]].}}

{{term|[[comma-separated values|CSV]]}}
{{defn|See ''{{gli|comma-separated values}}''.}}

{{term|[[cyberbullying]]}}
{{ghat|Also '''cyberharassment''' or '''online bullying'''.}}
{{defn|A form of [[bullying]] or [[harassment]] using electronic means.}}

{{term|[[cyberspace]]}}
{{defn|Widespread, interconnected digital [[technology]].}}
{{glossaryend}}

==D==
{{glossary}}
{{term|[[daemon (computing)|daemon]]}}
{{defn|In [[computer multitasking|multitasking]] computer [[operating system]]s, a daemon ({{IPAc-en|ˈ|d|iː|m|ən}} or {{IPAc-en|ˈ|d|eɪ|m|ən}})&lt;ref name="jargon"&gt;{{Cite web|url=http://catb.org/~esr/jargon/html/D/daemon.html |title=daemon |author=Eric S. Raymond |author-link=Eric S. Raymond |access-date=2008-10-22 |work=[[Jargon File|The Jargon File]] }}&lt;/ref&gt; is a [[computer program]] that runs as a [[background process]], rather than being under the direct control of an interactive user. Traditionally, the process names of a daemon end with the letter ''d'', for clarification that the process is in fact a daemon, and for differentiation between a daemon and a normal computer program. For example, {{mono|[[syslogd]]}} is a daemon that implements system logging facility, and {{mono|sshd}} is a daemon that serves incoming [[Secure Shell|SSH]] connections.}}

{{term|[[data center]]}}
{{ghat|Also '''data centre'''.}}
{{defn|A dedicated space used to house {{gli|computer|computer systems}} and associated components, such as telecommunications and [[computer data storage|data storage systems]]. It generally includes [[Redundancy (engineering)|redundant]] or backup components and infrastructure for [[power supply]], data communications connections, environmental controls (e.g. air conditioning and fire suppression) and various security devices.&lt;ref name=NYT92212&gt;{{cite news|title=Power, Pollution and the Internet|url=https://www.nytimes.com/2012/09/23/technology/data-centers-waste-vast-amounts-of-energy-belying-industry-image.html|access-date=2012-09-25|newspaper=The New York Times|date=September 22, 2012|author=James Glanz}}&lt;/ref&gt;&lt;ref name="ReferenceDC2"&gt;{{cite journal|url=https://www.academia.edu/6982393|title=Power Management Techniques for Data Centers: A Survey|first=Mittal|last=Sparsh}}&lt;/ref&gt;}}

{{term|[[database]]}}
{{defn|An organized collection of [[Data (computing)|data]], generally stored and accessed electronically from a computer system. Where databases are more complex, they are often developed using formal design and modeling techniques.}}

{{term|[[data mining]]}}
{{defn|Is a process of discovering patterns in large [[data set]]s involving methods at the intersection of [[machine learning]], [[statistics]], and [[database system]]s.&lt;ref name="acm" /&gt; Data mining is an [[interdisciplinary]] subfield of [[computer science]] and [[statistics]] with an overall goal to extract information (with intelligent methods) from a data set and transform the information into a comprehensible structure for further use.&lt;ref name="acm"&gt;{{cite web |url=http://www.kdd.org/curriculum/index.html |title=Data Mining Curriculum |publisher=[[Association for Computing Machinery|ACM]] [[SIGKDD]] |date=2006-04-30 |access-date=2014-01-27 }}&lt;/ref&gt;&lt;ref name="brittanica"&gt;{{cite web |last=Clifton |first=Christopher |title=Encyclopædia Britannica: Definition of Data Mining |year=2010 |url=http://www.britannica.com/EBchecked/topic/1056150/data-mining |access-date=2010-12-09 }}&lt;/ref&gt;&lt;ref name="elements"&gt;{{cite web|last1=Hastie|first1=Trevor|author-link1=Trevor Hastie|last2=Tibshirani|first2=Robert|author-link2=Robert Tibshirani|last3=Friedman|first3=Jerome|author-link3=Jerome H. Friedman|title=The Elements of Statistical Learning: Data Mining, Inference, and Prediction|year=2009|url=http://www-stat.stanford.edu/~tibs/ElemStatLearn/|access-date=2012-08-07|archive-url=https://web.archive.org/web/20091110212529/http://www-stat.stanford.edu/~tibs/ElemStatLearn/|archive-date=2009-11-10|url-status=dead}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Han, Kamber, Pei|first1=Jaiwei, Micheline, Jian|title=Data Mining: Concepts and Techniques|date=2011|publisher=Morgan Kaufmann|isbn=978-0-12-381479-1|edition=3rd}}&lt;/ref&gt; Data mining is the analysis step of the "knowledge discovery in databases" process, or KDD.&lt;ref&gt;Fayyad, Usama; Piatetsky-Shapiro, Gregory; Smyth, Padhraic (1996). "From Data Mining to Knowledge Discovery in Databases" (PDF). Retrieved 17 December 2008.&lt;/ref&gt; Aside from the raw analysis step, it also involves database and [[data management]] aspects, [[data pre-processing]], [[statistical model|model]] and [[Statistical inference|inference]] considerations, interestingness metrics, [[Computational complexity theory|complexity]] considerations, post-processing of discovered structures, [[Data visualization|visualization]], and [[Online algorithm|online updating]].&lt;ref name="acm" /&gt; }}

{{term|[[data science]]}}
{{defn|An interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from [[data]] in various forms, both structured and unstructured,&lt;ref&gt;{{Cite journal | last1 = Dhar | first1 = V. | title = Data science and prediction | doi = 10.1145/2500499 | journal = Communications of the ACM | volume = 56 | issue = 12 | pages = 64–73 | year = 2013 | s2cid = 6107147 | url = http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext}}&lt;/ref&gt;&lt;ref&gt;{{cite web | url=http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/ | title=The key word in "Data Science" is not Data, it is Science | publisher=Simply Statistics | date=2013-12-12 | author=Jeff Leek | author-link=Jeffrey T. Leek }}&lt;/ref&gt; similar to {{gli|data mining}}. Data science is a "concept to unify statistics, data analysis, machine learning and their related methods" in order to "understand and analyze actual phenomena" with data.&lt;ref name="Hayashi"&gt;{{Cite book|chapter-url=https://www.springer.com/book/9784431702085|title=Data Science, Classification, and Related Methods|last=Hayashi|first=Chikio|date=1998-01-01|publisher=Springer Japan|isbn=9784431702085|editor-last=Hayashi|editor-first=Chikio|series=Studies in Classification, Data Analysis, and Knowledge Organization|pages=40–51|language=en|chapter=What is Data Science? Fundamental Concepts and a Heuristic Example|doi=10.1007/978-4-431-65950-1_3|editor-last2=Yajima|editor-first2=Keiji|editor-last3=Bock|editor-first3=Hans-Hermann|editor-last4=Ohsumi|editor-first4=Noboru|editor-last5=Tanaka|editor-first5=Yutaka|editor-last6=Baba|editor-first6=Yasumasa}}&lt;/ref&gt; It employs techniques and theories drawn from many fields within the context of mathematics, statistics, [[information science]], and {{gli|computer science}}.}}

{{term|[[data structure]]}}
{{defn|A data organization, management, and storage format that enables [[Algorithmic efficiency|efficient]] access and modification.&lt;ref&gt;{{Cite book|url=https://dl.acm.org/citation.cfm?id=1614191|title=Introduction to Algorithms, Third Edition|last1=Cormen|first1=Thomas H.|last2=Leiserson|first2=Charles E.|last3=Rivest|first3=Ronald L.|last4=Stein|first4=Clifford|date=2009|publisher=The MIT Press|isbn=978-0262033848|edition=3rd}}&lt;/ref&gt;&lt;ref&gt;{{cite book |last1=Black |first1=Paul E. |editor1-last=Pieterse |editor1-first=Vreda |editor2-last=Black |editor2-first=Paul E. |title=Dictionary of Algorithms and Data Structures [online] |date=15 December 2004 |publisher=[[National Institute of Standards and Technology]] |chapter-url=https://xlinux.nist.gov/dads/HTML/datastructur.html |access-date=2018-11-06 |chapter=data structure}}&lt;/ref&gt;&lt;ref&gt;{{cite encyclopedia |encyclopedia=Encyclopaedia Britannica |title= Data structure |url=https://www.britannica.com/technology/data-structure |access-date=2018-11-06 |date=17 April 2017}}&lt;/ref&gt; More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data.&lt;ref&gt;{{Cite book|url=http://dl.acm.org/citation.cfm?id=1074100.1074312|title=Encyclopedia of Computer Science|last1=Wegner|first1=Peter|last2=Reilly|first2=Edwin D.|publisher=John Wiley and Sons |isbn=978-0470864128|location=Chichester, UK|pages=507–512|date=2003-08-29}}&lt;/ref&gt;}}

{{term|[[data type]]}}
{{ghat|Also simply '''type'''.}}
{{defn|An attribute of [[data]] which tells the {{gli|compiler}} or {{gli|interpreter}} how the programmer intends to use the data. Most {{gli|programming language|programming languages}} support common data types of [[Real number|real]], [[integer (computer science)|integer]], and [[Boolean data type|Boolean]]. A data type constrains the values that an {{gli|expression}}, such as a {{gli|variable}} or a {{gli|function}}, might take. This data type defines the operations that can be done on the data, the meaning of the data, and the way values of that type can be stored. A type of value from which an expression may take its value.&lt;ref&gt;{{FOLDOC|type|new=yes}}&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Shaffer |first=C. A. |title=Data Structures &amp; Algorithm Analysis in C++ |location=Mineola, NY |publisher=Dover |edition=3rd |year=2011 |at=1.2 |isbn=978-0-486-48582-9 }}&lt;/ref&gt;}}

{{term|[[debugging]]}}
{{defn|The process of finding and resolving defects or problems within a {{gli|computer program}} that prevent correct operation of {{gli|computer software}} or the system as a whole. Debugging tactics can involve interactive debugging, {{gli|control flow}} analysis, [[unit testing]], [[integration testing]], [[Logfile|log file analysis]], monitoring at the [[Application monitoring|application]] or [[system monitoring|system]] level, [[memory dump]]s, and [[Profiling (computer programming)|profiling]].}}

{{term|[[declaration (computer programming)|declaration]]}}
{{defn|In {{gli|computer programming}}, a [[language construct]] that specifies properties of an {{gli|identifier}}: it declares what a word (identifier) "means".&lt;ref name="c11"&gt;"A declaration specifies the interpretation and attributes of a set of identifiers. A ''definition'' of an identifier is a declaration for that identifier that:
* for an object [variable or constant], causes storage to be reserved for that object;
* for a function, includes the function body;
* for an enumeration constant, is the (only) declaration of the identifier;
* for a typedef name, is the first (or only) declaration of the identifier."
C11 specification, 6.7: Declarations, paragraph 5.&lt;/ref&gt; Declarations are most commonly used for [[subroutine|functions]], [[Variable (computer science)|variables]], [[Constant (computer programming)|constants]], and [[Class (computer programming)|classes]], but can also be used for other entities such as enumerations and type definitions.&lt;ref name="c11"/&gt; Beyond the name (the identifier itself) and the kind of entity (function, variable, etc.), declarations typically specify the {{gli|data type}} (for variables and constants), or the [[type signature]] (for functions); types may also include dimensions, such as for arrays. A declaration is used to announce the existence of the entity to the {{gli|compiler}}; this is important in those [[strongly typed]] languages that require functions, variables, and constants, and their types, to be specified with a declaration before use, and is used in [[forward declaration]].&lt;ref&gt;{{cite web
| access-date = 2011-06-08
| author = Mike Banahan
| location = http://publications.gbdirect.co.uk/c_book/
| publisher = GBdirect 
| title = 2.5. Declaration of variables
| quote = [A] declaration [...] introduces just the name and type of something but allocates no storage[...].
| url = http://publications.gbdirect.co.uk/c_book/chapter2/variable_declaration.html}}&lt;/ref&gt; The term "declaration" is frequently contrasted with the term "definition",&lt;ref name="c11"/&gt; but meaning and usage varies significantly between languages.}}

{{term|[[digital data]]}}
{{defn|In [[information theory]] and [[information systems]], the discrete, discontinuous [[Representation (mathematics)|representation]] of information or works. Numbers and letters are commonly used representations.}}

{{term|[[digital signal processing]] ('''DSP''')}}{{anchor|digital signal processing}}
{{defn|The use of [[digital processing]], such as by computers or more specialized [[digital signal processor]]s, to perform a wide variety of [[signal processing]] operations.  The signals processed in this manner are a sequence of numbers that represent [[Sampling (signal processing)|samples]] of a [[continuous variable]] in a domain such as time, space, or frequency.}}

{{term|[[discrete event simulation]] ('''DES''')}}{{anchor|discrete event simulation}}
{{defn|A model of the operation of a system as a [[discrete time|discrete]] sequence of events in time. Each event occurs at a particular instant in time and marks a change of {{gli|state}} in the system.&lt;ref&gt;{{cite book|title=Simulation – The practice of model development and use|author=Stewart Robinson|publisher=Wiley|year=2004}}&lt;/ref&gt; Between consecutive events, no change in the system is assumed to occur; thus the [[simulation]] can directly jump in time from one event to the next.}}

{{term|[[disk storage]]}}
{{defn|(Also sometimes called drive storage) is a general category of storage mechanisms where data is recorded by various electronic, magnetic, optical, or mechanical changes to a surface layer of one or more rotating disks. A disk drive is a device implementing such a storage mechanism. Notable types are the [[hard disk drive]] (HDD) containing a non-removable disk, the [[floppy disk| floppy disk drive]] (FDD) and its removable [[floppy disk]], and various [[optical disc drive]]s (ODD) and associated [[optical disc]] media.}}

{{term|[[distributed computing]]}}
{{defn|A field of {{gli|computer science}} that studies distributed systems. A ''distributed system'' is a system whose components are located on different [[computer network|networked computers]], which communicate and coordinate their actions by [[message passing|passing messages]] to one another.&lt;ref name="Coulouris"&gt;{{cite book|last=Coulouris|first=George|author2=Jean Dollimore|author-link2=Jean Dollimore|author3=Tim Kindberg|author4=Gordon Blair|title=Distributed Systems: Concepts and Design|publisher = Addison-Wesley|year=2011|location=Boston|isbn=978-0-132-14301-1|edition=5th}}&lt;/ref&gt; The components interact with one another in order to achieve a common goal. Three significant characteristics of distributed systems are: concurrency of components, [[clock synchronization|lack of a global clock]], and independent failure of components.&lt;ref name="Coulouris" /&gt; Examples of distributed systems vary from [[service-oriented architecture|SOA-based systems]] to [[massively multiplayer online game]]s to [[peer-to-peer|peer-to-peer applications]].}}

{{term|[[divide and conquer algorithm]]}}
{{defn|An [[algorithm design paradigm]] based on multi-branched {{gli|recursion}}. A divide-and-conquer {{gli|algorithm}} works by recursively breaking down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.}}

{{term|[[Domain Name System|DNS]]}}
{{defn|See ''{{gli|Domain Name System}}''.}}

{{term|[[software documentation|documentation]]}}
{{defn|Written text or illustration that accompanies {{gli|computer software}} or is embedded in the {{gli|source code}}. It either explains how it operates or how to use it, and may mean different things to people in different roles.}}

{{term|[[domain (software engineering)|domain]]}}
{{defn|Is the targeted subject area of a [[computer program]]. It is a term used in [[software engineering]]. Formally it represents the target subject of a specific programming project, whether narrowly or broadly defined.&lt;ref name="Bjørner"&gt;{{cite book | last = Bjørner | first = Dines | title = Software Engineering 3 – Domains, Requirements, and Software Design | url = https://www.springer.com/us/book/9783540211518 | access-date = 2016-12-19 | type = book | volume = I | year = 2006 | publisher = Springer Verlag | language = en | isbn = 978-3-540-33653-2 | page = 9 | chapter = The Tryptych of Software Engineering }}&lt;/ref&gt;}}

{{term|[[Domain Name System]] (DNS)}}{{anchor|Domain Name System}}
{{defn|A hierarchical and decentralized naming system for computers, services, or other resources connected to the {{gli|Internet}} or to a private network. It associates various information with [[domain name]]s assigned to each of the participating entities. Most prominently, it translates more readily memorized domain names to the numerical [[IP address]]es needed for locating and identifying computer services and devices with the underlying [[communication protocol|network protocol]]s. By providing a worldwide, [[Distributed computing|distributed]] [[directory service]], the Domain Name System has been an essential component of the functionality of the Internet since 1985.}}

{{term|[[double-precision floating-point format]]}}
{{defn|A [[computer number format]]. It represents a wide dynamic range of numerical values by using a floating {{gli|radix}} point.}}

{{term|[[download]]}}
{{defn|In [[computer network]]s, to receive data from a remote system, typically a [[Server (computing)|server]]&lt;ref name="main"&gt;{{cite web|url=http://searchnetworking.techtarget.com/definition/downloading|title=What is downloading? - Definition from WhatIs.com|work=SearchNetworkNexting|access-date=2019-03-04|archive-url=https://web.archive.org/web/20190905142601/https://searchnetworking.techtarget.com/definition/downloading|archive-date=2019-09-05|url-status=dead}}&lt;/ref&gt; such as a [[web server]], an [[File Transfer Protocol|FTP]] server, an [[email]] server, or other similar systems. This contrasts with {{gli|upload|uploading}}, where data is sent ''to'' a remote server. A ''download'' is a [[computer file|file]] offered for downloading or that has been downloaded, or the process of receiving such a file.}}
{{glossaryend}}

==E==
{{glossary}}
{{term|[[edge device]]}}
{{defn|A device which provides an entry point into enterprise or service provider core networks. Examples include [[router (computing)|router]]s, routing [[network switch|switch]]es, [[integrated access device]]s (IADs), multiplexers, and a variety of [[metropolitan area network]] (MAN) and [[wide area network]] (WAN) access devices.  Edge devices also provide connections into carrier and service provider networks. An edge device that connects a [[local area network]] to a high speed switch or backbone (such as an ATM switch) may be called an edge concentrator.}}

{{term|[[encryption]]}}
{{defn|In [[cryptography]], encryption is the process of [[Data compression|encoding]] information. This process converts the original representation of the information, known as [[plaintext]], into an alternative form known as [[ciphertext]]. Ideally, only authorized parties can decipher a ciphertext back to plaintext and access the original information. Encryption does not itself prevent interference but denies the intelligible content to a would-be interceptor. For technical reasons, an encryption scheme usually uses a [[pseudo-random]] encryption [[Key (cryptography)|key]] generated by an [[algorithm]]. It is possible to decrypt the message without possessing the key, but, for a well-designed encryption scheme, considerable computational resources and skills are required. An authorized recipient can easily decrypt the message with the key provided by the originator to recipients but not to unauthorized users. Historically, various forms of encryption have been used to aid in cryptography. Early encryption techniques were often utilized in military messaging. Since then, new techniques have emerged and become commonplace in all areas of modern computing.&lt;ref name=":1"&gt;{{Cite journal|last=Kessler|first=Gary|date=November 17, 2006|title=An Overview of Cryptography|url=https://www.garykessler.net/library/crypto.html|journal=Princeton University}}&lt;/ref&gt; Modern encryption schemes utilize the concepts of [[Public-key cryptography|public-key]] and [[Symmetric-key algorithm|symmetric-key]].&lt;ref name=":1" /&gt; Modern encryption techniques ensure security because modern computers are inefficient at cracking the encryption.}}

{{term|[[event (computing)|event]]}}
{{defn|An action or occurrence recognized by software, often originating [[asynchronous I/O|asynchronously]] from the external environment, that may be [[Event handler|handled]] by the software. Because an event is an entity which encapsulates the action and the contextual variables triggering the action, the acrostic mnemonic "'''E'''xecution '''V'''ariable '''E'''ncapsulating '''N'''amed '''T'''rigger" is often used to clarify the concept.}}

{{term|[[event-driven programming]]}}
{{defn|A {{gli|programming paradigm}} in which the {{gli|control flow|flow of the program}} is determined by {{gli|event|events}} such as user actions ([[computer mouse|mouse]] clicks, key presses), [[sensor]] outputs, or [[message passing|messages]] from other programs or {{gli|thread|threads}}. Event-driven programming is the dominant paradigm used in [[graphical user interface]]s and other applications (e.g. JavaScript [[web application]]s) that are centered on performing certain actions in response to {{gli|input/output|user input}}. This is also true of programming for [[device driver]]s (e.g. [[P (programming language)|P]] in USB device driver stacks&lt;ref&gt;{{cite web |url=https://www.microsoft.com/en-us/research/publication/p-safe-asynchronous-event-driven-programming/ |title=P: Safe Asynchronous Event-Driven Programming |author=Vivek Gupta |author2=Ethan Jackson |author3=Shaz Qadeer |author4=Sriram Rajamani |access-date=20 February 2017}}&lt;/ref&gt;).}}

{{term|[[evolutionary computing]]}}
{{defn|A family of {{gli|algorithm|algorithms}} for [[global optimization]] inspired by [[biological evolution]], and the subfield of {{gli|artificial intelligence}} and {{gli|soft computing}} studying these algorithms. In technical terms, they are a family of population-based trial-and-error problem-solvers with a [[metaheuristic]] or [[stochastic optimization]] character.}}

{{term|[[executable]]}}
{{ghat|Also '''executable code''', '''executable file''', '''executable program''', or simply '''executable'''.}}
{{defn|Causes a computer "to perform indicated tasks according to encoded [[instruction (computer science)|instructions]],"&lt;ref&gt;{{cite web |url=http://www.merriam-webster.com/dictionary/executable |title=executable |access-date=2008-07-19 |work=Merriam-Webster's Online Dictionary |publisher=[[Merriam-Webster]]}}&lt;/ref&gt; as opposed to a [[Data (computing)|data file]] that must be [[parser|parsed]] by a program to be meaningful. The exact interpretation depends upon the use - while "instructions" is traditionally taken to mean [[machine code]] instructions for a physical [[Central processing unit|CPU]], in some contexts a file containing [[bytecode]] or [[scripting language]] instructions may also be considered executable.}}

{{term|executable module}}
{{defn|}}

{{term|[[execution (computing)|execution]]}}
{{defn|In [[computer engineering|computer]] and software engineering is the process by which a [[computer]] or  [[virtual machine]] executes the instructions of a [[computer program]]. Each instruction of a program is a description of a particular 
action which to be carried out in order for a specific problem to be solved; as instructions of a program and therefore the actions they describe are being carried out by an executing machine, specific effects are produced in accordance to the [[Formal semantics of programming languages|semantics]] of the instructions being executed. }}

{{term|[[exception handling]]}}
{{defn|The process of responding to the occurrence, during {{gli|computation}}, of ''exceptions'' – anomalous or exceptional conditions requiring special processing – often disrupting the normal flow of {{gli|computer program|program}} {{gli|execution}}. It is provided by specialized {{gli|programming language}} constructs, [[computer hardware]] mechanisms like [[interrupt]]s, or [[operating system]] [[inter-process communication|IPC]] facilities like [[Signal (IPC)|signals]].}}

{{term|[[expression (computer science)|expression]]}}
{{defn|In a {{gli|programming language}}, a combination of one or more {{gli|constant|constants}}, {{gli|variable|variables}}, {{gli|operator|operators}}, and {{gli|function|functions}} that the programming language interprets (according to its particular [[Order of operations|rules of precedence]] and of association) and computes to produce ("to return", in a {{gli|state|stateful}} environment) another value. This process, as for [[mathematical expression]]s, is called evaluation.}}

{{term|external library}}
{{defn|}}
{{glossaryend}}

==F==
{{glossary}}
{{term|[[fault-tolerant computer system]]}}
{{defn|A system designed around the concept of [[fault tolerance]]. In essence, they must be able to continue working to a level of satisfaction in the presence of errors or breakdowns.}}

{{term|[[feasibility study]]}}
{{defn|An investigation which aims to objectively and rationally uncover the strengths and weaknesses of an existing business or proposed venture, opportunities and threats present in the [[natural environment]], the resources required to carry through, and ultimately the prospects for success.&lt;ref name="Justis"&gt;Justis, R. T. &amp; Kreigsmann, B. (1979). The feasibility study as a tool for venture analysis. ''Business Journal of Small Business Management'' 17 (1) 35-42.&lt;/ref&gt;&lt;ref&gt;Georgakellos, D. A. &amp; Marcis, A. M. (2009). Application of the semantic learning approach in the feasibility studies preparation training process. ''Information Systems Management'' 26 (3) 231–240.&lt;/ref&gt; In its simplest terms, the two criteria to judge feasibility are cost required and value to be attained.&lt;ref&gt;Young, G. I. M. (1970). Feasibility studies. ''Appraisal Journal'' 38 (3) 376-383.&lt;/ref&gt;}}

{{term|[[field (computer science)|field]]}}
{{defn|Data that has several parts, known as a ''[[record (computer science)|record]],'' can be divided into fields. [[Relational database]]s arrange data as sets of [[database record]]s, so called [[Row (database)|rows]]. Each record consists of several fields; the fields of all records form the [[Column (database)|columns]].
Examples of fields: name, gender, hair colour. }}

{{term|[[filename extension]]}}
{{defn|An identifier specified as a [[substring|suffix]] to the [[filename|name]] of a [[computer file]]. The extension indicates a characteristic of the file contents or its intended use.}}

{{term|[[filter (software)]]}}
{{defn|A {{gli|computer program}} or {{gli|subroutine}} to process a [[Stream (computing)|stream]], producing another stream. While a single filter can be used individually, they are frequently strung together to form a [[Pipeline (software)|pipeline]].}}

{{term|[[floating point arithmetic]]}}
{{defn|In [[computing]], floating-point arithmetic (FP) is arithmetic using formulaic representation of [[real number]]s as an approximation to support a [[trade-off]] between range and precision. For this reason, floating-point computation is often found in systems which include very small and very large real numbers, which require fast processing times. A number is, in general, represented approximately to a fixed number of [[Significant figures|significant digits]] (the [[significand]]) and scaled using an [[exponentiation|exponent]] in some fixed base; the base for the scaling is normally two, ten, or sixteen. A number that can be represented exactly is of the following form:
: &lt;math&gt;\text{significand} \times \text{base}^\text{exponent},&lt;/math&gt;
where significand is an [[integer]], base is an integer greater than or equal to two, and exponent is also an integer.
For example:
: &lt;math&gt;1.2345 = \underbrace{12345}_\text{significand} \times \underbrace{10}_\text{base}\!\!\!\!\!\!^{\overbrace{-4}^\text{exponent}}.&lt;/math&gt;}}

{{term|[[for loop]]}}
{{ghat|Also '''for-loop'''.}} 
{{defn|A {{gli|control flow}} {{gli|statement}} for specifying [[iteration]], which allows code to be [[execution (computers)|executed]] repeatedly. Various keywords are used to specify this statement: descendants of [[ALGOL]] use "for", while descendants of [[Fortran]] use "do". There are also other possibilities, e.g. [[COBOL]] uses "PERFORM VARYING".}}

{{term|[[formal methods]]}}
{{defn|A set of mathematically based techniques for the [[formal specification|specification]], development, and [[formal verification|verification]] of {{gli|software}} and [[computer hardware|hardware]] systems.&lt;ref name="butler"&gt;{{cite web|author=R. W. Butler|title=What is Formal Methods?|url=http://shemesh.larc.nasa.gov/fm/fm-what.html|date=2001-08-06|access-date=2006-11-16}}&lt;/ref&gt; The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design.&lt;ref&gt;{{cite journal|author=C. Michael Holloway|title=Why Engineers Should Consider Formal Methods|url=http://klabs.org/richcontent/verification/holloway/nasa-97-16dasc-cmh.pdf|publisher=16th Digital Avionics Systems Conference (27–30 October 1997)|access-date=2006-11-16|url-status=dead|archive-url=https://web.archive.org/web/20061116210448/http://klabs.org/richcontent/verification/holloway/nasa-97-16dasc-cmh.pdf|archive-date=16 November 2006}}&lt;/ref&gt;}}

{{term|[[formal verification]]}}
{{defn|The act of [[Mathematical proof|proving]] or disproving the {{gli|correctness}} of intended {{gli|algorithm|algorithms}} underlying a system with respect to a certain [[formal specification]] or property, using {{gli|formal methods}} of mathematics.&lt;ref&gt;{{cite journal|last=Sanghavi|first=Alok|title=What is formal verification?|journal=EE Times Asia|date=May 21, 2010}}&lt;/ref&gt;}}

{{term|[[functional programming]]}}
{{defn|A {{gli|programming paradigm}}—a style of building the structure and elements of {{gli|computer program|computer programs}}–that treats {{gli|computation}} as the evaluation of [[function (mathematics)|mathematical functions]] and avoids changing-[[program state|state]] and [[Immutable object|mutable]] data. It is a [[declarative programming]] paradigm in that programming is done with {{gli|expression|expressions}} or {{gli|declaration|declarations}}&lt;ref name="expression style"&gt;{{cite web|url=https://wiki.haskell.org/Declaration_vs._expression_style#Expression_style|title=Declaration vs. expression style - HaskellWiki}}&lt;/ref&gt; instead of {{gli|statement|statements}}.}}
{{glossaryend}}

==G==
{{glossary}}
{{term|[[game theory]]}}
{{defn|The study of [[mathematical model]]s of strategic interaction between rational decision-makers.&lt;ref name=Myerson&gt;[[Roger B. Myerson|Myerson, Roger B.]] (1991). ''Game Theory: Analysis of Conflict,'' Harvard University Press, p.&amp;nbsp;[https://books.google.com/books?id=E8WQFRCsNr0C&amp;printsec=find&amp;pg=PA1 1]. Chapter-preview links, pp. [https://books.google.com/books?id=E8WQFRCsNr0C&amp;printsec=find&amp;pg=PR7 vii–xi].&lt;/ref&gt; It has applications in all fields of [[social science]], as well as in [[logic]] and {{gli|computer science}}. Originally, it addressed [[zero-sum game]]s, in which each participant's gains or losses are exactly balanced by those of the other participants. Today, game theory applies to a wide range of behavioral relations, and is now an [[umbrella term]] for the [[science]] of logical decision making in humans, animals, and computers.}}

{{term|[[garbage in, garbage out]] (GIGO)}}
{{defn|A term used to describe the concept that flawed or nonsense [[input (computer science)|input]] data produces nonsense [[input/output|output]] or "garbage". It can also refer to the unforgiving nature of {{gli|coding|programming}}, in which a poorly written program might produce nonsensical behavior.}}

{{term|[[Graphics Interchange Format]]}}
{{defn|}}

{{term|[[gigabyte]]}}
{{defn|A multiple of the unit {{gli|byte}} for digital information. The [[SI prefix|prefix]] ''[[giga-|giga]]'' means 10&lt;sup&gt;9&lt;/sup&gt; in the [[International System of Units]] (SI). Therefore, one gigabyte is {{gaps|1|000|000|000|bytes}}.  The unit symbol for the gigabyte is GB.}}

{{term|[[global variable]]}}
{{defn|In {{gli|computer programming}}, a variable with global {{gli|scope}}, meaning that it is visible (hence accessible) throughout the program, unless [[Variable shadowing|shadowed]]. The set of all global variables is known as the ''global environment'' or ''global state''. In compiled languages, global variables are generally [[static variable]]s, whose [[Variable (programming)#Scope and extent|extent]] (lifetime) is the entire runtime of the program, though in interpreted languages (including [[command-line interpreter]]s), global variables are generally dynamically allocated when declared, since they are not known ahead of time.}}

{{term|[[graph theory]]}}
{{defn|In mathematics, the study of ''[[graph (discrete mathematics)|graph]]s'', which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of ''[[Vertex (graph theory)|vertices]]'' (also called ''nodes'' or ''points'') which are connected by ''[[Glossary of graph theory terms#edge|edges]]'' (also called ''links'' or ''lines''). A distinction is made between undirected graphs, where edges link two vertices symmetrically, and directed graphs, where edges link two vertices asymmetrically.}}
{{glossaryend}}

==H==
{{glossary}}
{{term|[[handle (computing)|handle]]}}
{{defn|In [[computer programming]], a handle is an abstract [[reference (computer science)|reference]] to a [[System resource|resource]] that is used when [[application software]] references blocks of [[memory (computing)|memory]] or objects that are managed by another system like a [[database]] or an [[operating system]].}}

{{term|[[computational complexity theory|hard problem]]}}
{{defn|Computational complexity theory focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.}}

{{term|[[hash function]]}}
{{defn|Any [[Function (mathematics)|function]] that can be used to map [[data (computing)|data]] of arbitrary size to data of a fixed size. The values returned by a hash function are called '''hash values''', '''hash codes''', '''digests''', or simply '''hashes'''. Hash functions are often used in combination with a [[hash table]], a common [[data structure]] used in computer software for rapid data lookup. Hash functions accelerate table or database lookup by detecting duplicated records in a large file.}}

{{term|[[hash table]]}}
{{defn|In {{gli|computing}}, a '''hash table''' ('''hash map''') is a [[data structure]] that implements an [[associative array]] [[abstract data type]], a structure that can map [[Unique key|keys]] to {{gli|value|values}}. A hash table uses a [[hash function]] to compute an ''index'' into an array of ''buckets'' or ''slots'', from which the desired value can be found.}}

{{term|[[heap (data structure)|heap]]}}
{{defn|A specialized [[Tree (data structure)|tree]]-based [[data structure]] which is essentially an almost complete&lt;ref&gt;{{Cite book|title=INTRODUCTION TO ALGORITHMS|url=https://archive.org/details/introductiontoal00corm_805|url-access=limited|last=CORMEN|first=THOMAS H.|publisher=The MIT Press Cambridge, Massachusetts London, England|year=2009|isbn=978-0-262-03384-8|location=United States of America|pages=[https://archive.org/details/introductiontoal00corm_805/page/n171 151]–152}}&lt;/ref&gt; tree that satisfies the ''heap property:'' if P is a parent [[Node (computer science)|node]] of C, then the ''key'' (the ''value'') of P is either greater than or equal to (in a ''max heap'') or less than or equal to (in a ''min heap'') the key of C.&lt;ref&gt;Black (ed.), Paul E. (2004-12-14). Entry for ''heap'' in ''[[Dictionary of Algorithms and Data Structures]]''. Online version. U.S. [[National Institute of Standards and Technology]], 14 December 2004. Retrieved on 2017-10-08 from https://xlinux.nist.gov/dads/HTML/heap.html.&lt;/ref&gt; The node at the "top" of the heap (with no parents) is called the ''root'' node.}}

{{term|[[heapsort]]}}
{{defn|A [[comparison sort|comparison-based]] [[sorting algorithm]]. Heapsort can be thought of as an improved [[selection sort]]: like that algorithm, it divides its input into a sorted and an unsorted region, and it iteratively shrinks the unsorted region by extracting the largest element and moving that to the sorted region. The improvement consists of the use of a [[heap (data structure)|heap]] data structure rather than a linear-time search to find the maximum.&lt;ref&gt;{{cite book |first=Steven |last=Skiena |author-link=Steven Skiena |title=The Algorithm Design Manual |url=https://archive.org/details/algorithmdesignm00skie_772 |url-access=limited |publisher=Springer |year=2008 |page=[https://archive.org/details/algorithmdesignm00skie_772/page/n120 109] |chapter=Searching and Sorting |isbn=978-1-84800-069-8 |quote=[H]eapsort is nothing but an implementation of selection sort using the right data structure.|doi=10.1007/978-1-84800-070-4_4}}&lt;!--DOI for chapter--&gt;&lt;/ref&gt;}}

{{term|[[human-computer interaction]] (HCI)}}
{{defn|Researches the design and use of computer technology, focused on the interfaces between people ([[user (computing)|users]]) and computers. Researchers in the field of HCI both observe the ways in which humans interact with computers and design technologies that let humans interact with computers in novel ways. As a field of research, human–computer interaction is situated at the intersection of {{gli|computer science}}, [[behavioral sciences]], [[design]], [[media studies]], and [[Outline of human–computer interaction#Related fields|several other fields of study]].}}
{{glossaryend}}

==I==
{{glossary}}
{{term|[[identifier (computer science)|identifier]]}}
{{defn|In [[computer language]]s, identifiers are [[Token (parser)|tokens]] (also called [[symbol]]s) which name language entities. Some of the kinds of entities an identifier might denote include [[variable (programming)|variables]], [[data type|types]], [[label (programming language)|labels]], [[subroutine]]s,  and [[modular programming|packages]].}}

{{term|[[integrated development environment|IDE]]}}
{{defn|Integrated development environment.}}

{{term|[[image processing]]}}
{{defn|}}

{{term|[[imperative programming]]}}
{{defn|A {{gli|programming paradigm}} that uses {{gli|statement|statements}} that change a program's {{gli|state}}. In much the same way that the [[imperative mood]] in [[natural language]]s expresses commands, an imperative program consists of {{gli|command|commands}} for the computer to perform. Imperative programming focuses on describing ''how'' a program operates.}}

{{term|[[incremental build model]]}}
{{defn|A method of [[software development]] where the product is [[software design|designed]], implemented and [[software testing|tested]] incrementally (a little more is added each time) until the product is finished. It involves both development and maintenance. The product is defined as finished when it satisfies all of its requirements. This model combines the elements of the {{gli|waterfall model}} with the iterative philosophy of [[software prototyping|prototyping]].}}

{{term|[[information space analysis]]}}
{{defn|A deterministic method, enhanced by {{gli|artificial intelligence|machine intelligence}}, for locating and assessing {{gli|resource|resources}} for team-centric efforts.}}

{{term|[[information visualization]]}}
{{defn|}}

{{term|[[inheritance (computer science)|inheritance]]}}
{{defn|In {{gli|object-oriented programming}}, the mechanism of basing an {{gli|object}} or {{gli|class}} upon another object ([[Prototype-based programming|prototype-based inheritance]]) or class ([[Class-based programming|class-based inheritance]]), retaining similar implementation. Also defined as deriving new classes ([[#Subclasses and superclasses|sub classes]]) from existing ones (super class or [[Fragile base class|base class]]) and forming them into a hierarchy of classes.}}

{{term|[[input/output]] (I/O)}}
{{ghat|Also informally '''io''' or '''IO'''.}} 
{{defn|The communication between an [[information processing system]], such as a {{gli|computer}}, and the outside world, possibly a human or another [[Information processor|information processing system]]. [[Information|Inputs]] are the signals or data received by the system and outputs are the signals or [[Data (computing)|data]] sent from it. The term can also be used as part of an action; to "perform I/O" is to perform an [[I/O scheduling|input or output operation]].}}

{{term|[[insertion sort]]}}
{{defn|A simple [[sorting algorithm]] that builds the final [[sorted array]] (or list) one item at a time.}}

{{term|[[instruction cycle]]}}
{{ghat|Also '''fetch–decode–execute cycle''' or simply '''fetch-execute cycle'''.}}
{{defn|The cycle which the {{gli|central processing unit}} (CPU) follows from {{gli|booting|boot-up}} until the computer has shut down in order to process instructions. It is composed of three main stages: the fetch stage, the decode stage, and the execute stage.}}

{{term|[[integer (computer science)|integer]]}}
{{defn|A datum of integral data type, a [[data type]] that represents some [[interval (mathematics)|range]] of mathematical [[integer]]s. Integral data types may be of different sizes and may or may not be allowed to contain negative values. Integers are commonly represented in a computer as a group of binary digits (bits). The size of the grouping varies so the set of integer sizes available varies between different types of computers. Computer hardware, including [[virtual machine]]s, nearly always provide a way to represent a processor [[word size|register]] or memory address as an integer.}}

{{term|[[integrated development environment]] (IDE)}}{{anchor|integrated development environment}}
{{defn|A [[Application software|software application]] that provides comprehensive facilities to computer programmers for [[software development]]. An IDE normally consists of at least a [[source code editor]], [[build automation]] tools, and a [[debugger]].}}

{{term|[[integration testing]]}}
{{defn|(sometimes called integration and testing, abbreviated I&amp;T) is the phase in [[software testing]] in which individual software modules are combined and tested as a group. Integration testing is conducted to evaluate the [[regulatory compliance|compliance]] of a system or component with specified [[functional requirement]]s.&lt;ref&gt;{{Cite book|title=ISO/IEC/IEEE International Standard - Systems and software engineering|publisher=ISO/IEC/IEEE 24765:2010(E)|year=2010|pages=vol., no., pp.1–418, 15 Dec. 2010}}&lt;/ref&gt; It occurs after [[unit testing]] and before [[Software verification and validation|validation testing]]. Integration testing takes as its input [[module (programming)|modules]] that have been unit tested, groups them in larger aggregates, applies tests defined in an integration [[test plan]] to those aggregates, and delivers as its output the integrated system ready for [[system testing]].&lt;ref&gt;[https://books.google.com/books?id=utFCImZOTEIC&amp;pg=PA73&amp;dq=integration+test&amp;hl=en&amp;sa=X&amp;ei=4EpTVOvJMayu7Aak5YCIDA&amp;ved=0CDwQ6AEwAg#v=onepage&amp;q=integration%20test&amp;f=false Martyn A Ould &amp; Charles Unwin (ed), ''Testing in Software Development'', BCS (1986), p71]. Accessed 31 Oct 2014&lt;/ref&gt;}}

{{term|[[intellectual property]] (IP)}}{{anchor|intellectual property}}
{{defn|A category of legal property that includes intangible creations of the human intellect.&lt;ref&gt;{{Cite web|url=https://www.wipo.int/publications/en/details.jsp?id=4080|title=Understanding Industrial Property|publisher=World Intellectual Property Organization|access-date=2018-12-06}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.europarl.europa.eu/factsheets/en/sheet/36/intellectual-industrial-and-commercial-property|title=Intellectual, industrial and commercial property {{!}} Fact Sheets on the European Union|publisher=European Parliament|access-date=2018-12-06}}&lt;/ref&gt; There are many types of intellectual property, and some countries recognize more than others.&lt;ref&gt;{{Cite web |url=https://www.wto.org/english/tratop_e/trips_e/intel1_e.htm |title=What are intellectual property rights? |website=World Trade Organization |publisher=World Trade Organization |access-date=2016-05-23}}&lt;/ref&gt;&lt;ref&gt;"Intellectual property", ''Black's Law Dictionary'', 10th ed. (2014).&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.wipo.int/edocs/pubdocs/en/wipo_pub_909_2016.pdf|title=Understanding Copyright and Related Rights|publisher=World Intellectual Property Organization|page=4|access-date=2018-12-06}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.wipo.int/edocs/pubdocs/en/intproperty/450/wipo_pub_450.pdf|title=What is Intellectual Property?|publisher=World Intellectual Property Organization (WIPO)|access-date=2018-12-07}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.wipo.int/edocs/pubdocs/en/wipo_pub_895_2016.pdf|title=Understanding Industrial Property|publisher=World Intellectual Property Organization (WIPO)|access-date=2018-12-07}}&lt;/ref&gt; The most well-known types are [[copyright]]s, [[patent]]s, [[trademark]]s, and [[trade secret]]s.}}

{{term|[[intelligent agent]]}}
{{defn|In [[artificial intelligence]], an '''intelligent agent''' ('''IA''') refers to an [[autonomous]] entity which acts, directing its activity towards achieving goals (i.e. it is an [[Software agent|agent]]), upon an [[Environment (biophysical)|environment]] using observation through sensors and consequent actuators (i.e. it is intelligent).&lt;ref&gt;{{Cite journal|last=Anderson|first=Michael|last2=Anderson|first2=Susan Leigh|date=2007-12-15|title=Machine Ethics: Creating an Ethical Intelligent Agent|url=https://ojs.aaai.org/index.php/aimagazine/article/view/2065|journal=AI Magazine|language=en|volume=28|issue=4|pages=15–15|doi=10.1609/aimag.v28i4.2065|issn=2371-9621}}&lt;/ref&gt; Intelligent agents may also [[machine learning|learn]] or use [[knowledge representation|knowledge]] to achieve their goals. They may be very simple or [[Complexity|very complex]]. A reflex machine, such as a [[thermostat]], is considered an example of an intelligent agent.&lt;ref&gt;According to the definition given by {{harvtxt|Russell|Norvig|2003|loc=chpt. 2}}&lt;/ref&gt;}}

{{term|[[interface (computing)|interface]]}}
{{defn|A shared boundary across which two or more separate components of a [[computer system]] exchange information. The exchange can be between {{gli|software}}, [[computer hardware]], [[peripheral]] devices, [[User interface|humans]], and combinations of these.&lt;ref name="HookwayInterface14"&gt;{{cite book |url=https://books.google.com/books?id=BQM_AwAAQBAJ |chapter=Chapter 1: The Subject of the Interface |title=Interface |author=Hookway, B. |publisher=MIT Press |pages=1–58 |year=2014 |isbn=9780262525503}}&lt;/ref&gt; Some computer hardware devices, such as a [[touchscreen]], can both send and receive data through the interface, while others such as a mouse or microphone may only provide an interface to send data to a given system.&lt;ref&gt;{{cite encyclopedia
 | year =2000
 | title =IEEE 100 - The Authoritative Dictionary Of IEEE Standards Terms 
 | publisher =IEEE Press
 | location =NYC, NY, USA
 | isbn =9780738126012
 | pages =574–575
}}&lt;/ref&gt;}}

{{term|[[internal documentation]]}}
{{defn|Computer {{gli|software}} is said to have Internal Documentation if the notes on how and why various parts of code operate is included within the {{gli|source code}} as comments.  It is often combined with meaningful [[variable (programming)|variable]] names with the intention of providing potential future programmers a means of understanding the workings of the code. This contrasts with external [[documentation]], where programmers keep their notes and explanations in a separate document.}}

{{term|[[internet]]}}
{{defn|The global system of interconnected [[computer network]]s that use the [[Internet protocol suite]] (TCP/IP) to link devices worldwide. It is a ''network of networks'' that consists of private, public, academic, business, and government networks of local to global scope, linked by a broad array of electronic, wireless, and optical networking technologies.}}

{{term|[[internet bot]]}}
{{ghat|Also '''web robot''', '''robot''', or simply '''bot'''.}}
{{defn|A {{gli|software application}} that runs automated tasks (scripts) over the [[Internet]].&lt;ref&gt;{{cite book |url=https://archive.org/details/malicio_dun_2009_00_4004 |url-access=registration |title=Malicious Bots: An Inside Look into the Cyber-Criminal Underground of the Internet |last1=Dunham |first1=Ken |last2=Melnick |first2=Jim |publisher=CRC Press |year=2008 |isbn=9781420069068 }}&lt;/ref&gt; Typically, bots perform tasks that are both simple and structurally repetitive, at a much higher rate than would be possible for a human alone. The largest use of bots is in [[web crawler|web spidering]] (''web crawler''), in which an automated script fetches, analyzes and files information from web servers at many times the speed of a [[human]].}}

{{term|[[interpreter (computing)|interpreter]]}}
{{defn|A {{gli|computer program}} that directly {{gli|execution|executes}} instructions written in a {{gli|programming language|programming}} or [[scripting language]], without requiring them to have been previously {{gli|compiler|compiled}} into a [[machine language]] program.}}

{{term|[[invariant (computer science)|invariant]]}}
{{defn|One can encounter invariants that can be relied upon to be true during the execution of a program, or during some portion of it. It is a [[logical assertion]] that is always held to be true during a certain phase of execution. For example, a [[loop invariant]] is a condition that is true at the beginning and the end of every execution of a loop.}}

{{term|[[iteration]]}}
{{defn|Is the repetition of a process in order to generate an outcome. The sequence will approach some end point or end value. Each repetition of the process is a single iteration, and the outcome of each iteration is then the starting point of the next iteration.  In [[mathematics]] and [[computer science]], iteration (along with the related technique of [[recursion]]) is a standard element of [[algorithm]]s.}}
{{glossaryend}}

==J==
{{glossary}}
{{term|[[java (programming language)|Java]]}}
{{defn|A [[General-purpose language|general-purpose]] {{gli|programming language}} that is [[class-based programming|class-based]], {{gli|object-oriented programming|object-oriented}}{{sfn|DECODER|p=1}}(although not a ''pure'' OO language&lt;ref&gt;{{cite web|url=https://stackoverflow.com/questions/12836522/java-is-pure-object-oriented-or-not|title=Java is pure object oriented or not?|website=Stack Overflow|access-date=2019-05-24}}&lt;/ref&gt;), and designed to have as few implementation {{gli|dependency|dependencies}} as possible. It is intended to let [[application developer]]s "[[write once, run anywhere]]" (WORA),&lt;ref&gt;{{cite web|url=http://www.computerweekly.com/Articles/2002/05/02/186793/write-once-run-anywhere.htm|title=Write once, run anywhere?|date=May 2, 2002|publisher=[[Computer Weekly]]|access-date=2009-07-27}}&lt;/ref&gt; meaning that {{gli|compiler|compiled}} Java code can run on all platforms that support Java without the need for recompilation.&lt;ref name="design_goals"&gt;{{cite web|url=https://www.oracle.com/technetwork/java/intro-141325.html|title=1.2 Design Goals of the Java™ Programming Language|publisher=Oracle|date=January 1, 1999|access-date=2013-01-14|archive-url=https://web.archive.org/web/20130123204103/http://www.oracle.com/technetwork/java/intro-141325.html|archive-date=January 23, 2013|url-status=live|df=mdy-all}}&lt;/ref&gt;}}
{{glossaryend}}

==K==
{{glossary}}
{{term|[[kernel (operating system)|kernel]]}}
{{defn|The first section of an {{gli|operating system}} to load into {{gli|data storage|memory}}. As the center of the operating system, the kernel needs to be small, efficient, and loaded into a protected area in the memory so that it cannot be overwritten. It may be responsible for such essential tasks as disk drive management, file management, memory management, process management, etc.}}
{{glossaryend}}

==L==
{{glossary}}
{{term|[[library (computing)]]}}
{{defn|A collection of [[non-volatile memory|non-volatile]] resources used by {{gli|computer program|computer programs}}, often for [[software development]]. These may include configuration data, documentation, help data, message templates, [[Code reuse|pre-written code]] and {{gli|subroutine|subroutines}}, {{gli|class|classes}}, {{gli|value|values}}, or {{gli|data type|type}} specifications.}}

{{term|[[linear search]]}}
{{ghat|Also '''sequential search'''.}}
{{defn|A method for finding an element within a {{gli|list}}. It sequentially checks each element of the list until a match is found or the whole list has been searched.{{Sfn|Knuth|1998|loc=§6.1 ("Sequential search")}}}}

{{term|[[linked list]]}}
{{defn|A linear collection of data elements, whose order is not given by their physical placement in memory. Instead, each element [[pointer (computer programming)|points]] to the next. It is a [[data structure]] consisting of a collection of [[node (computer science)|node]]s which together represent a [[sequence]].}}

{{term|[[linker (computing)|linker]]}}
{{defn| or link editor, is a computer [[System utility|utility]] program that takes one or more [[object file]]s generated by a {{gli|compiler}} or an [[assembler (computing)|assembler]] and combines them into a single [[executable]] file, [[Library (computing)|library]] file, or another 'object' file.  A simpler version that writes its output directly to memory is called the ''loader'', though [[loader (computing)|loading]] is typically considered a separate process.&lt;ref&gt;{{cite book |last=IBM Corporation |title=IBM OS Linkage Editor and Loader |year=1972 |url= http://bitsavers.informatik.uni-stuttgart.de/pdf/ibm/360/os/R21.0_Mar72/GC28-6538-9_OS_Linkage_Editor_and_Loader_Release_21_Jan72.pdf}}&lt;/ref&gt;}}

{{term|[[list (abstract data type)|list]]}}
{{defn|An [[abstract data type]] that represents a countable number of ordered {{gli|value|values}}, where the same value may occur more than once. An instance of a list is a computer representation of the mathematical concept of a finite [[sequence (mathematics)|sequence]]; the (potentially) infinite analog of a list is a {{gli|stream}}.&lt;ref&gt;{{cite book |title=Structure and Interpretation of Computer Programs |first1=Harold |last1=Abelson |first2=Gerald Jay |last2=Sussman |year=1996 |publisher=MIT Press|title-link=Structure and Interpretation of Computer Programs }}&lt;/ref&gt;{{rp|§3.5}} Lists are a basic example of {{gli|container|containers}}, as they contain other values. If the same value occurs multiple times, each occurrence is considered a distinct item.}}

{{term|[[loader (computing)|loader]]}}
{{defn|The part of an [[operating system]] that is responsible for loading [[computer program|programs]] and [[Library (computing)|libraries]]. It is one of the essential stages in the process of starting a program, as it places programs into memory and prepares them for execution. Loading a program involves reading the contents of the [[executable|executable file]] containing the program instructions into memory, and then carrying out other required preparatory tasks to prepare the executable for running. Once loading is complete, the operating system starts the program by passing control to the loaded program code.}}

{{term|[[logic error]]}}
{{defn|In {{gli|computer programming}}, a [[Software bug|bug]] in a program that causes it to operate incorrectly, but not to terminate abnormally (or [[crash (computing)|crash]]). A logic error produces unintended or undesired output or other behaviour, although it may not immediately be recognized as such.}}

{{term|[[logic programming]]}}
{{defn|A type of {{gli|programming paradigm}} which is largely based on [[formal logic]]. Any program written in a logic {{gli|programming language}} is a set of sentences in logical form, expressing facts and rules about some problem domain.  Major logic programming language families include [[Prolog]], [[answer set programming]] (ASP), and [[Datalog]].}}
{{glossaryend}}

==M==
{{glossary}}
{{term|[[machine learning]] (ML)}}{{anchor|machine learning}}
{{defn|The scientific study of {{gli|algorithm|algorithms}} and [[statistical model]]s that [[computer systems]] use to perform a specific task without using explicit instructions, relying on patterns and [[inference]] instead. It is seen as a subset of [[artificial intelligence]]. Machine learning algorithms build a [[mathematical model]] based on sample data, known as "[[training data]]", in order to make predictions or decisions without being explicitly programmed to perform the task.{{refn|The definition "without being explicitly programmed" is often attributed to [[Arthur Samuel]], who coined the term "machine learning" in 1959, but the phrase is not found verbatim in this publication, and may be a [[paraphrase]] that appeared later. Confer "Paraphrasing Arthur Samuel (1959), the question is: How can computers learn to solve problems without being explicitly programmed?" in {{Cite conference|title=Automated Design of Both the Topology and Sizing of Analog Electrical Circuits Using Genetic Programming|conference=Artificial Intelligence in Design '96|last1=Koza|first1=John R.|last2=Bennett|first2=Forrest H.|last3=Andre|first3=David|last4=Keane|first4=Martin A.|date=1996|publisher=Springer, Dordrecht|pages=151–170|language=en|doi=10.1007/978-94-009-0279-4_9}}}}&lt;ref&gt;&lt; Bishop, C. M. (2006), Pattern Recognition and Machine Learning, Springer, {{ISBN|978-0-387-31073-2}}&lt;/ref&gt;}}

{{term|[[machine vision]] (MV)}}{{anchor|machine vision}}
{{defn|The technology and methods used to provide imaging-based automatic inspection and analysis for such applications as automatic inspection, [[process control]], and robot guidance, usually in industry. Machine vision refers to many technologies, software and hardware products, integrated systems, actions, methods and expertise. Machine vision as a [[systems engineering]] discipline can be considered distinct from [[computer vision]], a form of {{gli|computer science}}. It attempts to integrate existing technologies in new ways and apply them to solve real world problems. The term is the prevalent one for these functions in industrial automation environments but is also used for these functions in other environments such as security and vehicle guidance.}}

{{term|[[mathematical logic]]}}
{{defn|A subfield of [[mathematics]] exploring the applications of formal [[logic]] to mathematics.  It bears close connections to [[metamathematics]], the [[foundations of mathematics]], and [[theoretical computer science]].&lt;ref&gt;Undergraduate texts include Boolos, Burgess, and Jeffrey [[#CITEREFBoolosBurgessJeffrey2002|(2002)]], [[Herbert Enderton|Enderton]] [[#CITEREFEnderton2001|(2001)]], and Mendelson [[#CITEREFMendelson1997|(1997)]]. A classic graduate text by Shoenfield [[#CITEREFShoenfield2001|(2001)]] first appeared in 1967.&lt;/ref&gt; The unifying themes in mathematical logic include the study of the expressive power of [[formal system]]s and the [[Deductive reasoning|deductive]] power of formal [[Mathematical proof|proof]] systems.}}

{{term|[[matrix (mathematics)|matrix]]}}
{{defn|In [[mathematics]], a matrix, (plural matrices), is a [[rectangle|rectangular]] ''[[wikt:array|array]]''&lt;ref&gt;Equivalently, ''[[wikt:table|table]]''.&lt;/ref&gt; (see [[irregular matrix]]) of [[number]]s, [[symbol (formal)|symbol]]s, or [[expression (mathematics)|expression]]s, arranged in ''[[wikt:row|row]]s'' and ''[[wikt:column|column]]s''.&lt;ref&gt;{{harvtxt|Anton|1987|p=23}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|p=56}}&lt;/ref&gt;}}

{{term|[[computer data storage|memory]]}}
{{defn|Computer data storage, often called storage, is a technology consisting of [[computer]] components and [[Data storage device|recording media]] that are used to retain digital [[data (computing)|data]]. It is a core function and fundamental component of computers.&lt;ref name="Patterson"&gt;{{Cite book |title=Computer Organization and Design: The Hardware/Software Interface |last1=Patterson |first1=David A. |last2=Hennessy |first2=John L. |date=2005 |publisher=[[Morgan Kaufmann Publishers]] |isbn=1-55860-604-1 |edition=3rd |location=[[Amsterdam]] |oclc=56213091 |url-access=registration |url=https://archive.org/details/isbn_9781558606043 }}&lt;/ref&gt;{{rp|15–16}}}}

{{term|[[merge sort]]}}
{{ghat|Also '''mergesort'''.}}

{{defn|An efficient, general-purpose, [[comparison sort|comparison-based]] [[sorting algorithm]]. Most implementations produce a [[Sorting algorithm#Stability|stable sort]], which means that the order of equal elements is the same in the input and output. Merge sort is a [[divide and conquer algorithm]] that was invented by [[John von Neumann]] in 1945.&lt;ref&gt;{{Harvtxt|Knuth|1998|p=158}}&lt;/ref&gt; A detailed description and analysis of bottom-up mergesort appeared in a report by [[Herman Goldstine|Goldstine]] and [[John von Neumann|von Neumann]] as early as 1948.&lt;ref&gt;{{cite conference |title=A meticulous analysis of mergesort programs |date=March 1997 |first1=Jyrki |last1=Katajainen |first2=Jesper Larsson |last2=Träff |conference=Italian Conference on Algorithms and Complexity |location=Rome |book-title=Proceedings of the 3rd Italian Conference on Algorithms and Complexity |pages=217–228 |doi=10.1007/3-540-62592-5_74 |citeseerx=10.1.1.86.3154  |url=http://hjemmesider.diku.dk/~jyrki/Paper/CIAC97.pdf }}&lt;/ref&gt;}}

{{term|[[method (computer programming)|method]]}}
{{defn|In {{gli|object-oriented programming}} (OOP), a {{gli|procedure}} associated with a [[Message passing|message]] and an {{gli|object}}. An object consists of data and behavior. The data and behavior comprise an interface, which specifies how the object may be utilized by any of various consumers&lt;ref name="consumerdef001a"&gt;Consumers of an object may consist of various kinds of elements, such as other programs, remote computer systems, or computer programmers who wish to utilize the object as part of their own programs.&lt;/ref&gt; of the object.}}

{{term|[[software development process|methodology]]}}
{{defn|In [[software engineering]], a software development process is the process of dividing [[software development]] work into distinct phases to improve [[Software design|design]], [[Software product management|product management]], and [[Software project management|project management]]. It is also known as a software development life cycle (SDLC). The methodology may include the pre-definition of specific [[deliverable]]s and artifacts that are created and completed by a project team to develop or maintain an application.&lt;ref name="Medicare 2008"&gt;Centers for Medicare &amp; Medicaid Services (CMS) Office of Information Service (2008). Selecting a development approach. Webarticle. United States Department of Health and Human Services (HHS). Re-validated: March 27, 2008. Retrieved 27 Oct 2008.&lt;/ref&gt;}}

{{term|[[modem]]}}
{{ghat|Portmanteau of '''modulator-demodulator'''.}}
{{defn|A [[Computer hardware|hardware]] device that converts data into a format suitable for a [[transmission medium]] so that it can be transmitted from one computer to another (historically along telephone wires). A modem [[Modulation#Digital modulation methods|modulates]] one or more [[carrier wave]] signals to encode [[digital information]] for transmission and [[Demodulation|demodulates]] signals to decode the transmitted information. The goal is to produce a [[Signal (electronics)|signal]] that can be transmitted easily and decoded reliably to reproduce the original digital data. Modems can be used with almost any means of transmitting analog signals from [[light-emitting diode]]s to [[radio]]. A common type of modem is one that turns the [[digital data]] of a [[computer]] into modulated [[electrical signal]] for transmission over [[telephone line]]s and demodulated by another modem at the receiver side to recover the digital data.}}
{{glossaryend}}

==N==
{{glossary}}
{{term|[[natural language processing]] (NLP)}}
{{defn|A subfield of [[linguistics]], {{gli|computer science}}, [[Information engineering (field)|information engineering]], and [[artificial intelligence]] concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of [[natural language]] data.  Challenges in natural language processing frequently involve [[speech recognition]], [[natural language understanding]], and [[natural language generation]].}}

{{term|[[node (computer science)|node]]}}
{{defn|Is a basic unit of a [[data structure]], such as a [[linked list]] or [[Tree (data structure)|tree]] data structure. Nodes contain [[data]] and also may link to other nodes. Links between nodes are often implemented by [[Pointer (computer programming)|pointers]].}}

{{term|[[number theory]]}}
{{defn|A branch of [[pure mathematics]] devoted primarily to the study of the [[integer]]s and [[arithmetic function|integer-valued functions]].}}

{{term|[[numerical analysis]]}}
{{defn|The study of {{gli|algorithm|algorithms}} that use numerical [[approximation]] (as opposed to [[symbolic computation|symbolic manipulations]]) for the problems of [[mathematical analysis]] (as distinguished from [[discrete mathematics]]).}}

{{term|[[numerical method]]}}
{{defn|In [[numerical analysis]], a numerical method is a mathematical tool designed to solve numerical problems. The implementation of a numerical method with an appropriate convergence check in a programming language is called a numerical algorithm.}}
{{glossaryend}}

==O==
{{glossary}}
{{term|[[object (computer science)|object]]}}
{{defn|An object can be a [[variable (computer science)|variable]], a [[data structure]], a [[subroutine|function]], or a [[Method (computer programming)|method]], and as such, is a [[Value (computer science)|value]] in [[Memory address|memory]] referenced by an [[identifier (computer programming)|identifier]].  In the [[class-based programming|class-based]] [[object-oriented programming]] paradigm, ''object'' refers to a particular [[Instance (computer science)|instance]] of a [[class (computer science)|class]], where the object can be a combination of variables, functions, and data structures.  In [[Relational model|relational]] [[database]] management, an object can be a table or column, or an association between data and a database entity (such as relating a person's age to a specific person).&lt;ref name=Oppel&gt;{{cite book |first=Andy |last=Oppel |title=SQL Demystified |publisher=McGraw Hill |year=2005| page=7 |isbn=0-07-226224-9}}&lt;/ref&gt;}}

{{term|[[object code]]}}
{{ghat|Also '''object module'''.}}
{{defn|The product of a {{gli|compiler}}.&lt;ref&gt;{{cite web|url=http://whatis.techtarget.com/definition/0,,sid9_gci211824,00.html|title=Compiler|publisher=TechTarget|quote=Traditionally, the output of the compilation has been called object code or sometimes an object module.|access-date=1 September 2011}}&lt;/ref&gt; In a general sense object code is a sequence of [[statement (computer science)|statements]] or instructions in a computer language,&lt;ref&gt;{{cite book|last1=Aho|first1=Alfred V.|author-link1=Alfred Aho|last2=Sethi|first2=Ravi|author-link2=Ravi Sethi|last3=Ullman|first3=Jeffrey D.|author-link3=Jeffrey Ullman|title=Compilers: principles, techniques, and tools|series=Computer Science|year=1986|publisher=Mark S. Dalton|isbn=0-201-10194-7|page=704|chapter=10 Code Optimization}}&lt;/ref&gt; usually a [[machine code]] language (i.e., [[binary file|binary]]) or an intermediate language such as [[register transfer language]] (RTL). The term indicates that the code is the [[goal]] or result of the compiling process, with some early sources referring to source code as a "subject program."}}

{{term|[[object-oriented analysis and design]] (OOAD)}}{{anchor|object-oriented analysis and design}}
{{defn|A technical approach for analyzing and designing an application, system, or business by applying {{gli|object-oriented programming}}, as well as using visual modeling throughout the software development process to guide stakeholder communication and product quality.}}

{{term|[[object-oriented programming]] (OOP)}}{{anchor|object-oriented programming}}
{{defn|A {{gli|programming paradigm}} based on the concept of "[[Object (computer science)|objects]]", which can contain [[data]], in the form of {{gli|field|fields}} (often known as ''attributes'' or ''properties''), and code, in the form of {{gli|procedure|procedures}} (often known as ''methods''). A feature of objects is an object's procedures that can access and often modify the data fields of the object with which they are associated (objects have a notion of "[[this (computer programming)|this]]" or "self"). In OOP, computer programs are designed by making them out of objects that interact with one another.&lt;ref&gt;{{Cite journal
  | last1 = Kindler | first1 =  E.
  | last2 = Krivy | first2 = I.
  | title = Object-Oriented Simulation of systems with sophisticated control
  | publisher = International Journal of General Systems
  | year = 2011 | pages = 313–343}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last1=Lewis|first1=John|last2=Loftus|first2= William|title=Java Software Solutions Foundations of Programming Design 6th ed|publisher=Pearson Education Inc.|year=2008|isbn=978-0-321-53205-3}}, section 1.6 "Object-Oriented Programming"&lt;/ref&gt; OOP languages are diverse, but the most popular ones are [[Class-based programming|class-based]], meaning that objects are [[instance (computer science)|instances]] of {{gli|class|classes}}, which also determine their [[data type|types]].}}

{{term|[[open-source software]] (OSS)}}{{anchor|open-source software}}
{{defn|A type of {{gli|computer software}} in which {{gli|source code}} is released under a [[Open-source license|license]] in which the [[copyright]] holder grants users the rights to study, change, and [[Software distribution|distribute the software]] to anyone and for any purpose.&lt;ref&gt;{{cite book|author=St. Laurent, Andrew M.|title=Understanding Open Source and Free Software Licensing|publisher=O'Reilly Media|year=2008|isbn=9780596553951|page=4|url=https://books.google.com/books?id=04jG7TTLujoC&amp;pg=PA4}}&lt;/ref&gt; Open-source software may be developed in a [[Open-source model|collaborative public manner]]. Open-source software is a prominent example of [[open collaboration]].&lt;ref name="Open Collaboration"&gt;{{Cite journal|last1=Levine|first1=Sheen S.|last2=Prietula|first2=Michael J.|date=2013-12-30|title=Open Collaboration for Innovation: Principles and Performance|journal=Organization Science|volume=25|issue=5|pages=1414–1433|doi=10.1287/orsc.2013.0872|issn=1047-7039|arxiv=1406.7541|s2cid=6583883}}&lt;/ref&gt;}}

{{term|[[operating system]] (OS)}}{{anchor|operating system}}
{{defn|[[System software]] that manages [[computer hardware]], {{gli|software}} resources, and provides common {{gli|daemon|services}} for {{gli|computer program|computer programs}}.}}

{{term|[[optical fiber]]}}
{{defn|A flexible, [[transparency and translucency|transparent]] [[fiber]] made by [[Drawing (manufacturing)|drawing]] [[glass]] ([[silica]]) or plastic to a diameter slightly thicker than that of a [[Hair's breadth|human hair]].&lt;ref&gt;{{cite web|title=Optical Fiber|url=http://www.thefoa.org/tech/ref/basic/fiber.html|website=www.thefoa.org |publisher=[[The Fiber Optic Association]] |access-date=17 April 2015}}&lt;/ref&gt; Optical fibers are used most often as a means to transmit light between the two ends of the fiber and find wide usage in [[fiber-optic communication]]s, where they permit transmission over longer distances and at higher [[Bandwidth (computing)|bandwidths]] (data rates) than electrical cables. Fibers are used instead of [[metal]] wires because signals travel along them with less [[Attenuation|loss]]; in addition, fibers are immune to [[electromagnetic interference]], a problem from which metal wires suffer.&lt;ref&gt;{{cite book|ref=Senior|last1=Senior|first1=John M.|last2=Jamro|first2=M. Yousif|title=Optical fiber communications: principles and practice|date=2009|publisher=Pearson Education|isbn=978-0130326812|pages=7–9}}&lt;/ref&gt;}}
{{glossaryend}}

==P==
{{glossary}}
{{term|[[pair programming]]}}
{{defn|An [[agile software development]] technique in which two [[computer programmer|programmers]] work together at one workstation. One, the ''driver'', writes [[Source code|code]] while the other, the ''observer'' or ''navigator'',&lt;ref&gt;{{cite conference |last1=Williams |first1=Laurie|author1-link=Laurie Williams (software engineer) |title=Integrating pair programming into a software development process |pages=27–36 |doi=10.1109/CSEE.2001.913816 |conference=14th Conference on Software Engineering Education and Training |date=February 19–20, 2001 |location=Charlotte |isbn=0-7695-1059-0 |quote=One of the programmers, the driver, has control of the keyboard/mouse and actively implements the program. The other programmer, the observer, continuously observes the work of the driver to identify tactical (syntactic, spelling, etc.) defects, and also thinks strategically about the direction of the work.}}&lt;/ref&gt; [[code review|reviews]] each line of code as it is typed in. The two programmers switch roles frequently.}}

{{term|[[parallel computing]]}}
{{defn|A type of {{gli|computation}} in which many calculations or the execution of [[Process (computing)|process]]es are carried out simultaneously.&lt;ref&gt;{{cite book|last=Gottlieb|first=Allan|title=Highly parallel computing|year=1989|publisher=Benjamin/Cummings|location=Redwood City, Calif.|isbn=978-0-8053-0177-9|url=http://dl.acm.org/citation.cfm?id=160438|author2=Almasi, George S.}}&lt;/ref&gt; Large problems can often be divided into smaller ones, which can then be solved at the same time. There are several different forms of parallel computing: [[Bit-level parallelism|bit-level]], [[Instruction-level parallelism|instruction-level]], [[Data parallelism|data]], and [[task parallelism]].}}

{{term|[[parameter (computer programming)|parameter]]}}
{{ghat|Also '''formal argument'''.}}
{{defn|In {{gli|computer programming}}, a special kind of [[Variable (programming)|variable]], used in a {{gli|subroutine}} to refer to one of the pieces of data provided as input to the subroutine.{{efn|1=In this article, the term "subroutine" refers to any subroutine-like construct, which have different names and slightly different meanings depending on the {{gli|programming language}} being discussed.}} These pieces of data are the values&lt;ref&gt;{{cite book|last1=Prata|first1=Stephen|title=C primer plus|date=2004|publisher=Sams|isbn=978-0-672-32696-7|pages=276–277|edition=5th}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Working Draft, Standard for Programming Language C++|url=http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1905.pdf|website=www.open-std.org|access-date=1 January 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Gordon|first1=Aaron|title=Subprograms and Parameter Passing|url=http://rowdysites.msudenver.edu/~gordona/cs3210/lects/lect10.html|website=rowdysites.msudenver.edu/~gordona|access-date=1 January 2018}}&lt;/ref&gt; of the arguments (often called ''actual arguments'' or ''actual parameters'') with which the subroutine is going to be called/invoked. An ordered list of parameters is usually included in the [[function signature|definition of a subroutine]], so that, each time the subroutine is called, its arguments for that call are evaluated, and the resulting values can be assigned to the corresponding parameters.}}

{{term|[[peripheral]]}}
{{defn|Any auxiliary or ancillary device connected to or integrated within a computer system and used to send information to or retrieve information from the computer. An ''input device'' sends data or instructions to the computer; an ''output device'' provides output from the computer to the user; and an ''input/output device'' performs both functions.}}

{{term|[[pointer (computer programming)|pointer]]}}
{{defn|Is an [[object (computer science)|object]] in many [[programming language]]s that stores a [[memory address]]. This can be that of another value located in [[computer memory]], or in some cases, that of [[Memory-mapped I/O|memory-mapped]] [[computer hardware]]. A pointer ''references'' a location in memory, and obtaining the value stored at that location is known as ''[[Dereference operator|dereferencing]]'' the pointer. As an analogy, a page number in a book's index could be considered a pointer to the corresponding page; dereferencing such a pointer would be done by flipping to the page with the given page number and reading the text found on that page. The actual format and content of a pointer variable is dependent on the underlying [[computer architecture]].}}

{{term|[[postcondition]]}}
{{defn|In {{gli|computer programming}}, a condition or [[Predicate (mathematics)|predicate]] that must always be true just after the execution of some section of code or after an operation in a [[formal specification]]. Postconditions are sometimes tested using [[assertion (computing)|assertions]] within the code itself. Often, postconditions are simply included in the documentation of the affected section of code.}}

{{term|[[precondition]]}}
{{defn|In {{gli|computer programming}}, a condition or [[Predicate (mathematics)|predicate]] that must always be true just prior to the execution of some section of [[code]] or before an operation in a [[formal specification]].  If a precondition is violated, the effect of the section of [[code]] becomes undefined and thus may or may not carry out its intended work.  [[Computer security|Security]] problems can arise due to incorrect preconditions.}}

{{term|[[primary storage]]}}
{{defn|(Also known as ''main memory'', ''internal memory'' or ''prime memory''), often referred to simply as ''memory'', is the only one directly accessible to the CPU. The CPU continuously reads instructions stored there and executes them as required. Any data actively operated on is also stored there in uniform manner.}}

{{term|[[primitive data type]]}}
{{defn|}}

{{term|[[priority queue]]}}
{{defn|An [[abstract data type]] which is like a regular {{gli|queue}} or {{gli|stack}} data structure, but where additionally each element has a "priority" associated with it. In a priority queue, an element with high priority is served before an element with low priority. In some implementations, if two elements have the same priority, they are served according to the order in which they were enqueued, while in other implementations, ordering of elements with the same priority is undefined.}}

{{term|[[procedural programming]]}}
{{defn|}}

{{term|[[procedure (computer science)|procedure]]}}
{{defn|In [[computer programming]], a subroutine is a sequence of program instructions that performs a specific task, packaged as a unit. This unit can then be used in programs wherever that particular [[Task (computing)|task]] should be performed.  {{anchor|SUBROUTINE_DEFINITION}}Subroutines may be defined within programs, or separately in [[library (computer science)|libraries]] that can be used by many programs.  In different programming languages, a subroutine may be called a routine, subprogram, function, [[method (computing)|method]], or procedure. Technically, these terms all have different definitions. The generic, [[umbrella term]]  callable unit is sometimes used.&lt;ref name="U.S. Election Assistance Commission 2007"&gt;{{cite web
 |author      = U.S. Election Assistance Commission
 |title       = Definitions of Words with Special Meanings
 |work        = [[Voluntary Voting System Guidelines]]
 |year        = 2007
 |url         = http://www.eac.gov/vvsg/glossary.aspx
 |access-date  = 2013-01-14
 |author-link  = Election Assistance Commission
 |url-status     = dead
 |archive-url  = https://web.archive.org/web/20121208084203/http://www.eac.gov/vvsg/glossary.aspx
 |archive-date = 2012-12-08
}}&lt;/ref&gt;}}

{{term|[[program lifecycle phase]]}}
{{defn|Program lifecycle phases are the stages a {{gli|computer program}} undergoes, from initial creation to deployment and [[Execution (computing)|execution]]. The phases are edit time, compile time, link time, distribution time, installation time, load time, and run time.}}

{{term|[[programming language]]}}
{{defn|A [[formal language]], which comprises a [[Instruction set|set of instructions]] that produce various kinds of [[Input/output|output]]. Programming languages are used in {{gli|computer programming}} to implement {{gli|algorithm|algorithms}}.}}

{{term|[[programming language implementation]]}}
{{defn|Is a system for executing [[computer programs]]. There are two general approaches to programming language implementation: [[interpreter (computing)|interpretation]] and [[compiler|compilation]].&lt;ref name="RantaBook"&gt;{{cite book |last1=Ranta |first1=Aarne |title=Implementing Programming Languages |date=9 May 2012 |publisher=College Publications |isbn=9781848900646 |pages=16–18 |url=http://www.cse.chalmers.se/edu/year/2012/course/DAT150/lectures/plt-book.pdf#page=16 |access-date=22 March 2020}}&lt;/ref&gt;}}

{{term|[[programming language theory]]}}
{{defn|(PLT) is a branch of [[computer science]] that deals with the design, implementation, analysis, characterization, and classification of [[programming language]]s and of their individual [[Programming language#Elements|features]].  It falls within the discipline of computer science, both depending on and affecting [[mathematics]], [[software engineering]], [[linguistics]] and even [[cognitive science]].  It has become a well-recognized branch of computer science, and an active research area, with results published in numerous [[Academic journal|journals]] dedicated to PLT, as well as in general computer science and engineering publications.}}

{{term|[[Prolog]]}}
{{defn|Is a [[logic programming]] language associated with [[artificial intelligence]] and [[computational linguistics]].&lt;ref name=Clocksin2003&gt;{{Cite book  | last1 = Clocksin | first1 = William F. | last2 = Mellish | first2 = Christopher S. | title = Programming in Prolog | year = 2003 | publisher = Springer-Verlag | location = Berlin ; New York | isbn = 978-3-540-00678-7 }}&lt;/ref&gt;&lt;ref name=Bratko2012&gt;{{Cite book  | last1 = Bratko | first1 = Ivan | title = Prolog programming for artificial intelligence |edition = 4th | year = 2012 | publisher = Addison Wesley | location = Harlow, England ; New York | isbn = 978-0-321-41746-6 }}&lt;/ref&gt;&lt;ref name=Covington1994&gt;{{Cite book  | last1 = Covington | first1 = Michael A. | title = Natural language processing for Prolog programmers | year = 1994 | publisher = Prentice Hall | location = Englewood Cliffs, N.J. | isbn = 978-0-13-629213-5 }}&lt;/ref&gt;  Prolog has its roots in [[first-order logic]], a [[formal logic]], and unlike many other [[programming language]]s, Prolog is intended primarily as a [[declarative programming]] language: the program logic is expressed in terms of [[Finitary relation|relations]], represented as facts and [[Rule of inference|rules]].  A [[computation]] is initiated by running a ''query'' over these relations.&lt;ref&gt;Lloyd, J. W. (1984). Foundations of logic programming. Berlin: Springer-Verlag. {{ISBN|978-3-540-13299-8}}.&lt;/ref&gt;}}

{{term|[[Python (programming language)|Python]]}}
{{defn|Is an [[interpreted language|interpreted]], [[high-level programming language|high-level]] and [[general-purpose programming language]]. Created by [[Guido van Rossum]] and first released in 1991, Python's design philosophy emphasizes [[code readability]] with its notable use of [[Off-side rule|significant whitespace]]. Its [[language construct]]s and [[object-oriented programming|object-oriented]] approach aim to help [[programmers]] write clear, logical code for small and large-scale projects.&lt;ref&gt;Kuhlman, Dave. "A Python Book: Beginning Python, Advanced Python, and Python Exercises". Section 1.1. Archived from the original (PDF) on 23 June 2012.&lt;/ref&gt;}}
{{glossaryend}}

==Q==
{{glossary}}
{{term|[[quantum computing]]}}
{{defn|The use of [[quantum mechanics|quantum-mechanical]] phenomena such as [[quantum superposition|superposition]] and [[quantum entanglement|entanglement]] to perform {{gli|computation}}. A quantum computer is used to perform such computation, which can be implemented theoretically or physically.&lt;ref name=2018Report&gt;{{cite book | title=Quantum Computing : Progress and Prospects (2018) | page= I-5 | publisher=National Academies Press | editor-last1 = Grumbling | editor-first1 = Emily | editor-last2 = Horowitz | editor-first2 = Mark | author= ((The National Academies of Sciences, Engineering, and Medicine)) |location=Washington, DC | year=2019 | doi=10.17226/25196|isbn=978-0-309-47969-1 | oclc=1081001288 }}&lt;/ref&gt;{{rp|I-5}}}}

{{term|[[queue (abstract data type)|queue]]}}
{{defn|A {{gli|collection}} in which the entities in the collection are kept in order and the principal (or only) operations on the collection are the addition of entities to the rear terminal position, known as ''enqueue'', and removal of entities from the front terminal position, known as ''dequeue''.}}

{{term|[[quicksort]]}}
{{ghat|Also '''partition-exchange sort'''.}}
{{defn|An [[Algorithm efficiency|efficient]] [[sorting algorithm]] which serves as a systematic method for placing the elements of a [[random access]] [[Computer file|file]] or an [[Array data structure|array]] in order.}}
{{glossaryend}}

==R==
{{glossary}}
{{term|[[r (programming language)|R programming language]]}}
{{defn|'''R''' is a [[programming language]] and [[free software]] environment for [[statistical computing]] and graphics supported by the R Foundation for Statistical Computing.{{refn | R language and environment
* {{Cite web |url=https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-R_003f |title=R FAQ| at=2.1 What is R? |date=2017-10-04 |first=Kurt |last=Hornik |website=The Comprehensive R Archive Network |access-date=2018-08-06}}
R Foundation
* {{Cite web |url=https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-the-R-Foundation_003f |title=R FAQ |at=2.13 What is the R Foundation? |date=2017-10-04 |first=Kurt |last=Hornik |website=The Comprehensive R Archive Network |access-date=2018-08-06}}
The R Core Team [https://cran.r-project.org/doc/FAQ/R-FAQ.html#Citing-R asks authors who use R in their data analysis] to cite the software using:
* R Core Team (2016). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/.
}} The R language is widely used among [[statistician]]s and [[Data mining|data miners]] for developing [[statistical software]]{{refn | widely used
* {{cite journal |author1=Fox, John  |author2=Andersen, Robert  |name-list-style=amp | title = Using the R Statistical Computing Environment to Teach Social Statistics Courses | publisher = Department of Sociology, McMaster University | date = January 2005 | url = https://socialsciences.mcmaster.ca/jfox/Teaching-with-R.pdf | access-date = 2018-08-06 }}
* {{cite news | url=https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html |title=Data Analysts Captivated by R's Power | date=2009-01-06 | access-date=2018-08-06|last=Vance| first=Ashlee |work=[[New York Times]]| quote=R is also the name of a popular programming language used by a growing number of data analysts inside corporations and academia. It is becoming their lingua franca...}}
}} and [[data analysis]].&lt;ref&gt;{{cite news | url=https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html |title=Data Analysts Captivated by R's Power | date=2009-01-06 | access-date=2018-08-06|last=Vance| first=Ashlee |work=[[New York Times]]| quote=R is also the name of a popular programming language used by a growing number of data analysts inside corporations and academia. It is becoming their lingua franca...}}&lt;/ref&gt;}}

{{term|[[radix]]}}
{{ghat|Also '''base'''.}}
{{defn|In [[numeral system|digital numeral systems]], the number of unique [[numerical digit|digits]], including the digit zero, used to represent numbers in a [[positional notation|positional]] numeral system. For example, in the decimal/denary system (the most common system in use today) the radix (base number) is ten, because it uses the ten digits from 0 through 9, and all other numbers are uniquely specified by positional combinations of these ten base digits; in the {{gli|binary number|binary system}} that is the standard in {{gli|computing}}, the radix is two, because it uses only two digits, 0 and 1, to uniquely specify each number.}}

{{term|[[record (computer science)|record]]}}
{{defn|A record (also called a structure,  [[struct (C programming language)|struct]], or compound data) is a basic [[data structure]]. Records in a [[database]] or [[spreadsheet]] are usually called "[[row (database)|row]]s".&lt;ref&gt;{{cite web|title=Computer Science Dictionary Definitions|url=http://www.computingstudents.com/dictionary/?word=Record|website=Computing Students|access-date=Jan 22, 2018}}&lt;/ref&gt;&lt;ref name="Radványi"&gt;{{cite book |last1=Radványi |first1=Tibor |title=Database Management Systems |date=2014 |publisher=Eszterházy Károly College |page=19 |url=https://www.tankonyvtar.hu/en/tartalom/tamop412A/2011-0038_49_radvanyi_en/index.html |access-date=23 September 2018}}&lt;/ref&gt;&lt;ref name="Kahate"&gt;{{cite book |last1=Kahate |first1=Atul |title=Introduction to Database Management Systems |date=2006 |publisher=Pearson |isbn=978-81-317-0078-5 |page=3 |url=https://books.google.com/books?id=mxYESolfLfoC |access-date=23 September 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite book |last1=Connolly |first1=Thomas |title=Database Solutions: A Step by Step Guide to Building Databases |url=https://archive.org/details/databasesolution00conn_535 |url-access=registration |date=2004 |publisher=Pearson |isbn=978-0-321-17350-8 |page=[https://archive.org/details/databasesolution00conn_535/page/n19 7] |edition=2nd }}&lt;/ref&gt;}}

{{term|[[recursion]]}}
{{defn|Occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from [[linguistics]] to [[logic]]. The most common application of recursion is in [[mathematics]] and {{gli|computer science}}, where a [[function (mathematics)|function]] being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references can occur.}}

{{term|[[reference (computer science)|reference]]}}
{{defn|Is a value that enables a program to indirectly access a particular [[datum]], such as a [[variable (computer science)|variable]]'s value or a [[record (computer science)|record]], in the [[computer]]'s [[memory (computing)|memory]] or in some other [[Data storage device|storage device]].  The reference is said to refer to the datum, and accessing the datum is called [[Dereference operator|dereferencing]] the reference.}}

{{term|[[reference counting]]}}
{{defn|A programming technique of storing the number of {{gli|reference|references}}, {{gli|pointer|pointers}}, or {{gli|handle|handles}} to a resource, such as an object, a block of memory, disk space, and others. In [[garbage collection (computer science)|garbage collection]] algorithms, reference counts may be used to deallocate objects which are no longer needed.}}

{{term|[[relational database]]}}
{{defn|Is a digital [[database]] based on the [[relational model]] of data, as proposed by [[E. F. Codd]] in 1970.&lt;ref&gt;Codd, E. F. (1970). "A Relational Model of Data for Large Shared Data Banks". Communications of the ACM. 13 (6): 377–387. doi:10.1145/362384.362685.&lt;/ref&gt;
A software system used to maintain relational databases is a [[relational database management system]] (RDBMS). Many relational database systems have an option of using the [[SQL]] (Structured Query Language) for querying and maintaining the database.&lt;ref&gt;{{cite web |last=Ambler |first=Scott |title=Relational Databases 101: Looking at the Whole Picture |url=http://www.agiledata.org/essays/relationalDatabases.html }}{{better source needed|date=June 2018}}&lt;/ref&gt;}}

{{term|[[reliability engineering]]}}
{{defn|A sub-discipline of [[systems engineering]] that emphasizes dependability in the [[product lifecycle management|lifecycle management]] of a product. Reliability describes the ability of a system or component to function under stated conditions for a specified period of time.&lt;ref&gt;Institute of Electrical and Electronics Engineers (1990) IEEE Standard Computer Dictionary: A Compilation of IEEE Standard Computer Glossaries. New York, NY {{ISBN|1-55937-079-3}}&lt;/ref&gt; Reliability is closely related to [[availability]], which is typically described as the ability of a component or system to function at a specified moment or interval of time.}}

{{term|[[regression testing]]}}
{{defn|(rarely ''non-regression testing''&lt;ref&gt;{{cite book |last1=Pezzè |first1=Mauro |last2=Young |first2=Michal |title=Software testing and analysis: process, principles, and techniques |date=2008 |publisher=Wiley |url=https://www.google.com/search?q=Mauro+%22non-regression%22+%22regression+testing%22 |quote=Testing activities that focus on regression problems are called (non) regression testing. Usually "non" is omitted}}&lt;/ref&gt;) is re-running [[functional testing|functional]] and [[non-functional testing|non-functional tests]] to ensure that previously developed and tested software still performs after a change.&lt;ref&gt;{{cite book|last=Basu|first=Anirban| title=Software Quality Assurance, Testing and Metrics| year=2015| publisher=PHI Learning| isbn=978-81-203-5068-7| url=https://books.google.com/books?id=aNTiCQAAQBAJ&amp;pg=PA150}}&lt;/ref&gt; If not, that would be called a ''[[software regression|regression]]''. Changes that may require regression testing include [[software bug|bug]] fixes, software enhancements, [[configuration file|configuration]] changes, and even substitution of [[electronic component]]s.&lt;ref&gt;[[National Academies of Sciences, Engineering, and Medicine|National Research Council]] Committee on Aging Avionics in Military Aircraft: [https://www.nap.edu/catalog/10108/aging-avionics-in-military-aircraft ''Aging Avionics in Military Aircraft'']. The National Academies Press, 2001, page 2: ″Each technology-refresh cycle requires regression testing.″&lt;/ref&gt; As regression test suites tend to grow with each found defect, test automation is frequently involved. Sometimes a [[change impact analysis]] is performed to determine an appropriate subset of tests (''non-regression analysis''&lt;ref&gt;{{cite book |last1=Boulanger |first1=Jean-Louis |title=CENELEC 50128 and IEC 62279 Standards |date=2015 |publisher=Wiley |isbn=978-1119122487 |url=https://books.google.com/books?id=IbZNCAAAQBAJ&amp;pg=PA149}}&lt;/ref&gt;).}}

{{term|[[requirements analysis]]}}
{{defn|In [[systems engineering]] and [[software engineering]], requirements analysis focuses on the tasks that determine the needs or conditions to meet the new or altered product or project, taking account of the possibly conflicting [[requirement]]s of the various [[Stakeholder (corporate)|stakeholders]], ''analyzing, documenting, validating and managing'' software or system requirements.&lt;ref&gt;{{cite book|isbn=9780471972082|title=Requirements Engineering: Processes and Techniques|url=https://archive.org/details/requirementsengi1998koto|url-access=registration|last1=Kotonya|first1=Gerald|last2=Sommerville|first2=Ian|year=1998|location=Chichester, UK|publisher=John Wiley and Sons}}&lt;/ref&gt;}}

{{term|[[robotics]]}}
{{defn|An interdisciplinary branch of [[List of engineering branches|engineering]] and [[Branch of science|science]] that includes [[mechanical engineering]], [[electronic engineering]], [[Information engineering (field)|information engineering]], {{gli|computer science}}, and others. Robotics involves design, construction, operation, and use of [[robot]]s, as well as [[computer system]]s for their perception, control, [[sensory feedback]], and [[information processing]]. The goal of robotics is to design intelligent machines that can help and assist humans in their day-to-day lives and keep everyone safe.}}

{{term|[[round-off error]]}}
{{ghat|Also '''rounding error'''.&lt;ref&gt;{{citation |title=Numerical Computation 1: Methods, Software, and Analysis |author-first=Christoph W. |author-last=Ueberhuber |publisher=Springer |date=1997 |isbn=978-3-54062058-7 |url=https://books.google.com/books?id=JH9I7EJh3JUC&amp;pg=PA139 |pages=139–146}}&lt;/ref&gt;}}
{{defn|The difference between the result produced by a given {{gli|algorithm}} using exact arithmetic and the result produced by the same algorithm using finite-precision, rounded arithmetic.&lt;ref name="Forrester_2018"&gt;{{cite book |title= Math/Comp241 Numerical Methods (lecture notes) |author-first=Dick |author-last=Forrester |publisher=[[Dickinson College]] |date=2018}}&lt;/ref&gt; Rounding errors are due to inexactness in the representation of real numbers and the arithmetic operations done with them. This is a form of [[quantization error]].&lt;ref&gt;{{citation |title=Information Technology in Theory |author-first1=Pelin |author-last1=Aksoy |author-first2=Laura |author-last2=DeNardis |publisher=Cengage Learning |date=2007 |isbn=978-1-42390140-2 |page=134 |url=https://books.google.com/books?id=KGS5IcixljwC&amp;pg=PA134}}&lt;/ref&gt; When using approximation [[equation]]s or algorithms, especially when using finitely many digits to represent real numbers (which in theory have infinitely many digits), one of the goals of [[numerical analysis]] is to [[error analysis (mathematics)|estimate]] computation errors.&lt;ref&gt;{{citation |title=A First Course in Numerical Analysis |edition=2nd |series=Dover Books on Mathematics |author-first1=Anthony |author-last1=Ralston |author-first2=Philip |author-last2=Rabinowitz |publisher=Courier Dover Publications |date=2012 |isbn=978-0-48614029-2 |url=https://books.google.com/books?id=TVq8AQAAQBAJ&amp;pg=PA2 |pages=2–4}}&lt;/ref&gt; Computation errors, also called [[numerical error]]s, include both [[truncation error]]s and roundoff errors.&lt;ref&gt;{{citation |title=Introduction to Numerical Analysis Using MATLAB |author-first=Rizwan |author-last=Butt |publisher=Jones &amp; Bartlett Learning |date=2009 |isbn=978-0-76377376-2 |pages=11–18 |url=https://books.google.com/books?id=QWub-UVGxqkC&amp;pg=PA11}}&lt;/ref&gt;}}

{{term|[[router (computing)|router]]}}
{{defn|A [[networking device]] that forwards [[data packet]]s between [[computer network]]s. Routers perform the traffic directing functions on the [[Internet]].  Data sent through the internet, such as a [[web page]] or [[email]], is in the form of data packets.   A packet is typically [[Packet forwarding|forwarded]] from one router to another router through the networks that constitute an [[internetwork]] (e.g. the Internet) until it reaches its destination [[Node (networking)|node]].&lt;ref&gt;{{cite web|url=http://www.tcpipguide.com/free/t_OverviewOfKeyRoutingProtocolConceptsArchitecturesP.htm|title=Overview Of Key Routing Protocol Concepts: Architectures, Protocol Types, Algorithms and Metrics|publisher=Tcpipguide.com|access-date=15 January 2011|url-status=live|archive-url=https://web.archive.org/web/20101220111345/http://tcpipguide.com/free/t_OverviewOfKeyRoutingProtocolConceptsArchitecturesP.htm|archive-date=20 December 2010}}&lt;/ref&gt;}}

{{term|[[routing table]]}}
{{defn|In [[computer networking]] a routing table, or routing information base (RIB), is a [[data table]] stored in a [[Router (computing)|router]] or a [[network host]] that lists the routes to particular network destinations, and in some cases, [[Metrics (networking)|metrics]] (distances) associated with those routes. The routing table contains information about the [[Network topology|topology of the network]] immediately around it.}}

{{term|[[run time (program lifecycle phase)|run time]]}}
{{defn|Runtime, run time, or execution time is the final phase of a [[computer program]]{{'}}s [[Program lifecycle phase|life cycle]], in which the code is being [[Execution (computing)|executed]] on the computer's [[central processing unit]] (CPU) as [[machine code]]. In other words, "runtime" is the running phase of a program.}}

{{term|[[run time (program lifecycle phase)|run time error]]}}
{{defn|A [[Runtime error detection|runtime error]] is detected after or during the execution (running state) of a program, whereas a [[Compile time|compile-time]] error is detected by the [[compiler]] before the program is ever executed. [[Type checking]], [[register allocation]], [[code generation (compiler)|code generation]], and code optimization are typically done at compile time, but may be done at runtime depending on the particular language and compiler. Many other runtime errors exist and are handled differently by different [[programming language]]s, such as [[division by zero]] errors, domain errors, [[Bounds checking|array subscript out of bounds]] errors, [[arithmetic underflow]] errors, several types of underflow and [[overflow (disambiguation)|overflow]] errors, and many other runtime errors generally considered as software bugs which may or may not be caught and handled by any particular computer language. }}

==S==
{{glossary}}
{{term|[[search algorithm]]}}
{{defn|Any {{gli|algorithm}} which solves the [[search problem]], namely, to retrieve information stored within some data structure, or calculated in the [[Feasible region|search space]] of a [[problem domain]], either with [[Continuous or discrete variable|discrete or continuous values]].}}

{{term|[[auxiliary memory|secondary storage]]}}
{{defn|Also known as ''external memory'' or ''auxiliary storage'', differs from primary storage in that it is not directly accessible by the CPU. The computer usually uses its [[input/output]] channels to access secondary storage and transfer the desired data to primary storage. Secondary storage is non-volatile (retaining data when power is shut off). Modern computer systems typically have two orders of magnitude more secondary storage than primary storage because secondary storage is less expensive.
}}

{{term|[[selection sort]]}}
{{defn|Is an [[in-place algorithm|in-place]] [[comparison sort|comparison]] [[sorting algorithm]]. It has an [[Big O notation|O]](''n''&lt;sup&gt;2&lt;/sup&gt;) [[time complexity]], which makes it inefficient on large lists, and generally performs worse than the similar [[insertion sort]]. Selection sort is noted for its simplicity and has performance advantages over more complicated algorithms in certain situations, particularly where [[auxiliary memory]] is limited.}}

{{term|[[semantics (computer science)|semantics]]}}
{{defn|In [[programming language theory]], semantics is the field concerned with the rigorous mathematical study of the meaning of [[programming language]]s. It does so by evaluating the meaning of [[programming language syntax|syntactically]] valid [[String (computer science)|strings]] defined by a specific programming language, showing the computation involved. In such a case that the evaluation would be of syntactically invalid strings, the result would be non-computation. Semantics describes the processes a computer follows when executing a program in that specific language. This can be shown by describing the relationship between the input and output of a program, or an explanation of how the program will be executed on a certain [[computer platform|platform]], hence creating a [[model of computation]].}}

{{term|[[sequence]]}}
{{defn|In [[mathematics]], a sequence is an enumerated collection of objects in which repetitions are allowed and [[order theory|order]] does matter.  Like a [[Set (mathematics)|set]], it contains [[Element (mathematics)|members]] (also called ''elements'', or ''terms'').  The number of elements (possibly infinite) is called the ''length'' of the sequence.  Unlike a set, the same elements can appear multiple times at different positions in a sequence, and order does matter.  Formally, a sequence can be defined as a [[function (mathematics)|function]] whose domain is either the set of the [[natural number]]s (for infinite sequences) or the set of the first ''n'' natural numbers (for a sequence of finite length ''n'').

The position of an element in a sequence is its ''rank'' or ''index''; it is the natural number for which the element is the image. The first element has index 0 or 1, depending on the context or a specific convention.  When a symbol is used to denote a sequence, the ''n''th element of the sequence is denoted by this symbol with ''n'' as subscript; for example, the ''n''th element of the [[Fibonacci sequence]] ''F'' is generally denoted ''F''&lt;sub&gt;''n''&lt;/sub&gt;.

For example, (M, A, R, Y) is a sequence of letters with the letter 'M' first and 'Y' last.  This sequence differs from (A, R, M, Y).  Also, the sequence (1, 1, 2, 3, 5, 8), which contains the number 1 at two different positions, is a valid sequence.  Sequences can be ''[[finite set|finite]]'', as in these examples, or ''[[Infinite set|infinite]]'', such as the sequence of all [[even and odd numbers|even]] [[positive integer]]s (2, 4, 6, ...).  In [[computing]] and [[computer science]], finite sequences are sometimes called [[string (computer science)|strings]], [[word (mathematics)|words]] or [[list (computer science)|lists]], the different names commonly corresponding to different ways to represent them in [[computer memory]]; infinite sequences are called [[stream (computing)|streams]].  The empty sequence&amp;nbsp;(&amp;nbsp;) is included in most notions of sequence, but may be excluded depending on the context.}}

{{term|[[serializability]]}}
{{defn|In [[concurrency control]] of [[database]]s,&lt;ref name=Bernstein87&gt;[[Phil Bernstein|Philip A. Bernstein]], Vassos Hadzilacos, Nathan Goodman (1987): [http://research.microsoft.com/en-us/people/philbe/ccontrol.aspx ''Concurrency Control and Recovery in Database Systems''] (free PDF download), Addison Wesley Publishing Company, {{ISBN|0-201-10715-5}}&lt;/ref&gt;&lt;ref name=Weikum01&gt;[[Gerhard Weikum]], Gottfried Vossen (2001): [http://www.elsevier.com/wps/find/bookdescription.cws_home/677937/description#description ''Transactional Information Systems''], Elsevier, {{ISBN|1-55860-508-8}}&lt;/ref&gt; [[transaction processing]] (transaction management), and various [[Database transaction|transactional]] applications (e.g., [[transactional memory]]&lt;ref name=Herlihy1993&gt;[[Maurice Herlihy]] and J. Eliot B. Moss. ''Transactional memory: architectural support for lock-free data structures.'' Proceedings of the 20th annual international symposium on Computer architecture (ISCA '93). Volume 21, Issue 2, May 1993.&lt;/ref&gt; and [[software transactional memory]]), both centralized and [[Distributed computing|distributed]], a transaction [[Schedule (computer science)|schedule]] is '''serializable''' if its outcome (e.g., the resulting database state) is equal to the outcome of its transactions executed serially, i.e. without overlapping in time. Transactions are normally executed concurrently (they overlap), since this is the most efficient way. Serializability is the major correctness criterion for concurrent transactions' executions{{Citation needed|date=February 2018}}. It is considered the highest level of [[isolation (computer science)|isolation]] between [[Database transaction|transactions]], and plays an essential role in [[concurrency control]]. As such it is supported in all general purpose database systems. ''[[Two-phase locking|Strong strict two-phase locking]]'' (SS2PL) is a popular serializability mechanism utilized in most of the database systems (in various variants) since their early days in the 1970s.
}}

{{term|[[serialization]]}}
{{defn|Is the process of translating [[data structure]]s or [[object (computer science)|object]] state into a format that can be stored (for example, in a [[computer file|file]] or memory [[Data buffer|buffer]]) or transmitted (for example, across a [[computer network|network]] connection link) and reconstructed later (possibly in a different computer environment).&lt;ref&gt;{{ cite web
 | author       = Marshall Cline
 | url          = http://www.parashift.com/c++-faq-lite/serialize-overview.html
 | title        = C++ FAQ: "What's this "serialization" thing all about?"
 | archive-url  = https://web.archive.org/web/20150405013606/http://isocpp.org/wiki/faq/serialization
 | archive-date = 2015-04-05
 | quote = It lets you take an object or group of objects, put them on a disk or send them through a wire or wireless transport mechanism, then later, perhaps on another computer, reverse the process, resurrecting the original object(s). The basic mechanisms are to flatten object(s) into a one-dimensional stream of bits, and to turn that stream of bits back into the original object(s).}}&lt;/ref&gt; When the resulting series of bits is reread according to the serialization format, it can be used to create a semantically identical clone of the original object. For many complex objects, such as those that make extensive use of [[reference (computer science)|references]], this process is not straightforward. Serialization of object-oriented [[object (computer science)|object]]s does not include any of their associated [[Method (computer science)|methods]] with which they were previously linked.

This process of serializing an object is also called [[Marshalling (computer science)|marshalling]] an object in some situations.[http://www.ruby-doc.org/core/classes/Marshal.html][http://caml.inria.fr/pub/docs/manual-ocaml/libref/Marshal.html] The opposite operation, extracting a data structure from a series of bytes, is '''deserialization''', (also called '''unserialization''' or '''[[unmarshalling]]''').}}

{{term|[[service level agreement]]}}
{{defn|(SLA), is a commitment between a service provider and a client. Particular aspects of the service&amp;nbsp;– quality, availability, responsibilities&amp;nbsp;– are agreed between the service provider and the service user.&lt;ref name="KearneyServ11"&gt;{{cite book |url=https://books.google.com/books?id=z306GUfFL5gC |chapter=The SLA Model |title=Service Level Agreements for Cloud Computing |author1=Kearney, K.T. |author2=Torelli, F. |editor1=Wieder, P. |editor2=Butler, J.M. |editor3=Theilmann, W. |editor4=Yahyapour, R.  |publisher=Springer Science+Business Media, LLC |pages=43–68 |year=2011 |isbn=9781461416142}}&lt;/ref&gt; The most common component of an SLA is that the services should be provided to the customer as agreed upon in the contract. As an example, [[Internet service provider]]s and [[Telephone company|telcos]] will commonly include service level agreements within the terms of their contracts with customers to define the level(s) of service being sold in plain language terms. In this case the SLA will typically have a technical definition in  ''[[mean time between failures]]'' (MTBF), ''[[mean time to repair]]'' or ''[[mean time to recovery]]'' (MTTR); identifying which party is responsible for reporting faults or paying fees; responsibility for various data rates; [[throughput]]; [[jitter]]; or similar measurable details.}}

{{term|[[set (abstract data type)|set]]}}
{{defn|Is an [[abstract data type]] that can store unique values, without any particular [[sequence|order]]. It is a computer implementation of the [[mathematics|mathematical]] concept of a [[finite set]]. Unlike most other [[collection (abstract data type)|collection]] types, rather than retrieving a specific element from a set, one typically tests a value for membership in a set.}}

{{term|'''soft computing'''}}
{{defn|}}

{{term|[[software]]}}
{{defn|Computer software, or simply software, is a collection of [[data (computing)|data]] or [[computer]] instructions that tell the computer how to work. This is in contrast to [[Computer hardware|physical hardware]], from which the system is built and actually performs the work. In [[computer science]] and [[software engineering]], computer software is all [[information]] processed by [[computer system]]s, [[Computer program|program]]s and [[data]]. Computer software includes [[computer program]]s, [[Library (computing)|libraries]] and related non-executable [[Data (computing)|data]], such as [[Software documentation|online documentation]] or [[digital media]]. Computer hardware and software require each other and neither can be realistically used on its own.}}

{{term|[[software agent]]}}
{{defn|Is a computer program that acts for a user or other program in a relationship of agency, which derives from the Latin ''agere'' (to do): an agreement to act on one's behalf. Such "action on behalf of" implies the [[authority]] to decide which, if any, action is appropriate.&lt;ref&gt;{{cite journal
 | last1         = Nwana
 | first1        = H.&amp;nbsp;S.
 | year          = 1996
 | title         = Software Agents: An Overview
 | volume        = 21
 | number        = 3
 | pages         = 205–244
 | journal       = Knowledge Engineering Review
 | doi=10.1017/s026988890000789x
 | citeseerx        = 10.1.1.50.660
 }}&lt;/ref&gt;&lt;ref&gt;{{cite book
 | last1         = Schermer
 | first1        = B.&amp;nbsp;W.
 | year          = 2007
 | title         = Software agents, surveillance, and the right to privacy: A legislative framework for agent-enabled surveillance
 | volume        = 21
 | number        = 3
 | pages         = 140, 205–244
 | publisher     = Leiden University Press
 | format        = paperback
 | isbn          = 978-0-596-00712-6
 | access-date    = 2012-10-30
 | url           = https://openaccess.leidenuniv.nl/handle/1887/11951
 | hdl          = 1887/11951}}&lt;/ref&gt; Agents are colloquially known as ''[[Bot (disambiguation)|bots]]'', from ''[[robot]]''. They may be embodied, as when execution is paired with a robot body, or  as software such as a chatbot
executing on a phone (e.g. [[Siri]])  or other computing device.  Software agents may be autonomous or work together with other agents or people.  Software agents interacting with people (e.g. [[chatbots]], [[human-robot interaction]] environments) may possess human-like qualities such as [[natural language understanding]] and speech, personality or embody humanoid form (see [[Asimo]]).}}

{{term|[[software construction]]}}
{{defn|Is a [[software engineering]] discipline. It is the detailed creation of working meaningful [[software]] through a combination of [[#Coding|coding]], [[Software verification|verification]], [[unit testing]], [[integration testing]], and [[debugging]]. It is linked to all the other [[software engineering]] disciplines, most strongly to [[software design]] and [[software testing]].&lt;ref name="SWEBOK"&gt;[[Software Engineering Body of Knowledge|SWEBOK]] {{Cite book |editor=Pierre Bourque |editor2=Robert Dupuis |editor3=Alain Abran |editor4=James W. Moore | title = Guide to the Software Engineering Body of Knowledge | publisher = [[IEEE Computer Society]] | year = 2004 | chapter = Chapter 4: Software Construction | pages = 4–1–4–5 | isbn = 0-7695-2330-7 | url = http://www.computer.org/portal/web/swebok/html/ch4#Ref2}}&lt;/ref&gt;}}

{{term|[[software deployment]]}}
{{defn|defn=Is all of the activities that make a [[software system]] available for use.&lt;ref&gt;[[Roger S. Pressman]] Software engineering: a practitioner's approach (eighth edition)&lt;/ref&gt;}}

{{term|[[software design]]}}
{{defn|defn=Is the process by which an [[Agency (philosophy)|agent]] creates a specification of a [[Artifact (software development)|software artifact]], intended to accomplish [[goal]]s, using a set of primitive components and subject to [[Constraint (mathematics)|constraint]]s.&lt;ref&gt;Ralph, P. and Wand, Y. (2009). A proposal for a formal definition of the design concept. In Lyytinen, K., Loucopoulos, P., [[John Mylopoulos|Mylopoulos, J.]], and Robinson, W., editors, Design Requirements Workshop (LNBIP 14), pp. 103–136. Springer-Verlag, p. 109 {{DOI|10.1007/978-3-540-92966-6_6}}.&lt;/ref&gt; Software design may refer to either "all the activity involved in conceptualizing, framing, implementing, commissioning, and ultimately modifying complex systems" or "the activity following [[Software requirements|requirements]] specification and before [[Computer programming|programming]], as ... [in] a stylized software engineering process."&lt;ref&gt;{{cite journal|last=Freeman|first=Peter|author2=David Hart |s2cid=14331332|title=A Science of design for software-intensive systems|journal=Communications of the ACM|year=2004|volume=47|issue=8|pages=19–21 [20]|doi=10.1145/1012037.1012054}}&lt;/ref&gt;}}

{{term|[[software development]]}}
{{defn|defn=Is the process of conceiving, specifying, designing, [[Computer programming|programming]], [[software documentation|documenting]], [[software testing|testing]], and [[Software bugs|bug fixing]] involved in creating and maintaining [[application software|applications]], [[software framework|frameworks]], or other software components. Software development is a process of writing and [[Software maintenance|maintaining]] the [[source code]], but in a broader sense, it includes all that is involved between the conception of the desired software through to the final manifestation of the software, sometimes in a planned and [[Software development process|structured]] process.&lt;ref&gt;{{cite web|url=http://www.bestpricecomputers.co.uk/glossary/application-development.htm |title=Application Development (AppDev) Defined and Explained |publisher=Bestpricecomputers.co.uk |date=2007-08-13 |access-date=2012-08-05}}&lt;/ref&gt; Therefore, software development may include research, new development, prototyping, modification, reuse, re-engineering, maintenance, or any other activities that result in software products.&lt;ref&gt;{{cite web|author=DRM Associates|title=New Product Development Glossary |url=http://www.npd-solutions.com/glossary.html |year=2002|access-date=2006-10-29}}&lt;/ref&gt;}}

{{term|[[software development process]]}}
{{defn|In [[software engineering]], a software development process is the process of dividing [[software development]] work into distinct phases to improve [[Software design|design]], [[Software product management|product management]], and [[Software project management|project management]].  It is also known as a software development life cycle (SDLC).  The methodology may include the pre-definition of specific [[deliverable]]s and artifacts that are created and completed by a project team to develop or maintain an application.&lt;ref name="Medicare 2008"&gt;Centers for Medicare &amp; Medicaid Services (CMS) Office of Information Service (2008). Selecting a development approach. Webarticle. United States Department of Health and Human Services (HHS). Re-validated: March 27, 2008. Retrieved 27 Oct 2008.&lt;/ref&gt;  Most modern development processes can be vaguely described as [[Agile software development|agile]]. Other methodologies include [[waterfall model|waterfall]], [[software prototyping|prototyping]], [[iterative and incremental development]], [[spiral development]], [[rapid application development]], and [[extreme programming]].}}

{{term|[[software engineering]]}}
{{defn|Is the systematic application of [[engineering]] approaches to the [[software development|development]] of [[software]].&lt;ref name="BoDu04"&gt;{{harvnb |Abran |Moore |Bourque| Dupuis |2004 |pp=1–1}}&lt;/ref&gt;&lt;ref name="ACM 2020"&gt;{{cite web |last=ACM |year=2007 |url=http://computingcareers.acm.org/?page_id=12|title=Computing Degrees &amp; Careers |publisher=ACM |access-date=2010-11-23}}&lt;/ref&gt;&lt;ref name="Laplante 2007"&gt;{{cite book |last=Laplante |first=Phillip |title=What Every Engineer Should Know about Software Engineering |publisher=CRC |location=Boca Raton |year=2007 |isbn=978-0-8493-7228-5 |url=https://books.google.com/books?id=pFHYk0KWAEgC&amp;q=What%20Every%20Engineer%20Should%20Know%20about%20Software%20Engineering.&amp;pg=PA1 |access-date=2011-01-21 }}&lt;/ref&gt; Software engineering is a [[computing]] discipline.&lt;ref&gt;{{Cite web|url=http://www.acm.org/education/curric_vols/CC2005-March06Final.pdf|archive-url=https://web.archive.org/web/20141021153204/http://www.acm.org/education/curric_vols/CC2005-March06Final.pdf|archive-date=2014-10-21|title=The Joint Task Force for Computing Curricula 2005|date=2014-10-21|url-status=live|access-date=2020-04-16}}&lt;/ref&gt;}}

{{term|[[software maintenance]]}}
{{defn|In [[software engineering]] is the modification of a software product after delivery to correct faults, to improve performance or other attributes.&lt;ref name="iso14764"&gt;{{cite web|url=http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=39064 |title=ISO/IEC 14764:2006 Software Engineering — Software Life Cycle Processes — Maintenance |publisher=Iso.org |date=2011-12-17 |access-date=2013-12-02}}&lt;/ref&gt;}}

{{term|[[software prototyping]]}}
{{defn|Is the activity of creating [[prototype]]s of software applications, i.e., incomplete versions of the [[Software|software program]] being developed. It is an activity that can occur in [[Software development process|software development]] and is comparable to [[prototyping]] as known from other fields, such as [[mechanical engineering]] or [[manufacturing]].  A prototype typically simulates only a few aspects of, and may be completely different from, the final product. }}

{{term|[[software requirements specification]]}}
{{defn|(SRS), is a description of a [[software system]] to be  [[Software development|developed]]. The software requirements specification lays out [[Functional requirement|functional]] and [[non-functional requirements]], and it may include a set of [[use case]]s that describe user interactions that the software must provide to the user for perfect interaction.}}

{{term|[[software testing]]}}
{{defn|Is an investigation conducted to provide stakeholders with information about the [[Software quality|quality]] of the [[software]] product or service under test.&lt;ref name="Kaner 1"&gt;{{cite conference | url = http://www.kaner.com/pdfs/ETatQAI.pdf | title = Exploratory Testing |author-link=Cem Kaner | last = Kaner | first = Cem |conference=Quality Assurance Institute Worldwide Annual Software Testing Conference | location = Orlando, FL | date = November 17, 2006 | access-date = November 22, 2014}}&lt;/ref&gt; Software testing can also provide an objective, independent view of the software to allow the business to appreciate and understand the risks of software implementation. Test techniques include the process of executing a program or application with the intent of finding [[software bug]]s (errors or other defects), and verifying that the software product is fit for use. }}

{{term|[[sorting algorithm]]}}
{{defn|Is an [[algorithm]] that puts elements of a [[List (computing)|list]] in a certain [[Total order|order]]. The most frequently used orders are [[numerical order]] and [[lexicographical order]]. Efficient [[sorting]] is important for optimizing the [[Algorithmic efficiency|efficiency]] of other algorithms (such as [[search algorithm|search]] and [[merge algorithm|merge]] algorithms) that require input data to be in sorted lists. Sorting is also often useful for [[Canonicalization|canonicalizing]] data and for producing human-readable output. More formally, the output of any sorting algorithm must satisfy two conditions:

# The output is in nondecreasing order (each element is no smaller than the previous element according to the desired [[total order]]);&lt;!-- confusing; this appears to mean that the output must be in ascending order, which isn't a necessary condition --&gt;
# The output is a [[permutation]] (a reordering, yet retaining all of the original elements) of the input.

Further, the input data is often stored in an [[Array data type|array]], which allows [[random access]], rather than a list, which only allows [[sequential access]]; though many algorithms can be applied to either type of data after suitable modification.
}}

{{term|[[source code]]}}
{{defn|In [[computing]], source code is any collection of code, with or without [[comment (computer programming)|comments]], written using&lt;ref&gt;"Programming in C: A Tutorial" (PDF). Archived from the original(PDF) on 23 February 2015.&lt;/ref&gt; a ''human-readable'' [[programming language]], usually as [[plain text]]. The source code of a program is specially designed to facilitate the work of computer [[programmer]]s, who specify the actions to be performed by a computer mostly by writing source code. The source code is often transformed by an [[assembler (computing)|assembler]] or [[compiler]] into [[Binary number|binary]] [[machine code]] that can be executed by the computer. The machine code might then be stored for [[execution (computing)|execution]] at a later time. Alternatively, source code may be [[interpreter (computing)|interpreted]] and thus immediately executed.}}

{{term|[[spiral model]]}}
{{defn|Is a risk-driven [[software development process]] model. Based on the unique risk patterns of a given project, the spiral model guides a team to adopt elements of one or more process models, such as [[Iterative and incremental development|incremental]], [[Waterfall model|waterfall]], or [[Software prototyping#Evolutionary prototyping|evolutionary prototyping]].}}

{{term|[[stack (abstract data type)|stack]]}}
{{defn|Is an [[abstract data type]] that serves as a [[collection (abstract data type)|collection]] of elements, with two main principal operations:
* {{visible anchor|push}}, which adds an element to the collection, and 
* {{visible anchor|pop}}, which removes the most recently added element that was not yet removed.
The order in which elements come off a stack gives rise to its alternative name, LIFO (last in, first out). Additionally, a [[peek (data type operation)|peek]] operation may give access to the top without modifying the stack.&lt;ref&gt;By contrast, a simple QUEUE operates FIFO ([[first in, first out]]).&lt;/ref&gt; The name "stack" for this type of structure comes from the analogy to a set of physical items stacked on top of each other. This structure makes it easy to take an item off the top of the stack, while getting to an item deeper in the stack may require taking off multiple other items first.&lt;ref name="clrs"&gt;{{Introduction to Algorithms|3|page=232–233}}&lt;/ref&gt;}}

{{term|[[state (computer science)|state]]}}
{{defn|In [[information technology]] and computer science, a system is described as stateful if it is designed to remember preceding events or user interactions;&lt;ref&gt;{{cite web |url=http://whatis.techtarget.com/definition/stateless |title=What is stateless? - Definition from WhatIs.com |website=techtarget.com}}&lt;/ref&gt; the remembered information is called the state of the system.}}

{{term|[[statement (computer science)|statement]]}}
{{defn|In [[computer programming]], a statement is a [[Syntax (programming languages)|syntactic]] unit of an [[Imperative programming|imperative programming language]] that expresses some action to be carried out.&lt;ref&gt;{{cite web | url = http://www.webopedia.com/TERM/S/statement.html | title = statement | publisher = webopedia | access-date = 2015-03-03}}&lt;/ref&gt; A [[Computer program|program]] written in such a language is formed by a sequence of one or more statements. A statement may have internal components (e.g., [[Expression (computer science)|expressions]]).}}

{{term|[[computer data storage|storage]]}}
{{defn|Computer data storage is a technology consisting of [[computer]] components and [[Data storage device|recording media]] that are used to retain digital [[data (computing)|data]]. It is a core function and fundamental component of computers.&lt;ref name="Patterson"&gt;{{Cite book |title=Computer Organization and Design: The Hardware/Software Interface |last1=Patterson |first1=David A. |last2=Hennessy |first2=John L. |date=2005 |publisher=[[Morgan Kaufmann Publishers]] |isbn=1-55860-604-1 |edition=3rd |location=[[Amsterdam]] |oclc=56213091 |url-access=registration |url=https://archive.org/details/isbn_9781558606043 }}&lt;/ref&gt;{{rp|15–16}}}}

{{term|[[stream (computing)|stream]]}}
{{defn|Is a [[sequence]] of [[data element]]s made available over time. A stream can be thought of as items on a [[conveyor belt]] being processed one at a time rather than in large batches.}}

{{term|[[string (computer science)|string]]}}
{{defn|In [[computer programming]], a string is traditionally a [[sequence]] of [[Character (computing)|characters]], either as a [[literal (computer programming)|literal constant]] or as some kind of variable. The latter may allow its elements to be mutated and the length changed, or it may be fixed (after creation). A string is generally considered as a [[data type]] and is often implemented as an [[array data structure]] of [[byte]]s (or [[word (computer architecture)|word]]s) that stores a sequence of elements, typically characters, using some [[character encoding]]. ''String'' may also denote more general [[Array data type|arrays]] or other sequence (or [[List (abstract data type)|list]]) data types and structures.}}

{{term|[[structured storage]]}}
{{defn|A NoSQL (originally referring to "non-[[SQL]]" or "non-relational")&lt;ref&gt;http://nosql-database.org/ "NoSQL DEFINITION: Next Generation Databases mostly addressing some of the points : being non-relational, distributed, open-source and horizontally scalable".&lt;/ref&gt; [[database]] provides a mechanism for [[Computer data storage|storage]] and [[data retrieval|retrieval]] of data that is modeled in means other than the tabular relations used in [[relational database]]s. Such databases have existed since the late 1960s, but the name "NoSQL" was only coined in the early 21st century,&lt;ref&gt;Leavitt, Neal (2010). "Will NoSQL Databases Live Up to Their Promise?" (PDF). IEEE Computer. 43 (2): 12–14. doi:10.1109/MC.2010.58. S2CID 26876882.&lt;/ref&gt; triggered by the needs of [[Web 2.0]] companies.&lt;ref&gt;{{cite conference |title=History Repeats Itself: Sensible and NonsenSQL Aspects of the NoSQL Hoopla |first=C. |last=Mohan |conference=Proc. 16th Int'l Conf. on Extending Database Technology |year=2013 |url=http://openproceedings.eu/2013/conf/edbt/Mohan13.pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://www.wired.com/2012/01/amazon-dynamodb/ |title=Amazon Goes Back to the Future With 'NoSQL' Database |publisher=WIRED |date=2012-01-19 |access-date=2017-03-06}}&lt;/ref&gt; NoSQL databases are increasingly used in [[big data]] and [[real-time web]] applications.&lt;ref&gt;{{cite web |url= http://db-engines.com/en/blog_post/23 |title= RDBMS dominate the database market, but NoSQL systems are catching up |publisher= DB-Engines.com |date= 21 Nov 2013 |access-date= 24 Nov 2013 }}&lt;/ref&gt;  NoSQL systems are also sometimes called "Not only SQL" to emphasize that they may support [[SQL]]-like query languages or sit alongside SQL databases in [[polyglot persistence|polyglot-persistent]] architectures.&lt;ref&gt;{{cite web |url=http://searchdatamanagement.techtarget.com/definition/NoSQL-Not-Only-SQL |title=NoSQL (Not Only SQL) |quote=NoSQL database, also called Not Only SQL}}&lt;/ref&gt;&lt;ref&gt;{{cite web | url = http://martinfowler.com/bliki/NosqlDefinition.html | title = NosqlDefinition | first = Martin | last = Fowler | author-link = Martin Fowler (software engineer) | quote = many advocates of NoSQL say that it does not mean a "no" to SQL, rather it means Not Only SQL }}&lt;/ref&gt;}}

{{term|[[subroutine]]}}
{{defn|In [[computer programming]], a subroutine is a sequence of program instructions that performs a specific task, packaged as a unit. This unit can then be used in programs wherever that particular [[Task (computing)|task]] should be performed.  {{anchor|SUBROUTINE_DEFINITION}}Subroutines may be defined within programs, or separately in [[library (computer science)|libraries]] that can be used by many programs.  In different programming languages, a subroutine may be called a routine, subprogram, function, [[method (computing)|method]], or procedure. Technically, these terms all have different definitions. The generic, [[umbrella term]]  callable unit is sometimes used.&lt;ref name="U.S. Election Assistance Commission 2007"&gt;{{cite web
 |author      = U.S. Election Assistance Commission
 |title       = Definitions of Words with Special Meanings
 |work        = [[Voluntary Voting System Guidelines]]
 |year        = 2007
 |url         = http://www.eac.gov/vvsg/glossary.aspx
 |access-date  = 2013-01-14
 |author-link  = Election Assistance Commission
 |url-status     = dead
 |archive-url  = https://web.archive.org/web/20121208084203/http://www.eac.gov/vvsg/glossary.aspx
 |archive-date = 2012-12-08
}}&lt;/ref&gt;}}

{{term|[[symbolic computation]]}}
{{defn|In [[mathematics]] and [[computer science]],&lt;ref&gt;{{Cite web |title=ACM Association in computer algebra |url=https://www.sigsam.org/cca/}}&lt;/ref&gt; computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of [[algorithm]]s and [[software]] for manipulating [[expression (mathematics)|mathematical expressions]] and other [[mathematical object]]s. Although computer algebra could be considered a subfield of [[scientific computing]], they are generally considered as distinct fields because scientific computing is usually based on [[numerical computation]] with approximate [[floating point number]]s, while symbolic computation emphasizes ''exact'' computation with expressions containing [[variable (mathematics)|variable]]s that have no given value and are manipulated as symbols.}}

{{term|[[syntax (programming languages)|syntax]]}}
{{defn|The syntax of a [[computer language]] is the set of rules that defines the combinations of symbols that are considered to be correctly structured [[Statement (computer science)|statement]]s or [[Expression (computer science)|expression]]s in that language. This applies both to [[programming language]]s, where the document represents [[source code]], and to [[markup language]]s, where the document represents data.}}

{{term|[[syntax error]]}}
{{defn|Is an error in the [[Syntax (programming languages)|syntax]] of a sequence of characters or [[Token (parser)|tokens]] that is intended to be written in [[compiler|compile-time]]. A program will not compile until all syntax errors are corrected. For [[interpreted language]]s, however, a syntax error may be detected during [[Run time (program lifecycle phase)|program execution]], and an interpreter's error messages might not differentiate syntax errors from errors of other kinds. There is some disagreement as to just what errors are "syntax errors". For example, some would say that the use of an uninitialized variable's value in Java code is a syntax error, but many others would disagree&lt;ref&gt;[https://stackoverflow.com/questions/8803718/issue-of-syntax-or-semantics/8803765#8803765 Issue of syntax or semantics?]&lt;/ref&gt;&lt;ref&gt;[https://www.dummies.com/programming/java/semantic-errors-in-java/ John Paul Mueller,Semantic Errors in Java]&lt;/ref&gt; and would classify this as a [[Programming language#Static semantics|(static) semantic]] error.}}

{{term|[[system console]]}}
{{defn|The system console, computer console, root console, [[computer operator|operator]]'s console, or simply console is the text entry and display device for system administration messages, particularly those from the [[BIOS]] or [[boot loader]], the [[Kernel (computer science)|kernel]], from the [[init]] system and from the [[syslog|system logger]]. It is a physical device consisting of a keyboard and a screen, and traditionally is a [[text terminal]], but may also be a [[graphical terminal]]. System consoles are generalized to [[computer terminal]]s, which are abstracted respectively by [[virtual console]]s and [[terminal emulator]]s. Today communication with system consoles is generally done abstractly, via the [[standard streams]] ([[stdin]], [[stdout]], and [[stderr]]), but there may be system-specific interfaces, for example those used by the system kernel.}}
{{glossaryend}}

==T==
{{glossary}}
{{term|[[technical documentation]]}}
{{defn|In engineering, any type of [[documentation]] that describes handling, functionality, and architecture of a technical product or a product under [[product development|development]] or use.&lt;ref&gt;[http://www.transcom.de/transcom/en/technische-dokumentation.htm What is "technical documentation"?] at Transcom.de. Accessed February 25, 2013.&lt;/ref&gt;&lt;ref&gt;[http://www.tetras.sk/en/stranka/what-is-technical-documentation What is Technical Documentation?] {{Webarchive|url=https://archive.is/20130418132550/http://www.tetras.sk/en/stranka/what-is-technical-documentation |date=2013-04-18 }} at Tetras Translations. Accessed February 25, 2013.&lt;/ref&gt;&lt;ref&gt;[http://www.igcseict.info/theory/8/docs/index.html Documenting the New System] at IGCSE ICT. Accessed February 25, 2013.&lt;/ref&gt; The intended recipient for product technical documentation is both the (proficient) {{gli|end user}} as well as the administrator/service or maintenance technician. In contrast to a mere "cookbook" [[User guide|manual]], technical documentation aims at providing enough information for a user to understand inner and outer dependencies of the product at hand.}}

{{term|[[third-generation programming language]]}}
{{defn|A third-generation programming language (3GL) is a [[high-level programming language|high-level]] computer [[programming language]] that tends to be more machine-independent and programmer-friendly than the [[machine code]] of the [[First-generation programming language|first-generation]] and [[assembly language]]s of the [[Second-generation programming language|second-generation]], while having a less specific focus to the [[Fourth-generation programming language|fourth]] and [[Fifth-generation programming language|fifth]] generations.&lt;ref name="Computer Hope"&gt;[http://www.computerhope.com/jargon/num/1gl.htm "Computer Hope, Generation languages"]&lt;/ref&gt; Examples of common and historical third-generation programming languages are [[ALGOL]], [[BASIC]], [[C (programming language)|C]], [[COBOL]], [[Fortran]], [[Java (programming language)|Java]], and [[Pascal (programming language)|Pascal]].}}

{{term|[[top-down and bottom-up design]]}}
{{defn|}}

{{term|[[tree (data structure)|tree]]}}
{{defn|A widely used {{gli|abstract data type}} (ADT) that simulates a hierarchical [[tree structure]], with a root value and subtrees of children with a {{gli|parent node}}, represented as a set of linked {{gli|node|nodes}}.}}

{{term|[[type theory]]}}
{{defn|In mathematics, logic, and computer science, a type theory is any of a class of [[formal system]]s, some of which can serve as alternatives to [[set theory]] as a [[Foundations of mathematics|foundation for all mathematics]]. In type theory, every "term" has a "type" and operations are restricted to terms of a certain type.}}
{{glossaryend}}

==U==
{{glossary}}
{{term|[[upload]]}}
{{defn|In [[computer network]]s, to send [[Data (computing)|data]] to a remote system such as a [[server (computing)|server]] or another client so that the remote system can store a copy.&lt;ref&gt;{{Cite web|url=https://techterms.com/definition/upload|title=Upload Definition|website=techterms.com|language=en|access-date=2017-03-30}}&lt;/ref&gt; Contrast ''{{gli|download}}''.}}

{{term|[[URL|Uniform Resource Locator]] (URL)}}
{{ghat|Colloquially '''web address'''.{{sfnp|W3C|2009}}}}
{{defn|A reference to a [[web resource]] that specifies its location on a [[computer network]] and a mechanism for retrieving it. A URL is a specific type of [[Uniform Resource Identifier]] (URI),&lt;ref&gt;{{Cite web|url=https://zzz.buzz/2017/09/19/forward-and-backslashes-in-urls/|title=Forward and Backslashes in URLs|website=zzz.buzz|language=en|access-date=2018-09-19}}&lt;/ref&gt;{{sfnp|RFC 3986|2005}} although many people use the two terms interchangeably.{{sfnp|Joint W3C/IETF URI Planning Interest Group|2002}}{{efn|A URL implies the means to access an indicated resource and is denoted by a protocol or an access mechanism, which is not true of every URI.{{sfnp|RFC 2396|1998}}{{sfnp|Joint W3C/IETF URI Planning Interest Group|2002}}  Thus &lt;code&gt;&lt;nowiki&gt;http:&lt;/nowiki&gt;//www.example.com&lt;/code&gt; is a URL, while &lt;code&gt;www.example.com&lt;/code&gt; is not.&lt;ref&gt;{{Cite web|url=https://danielmiessler.com/study/url-uri/#gs.Hs64zOs|title=The Difference Between URLs and URIs|last=Miessler|first=Daniel}}&lt;/ref&gt;}} URLs occur most commonly to reference web pages ([[http]]), but are also used for file transfer ([[File Transfer Protocol|ftp]]), email ([[mailto]]), database access ([[Java Database Connectivity|JDBC]]), and many other applications.}}

{{term|[[user (computing)|user]]}}
{{defn|Is a person who utilizes a [[computer]] or [[Computer network|network]] [[Service (systems architecture)|service]]. Users of computer systems and software products generally lack the technical expertise required to fully understand how they work.&lt;ref name=":0"&gt;[[Jargon File]] entry for {{cite web |url=http://catb.org/jargon/html/U/user.html |title=User |access-date=November 7, 2010}}&lt;/ref&gt; [[Power user]]s use advanced features of programs, though they are not necessarily capable of [[computer programming]] and [[system administration]].}}

{{term|[[user agent]]}}
{{defn|Software (a {{gli|software agent}}) that acts on behalf of a {{gli|user}}, such as a [[web browser]] that "retrieves, renders and facilitates end user interaction with Web content".&lt;ref&gt;{{cite web|url=https://www.w3.org/WAI/UA/work/wiki/Definition_of_User_Agent |title=W3C Definition of User Agent |publisher=www.w3.org |date=16 June 2011 |access-date=2018-10-20}}&lt;/ref&gt; An email reader is a [[mail user agent]].}}

{{term|[[user interface]] (UI)}}{{anchor|user interface}}
{{defn|The space where interactions between humans and machines occur. The goal of this interaction is to allow effective operation and control of the machine from the human end, whilst the machine simultaneously feeds back information that aids the operators' [[decision-making]] process. Examples of this broad concept of user interfaces include the interactive aspects of computer [[operating system]]s, hand [[tools]], [[heavy machinery]] operator controls, and [[Unit operation|process]] controls. The design considerations applicable when creating user interfaces are related to or involve such disciplines as [[ergonomics]] and [[psychology]].}}

{{term|[[user interface design]]}}
{{ghat|Also '''user interface engineering'''.}}
{{defn|The design of {{gli|user interface|user interfaces}} for machines and {{gli|software}}, such as computers, home appliances, mobile devices, and other electronic devices, with the focus on maximizing [[usability]] and the [[user experience]]. The goal of user interface design is to make the user's interaction as simple and efficient as possible, in terms of accomplishing user goals ([[user-centered design]]).}}
{{glossaryend}}

==V==
{{glossary}}
{{term|[[variable (computer science)|variable]]}}
{{defn|In {{gli|computer programming}}, a variable, or scalar, is a storage location (identified by a [[memory address]]) paired with an associated symbolic name (an ''{{gli|identifier}}''), which contains some known or unknown quantity of information referred to as a ''{{gli|value}}''. The variable name is the usual way to {{gli|reference}} the stored value, in addition to referring to the variable itself, depending on the context. This separation of name and content allows the name to be used independently of the exact information it represents. The identifier in computer {{gli|source code}} can be [[Name binding|bound]] to a value during [[Run time (program lifecycle phase)|run time]], and the value of the variable may therefore change during the course of {{gli|execution|program execution}}.&lt;ref&gt;{{citation | title=Compilers: Principles, Techniques, and Tools | pages=26–28| title-link=Compilers: Principles, Techniques, and Tools}}&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Knuth |first=Donald |date=1997 |title=The Art of Computer Programming |volume=1 |edition=3rd |location=Reading, Massachusetts |publisher=Addison-Wesley |pages=3–4 |isbn=0-201-89683-4 }}&lt;/ref&gt;}}

{{term|[[virtual machine]] (VM)}}{{anchor|virtual machine}}
{{defn|An {{gli|emulator|emulation}} of a computer system. Virtual machines are based on {{gli|computer architecture|computer architectures}} and attempt to provide the same functionality as a physical computer. Their implementations may involve specialized hardware, software, or a combination of both.}}

{{term|[[V-Model (software development)|V-Model]]}}
{{defn|A [[software development process]] that may be considered an extension of the {{gli|waterfall model}}, and is an example of the more [[V-model|general V-model]]. Instead of moving down in a linear way, the process steps are bent upwards after the {{gli|source code|coding}} phase, to form the typical V shape. The V-Model demonstrates the relationships between each phase of the development life cycle and its associated phase of [[Software testing|testing]]. The horizontal and vertical axes represent time or project completeness (left-to-right) and level of abstraction (coarsest-grain abstraction uppermost), respectively.&lt;ref&gt;[[Kevin Forsberg]] and [[Harold Mooz]], "The Relationship of System Engineering to the Project Cycle", in Proceedings of the First Annual Symposium of National Council on System Engineering, October 1991: 57–65.&lt;/ref&gt;}}
{{glossaryend}}

==W==
{{glossary}}
{{term|[[waterfall model]]}}
{{defn|A breakdown of project activities into linear [[sequence|sequential]] phases, where each phase depends on the deliverables of the previous one and corresponds to a specialisation of tasks.  The approach is typical for certain areas of [[engineering design]]. In [[software development process|software development]], it tends to be among the less iterative and flexible approaches, as progress flows in largely one direction ("downwards" like a [[waterfall]]) through the phases of conception, initiation, [[analysis]], [[Software design|design]], [[Software construction|construction]], [[Software testing|testing]], [[Implementation|deployment]] and [[software maintenance|maintenance]].}}

{{term|[[WAV|Waveform Audio File Format]]}}
{{ghat|Also '''WAVE''' or '''WAV''' due to its [[filename extension]].}}
{{defn|An [[audio file format]] standard, developed by [[Microsoft]] and [[International Business Machines|IBM]], for storing an audio bitstream on [[personal computer|PCs]]. It is an application of the [[Resource Interchange File Format]] (RIFF) [[bitstream format]] method for storing data in "chunks", and thus is also close to the [[8SVX]] and the [[Audio Interchange File Format|AIFF]] format used on [[Amiga]] and [[Apple Macintosh|Macintosh]] computers, respectively. It is the main format used on [[Microsoft Windows]] systems for raw and typically uncompressed audio. The usual bitstream encoding is the [[linear pulse-code modulation]] (LPCM) format.}}

{{term|[[web crawler]]}}
{{ghat|Also '''spider''', '''spiderbot''', or simply '''crawler'''.}}
{{defn|An {{gli|Internet bot}} that systematically browses the [[World Wide Web]], typically for the purpose of [[Web indexing]] (''web spidering'').}}

{{term|[[Wi-Fi]]}}
{{defn|A family of wireless networking technologies, based on the [[IEEE 802.11]] family of standards, which are commonly used for [[Wireless LAN|local area network]]ing of devices and [[Internet]] access. ''Wi{{nbh}}Fi'' is a trademark of the non-profit [[Wi-Fi Alliance]], which restricts the use of the term ''Wi-Fi Certified'' to products that successfully complete [[Interoperability Solutions for European Public Administrations|interoperability]] certification testing.&lt;ref&gt;{{cite web|url=http://www.webopedia.com/TERM/W/Wi_Fi.html|title=What is Wi-Fi (IEEE 802.11x)? A Webopedia Definition|last=Beal|first=Vangie|website=Webopedia|archive-url=https://web.archive.org/web/20120308123721/http://www.webopedia.com/term/w/wi_fi.html|archive-date=2012-03-08|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.theguardian.com/technology/blog/2007/may/21/thedangersof|title=The dangers of Wi-Fi radiation (updated)|first=Jack|last=Schofield|date=21 May 2007|via=www.theguardian.com}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.wi-fi.org/certification|title=Certification &amp;#124; Wi-Fi Alliance|website=www.wi-fi.org}}&lt;/ref&gt;}}
{{glossaryend}}

==X==
{{glossary}}
{{term|[[XHTML]]}}
{{ghat|Abbreviaton of '''eXtensible HyperText Markup Language'''.}}
{{defn|Part of the family of [[XML]] [[markup language]]s. It mirrors or extends versions of the widely used [[HyperText Markup Language]] (HTML), the language in which [[web page]]s are formulated.}}
{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==See also==
*[[Outline of computer science]]

==References==
{{reflist}}

==Notes==
{{reflist|group=lower-alpha}}

{{Computer science}}
{{Software engineering}}
{{Glossaries of science and engineering}}

[[Category:Computer science| ]]
[[Category:Glossaries of computers|science]]
[[Category:Glossaries of science|Computer science]]
[[Category:Computers]]</text>
      <sha1>cjvbmuuupuo58mug6ekd742xxgr071m</sha1>
    </revision>
  </page>
  <page>
    <title>Category:History of computer science</title>
    <ns>14</ns>
    <id>30730499</id>
    <revision>
      <id>992053069</id>
      <parentid>992052693</parentid>
      <timestamp>2020-12-03T06:22:19Z</timestamp>
      <contributor>
        <username>SomeRandomPasserby</username>
        <id>24207291</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="246" xml:space="preserve">{{Cat main|History of computer science}}
{{DEFAULTSORT:Computer Science, History}}
[[Category:Computer science| History]]
[[Category:History of computing| History]]
[[Category:History of mathematics]]
[[Category:History of science by discipline]]</text>
      <sha1>mfy9xpxkm91nrm5o8q3gb31smjcgdtg</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Information theory</title>
    <ns>14</ns>
    <id>694025</id>
    <revision>
      <id>993882292</id>
      <parentid>993879913</parentid>
      <timestamp>2020-12-13T00:23:18Z</timestamp>
      <contributor>
        <username>Dimadick</username>
        <id>24198</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="597" xml:space="preserve">{{Commons category|Information theory}}
{{catdiffuse}}
{{Cat main|Information theory}}
Articles relating to [[information theory]], which studies the [[quantification (science)|quantification]], [[computer data storage|storage]], and [[telecommunication|communication]] of [[information]]. 
{{CatAutoTOC}}

[[Category:Computer science]]
[[Category:Cybernetics]]
[[Category:Formal sciences]]
[[Category:Information|Theory]]
[[Category:Information Age]]
[[Category:Claude Shannon]]
[[Category:Statistical theory]]
[[Category:Telecommunications engineering]]
[[Category:Theoretical computer science]]</text>
      <sha1>42ut7fheh9j9pjva4ab7fbxbry8zx2r</sha1>
    </revision>
  </page>
  <page>
    <title>Information processing</title>
    <ns>0</ns>
    <id>315578</id>
    <revision>
      <id>1002467157</id>
      <parentid>998579442</parentid>
      <timestamp>2021-01-24T16:26:06Z</timestamp>
      <contributor>
        <username>Shiningmatcha</username>
        <id>33525612</id>
      </contributor>
      <minor/>
      <comment>Edited short description</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="15205" xml:space="preserve">{{other uses|Information processor|Information processing theory}}
{{short description|Psychological process by which input information is analysed or transformed to produce information as output}}
{{Multiple issues|
{{expert needed|psychology|ex2=philosophy|ex3=computer science|ex4=cognitive science|date=February 2010}}
{{original research|date=September 2009}}
{{more footnotes|date=February 2012}}
}}

'''Information processing''' is the change (processing) of [[information]] in any manner detectable by an [[observation|observer]].  As such, it is a  process that ''describes'' everything that happens (changes) in the [[universe]], from the falling of a rock (a change in position) to the printing of a text file from a digital computer system. In the latter case, an [[information processor]] (the printer) is changing the [[content format|form]] of presentation of that text file (from bytes to glyphs).The computers up to this period function on the basis of programmes saved in the memory, they have no intelligence of their own.

==In cognitive psychology==
Within the field of [[cognitive psychology]], information processing is an approach to the goal of understanding human thinking in relation to how they process the same kind of information as computers (Shannon &amp; Weaver, 1963).  It arose in the 1940s and 1950s, after World War II (Sternberg &amp; Sternberg, 2012). The approach treats [[cognition]] as essentially [[Computing|computational]] in nature, with ''mind'' being the ''software'' and the brain being the ''hardware''. The information processing approach in psychology is closely allied to the [[computational theory of mind]] in philosophy; it is also related, though not identical, to [[Cognitivism (psychology)|cognitivism]] in psychology and [[Functionalism (philosophy of mind)|functionalism]] in philosophy (Horst, 2011).

===Two types===
Information processing  may  be '''vertical''' or '''horizontal''', either of which  may be '''centralized''' or [[decentralized]] ('''distributed'''). The [[horizontal distributed processing]] approach of the mid-1980s became popular under the name [[connectionism]]. The connectionist network is made up of different nodes, and it works by a "priming effect," and this happens when a "prime node activates a connected node" (Sternberg &amp; Sternberg, 2012). But "unlike in [[semantic network]]s, it is not a single node that has a specific meaning, but rather the knowledge is represented in a combination of differently activated nodes"(Goldstein, as cited in Sternberg, 2012).

===Models and theories===
There are several proposed models or theories that describe the way in which we process information.
Every individual has different information overload point with same information load, because individuals have different information-processing capacity (Eppler and Mengis, 2004)

====Sternberg's triarchic theory of intelligence====
Sternberg's [[Triarchic theory of intelligence|theory of intelligence]] is made up of three different components: creative, analytical, and practical abilities (Sternberg &amp; Sternberg, 2012). Creativeness is the ability to have new original ideas, and being analytical can help a person decide whether the idea is a good one or not. "Practical abilities are used to implement the ideas and persuade others of their value" (Sternberg &amp; Sternberg, 2012 p.&amp;nbsp;21). In the middle of Sternberg's theory is cognition and with that is information processing. In Sternberg's theory, he says that information processing is made up of three different parts, metacomponents, performance components, and knowledge-acquisition components (Sternberg &amp; Sternberg, 2012). These processes move from higher-order executive functions to lower-order functions. Metacomponents are used for planning and evaluating problems, while performance components follow the orders of the metacomponents, and the knowledge-acquisition component learns how to solve the problems (Sternberg &amp; Sternberg, 2012). This theory in action can be explained by working on an art project. First is a decision about what to draw, then a plan and a sketch. During this process there is simultaneous monitoring of the process, and whether it is producing the desired accomplishment. All these steps fall under the metacomponent processing, and the performance component is the art. The knowledge-acquisition portion is the learning or improving drawing skills.

====Information processing model: the working memory====
[[File:Information Processing Model - Atkinson &amp; Shiffrin.jpg|alt=information processing model with sensory memory, working, memory and long-term memory|thumb|400x400px|Adapted from Atkinson, R.C. and Shiffrin, R.M. (1968). 'Human memory: A Proposed System and its Control Processes'.]]
Information processing has been described as "the sciences concerned with gathering, manipulating, storing, retrieving, and classifying recorded information".&lt;ref&gt;{{cite web | url=http://www.thefreedictionary.com/information+processing | title=Definition of information processing | work=The Free Dictionary | access-date=July 26, 2016 |year=2012|publisher= Princeton University}}&lt;/ref&gt; According to the [[Atkinson–Shiffrin memory model|Atkinson-Shiffrin memory model]] or multi-store model, for information to be firmly implanted in memory it must pass through three stages of mental processing: sensory memory, short-term memory, and long-term memory.&lt;ref&gt;{{Cite book|title=The Psychology of Learning and Motivation|last1=Atkinson|first1=R.C.|last2=Shiffrin|first2=R.M.|publisher=Academic Press|year=1968|location=New York|pages=89–195|chapter=Human memory: A proposed system and its control processes}}&lt;/ref&gt;

An example of this is the working memory model.  This includes the central executive, phonologic loop, episodic buffer, visuospatial sketchpad, verbal information, long term memory, and visual information (Sternberg &amp; Sternberg, 2012).  The central executive is like the secretary of the brain.  It decides what needs attention and how to respond.The central executive then leads to three different subsections.  The first is phonological storage, subvocal rehearsal, and the phonological loop.  These sections work together to understand words, put the information into memory, and then hold the memory.  The result is verbal information storage.  The next subsection is the visuospatial sketchpad which works to store visual images.  The storage capacity is brief but leads to understanding of visual stimuli.  Finally, there is an episodic buffer.  This section is capable of taking information and putting it into long-term memory.  It is also able to take information from the phonological loop and visuospatial sketchpad, combining them with long-term memory to make "a unitary episodic representation (Sternberg &amp; Sternberg, 2012).  
In order for these to work, the sensory register takes in via the five senses: visual, auditory, tactile, olfactory, and taste. These are all present since birth and are able to handle simultaneous processing (e.g., food – taste it, smell it, see it). In general, learning benefits occur when there is a developed process of pattern recognition. The sensory register has a large capacity and its behavioral response is very short (1–3 seconds). 
Within this model, sensory store and short term memory or working memory has limited capacity. Sensory store is able to hold very limited amounts of information for very limited amounts of time.  This phenomenon is very similar to having a picture taken with a flash.  For a few brief moments after the flash goes off, the flash it seems to still be there.  However, it is soon gone and there is no way to know it was there (Sternberg &amp; Sternberg, 2012). Short term memory holds information for slightly longer periods of time, but still has a limited capacity. According to Linden (2007), "The capacity of STM had initially been estimated at "seven plus or minus two" items (Miller 1956), which fits the observation from neuropsychological testing that the average digit span of healthy adults is about seven (Cowan and others 2005). However, it emerged that these numbers of items can only be retained if they are grouped into so-called chunks, using perceptual or conceptual associations between individual stimuli." Its duration is of 5–20 seconds before it is out of the subject's mind. This occurs often with names of people newly introduced to. Images or information based on meaning are stored here as well, but it decays without rehearsal or repetition of such information. 
On the other hand, long-term memory has a potentially unlimited capacity (Sternberg &amp; Sternberg, 2012) and its duration is as good as indefinite. Although sometimes it is difficult to access, it encompasses everything learned until this point in time. One might become forgetful or feel as if the information is on the [[tip of the tongue]].

====Cognitive development theory====
Another approach to viewing the ways in which information is processed in humans was suggested by [[Jean Piaget]] in what is called the ''Piaget's Cognitive Development Theory'' (Presnell, 1999). Piaget developed his model based on development and growth. He identified four different stages between different age brackets characterized by the type of information and by a distinctive thought process. The four stages are: the sensorimotor (from birth to 2 years), preoperational (2–6 years), concrete operational (6–11 years), and formal operational periods (11 years and older). During the sensorimotor stage, newborns and toddlers rely on their senses for information processing to which they respond with reflexes. In the preoperational stage, children learn through imitation and remain unable to take other people's point of view. The concrete operational stage is characterized by the developing ability to use logic and to consider multiple factors to solve a problem. The last stage is the formal operational, in which preadolescents and adolescents begin to understand abstract concepts and to develop the ability to create arguments and counter arguments.

Furthermore, adolescence is characterized by a series of changes in the biological, cognitive, and social realms. In the cognitive area, it is worth noting that the brain's prefrontal cortex as well as the limbic system undergoes important changes. The prefrontal cortex is the part of the brain that is active when engaged in complicated cognitive activities such as planning, generating goals and strategies, intuitive decision-making, and [[metacognition]] (thinking about thinking). This is consistent with Piaget's last stage of formal operations (McLeod, 2010). The prefrontal cortex becomes complete between adolescence and early adulthood. The limbic system is the part of the brain that modulates reward sensitivity based on changes in the levels of neurotransmitters (e.g., dopamine) and emotions.

In short, cognitive abilities vary according to our development and stages in life. It is at the adult stage that we are better able to be better planners, process and comprehend abstract concepts, and evaluate risks and benefits more aptly than an adolescent or child would be able to.

In computing, '''information processing''' broadly refers to the use of algorithms to transform data—the defining activity of computers;&lt;ref&gt;{{cite book | title=Dictionary of Computing | publisher=Oxford University Press | isbn=9780192800466 | edition=4th | first=Valerie | last=Illingworth | series=Oxford Paperback Reference | page=[https://archive.org/details/dictionaryofcomp00illi/page/241 241] | date=11 December 1997 | url-access=registration | url=https://archive.org/details/dictionaryofcomp00illi/page/241 }}&lt;/ref&gt; indeed, a broad computing professional organization is known as the International Federation for Information Processing ([[International Federation for Information Processing|IFIP]]). It is essentially synonymous with the terms [[data processing]] or [[computation]], although with a more general connotation.&lt;ref name="Ralston2000"&gt;{{cite book|author=Anthony Ralston|title=Encyclopedia of computer science|url=https://books.google.com/books?id=yQ9LAQAAIAAJ|year=2000|publisher=Nature Pub. Group|isbn=978-1-56159-248-7}}&lt;/ref&gt;

== See also ==
* [[Information engineering (field)|Information engineering]]
* [[Information processing system]]
* [[Computer data processing]]
* [[Information processing technology and aging]]

==References==
{{Reflist}}
* Eppler, M.J., Mengis, J., 2004. The Concept of Information Overload : A Review of Literature from Organization Science, Accounting, Marketing, MIS, and Related Disciplines 325–344.

== Bibliography ==
*{{cite magazine|author1=Denning, P. J.|author2=Bell, T.|name-list-style=amp|year=2012|title=The Information Paradox. American Scientist|volume=100|issue=6|pages=470–477|url=https://www.americanscientist.org/article/the-information-paradox|doi= 10.1511/2012.99.470}}
*{{cite encyclopedia|author=Horst, Steven|title=The Computational Theory of Mind|encyclopedia=The Stanford Encyclopedia of Philosophy|edition=Spring 2011|date=Spring 2011|editor=Edward N. Zalta|url =http://plato.stanford.edu/archives/spr2011/entries/computational-mind/}}
* {{cite journal|author1=Lehrl, S.|author2=Fischer, B.|name-list-style=amp|year=1990|title=A Basic Information Psychological Parameter (BIP) for the Reconstruction of Concepts of Intelligence|journal=European Journal of Personality|volume=4|issue=4|pages=259–286|url=http://www.v-weiss.de/lehrl-full.html|doi=10.1002/per.2410040402}}
* {{cite journal|author=Linden, D. E.|year=2007|title=The working memory networks of the human brain|journal=The Neuroscientist|volume=13|issue=3|pages=257–269|doi=10.1177/1073858406298480|pmid=17519368|s2cid=23799348}}
*{{cite book|author1=McGonigle, D.|author2=Mastrian, K.|name-list-style=amp|year=2011|title=Introduction to information, information science, and information systems|edition=2|page=22|publisher=Jones &amp; Bartlett|url=http://samples.jbpub.com/9781449631741/92367_CH02_017_032.pdf}}
*{{cite web|author=McLeod, S. A.|year=2010|title=Formal operational stage|url=http://www.simplypsychology.org/formal-operational.html}}
*{{cite book|author=Nake, F.|author-link=Frieder Nake|year=1974|title=Ästhetik als Informationsverarbeitung|trans-title=[[Aesthetics]] as information processing|language=de|publisher=Springer|isbn=978-3-211-81216-7}}, {{ISBN|978-3-211-81216-7}}
*{{cite web|author=Presnell, F. |year=1999|title=Jean Piaget|url=http://www.muskingum.edu/~psych/psycweb/history/piaget.htm}}
*{{cite book|author1=Shannon, C.|author2=Weaver, W.|name-list-style=amp|year=1963|title=The mathematical theory of communication|location=Urbana, IL|publisher=University of Illinois Press}}
*{{cite book|author=Steinberg, L.|year=2010|title=Adolescence|edition= 9th|location=New York, NY|publisher=McGraw Hill}}
*{{cite book|author1=Sternberg, R. J.|author2=Sternberg, K.|name-list-style=amp|year=2012|title=Cognitive psychology|edition=6th|pages=21, 193–205, 212–213|location=Belmont, California|publisher=Wadsworth}}

{{Informatics}}
{{Authority control}}

[[Category:Cognitive science]]
[[Category:Computer science]]</text>
      <sha1>a3v7mfigm7c70n421i069jovzhlhx2e</sha1>
    </revision>
  </page>
  <page>
    <title>Stewart Nelson</title>
    <ns>0</ns>
    <id>3506655</id>
    <revision>
      <id>996926354</id>
      <parentid>996926210</parentid>
      <timestamp>2020-12-29T05:51:46Z</timestamp>
      <contributor>
        <username>Gjs238</username>
        <id>486612</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2129" xml:space="preserve">{{for|the English footballer|Stuart Nelson}}
'''Stewart Nelson''' is an American mathematician and programmer from [[The Bronx]] who co-founded [[Systems Concepts]].

From a young age, Nelson was tinkering with electronics, aided and abetted by his father who was a physicist that had become an engineer. Nelson enrolled at [[Massachusetts Institute of Technology|MIT]] in 1963 and quickly became known for hooking up the [[AI Lab]]'s [[PDP-1]] (and later the [[PDP-6]]) to the telephone network, making him one of the first [[phreaker]]s. Nelson later accomplished other feats like hardwiring additional instructions into the PDP-1. Nelson was hired by [[Ed Fredkin]]'s [[Information International Inc.]] at the urging of [[Marvin Minsky]] to work on [[PDP-7]] programs at the [[MIT Computer Science and Artificial Intelligence Laboratory]].&lt;ref name=MITClassNotes&gt;{{cite web|url=http://web.mit.edu/quentin/Documents/Class%20Notes/STS.001/|access-date=September 24, 2019}}&lt;/ref&gt;

Nelson was known as a brilliant software programmer. He was influential in LISP, the assembly instructions for the [[Digital Equipment Corporation]] PDP, and a number of other systems. &lt;ref&gt;{{cite book|last=Levy|first=Steven|title=Hackers: Heroes of the Computer Revolution|year=1984|publisher=Dell Publishing Co., Inc|isbn=0-440-13405-6|chapter=Chapter 5: The Midnight Computer Wiring Society}}&lt;/ref&gt;

The group of young hackers was known for working on systems after hours. One night, Nelson and others decided to rewire MIT’s PDP-1 as a prank. Later, [[Margaret Hamilton (software engineer)|Margaret Hamilton]] tried to use the DEC-supplied DECAL assembler on the machine and it crashed repeatedly. 

==References==
{{reflist}}

{{DEFAULTSORT:Nelson, Stewart}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:American mathematicians]]
[[Category:Computer programmers]]
[[Category:Artificial intelligence]]
[[Category:Digital Equipment Corporation people]]
[[Category:Computer science]]
[[Category:People from the Bronx]]


{{US-compu-bio-stub}}</text>
      <sha1>kj9w31v3bg9n6n85mt6khaspjro9p97</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Software</title>
    <ns>14</ns>
    <id>691633</id>
    <revision>
      <id>999842284</id>
      <parentid>999841914</parentid>
      <timestamp>2021-01-12T06:21:38Z</timestamp>
      <contributor>
        <username>PohranicniStraze</username>
        <id>13080272</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/2402:3A80:1862:2195:0:3C:3F6B:8E01|2402:3A80:1862:2195:0:3C:3F6B:8E01]] ([[User talk:2402:3A80:1862:2195:0:3C:3F6B:8E01|talk]]) to last version by Sm8900</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1073" xml:space="preserve">{{catdiffuse}}
{{JEL code|C88}}
{{Commons category|Software}}
{{Infobox catalog
|DDC = 
|LCC =
|UDC = 0 004.4
}}

This [[Wikipedia:Category|category]] is about all aspects of '''[[software]]''' (SW) which here is taken to include the following categories:
*[[:category:application software|Application software]] ([[application software]]: office suites, word processors, spreadsheets, etc.)
*[[:category:system software|System software]] ([[system software]]: operating systems, device drivers, desktop environments, etc.)
*[[:category:computer programming tools|Computer programming tools]] ([[programming tools]]: assemblers, compilers, linkers, etc.)

The first two of these are classified for running software on computers (i.e., actually ''using'' the computers), while the last one is about developing the software in the first place.

{{cat main|Software}}

[[Category:Computer science]]
[[Category:Computing]]
[[Category:Digital media]]
[[Category:Intellectual works]]
[[Category:Software development| ]]
[[Category:Software engineering| ]]
[[Category:Technology]]</text>
      <sha1>7o5ym3xcu4h4fb30lpm5thqdnfawl2d</sha1>
    </revision>
  </page>
  <page>
    <title>Psychoinformatics</title>
    <ns>0</ns>
    <id>66760902</id>
    <revision>
      <id>1007100491</id>
      <parentid>1007100004</parentid>
      <timestamp>2021-02-16T13:33:39Z</timestamp>
      <contributor>
        <username>Ozzie10aaaa</username>
        <id>17794675</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1848" xml:space="preserve">'''Psychoinformatics''' is an emerging interdisciplinary field that uses principles from [[computer science]] for the acquisition, organization, and synthesis of data collected from [[psychology]] to reveal information about psychological traits such as [[personality]] and [[Mood (psychology)|mood]]. &lt;ref&gt;{{cite journal |last1=Yarkani |first1= Tal|date=3 December 2012|title=Psychoinformatics: New Horizons at the Interface of the Psychological and Computing Sciences |url=https://journals.sagepub.com/doi/10.1177/0963721412457362 |journal=Psychoinformatics: New Horizons at the Interface of the Psychological and Computing Sciences |volume= |issue= |pages= |doi= |access-date=}}&lt;/ref&gt;

[[Psychology]] has historically relied on experiments and questionnaires in order to collect data. These methods face several disadvantages, namely that experiments often consist of a small quantity of users (who must be incentivized to participate) and self-reported
questionnaires and interviews are subject to bias and unreliable memory.&lt;ref name="rf"&gt;{{cite journal |last1=Montag |first1= Christian|last2=Duke |first2=Eilish |last3=Markowetz |first3=Alexander|date=16 May 2016 |title=Toward Psychoinformatics: Computer Science Meets Psychology |url=https://pubmed.ncbi.nlm.nih.gov/27403204/ |journal=Computational and Mathematical Methods in Medicine |volume= |issue= |pages= |doi= |access-date=}}&lt;/ref&gt; Psychoinformatics solves these problems by storing [[Big Data]] related to psychology (such as communications on [[smartphone]]s or [[social media]] websites) and then [[data mining]] for relevant psychological information.&lt;ref name=rf/&gt;
==See also==
* [[Bioinformatics]]
* [[Neuroinformatics]]
* [[Psychometrics]]
* [[Quantitative psychology]]

==References==
{{reflist}}



[[Category:Computer science]]
[[Category:Psychology]]
[[Category:Medicine]]</text>
      <sha1>btqvr8ahba1mzbnqnfwvy6dxe1nroyg</sha1>
    </revision>
  </page>
  <page>
    <title>Adenike Osofisan</title>
    <ns>0</ns>
    <id>56734456</id>
    <revision>
      <id>1015197032</id>
      <parentid>1009319032</parentid>
      <timestamp>2021-03-31T03:38:35Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 2 sources and tagging 0 as dead.) #IABot (v2.0.8</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7561" xml:space="preserve">{{Infobox officeholder
| name                = Adenike Osofisan
| image               =
| honorific_suffix          = FNIM, FNCS, CITP
| office1             = Professor of [[Computer Science]] at [[University of Ibadan]]
| term_start1         = 2006    
| term_end1           = present
| successor1      =
| office2             = 
| term_start2         = 
| term_end2           = 
|predecessor2      = 
| office3             = 
| term_start3         =  
| term_end3           = 
| predecessor3        = 
| known_for          = Being the first African woman to become a Computer science professor
| birth_date          = {{birth date and age|df=yes|1950|03|11}}
| birth_place         =  [[Osogbo]]
| alma_mater          = '''[[Obafemi Awolowo University]]'''&lt;br/&gt; {{small|([[Bachelor of Science]] in [[Computer Science|Computer Science &amp; Economics]])}}&lt;br/&gt;'''[[Georgia Institute of Technology]]'''&lt;br/&gt;{{small|([[Master of Science| Master of Science in Information and Computer Science]])}}&lt;br/&gt;'''[[Obafemi Awolowo University]]'''&lt;br/&gt;{{small|([[Doctor of Philosophy]] in Computer Science)}}&lt;br/&gt;'''[[University of Ibadan]]'''&lt;br/&gt;{{small|([[Master of Business Administration|MBA]] in Account and Finance)}}
| birth_name         = Adenike Oyinlola Osofisan
| residence               =
}}

'''Adenike Osofisan''' (born 11 March 1950) is a Nigerian professor of [[Computer science]], who specialize in [[data mining]] and [[knowledge management]]. She is the first Nigerian woman to hold a PhD in Computer science, a feat she accomplished in 1989. In 2006, she became a full professor at [[University of Ibadan]], a promotion that made her the first African woman to become a Computer science professor.&lt;ref&gt;{{Cite web |url=http://nigeriacomputers.com/tech-news/professor-mrs-adenike-osofisan-special-recognition-award-citation/ |title=Professor (Mrs) Adenike Osofisan – Special Recognition Award Citation |access-date=2018-03-03 |archive-date=2018-03-08 |archive-url=https://web.archive.org/web/20180308113908/http://nigeriacomputers.com/tech-news/professor-mrs-adenike-osofisan-special-recognition-award-citation/ |url-status=dead }}&lt;/ref&gt;

== Early life and education ==
Osofisan had her secondary education at Fiwasaiye Girls' Grammar School, [[Akure]] and [[Comprehensive High School, Aiyetoro|Comprehensive High School]], [[Ayetoro]] (1968). Between 1971 and 1976, she got her first degree from [[University of Ile-Ife]], obtaining a federal government scholarship throughout most of her university years. She then proceeded to [[Georgia Institute of Technology]] in 1978, obtaining a master's degree in [[Information and Computer Science]] in 1979. Her PhD thesis on ''Data Processing Model for a Multi-access Computer Communication Network'' was completed in 1989 at the [[Obafemi Awolowo University]] under the supervision of [[Adebayo Akinde]]. In 1993, she completed her [[Master of Business Administration]] in [[Financial accounting|Accounts and Finance]] from [[University of Ibadan]], with her dissertation on ''An Asset Portfolio Management Model for Nigerian Commercial Banks: A Case Study'', graduating as the best MBA student for the year.&lt;ref&gt;{{Cite web |url=http://sci.ui.edu.ng/sites/default/files/Nike%20CV%202013(2)_0.pdf |title=Adenike Osofisan |website=[[University of Ibadan]] |access-date=2018-03-03}}&lt;/ref&gt;

== Career ==
=== Lecturing career ===
Osofisan began her lecturing career at [[The Polytechnic, Ibadan]] in 1979. Over the next few years, she rose to become the dean of Faculty of Science at the same institution. In 1999, she joined [[University of Ibadan]] and immediately began to serve as the acting head of department of computer science. In 2003, she earned promotion to the rank of associate professor. She earned a full professor chair in 2006. She has also had visiting professorial stints at [[Lagos State University]].

== Memembership of Professional Bodies ==
&lt;nowiki&gt;*&lt;/nowiki&gt;Member Board of Trustees of Nigeria Internet Registration Association (NIRA)

&lt;nowiki&gt;*&lt;/nowiki&gt;Former Member of Nigeria Mathematical Centre and Nigeria Institute of Management (NIM) Councils and now current

&lt;nowiki&gt;*&lt;/nowiki&gt;Member of their Academic Boards.

&lt;nowiki&gt;*&lt;/nowiki&gt;Member of Africa Academic Board of SAP (Systems, Applications, and Products in Data Processing).

Currently, Adenike is the Director of University of Ibadan School of Business (UISB) as the foundation Director. She was elected as the First Female Provost Nigeria Computer Society College of Fellows in July 2017.

=== Recognition ===
As a pioneer woman academic in her field, Osofisan is a recipient of several fellowships including "Nigeria Institute of Management" (1997), "Computer Association of Nigeria" (1998) and "Nigeria Computer Society" (life member, 2014).&lt;ref&gt;{{Cite web |url=http://www.ncs.org.ng/recognition-awards/ |title=Honourary Fellowship and Recognition Awards |website=Nigeria Computer Society  |access-date=2018-03-03}}&lt;/ref&gt; She is also the pioneer president of "Nigeria Women in Information Technology" (2003). From 2005 to 2009, she became the first female president and chairman of governing council of "Computer Professionals Registration Council of Nigeria".&lt;ref&gt;{{Cite web |url=https://zodml.org/blog/nigerian-women-science#.Wp1MCGrwbIU |title=Nigerian Women In Science |last=Egenuka |first=Nkem |access-date=2018-03-05 |archive-date=2018-03-06 |archive-url=https://web.archive.org/web/20180306022934/https://zodml.org/blog/nigerian-women-science#.Wp1MCGrwbIU |url-status=dead }}&lt;/ref&gt;
She was inducted into the Nigeria Women Hall of Fame on June 10, 2019 in Abuja.

=== Publications and commentaries ===
A 2009 study, which focused on the current digital divide as regards information technology in Nigeria is indexed top on [[Google scholar]], her research revisited the challenges facing the adoption of digital technologies in Nigeria, in relation to what is being done in developed countries. She also recommended steps and policies that will hasten embracing and implementation of digital standards in the Nigerian ecosystem. The research is published in "International Journal of Global Business".&lt;ref&gt;{{Cite document |title=Bridging the digital divide: The Nigerian journey so far }}&lt;/ref&gt;

Following the economic recession due to over-dependence on petroleum exports and dwindling dollar prices, Osofisan urged the Nigerian government to utilize the ICT sector as it has so much to contribute to Nigerian economy if proper investment are put into it, she noted that despite the challenges being faced, 12 million jobs were created by the sector between 2012 and 2016. The remark was given at the 9th Annual Forum of Laureates of the Nigerian National Order of Merit in Abuja.&lt;ref&gt;{{Cite web |url=http://punchng.com/recession-expert-calls-economic-diversification-ict/ |title=Recession: Expert calls for economic diversification through ICT |date=November 30, 2016 |website=[[The Punch]] |access-date=2018-03-03}}&lt;/ref&gt;

== References ==
{{reflist}}

{{authority control}}

{{DEFAULTSORT:Osofisan, Adenike}}
[[Category:1950 births]]
[[Category:Living people]]
[[Category:Obafemi Awolowo University alumni]]
[[Category:University of Ibadan faculty]]
[[Category:Georgia Tech alumni]]
[[Category:Nigerian women academics]]
[[Category:Yoruba women academics]]
[[Category:Yoruba people]]
[[Category:Yoruba women educators]]
[[Category:Nigerian women educators]]
[[Category:Computer science]]
[[Category:Citizens of Nigeria through descent]]
[[Category:University of Ibadan alumni]]
[[Category:Obafemi Awolowo University]]</text>
      <sha1>bz6bc0vitna7s1h1xvukvm83u5vonix</sha1>
    </revision>
  </page>
  <page>
    <title>Ajayendra Urmila Tripathi</title>
    <ns>0</ns>
    <id>67252854</id>
    <revision>
      <id>1015062556</id>
      <parentid>1015053944</parentid>
      <timestamp>2021-03-30T12:59:19Z</timestamp>
      <contributor>
        <username>Gocorona</username>
        <id>41037825</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4916" xml:space="preserve">{{Notability|date=March 2021}}
{{Infobox person
| name        = Ajayendra Urmila Tripathi
| image       = [[File:Ajayendra tripathi.jpg]]
| caption     = 
| birth_date  = {{Birth date and age|df=yes|1989|10|15}}
| birth_place = [[Balliya]] , [[Uttar Pradesh]] , [[India]]&lt;ref&gt;{{Cite web|title=PM मोदी ऐसे दर्जनों नफरती चिंटुओं के फॉलोवर जो करते हैं अभद्र ट्वीट, एक ने ठहराया था गौरी लंकेश की हत्या को जायज|url=https://www.newswaala.in/politics/pm-modis-followers-of-dozens-of-hateful-ants-who-indulge-in-indecent-tweet-one-justified-the-killing-of-gauri-lankesh/|access-date=24 September 2020|website=newswaala.in|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=36 गंदे लोगों को फॉलो करते हैं प्रधानमंत्री नरेंद्र मोदी|url=https://livecities.in/trending/pm-modi-follows-atleast-36-person-who-use-abusing-words-on-social-media/|access-date=24 September 2017|website=newswaala.in|language=en}}&lt;/ref&gt;
| education   = Uma Nath Singh Institute of Engineering &amp; Technology
| occupation  = [[Programmer]] , [[Social media analytics]] , [[Journalist]] and [[Social activity]]
| website     = }}

''Ajayendra Urmila Tripathi''&lt;ref&gt;{{Cite web|title=Twitter handles impersonating Arab personalities criticise India over Islamophobia|url=https://www.altnews.in/pakistani-twitter-handles-impersonating-as-arab-personalities-criticize-india-over-islamophobia/|access-date=28 April 2020|website=altnews.in|language=en}}&lt;/ref&gt;
&lt;ref&gt;{{Cite web|title=टि्वटर पर जिस बात के लिए मोदी और बीजेपी की आलोचना होती है, कांग्रेस भी उस मामले में पीछे नहीं है|url=https://www.thelallantop.com/jhamajham/not-just-pm-modi-and-bjp-but-congress-also-follows-abusive-twitter-accounts/|access-date=17 May 2020|website=thelallantop.com|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=सोनू सूद से मदद मांगने वालों ने अपने ट्वीट क्यों डिलीट किए थे, पता चल गया|url=https://www.thelallantop.com/bherant/sonu-sood-why-migrant-workers-asking-for-help-from-bollywood-actor-deleted-their-tweet/|access-date=9 June 2020|website=thelallantop.com|language=en}}&lt;/ref&gt; (born 15 October 1989) is an [[Indian people|Indian]], web [[programmer]], [[social media analytics]], and [[activist]].&lt;ref&gt;{{Cite web|title=15 घंटे से ज्यादा लेट होने वाली ट्रेनों में 800 फीसदी की वृद्धि|url=https://www.aajtak.in/india-today-hindi/special-report/story/800-percent-increase-in-late-by-indian-trains-in-last-one-year-443696-2017-04-17|access-date=17 April 2017|website=aajtak.in|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=अभद्र ट्वीट करने वाले 36 लोगों को फॉलो करते हैं पीएम मोदी|url=https://www.bhaskar.com/news/UT-DEL-HMU-NEW-pm-modi-follows-36-people-on-twitter-who-tweets-abusive-5703229-PHO.html|access-date=12 April 2017|website=bhaskar.com|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=PM मोदी ऐसे दर्जनों नफरती चिंटुओं के फॉलोवर जो करते हैं अभद्र ट्वीट, एक ने ठहराया था गौरी लंकेश की हत्या को जायज|url=https://janjwar.com/rajniti/narendra-modi-follows-36-people-who-make-abusive-remarks-626615|access-date=24 September 2020|website=janjwar.com|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=समर्थ प्रस्तुत करता है अपना नया नाटक In collaboration with chhanv foundation, "Stop Acid Attacks" |url=http://lokkalamanch.org/event_detail2.php?productid=331&amp;subcategoryid=287&amp;categoryid=265&amp;eventType=past|access-date=16 October 2016|website=lokklamanch.org|language=en}}&lt;/ref&gt;

== References ==
{{Reflist}}

==External links==
*[https://muckrack.com/ajayendra-tripathi]
* {{Twitter|ajayendra_}}
* {{Facebook|AjayendraTripathi}}


[[Category:Living people]]
[[Category:1989 births]]
[[Category:Journalists from Uttar Pradesh]]
[[Category:Activism| ]]
[[Category:Community organizing]]
[[Category:Activism by issue]]
[[Category:Computer occupations]]
[[Category:Computer science]]
[[Category:Software industry]]
[[Category:Information technology]]
[[Category:Film critics| ]]
[[Category:Lists of people by filmmaking occupation|Critics]]
[[Category:Lists of writers|Critics]]
[[Category:Social media]]
[[Category:Types of analytics]]

{{India-journalist-stub}}</text>
      <sha1>2tgtbey4j6xie4j01g8utyxlls8kful</sha1>
    </revision>
  </page>
</mediawiki>
